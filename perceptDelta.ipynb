{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 1.4]\n",
      " [4.9 1.4]\n",
      " [4.7 1.3]\n",
      " [4.6 1.5]\n",
      " [5.  1.4]\n",
      " [5.4 1.7]\n",
      " [4.6 1.4]\n",
      " [5.  1.5]\n",
      " [4.4 1.4]\n",
      " [4.9 1.5]\n",
      " [5.4 1.5]\n",
      " [4.8 1.6]\n",
      " [4.8 1.4]\n",
      " [4.3 1.1]\n",
      " [5.8 1.2]\n",
      " [5.7 1.5]\n",
      " [5.4 1.3]\n",
      " [5.1 1.4]\n",
      " [5.7 1.7]\n",
      " [5.1 1.5]\n",
      " [5.4 1.7]\n",
      " [5.1 1.5]\n",
      " [4.6 1. ]\n",
      " [5.1 1.7]\n",
      " [4.8 1.9]\n",
      " [5.  1.6]\n",
      " [5.  1.6]\n",
      " [5.2 1.5]\n",
      " [5.2 1.4]\n",
      " [4.7 1.6]\n",
      " [4.8 1.6]\n",
      " [5.4 1.5]\n",
      " [5.2 1.5]\n",
      " [5.5 1.4]\n",
      " [4.9 1.5]\n",
      " [5.  1.2]\n",
      " [5.5 1.3]\n",
      " [4.9 1.5]\n",
      " [4.4 1.3]\n",
      " [5.1 1.5]\n",
      " [5.  1.3]\n",
      " [4.5 1.3]\n",
      " [4.4 1.3]\n",
      " [5.  1.6]\n",
      " [5.1 1.9]\n",
      " [4.8 1.4]\n",
      " [5.1 1.6]\n",
      " [4.6 1.4]\n",
      " [5.3 1.5]\n",
      " [5.  1.4]\n",
      " [7.  4.7]\n",
      " [6.4 4.5]\n",
      " [6.9 4.9]\n",
      " [5.5 4. ]\n",
      " [6.5 4.6]\n",
      " [5.7 4.5]\n",
      " [6.3 4.7]\n",
      " [4.9 3.3]\n",
      " [6.6 4.6]\n",
      " [5.2 3.9]\n",
      " [5.  3.5]\n",
      " [5.9 4.2]\n",
      " [6.  4. ]\n",
      " [6.1 4.7]\n",
      " [5.6 3.6]\n",
      " [6.7 4.4]\n",
      " [5.6 4.5]\n",
      " [5.8 4.1]\n",
      " [6.2 4.5]\n",
      " [5.6 3.9]\n",
      " [5.9 4.8]\n",
      " [6.1 4. ]\n",
      " [6.3 4.9]\n",
      " [6.1 4.7]\n",
      " [6.4 4.3]\n",
      " [6.6 4.4]\n",
      " [6.8 4.8]\n",
      " [6.7 5. ]\n",
      " [6.  4.5]\n",
      " [5.7 3.5]\n",
      " [5.5 3.8]\n",
      " [5.5 3.7]\n",
      " [5.8 3.9]\n",
      " [6.  5.1]\n",
      " [5.4 4.5]\n",
      " [6.  4.5]\n",
      " [6.7 4.7]\n",
      " [6.3 4.4]\n",
      " [5.6 4.1]\n",
      " [5.5 4. ]\n",
      " [5.5 4.4]\n",
      " [6.1 4.6]\n",
      " [5.8 4. ]\n",
      " [5.  3.3]\n",
      " [5.6 4.2]\n",
      " [5.7 4.2]\n",
      " [5.7 4.2]\n",
      " [6.2 4.3]\n",
      " [5.1 3. ]\n",
      " [5.7 4.1]] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)\n",
    "\n",
    "# setosa and versicolor\n",
    "y = df.iloc[0:100, 4].values\n",
    "y = np.where(y == 'Iris-setosa', -1, 1)\n",
    "\n",
    "# sepal length and petal length\n",
    "X = df.iloc[0:100, [0,2]].values\n",
    "print(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "fil = open(\"irisData.txt\",'w+')\n",
    "df.to_csv(fil)\n",
    "fil.close()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# each pattern has values for inputs and corresponding desired output\n",
    "patterns = np.array([(0,0,1),(0,1,1),(1,0,-1),(1,1,1)]) \n",
    "m = patterns.shape[0] # number of patterns\n",
    "ni = patterns.shape[1] -1 # ni is number of inputs assuming one output node\n",
    "X=patterns[:,:ni].T # input matrix with each column representing an input vector\n",
    "desiredOutputs =patterns[:,ni] # one desired output for each input vector\n",
    "currentWeights = np.zeros(ni)  # weight vector initialized to zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic(sp) :\n",
    "    return 1.0/(1 + np.exp(-sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.999909204262595 0.0 0.7615941559557649 0.999909204262595\n"
     ]
    }
   ],
   "source": [
    "def bipolarLogistic(sp) :\n",
    "    return ((np.exp(sp)-np.exp(-sp)))/((np.exp(sp) + np.exp(-sp)))\n",
    "print(bipolarLogistic(-5),bipolarLogistic(0),bipolarLogistic(+1),bipolarLogistic(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.31409724 -0.74649234  0.53572362  0.16147102 -0.99014659]\n"
     ]
    }
   ],
   "source": [
    "def randomize(num) : \n",
    "    \"\"\"  Generates num random numbers \n",
    "        returns a numpy array of random numbers\n",
    "    \"\"\"\n",
    "    import random\n",
    "    randomList = []\n",
    "    for i in range(num) :\n",
    "        randomList.append(random.uniform(-1,1))\n",
    "    return np.array(randomList)\n",
    "print(randomize(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tabulate (vec,bias) :\n",
    "    print(\"weights \",vec,\" bias \",bias)\n",
    "    computedOutputs = feedForward(vec,bias)\n",
    "    for i in range(4) :\n",
    "        desired = desiredOutputs[i]\n",
    "        computed = computedOutputs[i]\n",
    "        print(\"pattern\"+str(i+1),patterns[i][0],patterns[i][1],desired,round(computed,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights  [-0.03653367 -0.53894928]  bias  [0.70706162]\n",
      "pattern1 0 0 1 0.608831\n",
      "pattern2 0 1 1 0.166546\n",
      "pattern3 1 0 -1 0.585327\n",
      "pattern4 1 1 1 0.130825\n",
      "[-0.03653367 -0.53894928] [0.70706162] [0.60883094 0.16654632 0.58532706 0.13082455]\n"
     ]
    }
   ],
   "source": [
    "def feedForward (weights,bias):\n",
    "    net = np.dot(weights.T,X)+bias\n",
    "    #print(\"weights \",weights,bias,\"nets \",net)\n",
    "    outputs = bipolarLogistic(net)\n",
    "    return outputs\n",
    "wts=randomize(2)\n",
    "bia=randomize(1)\n",
    "tabulate(wts,bia)\n",
    "outs = feedForward(wts,bia)\n",
    "print(wts,bia,outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights  [-0.60415347  0.80169116]  bias  -0.6092016110400231\n",
      "pattern1 0 0 1 -0.543565\n",
      "pattern2 0 1 1 0.190147\n",
      "pattern3 1 0 -1 -0.837683\n",
      "pattern4 1 1 1 -0.389885\n",
      "weights  [-0.48629264  0.91955198]  bias  -0.49134078662537833\n",
      "pattern1 0 0 1 -0.45528\n",
      "pattern2 0 1 1 0.403825\n",
      "pattern3 1 0 -1 -0.75204\n",
      "pattern4 1 1 1 -0.058016\n",
      "weights  [-0.49706494  0.91955198]  bias  -0.502113089276973\n",
      "pattern1 0 0 1 -0.463777\n",
      "pattern2 0 1 1 0.394771\n",
      "pattern3 1 0 -1 -0.761249\n",
      "pattern4 1 1 1 -0.079458\n"
     ]
    }
   ],
   "source": [
    "learningRate=0.1\n",
    "def trainDelta(weights,bias,pn) :\n",
    "    currentInputs=X[:,pn]\n",
    "    net = np.dot(weights.T,currentInputs) + bias\n",
    "    output = bipolarLogistic(net)\n",
    "    desired = desiredOutputs[pn]\n",
    "    difference = desired - output\n",
    "    #print(output,desired,difference)\n",
    "    gradient = 1-output * output\n",
    "    correction = learningRate * gradient * difference \n",
    "    deltaW = currentInputs * correction\n",
    "    newWeights = weights + deltaW\n",
    "    newBias = np.copy(bias + correction)\n",
    "    #print(weights,bias,\" changed to \",newWeights,newBias)\n",
    "    return newWeights,newBias,difference\n",
    "    \n",
    "wts=randomize(2)\n",
    "bia = randomize(1)[0]\n",
    "tabulate(wts,bia)\n",
    "nwts,nb,diff=trainDelta(wts,bia,3)\n",
    "tabulate(nwts,nb)\n",
    "nwts,nb,dif=trainDelta(nwts,nb,2)\n",
    "tabulate(nwts,nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights  [0.19557118 0.40041917]  bias  0.18435533664558257\n",
      "pattern1 0 0 1 0.182295\n",
      "pattern2 0 1 1 0.526127\n",
      "pattern3 1 0 -1 0.362644\n",
      "pattern4 1 1 1 0.652905\n",
      " Training with pattern  1  weights  [0.19557118 0.40041917] 0.18435533664558257   weights  [0.19557118 0.40041917]  bias  0.26340850954781936\n",
      "pattern1 0 0 1 0.257481\n",
      "pattern2 0 1 1 0.580905\n",
      "pattern3 1 0 -1 0.429252\n",
      "pattern4 1 1 1 0.695948\n",
      " modified Weights  [0.19557118 0.40041917] 0.26340850954781936\n",
      " Training with pattern  2  weights  [0.19557118 0.40041917] 0.18435533664558257   weights  [0.19557118 0.42818627]  bias  0.2911756140051111\n",
      "pattern1 0 0 1 0.283216\n",
      "pattern2 0 1 1 0.616514\n",
      "pattern3 1 0 -1 0.451631\n",
      "pattern4 1 1 1 0.723492\n",
      " modified Weights  [0.19557118 0.42818627] 0.2911756140051111\n",
      " Training with pattern  3  weights  [0.19557118 0.40041917] 0.18435533664558257   weights  [0.08001705 0.42818627]  bias  0.1756214916569712\n",
      "pattern1 0 0 1 0.173838\n",
      "pattern2 0 1 1 0.539754\n",
      "pattern3 1 0 -1 0.250212\n",
      "pattern4 1 1 1 0.594\n",
      " modified Weights  [0.08001705 0.42818627] 0.1756214916569712\n",
      " Training with pattern  4  weights  [0.19557118 0.40041917] 0.18435533664558257   weights  [0.10629188 0.4544611 ]  bias  0.20189631587874515\n",
      "pattern1 0 0 1 0.199197\n",
      "pattern2 0 1 1 0.575934\n",
      "pattern3 1 0 -1 0.298788\n",
      "pattern4 1 1 1 0.642635\n",
      " modified Weights  [0.10629188 0.4544611 ] 0.20189631587874515\n",
      "[0.10629188 0.4544611 ] 0.20189631587874515 2.6356771250434607\n"
     ]
    }
   ],
   "source": [
    "def trainEpoch (weights, bias) :\n",
    "    wts = np.copy(weights)\n",
    "    bia =np.copy(bias)\n",
    "    for j in range(m) :\n",
    "        print(\" Training with pattern \",j+1,\" weights \",weights,bias, end =\"   \")\n",
    "        newWeights,newBias,diff = trainDelta(wts,bia,j)\n",
    "        tabulate(newWeights,newBias)\n",
    "        wts = np.copy(newWeights)\n",
    "        bia = np.copy(newBias)\n",
    "        print(\" modified Weights \",newWeights,newBias,)\n",
    "    error = np.sum((desiredOutputs - feedForward(wts,bia))**2 )  \n",
    "    return wts,bia,error\n",
    "\n",
    "wts=randomize(2)\n",
    "bia = randomize(1)[0]\n",
    "tabulate(wts,bia)\n",
    "nwts,nb, cost= trainEpoch(wts,bia)\n",
    "print(nwts,nb,cost)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights  [0.18797151 0.99800185]  bias  0.6854966625092835\n",
      "pattern1 0 0 1 0.595081\n",
      "pattern2 0 1 1 0.933314\n",
      "pattern3 1 0 -1 0.703132\n",
      "pattern4 1 1 1 0.953727\n",
      " Training with pattern  1  weights  [0.18797151 0.99800185] 0.6854966625092835   weights  [0.18797151 0.99800185]  bias  0.7116494934082261\n",
      "pattern1 0 0 1 0.61171\n",
      "pattern2 0 1 1 0.936605\n",
      "pattern3 1 0 -1 0.716113\n",
      "pattern4 1 1 1 0.956033\n",
      " modified Weights  [0.18797151 0.99800185] 0.7116494934082261\n",
      " Training with pattern  2  weights  [0.18797151 0.99800185] 0.6854966625092835   weights  [0.18797151 0.99878016]  bias  0.7124278066257534\n",
      "pattern1 0 0 1 0.612197\n",
      "pattern2 0 1 1 0.936796\n",
      "pattern3 1 0 -1 0.716492\n",
      "pattern4 1 1 1 0.956167\n",
      " modified Weights  [0.18797151 0.99878016] 0.7124278066257534\n",
      " Training with pattern  3  weights  [0.18797151 0.99800185] 0.6854966625092835   weights  [0.10444033 0.99878016]  bias  0.6288966238994868\n",
      "pattern1 0 0 1 0.557292\n",
      "pattern2 0 1 1 0.92573\n",
      "pattern3 1 0 -1 0.625103\n",
      "pattern4 1 1 1 0.939306\n",
      " modified Weights  [0.10444033 0.99878016] 0.6288966238994868\n",
      " Training with pattern  4  weights  [0.18797151 0.99800185] 0.6854966625092835   weights  [0.10515473 0.99949456]  bias  0.6296110267137537\n",
      "pattern1 0 0 1 0.557784\n",
      "pattern2 0 1 1 0.925934\n",
      "pattern3 1 0 -1 0.625972\n",
      "pattern4 1 1 1 0.939557\n",
      " modified Weights  [0.10515473 0.99949456] 0.6296110267137537\n",
      "+++++++++++Epoch  1  cost=  2.8484798115861825\n",
      " *********Epoch  0 Error  2.8484798115861825\n",
      " Training with pattern  1  weights  [0.10515473 0.99949456] 0.6296110267137537   weights  [0.10515473 0.99949456]  bias  0.6600742325484275\n",
      "pattern1 0 0 1 0.578413\n",
      "pattern2 0 1 1 0.930159\n",
      "pattern3 1 0 -1 0.644147\n",
      "pattern4 1 1 1 0.943028\n",
      " modified Weights  [0.10515473 0.99949456] 0.6600742325484275\n",
      " Training with pattern  2  weights  [0.10515473 0.99949456] 0.6296110267137537   weights  [0.10515473 1.00043605]  bias  0.6610157167335592\n",
      "pattern1 0 0 1 0.579039\n",
      "pattern2 0 1 1 0.930412\n",
      "pattern3 1 0 -1 0.644697\n",
      "pattern4 1 1 1 0.943236\n",
      " modified Weights  [0.10515473 1.00043605] 0.6610157167335592\n",
      " Training with pattern  3  weights  [0.10515473 0.99949456] 0.6296110267137537   weights  [0.00904428 1.00043605]  bias  0.5649052698934512\n",
      "pattern1 0 0 1 0.511608\n",
      "pattern2 0 1 1 0.916282\n",
      "pattern3 1 0 -1 0.518254\n",
      "pattern4 1 1 1 0.917721\n",
      " modified Weights  [0.00904428 1.00043605] 0.5649052698934512\n",
      " Training with pattern  4  weights  [0.10515473 0.99949456] 0.6296110267137537   weights  [0.01034256 1.00173433]  bias  0.5662035489568409\n",
      "pattern1 0 0 1 0.512566\n",
      "pattern2 0 1 1 0.916697\n",
      "pattern3 1 0 -1 0.520151\n",
      "pattern4 1 1 1 0.918333\n",
      " modified Weights  [0.01034256 1.00173433] 0.5662035489568409\n",
      "+++++++++++Epoch  2  cost=  2.562058749568834\n",
      " Training with pattern  1  weights  [0.01034256 1.00173433] 0.5662035489568409   weights  [0.01034256 1.00173433]  bias  0.6021409304784937\n",
      "pattern1 0 0 1 0.538571\n",
      "pattern2 0 1 1 0.92225\n",
      "pattern3 1 0 -1 0.545873\n",
      "pattern4 1 1 1 0.923781\n",
      " modified Weights  [0.01034256 1.00173433] 0.6021409304784937\n",
      " Training with pattern  2  weights  [0.01034256 1.00173433] 0.5662035489568409   weights  [0.01034256 1.00289634]  bias  0.603302948281483\n",
      "pattern1 0 0 1 0.539396\n",
      "pattern2 0 1 1 0.922596\n",
      "pattern3 1 0 -1 0.546688\n",
      "pattern4 1 1 1 0.924121\n",
      " modified Weights  [0.01034256 1.00289634] 0.603302948281483\n",
      " Training with pattern  3  weights  [0.01034256 1.00173433] 0.5662035489568409   weights  [-0.0981007   1.00289634]  bias  0.4948596848998023\n",
      "pattern1 0 0 1 0.458065\n",
      "pattern2 0 1 1 0.904742\n",
      "pattern3 1 0 -1 0.377172\n",
      "pattern4 1 1 1 0.885277\n",
      " modified Weights  [-0.0981007   1.00289634] 0.4948596848998023\n",
      " Training with pattern  4  weights  [0.01034256 1.00173433] 0.5662035489568409   weights  [-0.09561942  1.00537762]  bias  0.4973409619072364\n",
      "pattern1 0 0 1 0.460023\n",
      "pattern2 0 1 1 0.905638\n",
      "pattern3 1 0 -1 0.381421\n",
      "pattern4 1 1 1 0.886877\n",
      " modified Weights  [-0.09561942  1.00537762] 0.4973409619072364\n",
      "+++++++++++Epoch  3  cost=  2.2215997919473667\n",
      " Training with pattern  1  weights  [-0.09561942  1.00537762] 0.4973409619072364   weights  [-0.09561942  1.00537762]  bias  0.5399115552120791\n",
      "pattern1 0 0 1 0.492921\n",
      "pattern2 0 1 1 0.913005\n",
      "pattern3 1 0 -1 0.417196\n",
      "pattern4 1 1 1 0.895628\n",
      " modified Weights  [-0.09561942  1.00537762] 0.5399115552120791\n",
      " Training with pattern  2  weights  [-0.09561942  1.00537762] 0.4973409619072364   weights  [-0.09561942  1.00682541]  bias  0.5413593465558624\n",
      "pattern1 0 0 1 0.494016\n",
      "pattern2 0 1 1 0.913485\n",
      "pattern3 1 0 -1 0.418391\n",
      "pattern4 1 1 1 0.896199\n",
      " modified Weights  [-0.09561942  1.00682541] 0.5413593465558624\n",
      " Training with pattern  3  weights  [-0.09561942  1.00537762] 0.4973409619072364   weights  [-0.21262945  1.00682541]  bias  0.42434932448269375\n",
      "pattern1 0 0 1 0.400588\n",
      "pattern2 0 1 1 0.891907\n",
      "pattern3 1 0 -1 0.208612\n",
      "pattern4 1 1 1 0.839225\n",
      " modified Weights  [-0.21262945  1.00682541] 0.42434932448269375\n",
      " Training with pattern  4  weights  [-0.09561942  1.00537762] 0.4973409619072364   weights  [-0.20787528  1.01157958]  bias  0.4291034897566858\n",
      "pattern1 0 0 1 0.404572\n",
      "pattern2 0 1 1 0.893835\n",
      "pattern3 1 0 -1 0.217688\n",
      "pattern4 1 1 1 0.843392\n",
      " modified Weights  [-0.20787528  1.01157958] 0.4291034897566858\n",
      "+++++++++++Epoch  4  cost=  1.873096814627672\n",
      " Training with pattern  1  weights  [-0.20787528  1.01157958] 0.4291034897566858   weights  [-0.20787528  1.01157958]  bias  0.4789004384465371\n",
      "pattern1 0 0 1 0.445363\n",
      "pattern2 0 1 1 0.903413\n",
      "pattern3 1 0 -1 0.264578\n",
      "pattern4 1 1 1 0.857177\n",
      " modified Weights  [-0.20787528  1.01157958] 0.4789004384465371\n",
      " Training with pattern  2  weights  [-0.20787528  1.01157958] 0.4291034897566858   weights  [-0.20787528  1.01335528]  bias  0.48067614062245617\n",
      "pattern1 0 0 1 0.446785\n",
      "pattern2 0 1 1 0.904064\n",
      "pattern3 1 0 -1 0.266229\n",
      "pattern4 1 1 1 0.858116\n",
      " modified Weights  [-0.20787528  1.01335528] 0.48067614062245617\n",
      " Training with pattern  3  weights  [-0.20787528  1.01157958] 0.4291034897566858   weights  [-0.32552342  1.01335528]  bias  0.36302800056866347\n",
      "pattern1 0 0 1 0.347878\n",
      "pattern2 0 1 1 0.880139\n",
      "pattern3 1 0 -1 0.037487\n",
      "pattern4 1 1 1 0.78214\n",
      " modified Weights  [-0.32552342  1.01335528] 0.36302800056866347\n",
      " Training with pattern  4  weights  [-0.20787528  1.01157958] 0.4291034897566858   weights  [-0.31706489  1.02181382]  bias  0.37148653679978483\n",
      "pattern1 0 0 1 0.355291\n",
      "pattern2 0 1 1 0.883895\n",
      "pattern3 1 0 -1 0.054368\n",
      "pattern4 1 1 1 0.791799\n",
      " modified Weights  [-0.31706489  1.02181382] 0.37148653679978483\n",
      "+++++++++++Epoch  5  cost=  1.5841692747517553\n",
      " Training with pattern  1  weights  [-0.31706489  1.02181382] 0.37148653679978483   weights  [-0.31706489  1.02181382]  bias  0.427819127698959\n",
      "pattern1 0 0 1 0.403497\n",
      "pattern2 0 1 1 0.89562\n",
      "pattern3 1 0 -1 0.110304\n",
      "pattern4 1 1 1 0.811896\n",
      " modified Weights  [-0.31706489  1.02181382] 0.427819127698959\n",
      " Training with pattern  2  weights  [-0.31706489  1.02181382] 0.37148653679978483   weights  [-0.31706489  1.02387912]  bias  0.42988443023378375\n",
      "pattern1 0 0 1 0.405225\n",
      "pattern2 0 1 1 0.896435\n",
      "pattern3 1 0 -1 0.112343\n",
      "pattern4 1 1 1 0.813299\n",
      " modified Weights  [-0.31706489  1.02387912] 0.42988443023378375\n",
      " Training with pattern  3  weights  [-0.31706489  1.02181382] 0.37148653679978483   weights  [-0.42689533  1.02387912]  bias  0.320053990284008\n",
      "pattern1 0 0 1 0.309556\n",
      "pattern2 0 1 1 0.872614\n",
      "pattern3 1 0 -1 -0.106437\n",
      "pattern4 1 1 1 0.724493\n",
      " modified Weights  [-0.42689533  1.02387912] 0.320053990284008\n",
      " Training with pattern  4  weights  [-0.31706489  1.02181382] 0.37148653679978483   weights  [-0.41380572  1.03696872]  bias  0.3331435955890533\n",
      "pattern1 0 0 1 0.321343\n",
      "pattern2 0 1 1 0.878718\n",
      "pattern3 1 0 -1 -0.080488\n",
      "pattern4 1 1 1 0.742625\n",
      " modified Weights  [-0.41380572  1.03696872] 0.3331435955890533\n",
      "+++++++++++Epoch  6  cost=  1.3870301693500717\n",
      " Training with pattern  1  weights  [-0.41380572  1.03696872] 0.3331435955890533   weights  [-0.41380572  1.03696872]  bias  0.39400144653490665\n",
      "pattern1 0 0 1 0.374805\n",
      "pattern2 0 1 1 0.891865\n",
      "pattern3 1 0 -1 -0.019802\n",
      "pattern4 1 1 1 0.768709\n",
      " modified Weights  [-0.41380572  1.03696872] 0.39400144653490665\n",
      " Training with pattern  2  weights  [-0.41380572  1.03696872] 0.3331435955890533   weights  [-0.41380572  1.03918091]  bias  0.3962136282609431\n",
      "pattern1 0 0 1 0.376705\n",
      "pattern2 0 1 1 0.892767\n",
      "pattern3 1 0 -1 -0.01759\n",
      "pattern4 1 1 1 0.770513\n",
      " modified Weights  [-0.41380572  1.03918091] 0.3962136282609431\n",
      " Training with pattern  3  weights  [-0.41380572  1.03696872] 0.3331435955890533   weights  [-0.51201629  1.03918091]  bias  0.29800305347465295\n",
      "pattern1 0 0 1 0.289484\n",
      "pattern2 0 1 1 0.870994\n",
      "pattern3 1 0 -1 -0.210805\n",
      "pattern4 1 1 1 0.677873\n",
      " modified Weights  [-0.51201629  1.03918091] 0.29800305347465295\n",
      " Training with pattern  4  weights  [-0.41380572  1.03696872] 0.3331435955890533   weights  [-0.49460568  1.05659152]  bias  0.3154136637479087\n",
      "pattern1 0 0 1 0.305354\n",
      "pattern2 0 1 1 0.879148\n",
      "pattern3 1 0 -1 -0.177298\n",
      "pattern4 1 1 1 0.705114\n",
      " modified Weights  [-0.49460568  1.05659152] 0.3154136637479087\n",
      "+++++++++++Epoch  7  cost=  1.2609336812838194\n",
      " Training with pattern  1  weights  [-0.49460568  1.05659152] 0.3154136637479087   weights  [-0.49460568  1.05659152]  bias  0.37840130178643006\n",
      "pattern1 0 0 1 0.361318\n",
      "pattern2 0 1 1 0.892685\n",
      "pattern3 1 0 -1 -0.115684\n",
      "pattern4 1 1 1 0.7354\n",
      " modified Weights  [-0.49460568  1.05659152] 0.37840130178643006\n",
      " Training with pattern  2  weights  [-0.49460568  1.05659152] 0.3154136637479087   weights  [-0.49460568  1.05877122]  bias  0.3805810048455391\n",
      "pattern1 0 0 1 0.363212\n",
      "pattern2 0 1 1 0.893567\n",
      "pattern3 1 0 -1 -0.113533\n",
      "pattern4 1 1 1 0.737395\n",
      " modified Weights  [-0.49460568  1.05877122] 0.3805810048455391\n",
      " Training with pattern  3  weights  [-0.49460568  1.05659152] 0.3154136637479087   weights  [-0.58210974  1.05877122]  bias  0.29307694594243366\n",
      "pattern1 0 0 1 0.284964\n",
      "pattern2 0 1 1 0.874489\n",
      "pattern3 1 0 -1 -0.281244\n",
      "pattern4 1 1 1 0.646777\n",
      " modified Weights  [-0.58210974  1.05877122] 0.29307694594243366\n",
      " Training with pattern  4  weights  [-0.49460568  1.05659152] 0.3154136637479087   weights  [-0.56156352  1.07931744]  bias  0.31362317074553336\n",
      "pattern1 0 0 1 0.30373\n",
      "pattern2 0 1 1 0.883816\n",
      "pattern3 1 0 -1 -0.242982\n",
      "pattern4 1 1 1 0.681215\n",
      " modified Weights  [-0.56156352  1.07931744] 0.31362317074553336\n",
      "+++++++++++Epoch  8  cost=  1.172992023358264\n",
      " Training with pattern  1  weights  [-0.56156352  1.07931744] 0.31362317074553336   weights  [-0.56156352  1.07931744]  bias  0.3768269956190047\n",
      "pattern1 0 0 1 0.359949\n",
      "pattern2 0 1 1 0.896901\n",
      "pattern3 1 0 -1 -0.182663\n",
      "pattern4 1 1 1 0.713649\n",
      " modified Weights  [-0.56156352  1.07931744] 0.3768269956190047\n",
      " Training with pattern  2  weights  [-0.56156352  1.07931744] 0.31362317074553336   weights  [-0.56156352  1.08133373]  bias  0.37884328162535136\n",
      "pattern1 0 0 1 0.361703\n",
      "pattern2 0 1 1 0.897687\n",
      "pattern3 1 0 -1 -0.180714\n",
      "pattern4 1 1 1 0.715622\n",
      " modified Weights  [-0.56156352  1.08133373] 0.37884328162535136\n",
      " Training with pattern  3  weights  [-0.56156352  1.07931744] 0.31362317074553336   weights  [-0.64081659  1.08133373]  bias  0.29959021296900634\n",
      "pattern1 0 0 1 0.290938\n",
      "pattern2 0 1 1 0.881158\n",
      "pattern3 1 0 -1 -0.328572\n",
      "pattern4 1 1 1 0.62921\n",
      " modified Weights  [-0.64081659  1.08133373] 0.29959021296900634\n",
      " Training with pattern  4  weights  [-0.56156352  1.07931744] 0.31362317074553336   weights  [-0.61841736  1.10373296]  bias  0.3219894411122585\n",
      "pattern1 0 0 1 0.311305\n",
      "pattern2 0 1 1 0.890787\n",
      "pattern3 1 0 -1 -0.28804\n",
      "pattern4 1 1 1 0.668101\n",
      " modified Weights  [-0.61841736  1.10373296] 0.3219894411122585\n",
      "+++++++++++Epoch  9  cost=  1.1032724659515487\n",
      " Training with pattern  1  weights  [-0.61841736  1.10373296] 0.3219894411122585   weights  [-0.61841736  1.10373296]  bias  0.38418478579491183\n",
      "pattern1 0 0 1 0.366336\n",
      "pattern2 0 1 1 0.902941\n",
      "pattern3 1 0 -1 -0.230041\n",
      "pattern4 1 1 1 0.70112\n",
      " modified Weights  [-0.61841736  1.10373296] 0.38418478579491183\n",
      " Training with pattern  2  weights  [-0.61841736  1.10373296] 0.3219894411122585   weights  [-0.61841736  1.10552562]  bias  0.3859774461827824\n",
      "pattern1 0 0 1 0.367887\n",
      "pattern2 0 1 1 0.903601\n",
      "pattern3 1 0 -1 -0.228342\n",
      "pattern4 1 1 1 0.702939\n",
      " modified Weights  [-0.61841736  1.10552562] 0.3859774461827824\n",
      " Training with pattern  3  weights  [-0.61841736  1.10373296] 0.3219894411122585   weights  [-0.69155969  1.10552562]  bias  0.3128351195008124\n",
      "pattern1 0 0 1 0.303014\n",
      "pattern2 0 1 1 0.889256\n",
      "pattern3 1 0 -1 -0.361599\n",
      "pattern4 1 1 1 0.621104\n",
      " modified Weights  [-0.69155969  1.10552562] 0.3128351195008124\n",
      " Training with pattern  4  weights  [-0.61841736  1.10373296] 0.3219894411122585   weights  [-0.6682868  1.1287985]  bias  0.3361080021133802\n",
      "pattern1 0 0 1 0.323998\n",
      "pattern2 0 1 1 0.898601\n",
      "pattern3 1 0 -1 -0.320477\n",
      "pattern4 1 1 1 0.662143\n",
      " modified Weights  [-0.6682868  1.1287985] 0.3361080021133802\n",
      "+++++++++++Epoch  10  cost=  1.0431587000597404\n",
      " Training with pattern  1  weights  [-0.6682868  1.1287985] 0.3361080021133802   weights  [-0.6682868  1.1287985]  bias  0.3966118426314837\n",
      "pattern1 0 0 1 0.377046\n",
      "pattern2 0 1 1 0.909636\n",
      "pattern3 1 0 -1 -0.265183\n",
      "pattern4 1 1 1 0.694773\n",
      " modified Weights  [-0.6682868  1.1287985] 0.3966118426314837\n",
      " Training with pattern  2  weights  [-0.6682868  1.1287985] 0.3361080021133802   weights  [-0.6682868   1.13035785]  bias  0.3981711887511956\n",
      "pattern1 0 0 1 0.378383\n",
      "pattern2 0 1 1 0.910173\n",
      "pattern3 1 0 -1 -0.263732\n",
      "pattern4 1 1 1 0.696382\n",
      " modified Weights  [-0.6682868   1.13035785] 0.3981711887511956\n",
      " Training with pattern  3  weights  [-0.6682868  1.1287985] 0.3361080021133802   weights  [-0.73679247  1.13035785]  bias  0.32966552328061316\n",
      "pattern1 0 0 1 0.31822\n",
      "pattern2 0 1 1 0.897657\n",
      "pattern3 1 0 -1 -0.38603\n",
      "pattern4 1 1 1 0.618907\n",
      " modified Weights  [-0.73679247  1.13035785] 0.32966552328061316\n",
      " Training with pattern  4  weights  [-0.6682868  1.1287985] 0.3361080021133802   weights  [-0.71328074  1.15386958]  bias  0.35317725559211266\n",
      "pattern1 0 0 1 0.33919\n",
      "pattern2 0 1 1 0.906414\n",
      "pattern3 1 0 -1 -0.345305\n",
      "pattern4 1 1 1 0.660537\n",
      " modified Weights  [-0.71328074  1.15386958] 0.35317725559211266\n",
      "+++++++++++Epoch  11  cost=  0.9892881819429511\n",
      " *********Epoch  10 Error  0.9892881819429511\n",
      " Training with pattern  1  weights  [-0.71328074  1.15386958] 0.35317725559211266   weights  [-0.71328074  1.15386958]  bias  0.41165560865691336\n",
      "pattern1 0 0 1 0.389878\n",
      "pattern2 0 1 1 0.916311\n",
      "pattern3 1 0 -1 -0.292799\n",
      "pattern4 1 1 1 0.69224\n",
      " modified Weights  [-0.71328074  1.15386958] 0.41165560865691336\n",
      " Training with pattern  2  weights  [-0.71328074  1.15386958] 0.35317725559211266   weights  [-0.71328074  1.15521173]  bias  0.4129977622264684\n",
      "pattern1 0 0 1 0.391015\n",
      "pattern2 0 1 1 0.91674\n",
      "pattern3 1 0 -1 -0.291572\n",
      "pattern4 1 1 1 0.693636\n",
      " modified Weights  [-0.71328074  1.15521173] 0.4129977622264684\n",
      " Training with pattern  3  weights  [-0.71328074  1.15386958] 0.35317725559211266   weights  [-0.77810095  1.15521173]  bias  0.3481775487817509\n",
      "pattern1 0 0 1 0.334758\n",
      "pattern2 0 1 1 0.905759\n",
      "pattern3 1 0 -1 -0.405257\n",
      "pattern4 1 1 1 0.620174\n",
      " modified Weights  [-0.77810095  1.15521173] 0.3481775487817509\n",
      " Training with pattern  4  weights  [-0.71328074  1.15386958] 0.35317725559211266   weights  [-0.75472709  1.17858559]  bias  0.3715514046702105\n",
      "pattern1 0 0 1 0.355348\n",
      "pattern2 0 1 1 0.913808\n",
      "pattern3 1 0 -1 -0.365462\n",
      "pattern4 1 1 1 0.661463\n",
      " modified Weights  [-0.75472709  1.17858559] 0.3715514046702105\n",
      "+++++++++++Epoch  12  cost=  0.9402509423501998\n",
      " Training with pattern  1  weights  [-0.75472709  1.17858559] 0.3715514046702105   weights  [-0.75472709  1.17858559]  bias  0.42787644669951747\n",
      "pattern1 0 0 1 0.403545\n",
      "pattern2 0 1 1 0.922635\n",
      "pattern3 1 0 -1 -0.315688\n",
      "pattern4 1 1 1 0.691975\n",
      " modified Weights  [-0.75472709  1.17858559] 0.42787644669951747\n",
      " Training with pattern  2  weights  [-0.75472709  1.17858559] 0.3715514046702105   weights  [-0.75472709  1.17973634]  bias  0.4290271953535249\n",
      "pattern1 0 0 1 0.404508\n",
      "pattern2 0 1 1 0.922977\n",
      "pattern3 1 0 -1 -0.314652\n",
      "pattern4 1 1 1 0.693172\n",
      " modified Weights  [-0.75472709  1.17973634] 0.4290271953535249\n",
      " Training with pattern  3  weights  [-0.75472709  1.17858559] 0.3715514046702105   weights  [-0.81647659  1.17973634]  bias  0.36727769947161754\n",
      "pattern1 0 0 1 0.351608\n",
      "pattern2 0 1 1 0.913291\n",
      "pattern3 1 0 -1 -0.42124\n",
      "pattern4 1 1 1 0.623394\n",
      " modified Weights  [-0.81647659  1.17973634] 0.36727769947161754\n",
      " Training with pattern  4  weights  [-0.75472709  1.17858559] 0.3715514046702105   weights  [-0.79345166  1.20276127]  bias  0.3903026293023648\n",
      "pattern1 0 0 1 0.371621\n",
      "pattern2 0 1 1 0.920618\n",
      "pattern3 1 0 -1 -0.38264\n",
      "pattern4 1 1 1 0.66382\n",
      " modified Weights  [-0.79345166  1.20276127] 0.3903026293023648\n",
      "+++++++++++Epoch  13  cost=  0.8953117889922663\n",
      " Training with pattern  1  weights  [-0.79345166  1.20276127] 0.3903026293023648   weights  [-0.79345166  1.20276127]  bias  0.4444624667797808\n",
      "pattern1 0 0 1 0.417337\n",
      "pattern2 0 1 1 0.928476\n",
      "pattern3 1 0 -1 -0.335479\n",
      "pattern4 1 1 1 0.693035\n",
      " modified Weights  [-0.79345166  1.20276127] 0.4444624667797808\n",
      " Training with pattern  2  weights  [-0.79345166  1.20276127] 0.3903026293023648   weights  [-0.79345166  1.20374782]  bias  0.4454490228598632\n",
      "pattern1 0 0 1 0.418151\n",
      "pattern2 0 1 1 0.928747\n",
      "pattern3 1 0 -1 -0.334603\n",
      "pattern4 1 1 1 0.694059\n",
      " modified Weights  [-0.79345166  1.20374782] 0.4454490228598632\n",
      " Training with pattern  3  weights  [-0.79345166  1.20276127] 0.3903026293023648   weights  [-0.85254163  1.20374782]  bias  0.38635905113904345\n",
      "pattern1 0 0 1 0.368217\n",
      "pattern2 0 1 1 0.920166\n",
      "pattern3 1 0 -1 -0.43511\n",
      "pattern4 1 1 1 0.627672\n",
      " modified Weights  [-0.85254163  1.20374782] 0.38635905113904345\n",
      " Training with pattern  4  weights  [-0.79345166  1.20276127] 0.3903026293023648   weights  [-0.82997751  1.22631195]  bias  0.40892317757323476\n",
      "pattern1 0 0 1 0.387558\n",
      "pattern2 0 1 1 0.926804\n",
      "pattern3 1 0 -1 -0.397818\n",
      "pattern4 1 1 1 0.666966\n",
      " modified Weights  [-0.82997751  1.22631195] 0.40892317757323476\n",
      "+++++++++++Epoch  14  cost=  0.8539775505496692\n",
      " Training with pattern  1  weights  [-0.82997751  1.22631195] 0.40892317757323476   weights  [-0.82997751  1.22631195]  bias  0.4609684276986539\n",
      "pattern1 0 0 1 0.430873\n",
      "pattern2 0 1 1 0.9338\n",
      "pattern3 1 0 -1 -0.353125\n",
      "pattern4 1 1 1 0.694865\n",
      " modified Weights  [-0.82997751  1.22631195] 0.4609684276986539\n",
      " Training with pattern  2  weights  [-0.82997751  1.22631195] 0.40892317757323476   weights  [-0.82997751  1.22715943]  bias  0.46181590561897934\n",
      "pattern1 0 0 1 0.431563\n",
      "pattern2 0 1 1 0.934017\n",
      "pattern3 1 0 -1 -0.352383\n",
      "pattern4 1 1 1 0.695741\n",
      " modified Weights  [-0.82997751  1.22715943] 0.46181590561897934\n",
      " Training with pattern  3  weights  [-0.82997751  1.22631195] 0.40892317757323476   weights  [-0.88669755  1.22715943]  bias  0.405095862243057\n",
      "pattern1 0 0 1 0.384301\n",
      "pattern2 0 1 1 0.926382\n",
      "pattern3 1 0 -1 -0.447525\n",
      "pattern4 1 1 1 0.632491\n",
      " modified Weights  [-0.88669755  1.22715943] 0.405095862243057\n",
      " Training with pattern  4  weights  [-0.82997751  1.22631195] 0.40892317757323476   weights  [-0.86464869  1.24920829]  bias  0.4271447232452789\n",
      "pattern1 0 0 1 0.402932\n",
      "pattern2 0 1 1 0.932387\n",
      "pattern3 1 0 -1 -0.411573\n",
      "pattern4 1 1 1 0.670529\n",
      " modified Weights  [-0.86464869  1.24920829] 0.4271447232452789\n",
      "+++++++++++Epoch  15  cost=  0.8158581523963202\n",
      " Training with pattern  1  weights  [-0.86464869  1.24920829] 0.4271447232452789   weights  [-0.86464869  1.24920829]  bias  0.47715782703151316\n",
      "pattern1 0 0 1 0.443965\n",
      "pattern2 0 1 1 0.938625\n",
      "pattern3 1 0 -1 -0.369195\n",
      "pattern4 1 1 1 0.697141\n",
      " modified Weights  [-0.86464869  1.24920829] 0.47715782703151316\n",
      " Training with pattern  2  weights  [-0.86464869  1.24920829] 0.4271447232452789   weights  [-0.86464869  1.24993855]  bias  0.4778880850555794\n",
      "pattern1 0 0 1 0.444551\n",
      "pattern2 0 1 1 0.938799\n",
      "pattern3 1 0 -1 -0.368564\n",
      "pattern4 1 1 1 0.697891\n",
      " modified Weights  [-0.86464869  1.24993855] 0.4778880850555794\n",
      " Training with pattern  3  weights  [-0.86464869  1.24920829] 0.4271447232452789   weights  [-0.91921487  1.24993855]  bias  0.42332190400733477\n",
      "pattern1 0 0 1 0.399725\n",
      "pattern2 0 1 1 0.931981\n",
      "pattern3 1 0 -1 -0.458881\n",
      "pattern4 1 1 1 0.637556\n",
      " modified Weights  [-0.91921487  1.24993855] 0.42332190400733477\n",
      " Training with pattern  4  weights  [-0.86464869  1.24920829] 0.4271447232452789   weights  [-0.89770304  1.27145038]  bias  0.44483373465345105\n",
      "pattern1 0 0 1 0.417643\n",
      "pattern2 0 1 1 0.937414\n",
      "pattern3 1 0 -1 -0.424255\n",
      "pattern4 1 1 1 0.674297\n",
      " modified Weights  [-0.89770304  1.27145038] 0.44483373465345105\n",
      "+++++++++++Epoch  16  cost=  0.7806217516296482\n",
      " Training with pattern  1  weights  [-0.89770304  1.27145038] 0.44483373465345105   weights  [-0.89770304  1.27145038]  bias  0.49291162150144163\n",
      "pattern1 0 0 1 0.456524\n",
      "pattern2 0 1 1 0.942988\n",
      "pattern3 1 0 -1 -0.384041\n",
      "pattern4 1 1 1 0.699673\n",
      " modified Weights  [-0.89770304  1.27145038] 0.49291162150144163\n",
      " Training with pattern  2  weights  [-0.89770304  1.27145038] 0.44483373465345105   weights  [-0.89770304  1.27208192]  bias  0.4935431599022157\n",
      "pattern1 0 0 1 0.457024\n",
      "pattern2 0 1 1 0.943128\n",
      "pattern3 1 0 -1 -0.383503\n",
      "pattern4 1 1 1 0.700317\n",
      " modified Weights  [-0.89770304  1.27208192] 0.4935431599022157\n",
      " Training with pattern  3  weights  [-0.89770304  1.27145038] 0.44483373465345105   weights  [-0.95028568  1.27208192]  bias  0.44096051914992396\n",
      "pattern1 0 0 1 0.41444\n",
      "pattern2 0 1 1 0.93702\n",
      "pattern3 1 0 -1 -0.469419\n",
      "pattern4 1 1 1 0.642698\n",
      " modified Weights  [-0.95028568  1.27208192] 0.44096051914992396\n",
      " Training with pattern  4  weights  [-0.89770304  1.27145038] 0.44483373465345105   weights  [-0.92931421  1.29305339]  bias  0.46193198976721234\n",
      "pattern1 0 0 1 0.431658\n",
      "pattern2 0 1 1 0.94194\n",
      "pattern3 1 0 -1 -0.436082\n",
      "pattern4 1 1 1 0.678145\n",
      " modified Weights  [-0.92931421  1.29305339] 0.46193198976721234\n",
      "+++++++++++Epoch  17  cost=  0.7479786501309769\n",
      " Training with pattern  1  weights  [-0.92931421  1.29305339] 0.46193198976721234   weights  [-0.92931421  1.29305339]  bias  0.5081764128879775\n",
      "pattern1 0 0 1 0.468523\n",
      "pattern2 0 1 1 0.946933\n",
      "pattern3 1 0 -1 -0.397889\n",
      "pattern4 1 1 1 0.702346\n",
      " modified Weights  [-0.92931421  1.29305339] 0.5081764128879775\n",
      " Training with pattern  2  weights  [-0.92931421  1.29305339] 0.46193198976721234   weights  [-0.92931421  1.29360166]  bias  0.5087246854541075\n",
      "pattern1 0 0 1 0.468951\n",
      "pattern2 0 1 1 0.947046\n",
      "pattern3 1 0 -1 -0.397427\n",
      "pattern4 1 1 1 0.702901\n",
      " modified Weights  [-0.92931421  1.29360166] 0.5087246854541075\n",
      " Training with pattern  3  weights  [-0.92931421  1.29305339] 0.46193198976721234   weights  [-0.98005398  1.29360166]  bias  0.45798491305002703\n",
      "pattern1 0 0 1 0.42844\n",
      "pattern2 0 1 1 0.941556\n",
      "pattern3 1 0 -1 -0.479295\n",
      "pattern4 1 1 1 0.64782\n",
      " modified Weights  [-0.98005398  1.29360166] 0.45798491305002703\n",
      " Training with pattern  4  weights  [-0.92931421  1.29305339] 0.46193198976721234   weights  [-0.95961592  1.31403972]  bias  0.47842297520520155\n",
      "pattern1 0 0 1 0.44498\n",
      "pattern2 0 1 1 0.94602\n",
      "pattern3 1 0 -1 -0.447198\n",
      "pattern4 1 1 1 0.682002\n",
      " modified Weights  [-0.95961592  1.31403972] 0.47842297520520155\n",
      "+++++++++++Epoch  18  cost=  0.7176738211894899\n",
      " Training with pattern  1  weights  [-0.95961592  1.31403972] 0.47842297520520155   weights  [-0.95961592  1.31403972]  bias  0.522935213870592\n",
      "pattern1 0 0 1 0.479962\n",
      "pattern2 0 1 1 0.950504\n",
      "pattern3 1 0 -1 -0.410889\n",
      "pattern4 1 1 1 0.705094\n",
      " modified Weights  [-0.95961592  1.31403972] 0.522935213870592\n",
      " Training with pattern  2  weights  [-0.95961592  1.31403972] 0.47842297520520155   weights  [-0.95961592  1.31451757]  bias  0.5234130601186895\n",
      "pattern1 0 0 1 0.48033\n",
      "pattern2 0 1 1 0.950596\n",
      "pattern3 1 0 -1 -0.410492\n",
      "pattern4 1 1 1 0.705574\n",
      " modified Weights  [-0.95961592  1.31451757] 0.5234130601186895\n",
      " Training with pattern  3  weights  [-0.95961592  1.31403972] 0.47842297520520155   weights  [-1.00863328  1.31451757]  bias  0.4743956950940132\n",
      "pattern1 0 0 1 0.441744\n",
      "pattern2 0 1 1 0.945646\n",
      "pattern3 1 0 -1 -0.488614\n",
      "pattern4 1 1 1 0.652867\n",
      " modified Weights  [-1.00863328  1.31451757] 0.4743956950940132\n",
      " Training with pattern  4  weights  [-0.95961592  1.31403972] 0.47842297520520155   weights  [-0.98871606  1.33443479]  bias  0.4943129217753392\n",
      "pattern1 0 0 1 0.457633\n",
      "pattern2 0 1 1 0.949703\n",
      "pattern3 1 0 -1 -0.457704\n",
      "pattern4 1 1 1 0.685826\n",
      " modified Weights  [-0.98871606  1.33443479] 0.4943129217753392\n",
      "+++++++++++Epoch  19  cost=  0.6894820925508297\n",
      " Training with pattern  1  weights  [-0.98871606  1.33443479] 0.4943129217753392   weights  [-0.98871606  1.33443479]  bias  0.5371909619947287\n",
      "pattern1 0 0 1 0.490859\n",
      "pattern2 0 1 1 0.953741\n",
      "pattern3 1 0 -1 -0.423152\n",
      "pattern4 1 1 1 0.707874\n",
      " modified Weights  [-0.98871606  1.33443479] 0.5371909619947287\n",
      " Training with pattern  2  weights  [-0.98871606  1.33443479] 0.4943129217753392   weights  [-0.98871606  1.33485287]  bias  0.5376090370030534\n",
      "pattern1 0 0 1 0.491176\n",
      "pattern2 0 1 1 0.953817\n",
      "pattern3 1 0 -1 -0.422809\n",
      "pattern4 1 1 1 0.708291\n",
      " modified Weights  [-0.98871606  1.33485287] 0.5376090370030534\n",
      " Training with pattern  3  weights  [-0.98871606  1.33443479] 0.4943129217753392   weights  [-1.03611692  1.33485287]  bias  0.4902081746407937\n",
      "pattern1 0 0 1 0.454382\n",
      "pattern2 0 1 1 0.949341\n",
      "pattern3 1 0 -1 -0.497448\n",
      "pattern4 1 1 1 0.65781\n",
      " modified Weights  [-1.03611692  1.33485287] 0.4902081746407937\n",
      " Training with pattern  4  weights  [-0.98871606  1.33443479] 0.4943129217753392   weights  [-1.01670501  1.35426478]  bias  0.5096200866169572\n",
      "pattern1 0 0 1 0.469649\n",
      "pattern2 0 1 1 0.953036\n",
      "pattern3 1 0 -1 -0.467671\n",
      "pattern4 1 1 1 0.689593\n",
      " modified Weights  [-1.01670501  1.35426478] 0.5096200866169572\n",
      "+++++++++++Epoch  20  cost=  0.6632043108650079\n",
      " Training with pattern  1  weights  [-1.01670501  1.35426478] 0.5096200866169572   weights  [-1.01670501  1.35426478]  bias  0.5509572075183542\n",
      "pattern1 0 0 1 0.501237\n",
      "pattern2 0 1 1 0.956682\n",
      "pattern3 1 0 -1 -0.434757\n",
      "pattern4 1 1 1 0.71066\n",
      " modified Weights  [-1.01670501  1.35426478] 0.5509572075183542\n",
      " Training with pattern  2  weights  [-1.01670501  1.35426478] 0.5096200866169572   weights  [-1.01670501  1.35463194]  bias  0.5513243641303195\n",
      "pattern1 0 0 1 0.501512\n",
      "pattern2 0 1 1 0.956744\n",
      "pattern3 1 0 -1 -0.434459\n",
      "pattern4 1 1 1 0.711024\n",
      " modified Weights  [-1.01670501  1.35463194] 0.5513243641303195\n",
      " Training with pattern  3  weights  [-1.01670501  1.35426478] 0.5096200866169572   weights  [-1.0625842   1.35463194]  bias  0.505445166217627\n",
      "pattern1 0 0 1 0.466389\n",
      "pattern2 0 1 1 0.952686\n",
      "pattern3 1 0 -1 -0.505852\n",
      "pattern4 1 1 1 0.662633\n",
      " modified Weights  [-1.0625842   1.35463194] 0.505445166217627\n",
      " Training with pattern  4  weights  [-1.01670501  1.35426478] 0.5096200866169572   weights  [-1.04366068  1.37355546]  bias  0.5243686891729216\n",
      "pattern1 0 0 1 0.481065\n",
      "pattern2 0 1 1 0.956059\n",
      "pattern3 1 0 -1 -0.477153\n",
      "pattern4 1 1 1 0.69329\n",
      " modified Weights  [-1.04366068  1.37355546] 0.5243686891729216\n",
      "+++++++++++Epoch  21  cost=  0.6386640411622837\n",
      " *********Epoch  20 Error  0.6386640411622837\n",
      " Training with pattern  1  weights  [-1.04366068  1.37355546] 0.5243686891729216   weights  [-1.04366068  1.37355546]  bias  0.5642528456057673\n",
      "pattern1 0 0 1 0.511126\n",
      "pattern2 0 1 1 0.95936\n",
      "pattern3 1 0 -1 -0.445769\n",
      "pattern4 1 1 1 0.713436\n",
      " modified Weights  [-1.04366068  1.37355546] 0.5642528456057673\n",
      " Training with pattern  2  weights  [-1.04366068  1.37355546] 0.5243686891729216   weights  [-1.04366068  1.37387907]  bias  0.5645764577381882\n",
      "pattern1 0 0 1 0.511365\n",
      "pattern2 0 1 1 0.959411\n",
      "pattern3 1 0 -1 -0.44551\n",
      "pattern4 1 1 1 0.713754\n",
      " modified Weights  [-1.04366068  1.37387907] 0.5645764577381882\n",
      " Training with pattern  3  weights  [-1.04366068  1.37355546] 0.5243686891729216   weights  [-1.08810422  1.37387907]  bias  0.5201329152590018\n",
      "pattern1 0 0 1 0.477803\n",
      "pattern2 0 1 1 0.955722\n",
      "pattern3 1 0 -1 -0.513868\n",
      "pattern4 1 1 1 0.667327\n",
      " modified Weights  [-1.08810422  1.37387907] 0.5201329152590018\n",
      " Training with pattern  4  weights  [-1.04366068  1.37355546] 0.5243686891729216   weights  [-1.06965165  1.39233164]  bias  0.538585484798144\n",
      "pattern1 0 0 1 0.491916\n",
      "pattern2 0 1 1 0.958807\n",
      "pattern3 1 0 -1 -0.486196\n",
      "pattern4 1 1 1 0.696909\n",
      " modified Weights  [-1.06965165  1.39233164] 0.538585484798144\n",
      "+++++++++++Epoch  22  cost=  0.6157046805395376\n",
      " Training with pattern  1  weights  [-1.06965165  1.39233164] 0.538585484798144   weights  [-1.06965165  1.39233164]  bias  0.5770991385482573\n",
      "pattern1 0 0 1 0.520554\n",
      "pattern2 0 1 1 0.961803\n",
      "pattern3 1 0 -1 -0.45624\n",
      "pattern4 1 1 1 0.71619\n",
      " modified Weights  [-1.06965165  1.39233164] 0.5770991385482573\n",
      " Training with pattern  2  weights  [-1.06965165  1.39233164] 0.538585484798144   weights  [-1.06965165  1.39261787]  bias  0.5773853681077915\n",
      "pattern1 0 0 1 0.520762\n",
      "pattern2 0 1 1 0.961846\n",
      "pattern3 1 0 -1 -0.456013\n",
      "pattern4 1 1 1 0.716469\n",
      " modified Weights  [-1.06965165  1.39261787] 0.5773853681077915\n",
      " Training with pattern  3  weights  [-1.06965165  1.39233164] 0.538585484798144   weights  [-1.11273822  1.39261787]  bias  0.534298800220995\n",
      "pattern1 0 0 1 0.48866\n",
      "pattern2 0 1 1 0.958483\n",
      "pattern3 1 0 -1 -0.52153\n",
      "pattern4 1 1 1 0.671889\n",
      " modified Weights  [-1.11273822  1.39261787] 0.534298800220995\n",
      " Training with pattern  4  weights  [-1.06965165  1.39233164] 0.538585484798144   weights  [-1.09473918  1.41061691]  bias  0.5522978415312858\n",
      "pattern1 0 0 1 0.50224\n",
      "pattern2 0 1 1 0.961312\n",
      "pattern3 1 0 -1 -0.494834\n",
      "pattern4 1 1 1 0.700446\n",
      " modified Weights  [-1.09473918  1.41061691] 0.5522978415312858\n",
      "+++++++++++Epoch  23  cost=  0.5941869388000924\n",
      " Training with pattern  1  weights  [-1.09473918  1.41061691] 0.5522978415312858   weights  [-1.09473918  1.41061691]  bias  0.5895180417672526\n",
      "pattern1 0 0 1 0.529549\n",
      "pattern2 0 1 1 0.964037\n",
      "pattern3 1 0 -1 -0.466213\n",
      "pattern4 1 1 1 0.718915\n",
      " modified Weights  [-1.09473918  1.41061691] 0.5895180417672526\n",
      " Training with pattern  2  weights  [-1.09473918  1.41061691] 0.5522978415312858   weights  [-1.09473918  1.41087093]  bias  0.5897720564223244\n",
      "pattern1 0 0 1 0.529732\n",
      "pattern2 0 1 1 0.964073\n",
      "pattern3 1 0 -1 -0.466015\n",
      "pattern4 1 1 1 0.71916\n",
      " modified Weights  [-1.09473918  1.41087093] 0.5897720564223244\n",
      " Training with pattern  3  weights  [-1.09473918  1.41061691] 0.5522978415312858   weights  [-1.13654119  1.41087093]  bias  0.5479700517010848\n",
      "pattern1 0 0 1 0.498997\n",
      "pattern2 0 1 1 0.961001\n",
      "pattern3 1 0 -1 -0.528867\n",
      "pattern4 1 1 1 0.67632\n",
      " modified Weights  [-1.13654119  1.41087093] 0.5479700517010848\n",
      " Training with pattern  4  weights  [-1.09473918  1.41061691] 0.5522978415312858   weights  [-1.11897856  1.42843356]  bias  0.5655326783008392\n",
      "pattern1 0 0 1 0.512071\n",
      "pattern2 0 1 1 0.963599\n",
      "pattern3 1 0 -1 -0.503098\n",
      "pattern4 1 1 1 0.703899\n",
      " modified Weights  [-1.11897856  1.42843356] 0.5655326783008392\n",
      "+++++++++++Epoch  24  cost=  0.5739866497552079\n",
      " Training with pattern  1  weights  [-1.11897856  1.42843356] 0.5655326783008392   weights  [-1.11897856  1.42843356]  bias  0.6015312761987985\n",
      "pattern1 0 0 1 0.538138\n",
      "pattern2 0 1 1 0.966085\n",
      "pattern3 1 0 -1 -0.475727\n",
      "pattern4 1 1 1 0.721605\n",
      " modified Weights  [-1.11897856  1.42843356] 0.6015312761987985\n",
      " Training with pattern  2  weights  [-1.11897856  1.42843356] 0.5655326783008392   weights  [-1.11897856  1.42865971]  bias  0.6017574261482219\n",
      "pattern1 0 0 1 0.538299\n",
      "pattern2 0 1 1 0.966115\n",
      "pattern3 1 0 -1 -0.475552\n",
      "pattern4 1 1 1 0.721822\n",
      " modified Weights  [-1.11897856  1.42865971] 0.6017574261482219\n",
      " Training with pattern  3  weights  [-1.11897856  1.42843356] 0.5655326783008392   weights  [-1.15956293  1.42865971]  bias  0.5611730569272133\n",
      "pattern1 0 0 1 0.508847\n",
      "pattern2 0 1 1 0.963302\n",
      "pattern3 1 0 -1 -0.535903\n",
      "pattern4 1 1 1 0.680621\n",
      " modified Weights  [-1.15956293  1.42865971] 0.5611730569272133\n",
      " Training with pattern  4  weights  [-1.11897856  1.42843356] 0.5655326783008392   weights  [-1.14242009  1.44580255]  bias  0.5783158990917523\n",
      "pattern1 0 0 1 0.52144\n",
      "pattern2 0 1 1 0.965693\n",
      "pattern3 1 0 -1 -0.511016\n",
      "pattern4 1 1 1 0.707269\n",
      " modified Weights  [-1.14242009  1.44580255] 0.5783158990917523\n",
      "+++++++++++Epoch  25  cost=  0.5549928765559329\n",
      " Training with pattern  1  weights  [-1.14242009  1.44580255] 0.5783158990917523   weights  [-1.14242009  1.44580255]  bias  0.6131598299234314\n",
      "pattern1 0 0 1 0.546348\n",
      "pattern2 0 1 1 0.967965\n",
      "pattern3 1 0 -1 -0.484815\n",
      "pattern4 1 1 1 0.724258\n",
      " modified Weights  [-1.14242009  1.44580255] 0.6131598299234314\n",
      " Training with pattern  2  weights  [-1.14242009  1.44580255] 0.5783158990917523   weights  [-1.14242009  1.44600451]  bias  0.6133617911894883\n",
      "pattern1 0 0 1 0.546489\n",
      "pattern2 0 1 1 0.96799\n",
      "pattern3 1 0 -1 -0.484661\n",
      "pattern4 1 1 1 0.72445\n",
      " modified Weights  [-1.14242009  1.44600451] 0.6133617911894883\n",
      " Training with pattern  3  weights  [-1.14242009  1.44580255] 0.5783158990917523   weights  [-1.18184888  1.44600451]  bias  0.573933002453093\n",
      "pattern1 0 0 1 0.518242\n",
      "pattern2 0 1 1 0.965409\n",
      "pattern3 1 0 -1 -0.542658\n",
      "pattern4 1 1 1 0.684795\n",
      " modified Weights  [-1.18184888  1.44600451] 0.573933002453093\n",
      " Training with pattern  4  weights  [-1.14242009  1.44580255] 0.5783158990917523   weights  [-1.16510976  1.46274362]  bias  0.5906721133495092\n",
      "pattern1 0 0 1 0.530379\n",
      "pattern2 0 1 1 0.967613\n",
      "pattern3 1 0 -1 -0.518611\n",
      "pattern4 1 1 1 0.710556\n",
      " modified Weights  [-1.16510976  1.46274362] 0.5906721133495092\n",
      "+++++++++++Epoch  26  cost=  0.5371062745583952\n",
      " Training with pattern  1  weights  [-1.16510976  1.46274362] 0.5906721133495092   weights  [-1.16510976  1.46274362]  bias  0.6244237072804255\n",
      "pattern1 0 0 1 0.554201\n",
      "pattern2 0 1 1 0.969695\n",
      "pattern3 1 0 -1 -0.493507\n",
      "pattern4 1 1 1 0.726869\n",
      " modified Weights  [-1.16510976  1.46274362] 0.6244237072804255\n",
      " Training with pattern  2  weights  [-1.16510976  1.46274362] 0.5906721133495092   weights  [-1.16510976  1.46292451]  bias  0.6246045979642131\n",
      "pattern1 0 0 1 0.554326\n",
      "pattern2 0 1 1 0.969717\n",
      "pattern3 1 0 -1 -0.49337\n",
      "pattern4 1 1 1 0.72704\n",
      " modified Weights  [-1.16510976  1.46292451] 0.6246045979642131\n",
      " Training with pattern  3  weights  [-1.16510976  1.46274362] 0.5906721133495092   weights  [-1.20344065  1.46292451]  bias  0.5862737124031229\n",
      "pattern1 0 0 1 0.52721\n",
      "pattern2 0 1 1 0.967344\n",
      "pattern3 1 0 -1 -0.549152\n",
      "pattern4 1 1 1 0.688847\n",
      " modified Weights  [-1.20344065  1.46292451] 0.5862737124031229\n",
      " Training with pattern  4  weights  [-1.16510976  1.46274362] 0.5906721133495092   weights  [-1.18708984  1.47927532]  bias  0.6026245213349856\n",
      "pattern1 0 0 1 0.538914\n",
      "pattern2 0 1 1 0.969379\n",
      "pattern3 1 0 -1 -0.525903\n",
      "pattern4 1 1 1 0.713761\n",
      " modified Weights  [-1.18708984  1.47927532] 0.6026245213349856\n",
      "+++++++++++Epoch  27  cost=  0.5202376772800403\n",
      " Training with pattern  1  weights  [-1.18708984  1.47927532] 0.6026245213349856   weights  [-1.18708984  1.47927532]  bias  0.6353418205155932\n",
      "pattern1 0 0 1 0.56172\n",
      "pattern2 0 1 1 0.971291\n",
      "pattern3 1 0 -1 -0.501829\n",
      "pattern4 1 1 1 0.729439\n",
      " modified Weights  [-1.18708984  1.47927532] 0.6353418205155932\n",
      " Training with pattern  2  weights  [-1.18708984  1.47927532] 0.6026245213349856   weights  [-1.18708984  1.47943779]  bias  0.6355042953174609\n",
      "pattern1 0 0 1 0.561831\n",
      "pattern2 0 1 1 0.971309\n",
      "pattern3 1 0 -1 -0.501708\n",
      "pattern4 1 1 1 0.729591\n",
      " modified Weights  [-1.18708984  1.47943779] 0.6355042953174609\n",
      " Training with pattern  3  weights  [-1.18708984  1.47927532] 0.6026245213349856   weights  [-1.22437654  1.47943779]  bias  0.5982175992749468\n",
      "pattern1 0 0 1 0.53578\n",
      "pattern2 0 1 1 0.969122\n",
      "pattern3 1 0 -1 -0.555402\n",
      "pattern4 1 1 1 0.692779\n",
      " modified Weights  [-1.22437654  1.47943779] 0.5982175992749468\n",
      " Training with pattern  4  weights  [-1.18708984  1.47927532] 0.6026245213349856   weights  [-1.20839924  1.49541509]  bias  0.6141948937637776\n",
      "pattern1 0 0 1 0.547073\n",
      "pattern2 0 1 1 0.971006\n",
      "pattern3 1 0 -1 -0.532913\n",
      "pattern4 1 1 1 0.716887\n",
      " modified Weights  [-1.20839924  1.49541509] 0.6141948937637776\n",
      "+++++++++++Epoch  28  cost=  0.5043068742880582\n",
      " Training with pattern  1  weights  [-1.20839924  1.49541509] 0.6141948937637776   weights  [-1.20839924  1.49541509]  bias  0.6459319629338091\n",
      "pattern1 0 0 1 0.568925\n",
      "pattern2 0 1 1 0.972765\n",
      "pattern3 1 0 -1 -0.509806\n",
      "pattern4 1 1 1 0.731965\n",
      " modified Weights  [-1.20839924  1.49541509] 0.6459319629338091\n",
      " Training with pattern  2  weights  [-1.20839924  1.49541509] 0.6141948937637776   weights  [-1.20839924  1.49556142]  bias  0.6460782902238876\n",
      "pattern1 0 0 1 0.569024\n",
      "pattern2 0 1 1 0.972781\n",
      "pattern3 1 0 -1 -0.509697\n",
      "pattern4 1 1 1 0.732101\n",
      " modified Weights  [-1.20839924  1.49556142] 0.6460782902238876\n",
      " Training with pattern  3  weights  [-1.20839924  1.49541509] 0.6141948937637776   weights  [-1.24469185  1.49556142]  bias  0.6097856786642791\n",
      "pattern1 0 0 1 0.543976\n",
      "pattern2 0 1 1 0.970762\n",
      "pattern3 1 0 -1 -0.561421\n",
      "pattern4 1 1 1 0.696595\n",
      " modified Weights  [-1.24469185  1.49556142] 0.6097856786642791\n",
      " Training with pattern  4  weights  [-1.20839924  1.49541509] 0.6141948937637776   weights  [-1.22907393  1.51117934]  bias  0.6254036042891358\n",
      "pattern1 0 0 1 0.554879\n",
      "pattern2 0 1 1 0.972508\n",
      "pattern3 1 0 -1 -0.539656\n",
      "pattern4 1 1 1 0.719935\n",
      " modified Weights  [-1.22907393  1.51117934] 0.6254036042891358\n",
      "+++++++++++Epoch  29  cost=  0.4892415535992588\n",
      " Training with pattern  1  weights  [-1.22907393  1.51117934] 0.6254036042891358   weights  [-1.22907393  1.51117934]  bias  0.6562108278506364\n",
      "pattern1 0 0 1 0.575836\n",
      "pattern2 0 1 1 0.97413\n",
      "pattern3 1 0 -1 -0.517459\n",
      "pattern4 1 1 1 0.734448\n",
      " modified Weights  [-1.22907393  1.51117934] 0.6562108278506364\n",
      " Training with pattern  2  weights  [-1.22907393  1.51117934] 0.6254036042891358   weights  [-1.22907393  1.51131147]  bias  0.6563429527188068\n",
      "pattern1 0 0 1 0.575925\n",
      "pattern2 0 1 1 0.974143\n",
      "pattern3 1 0 -1 -0.517362\n",
      "pattern4 1 1 1 0.734569\n",
      " modified Weights  [-1.22907393  1.51131147] 0.6563429527188068\n",
      " Training with pattern  3  weights  [-1.22907393  1.51117934] 0.6254036042891358   weights  [-1.26441926  1.51131147]  bias  0.6209976192392311\n",
      "pattern1 0 0 1 0.551822\n",
      "pattern2 0 1 1 0.972275\n",
      "pattern3 1 0 -1 -0.567225\n",
      "pattern4 1 1 1 0.7003\n",
      " modified Weights  [-1.26441926  1.51131147] 0.6209976192392311\n",
      " Training with pattern  4  weights  [-1.22907393  1.51117934] 0.6254036042891358   weights  [-1.24914719  1.52658354]  bias  0.6362696904111623\n",
      "pattern1 0 0 1 0.562354\n",
      "pattern2 0 1 1 0.973897\n",
      "pattern3 1 0 -1 -0.546149\n",
      "pattern4 1 1 1 0.722906\n",
      " modified Weights  [-1.24914719  1.52658354] 0.6362696904111623\n",
      "+++++++++++Epoch  30  cost=  0.47497638486757576\n",
      " Training with pattern  1  weights  [-1.24914719  1.52658354] 0.6362696904111623   weights  [-1.24914719  1.52658354]  bias  0.666194052360346\n",
      "pattern1 0 0 1 0.582471\n",
      "pattern2 0 1 1 0.975395\n",
      "pattern3 1 0 -1 -0.524809\n",
      "pattern4 1 1 1 0.736886\n",
      " modified Weights  [-1.24914719  1.52658354] 0.666194052360346\n",
      " Training with pattern  2  weights  [-1.24914719  1.52658354] 0.6362696904111623   weights  [-1.24914719  1.52670313]  bias  0.6663136483784559\n",
      "pattern1 0 0 1 0.58255\n",
      "pattern2 0 1 1 0.975406\n",
      "pattern3 1 0 -1 -0.524722\n",
      "pattern4 1 1 1 0.736995\n",
      " modified Weights  [-1.24914719  1.52670313] 0.6663136483784559\n",
      " Training with pattern  3  weights  [-1.24914719  1.52658354] 0.6362696904111623   weights  [-1.28358903  1.52670313]  bias  0.631871810997102\n",
      "pattern1 0 0 1 0.55934\n",
      "pattern2 0 1 1 0.973675\n",
      "pattern3 1 0 -1 -0.572825\n",
      "pattern4 1 1 1 0.703898\n",
      " modified Weights  [-1.28358903  1.52670313] 0.631871810997102\n",
      " Training with pattern  4  weights  [-1.24914719  1.52658354] 0.6362696904111623   weights  [-1.26864991  1.54164225]  bias  0.6468109283988852\n",
      "pattern1 0 0 1 0.569519\n",
      "pattern2 0 1 1 0.975183\n",
      "pattern3 1 0 -1 -0.552407\n",
      "pattern4 1 1 1 0.725804\n",
      " modified Weights  [-1.26864991  1.54164225] 0.6468109283988852\n",
      "+++++++++++Epoch  31  cost=  0.4614522230396772\n",
      " *********Epoch  30 Error  0.4614522230396772\n",
      " Training with pattern  1  weights  [-1.26864991  1.54164225] 0.6468109283988852   weights  [-1.26864991  1.54164225]  bias  0.6758962735684083\n",
      "pattern1 0 0 1 0.588845\n",
      "pattern2 0 1 1 0.976569\n",
      "pattern3 1 0 -1 -0.531873\n",
      "pattern4 1 1 1 0.739279\n",
      " modified Weights  [-1.26864991  1.54164225] 0.6758962735684083\n",
      " Training with pattern  2  weights  [-1.26864991  1.54164225] 0.6468109283988852   weights  [-1.26864991  1.54175076]  bias  0.67600478543998\n",
      "pattern1 0 0 1 0.588916\n",
      "pattern2 0 1 1 0.976579\n",
      "pattern3 1 0 -1 -0.531795\n",
      "pattern4 1 1 1 0.739378\n",
      " modified Weights  [-1.26864991  1.54175076] 0.67600478543998\n",
      " Training with pattern  3  weights  [-1.26864991  1.54164225] 0.6468109283988852   weights  [-1.30222925  1.54175076]  bias  0.6424254417624699\n",
      "pattern1 0 0 1 0.566549\n",
      "pattern2 0 1 1 0.974973\n",
      "pattern3 1 0 -1 -0.578233\n",
      "pattern4 1 1 1 0.707393\n",
      " modified Weights  [-1.30222925  1.54175076] 0.6424254417624699\n",
      " Training with pattern  4  weights  [-1.26864991  1.54164225] 0.6468109283988852   weights  [-1.28761078  1.55636923]  bias  0.6570439137404931\n",
      "pattern1 0 0 1 0.576393\n",
      "pattern2 0 1 1 0.976378\n",
      "pattern3 1 0 -1 -0.558442\n",
      "pattern4 1 1 1 0.728631\n",
      " modified Weights  [-1.28761078  1.55636923] 0.6570439137404931\n",
      "+++++++++++Epoch  32  cost=  0.4486154151724199\n",
      " Training with pattern  1  weights  [-1.28761078  1.55636923] 0.6570439137404931   weights  [-1.28761078  1.55636923]  bias  0.6853311900356969\n",
      "pattern1 0 0 1 0.594974\n",
      "pattern2 0 1 1 0.977662\n",
      "pattern3 1 0 -1 -0.53867\n",
      "pattern4 1 1 1 0.741629\n",
      " modified Weights  [-1.28761078  1.55636923] 0.6853311900356969\n",
      " Training with pattern  2  weights  [-1.28761078  1.55636923] 0.6570439137404931   weights  [-1.28761078  1.55646791]  bias  0.685429868865858\n",
      "pattern1 0 0 1 0.595038\n",
      "pattern2 0 1 1 0.977671\n",
      "pattern3 1 0 -1 -0.5386\n",
      "pattern4 1 1 1 0.741718\n",
      " modified Weights  [-1.28761078  1.55646791] 0.685429868865858\n",
      " Training with pattern  3  weights  [-1.28761078  1.55636923] 0.6570439137404931   weights  [-1.32036608  1.55646791]  bias  0.6526745760178166\n",
      "pattern1 0 0 1 0.573468\n",
      "pattern2 0 1 1 0.976177\n",
      "pattern3 1 0 -1 -0.583459\n",
      "pattern4 1 1 1 0.710789\n",
      " modified Weights  [-1.32036608  1.55646791] 0.6526745760178166\n",
      " Training with pattern  4  weights  [-1.28761078  1.55636923] 0.6570439137404931   weights  [-1.30605651  1.57077748]  bias  0.6669841421774305\n",
      "pattern1 0 0 1 0.582993\n",
      "pattern2 0 1 1 0.977488\n",
      "pattern3 1 0 -1 -0.564268\n",
      "pattern4 1 1 1 0.731388\n",
      " modified Weights  [-1.30605651  1.57077748] 0.6669841421774305\n",
      "+++++++++++Epoch  33  cost=  0.4364171957129951\n",
      " Training with pattern  1  weights  [-1.30605651  1.57077748] 0.6669841421774305   weights  [-1.30605651  1.57077748]  bias  0.694511624215385\n",
      "pattern1 0 0 1 0.600873\n",
      "pattern2 0 1 1 0.978681\n",
      "pattern3 1 0 -1 -0.545214\n",
      "pattern4 1 1 1 0.743934\n",
      " modified Weights  [-1.30605651  1.57077748] 0.694511624215385\n",
      " Training with pattern  2  weights  [-1.30605651  1.57077748] 0.6669841421774305   weights  [-1.30605651  1.57086741]  bias  0.6946015567838936\n",
      "pattern1 0 0 1 0.60093\n",
      "pattern2 0 1 1 0.978688\n",
      "pattern3 1 0 -1 -0.54515\n",
      "pattern4 1 1 1 0.744015\n",
      " modified Weights  [-1.30605651  1.57086741] 0.6946015567838936\n",
      " Training with pattern  3  weights  [-1.30605651  1.57077748] 0.6669841421774305   weights  [-1.33802383  1.57086741]  bias  0.662634232641804\n",
      "pattern1 0 0 1 0.580114\n",
      "pattern2 0 1 1 0.977297\n",
      "pattern3 1 0 -1 -0.588514\n",
      "pattern4 1 1 1 0.714089\n",
      " modified Weights  [-1.33802383  1.57086741] 0.662634232641804\n",
      " Training with pattern  4  weights  [-1.30605651  1.57077748] 0.6669841421774305   weights  [-1.32401198  1.58487927]  bias  0.6766460885055323\n",
      "pattern1 0 0 1 0.589335\n",
      "pattern2 0 1 1 0.978521\n",
      "pattern3 1 0 -1 -0.569894\n",
      "pattern4 1 1 1 0.734078\n",
      " modified Weights  [-1.32401198  1.58487927] 0.6766460885055323\n",
      "+++++++++++Epoch  34  cost=  0.42481315776874906\n",
      " Training with pattern  1  weights  [-1.32401198  1.58487927] 0.6766460885055323   weights  [-1.32401198  1.58487927]  bias  0.7034495834786786\n",
      "pattern1 0 0 1 0.606553\n",
      "pattern2 0 1 1 0.979631\n",
      "pattern3 1 0 -1 -0.551519\n",
      "pattern4 1 1 1 0.746196\n",
      " modified Weights  [-1.32401198  1.58487927] 0.7034495834786786\n",
      " Training with pattern  2  weights  [-1.32401198  1.58487927] 0.6766460885055323   weights  [-1.32401198  1.5849614 ]  bias  0.7035317166225863\n",
      "pattern1 0 0 1 0.606605\n",
      "pattern2 0 1 1 0.979638\n",
      "pattern3 1 0 -1 -0.551462\n",
      "pattern4 1 1 1 0.746269\n",
      " modified Weights  [-1.32401198  1.5849614 ] 0.7035317166225863\n",
      " Training with pattern  3  weights  [-1.32401198  1.58487927] 0.6766460885055323   weights  [-1.35522523  1.5849614 ]  bias  0.6723184596318607\n",
      "pattern1 0 0 1 0.586503\n",
      "pattern2 0 1 1 0.97834\n",
      "pattern3 1 0 -1 -0.593406\n",
      "pattern4 1 1 1 0.717297\n",
      " modified Weights  [-1.35522523  1.5849614 ] 0.6723184596318607\n",
      " Training with pattern  4  weights  [-1.32401198  1.58487927] 0.6766460885055323   weights  [-1.34150041  1.59868622]  bias  0.6860432816100613\n",
      "pattern1 0 0 1 0.595434\n",
      "pattern2 0 1 1 0.979485\n",
      "pattern3 1 0 -1 -0.575332\n",
      "pattern4 1 1 1 0.736702\n",
      " modified Weights  [-1.34150041  1.59868622] 0.6860432816100613\n",
      "+++++++++++Epoch  35  cost=  0.41376278978031034\n",
      " Training with pattern  1  weights  [-1.34150041  1.59868622] 0.6860432816100613   weights  [-1.34150041  1.59868622]  bias  0.7121563184155094\n",
      "pattern1 0 0 1 0.612027\n",
      "pattern2 0 1 1 0.980519\n",
      "pattern3 1 0 -1 -0.5576\n",
      "pattern4 1 1 1 0.748415\n",
      " modified Weights  [-1.34150041  1.59868622] 0.7121563184155094\n",
      " Training with pattern  2  weights  [-1.34150041  1.59868622] 0.6860432816100613   weights  [-1.34150041  1.59876138]  bias  0.7122314794095926\n",
      "pattern1 0 0 1 0.612074\n",
      "pattern2 0 1 1 0.980525\n",
      "pattern3 1 0 -1 -0.557549\n",
      "pattern4 1 1 1 0.748481\n",
      " modified Weights  [-1.34150041  1.59876138] 0.7122314794095926\n",
      " Training with pattern  3  weights  [-1.34150041  1.59868622] 0.6860432816100613   weights  [-1.37199149  1.59876138]  bias  0.6817404047983011\n",
      "pattern1 0 0 1 0.59265\n",
      "pattern2 0 1 1 0.979313\n",
      "pattern3 1 0 -1 -0.598143\n",
      "pattern4 1 1 1 0.720416\n",
      " modified Weights  [-1.37199149  1.59876138] 0.6817404047983011\n",
      " Training with pattern  4  weights  [-1.34150041  1.59868622] 0.6860432816100613   weights  [-1.35854352  1.61220935]  bias  0.6951883749767476\n",
      "pattern1 0 0 1 0.601305\n",
      "pattern2 0 1 1 0.980386\n",
      "pattern3 1 0 -1 -0.580592\n",
      "pattern4 1 1 1 0.739264\n",
      " modified Weights  [-1.35854352  1.61220935] 0.6951883749767476\n",
      "+++++++++++Epoch  36  cost=  0.403229068604199\n",
      " Training with pattern  1  weights  [-1.35854352  1.61220935] 0.6951883749767476   weights  [-1.35854352  1.61220935]  bias  0.7206423777511953\n",
      "pattern1 0 0 1 0.617307\n",
      "pattern2 0 1 1 0.98135\n",
      "pattern3 1 0 -1 -0.563469\n",
      "pattern4 1 1 1 0.750591\n",
      " modified Weights  [-1.35854352  1.61220935] 0.7206423777511953\n",
      " Training with pattern  2  weights  [-1.35854352  1.61220935] 0.6951883749767476   weights  [-1.35854352  1.61227827]  bias  0.7207112914013245\n",
      "pattern1 0 0 1 0.61735\n",
      "pattern2 0 1 1 0.981355\n",
      "pattern3 1 0 -1 -0.563422\n",
      "pattern4 1 1 1 0.750652\n",
      " modified Weights  [-1.35854352  1.61227827] 0.7207112914013245\n",
      " Training with pattern  3  weights  [-1.35854352  1.61220935] 0.6951883749767476   weights  [-1.38834243  1.61227827]  bias  0.6909123819689842\n",
      "pattern1 0 0 1 0.598568\n",
      "pattern2 0 1 1 0.980222\n",
      "pattern3 1 0 -1 -0.602734\n",
      "pattern4 1 1 1 0.723451\n",
      " modified Weights  [-1.38834243  1.61227827] 0.6909123819689842\n",
      " Training with pattern  4  weights  [-1.35854352  1.61220935] 0.6951883749767476   weights  [-1.3751616  1.6254591]  bias  0.704093212387199\n",
      "pattern1 0 0 1 0.606959\n",
      "pattern2 0 1 1 0.981228\n",
      "pattern3 1 0 -1 -0.585682\n",
      "pattern4 1 1 1 0.741764\n",
      " modified Weights  [-1.3751616  1.6254591] 0.704093212387199\n",
      "+++++++++++Epoch  37  cost=  0.393178101353036\n",
      " Training with pattern  1  weights  [-1.3751616  1.6254591] 0.704093212387199   weights  [-1.3751616  1.6254591]  bias  0.7289176596119263\n",
      "pattern1 0 0 1 0.622403\n",
      "pattern2 0 1 1 0.982129\n",
      "pattern3 1 0 -1 -0.569136\n",
      "pattern4 1 1 1 0.752726\n",
      " modified Weights  [-1.3751616  1.6254591] 0.7289176596119263\n",
      " Training with pattern  2  weights  [-1.3751616  1.6254591] 0.704093212387199   weights  [-1.3751616  1.6255224]  bias  0.728980962639244\n",
      "pattern1 0 0 1 0.622442\n",
      "pattern2 0 1 1 0.982134\n",
      "pattern3 1 0 -1 -0.569093\n",
      "pattern4 1 1 1 0.752781\n",
      " modified Weights  [-1.3751616  1.6255224] 0.728980962639244\n",
      " Training with pattern  3  weights  [-1.3751616  1.6254591] 0.704093212387199   weights  [-1.40429663  1.6255224 ]  bias  0.699845932575692\n",
      "pattern1 0 0 1 0.60427\n",
      "pattern2 0 1 1 0.981072\n",
      "pattern3 1 0 -1 -0.607185\n",
      "pattern4 1 1 1 0.726404\n",
      " modified Weights  [-1.40429663  1.6255224 ] 0.699845932575692\n",
      " Training with pattern  4  weights  [-1.3751616  1.6254591] 0.704093212387199   weights  [-1.39137367  1.63844536]  bias  0.7127688887842146\n",
      "pattern1 0 0 1 0.61241\n",
      "pattern2 0 1 1 0.982017\n",
      "pattern3 1 0 -1 -0.590612\n",
      "pattern4 1 1 1 0.744206\n",
      " modified Weights  [-1.39137367  1.63844536] 0.7127688887842146\n",
      "+++++++++++Epoch  38  cost=  0.38357880947181094\n",
      " Training with pattern  1  weights  [-1.39137367  1.63844536] 0.7127688887842146   weights  [-1.39137367  1.63844536]  bias  0.736991459103751\n",
      "pattern1 0 0 1 0.627324\n",
      "pattern2 0 1 1 0.98286\n",
      "pattern3 1 0 -1 -0.574613\n",
      "pattern4 1 1 1 0.754819\n",
      " modified Weights  [-1.39137367  1.63844536] 0.736991459103751\n",
      " Training with pattern  2  weights  [-1.39137367  1.63844536] 0.7127688887842146   weights  [-1.39137367  1.63850361]  bias  0.7370497122882091\n",
      "pattern1 0 0 1 0.627359\n",
      "pattern2 0 1 1 0.982864\n",
      "pattern3 1 0 -1 -0.574574\n",
      "pattern4 1 1 1 0.75487\n",
      " modified Weights  [-1.39137367  1.63850361] 0.7370497122882091\n",
      " Training with pattern  3  weights  [-1.39137367  1.63844536] 0.7127688887842146   weights  [-1.4198715   1.63850361]  bias  0.7085518826902089\n",
      "pattern1 0 0 1 0.609768\n",
      "pattern2 0 1 1 0.981868\n",
      "pattern3 1 0 -1 -0.611504\n",
      "pattern4 1 1 1 0.729278\n",
      " modified Weights  [-1.4198715   1.63850361] 0.7085518826902089\n",
      " Training with pattern  4  weights  [-1.39137367  1.63844536] 0.7127688887842146   weights  [-1.40719758  1.65117753]  bias  0.7212258064532949\n",
      "pattern1 0 0 1 0.617668\n",
      "pattern2 0 1 1 0.982756\n",
      "pattern3 1 0 -1 -0.595388\n",
      "pattern4 1 1 1 0.74659\n",
      " modified Weights  [-1.40719758  1.65117753] 0.7212258064532949\n",
      "+++++++++++Epoch  39  cost=  0.3744026494812806\n",
      " Training with pattern  1  weights  [-1.40719758  1.65117753] 0.7212258064532949   weights  [-1.40719758  1.65117753]  bias  0.7448725123036968\n",
      "pattern1 0 0 1 0.63208\n",
      "pattern2 0 1 1 0.983546\n",
      "pattern3 1 0 -1 -0.579909\n",
      "pattern4 1 1 1 0.756873\n",
      " modified Weights  [-1.40719758  1.65117753] 0.7448725123036968\n",
      " Training with pattern  2  weights  [-1.40719758  1.65117753] 0.7212258064532949   weights  [-1.40719758  1.65123123]  bias  0.7449262107681907\n",
      "pattern1 0 0 1 0.632112\n",
      "pattern2 0 1 1 0.98355\n",
      "pattern3 1 0 -1 -0.579873\n",
      "pattern4 1 1 1 0.756918\n",
      " modified Weights  [-1.40719758  1.65123123] 0.7449262107681907\n",
      " Training with pattern  3  weights  [-1.40719758  1.65117753] 0.7212258064532949   weights  [-1.43508339  1.65123123]  bias  0.7170403956909915\n",
      "pattern1 0 0 1 0.615073\n",
      "pattern2 0 1 1 0.982615\n",
      "pattern3 1 0 -1 -0.615696\n",
      "pattern4 1 1 1 0.732077\n",
      " modified Weights  [-1.43508339  1.65123123] 0.7170403956909915\n",
      " Training with pattern  4  weights  [-1.40719758  1.65117753] 0.7212258064532949   weights  [-1.42265006  1.66366456]  bias  0.7294737267555094\n",
      "pattern1 0 0 1 0.622743\n",
      "pattern2 0 1 1 0.983451\n",
      "pattern3 1 0 -1 -0.600019\n",
      "pattern4 1 1 1 0.748919\n",
      " modified Weights  [-1.42265006  1.66366456] 0.7294737267555094\n",
      "+++++++++++Epoch  40  cost=  0.3656233656233318\n",
      " Training with pattern  1  weights  [-1.42265006  1.66366456] 0.7294737267555094   weights  [-1.42265006  1.66366456]  bias  0.7525690368356338\n",
      "pattern1 0 0 1 0.636679\n",
      "pattern2 0 1 1 0.984192\n",
      "pattern3 1 0 -1 -0.585033\n",
      "pattern4 1 1 1 0.758886\n",
      " modified Weights  [-1.42265006  1.66366456] 0.7525690368356338\n",
      " Training with pattern  2  weights  [-1.42265006  1.66366456] 0.7294737267555094   weights  [-1.42265006  1.66371415]  bias  0.7526186187819948\n",
      "pattern1 0 0 1 0.636709\n",
      "pattern2 0 1 1 0.984195\n",
      "pattern3 1 0 -1 -0.585001\n",
      "pattern4 1 1 1 0.758928\n",
      " modified Weights  [-1.42265006  1.66371415] 0.7526186187819948\n",
      " Training with pattern  3  weights  [-1.42265006  1.66366456] 0.7294737267555094   weights  [-1.44994766  1.66371415]  bias  0.7253210208021313\n",
      "pattern1 0 0 1 0.620194\n",
      "pattern2 0 1 1 0.983316\n",
      "pattern3 1 0 -1 -0.619767\n",
      "pattern4 1 1 1 0.734803\n",
      " modified Weights  [-1.44994766  1.66371415] 0.7253210208021313\n",
      " Training with pattern  4  weights  [-1.42265006  1.66366456] 0.7294737267555094   weights  [-1.43774686  1.67591494]  bias  0.7375218176913514\n",
      "pattern1 0 0 1 0.627646\n",
      "pattern2 0 1 1 0.984104\n",
      "pattern3 1 0 -1 -0.604511\n",
      "pattern4 1 1 1 0.751194\n",
      " modified Weights  [-1.43774686  1.67591494] 0.7375218176913514\n",
      "+++++++++++Epoch  41  cost=  0.3572167703222871\n",
      " *********Epoch  40 Error  0.3572167703222871\n",
      " Training with pattern  1  weights  [-1.43774686  1.67591494] 0.7375218176913514   weights  [-1.43774686  1.67591494]  bias  0.760088769240692\n",
      "pattern1 0 0 1 0.641129\n",
      "pattern2 0 1 1 0.9848\n",
      "pattern3 1 0 -1 -0.589995\n",
      "pattern4 1 1 1 0.760861\n",
      " modified Weights  [-1.43774686  1.67591494] 0.760088769240692\n",
      " Training with pattern  2  weights  [-1.43774686  1.67591494] 0.7375218176913514   weights  [-1.43774686  1.6759608 ]  bias  0.7601346233925432\n",
      "pattern1 0 0 1 0.641156\n",
      "pattern2 0 1 1 0.984803\n",
      "pattern3 1 0 -1 -0.589965\n",
      "pattern4 1 1 1 0.7609\n",
      " modified Weights  [-1.43774686  1.6759608 ] 0.7601346233925432\n",
      " Training with pattern  3  weights  [-1.43774686  1.67591494] 0.7375218176913514   weights  [-1.46447875  1.6759608 ]  bias  0.7334027377747855\n",
      "pattern1 0 0 1 0.625143\n",
      "pattern2 0 1 1 0.983975\n",
      "pattern3 1 0 -1 -0.623723\n",
      "pattern4 1 1 1 0.737459\n",
      " modified Weights  [-1.46447875  1.6759608 ] 0.7334027377747855\n",
      " Training with pattern  4  weights  [-1.43774686  1.67591494] 0.7375218176913514   weights  [-1.45250279  1.68793676]  bias  0.7453786975924076\n",
      "pattern1 0 0 1 0.632384\n",
      "pattern2 0 1 1 0.984719\n",
      "pattern3 1 0 -1 -0.60887\n",
      "pattern4 1 1 1 0.753417\n",
      " modified Weights  [-1.45250279  1.68793676] 0.7453786975924076\n",
      "+++++++++++Epoch  42  cost=  0.3491605489510374\n",
      " Training with pattern  1  weights  [-1.45250279  1.68793676] 0.7453786975924076   weights  [-1.45250279  1.68793676]  bias  0.7674389993668658\n",
      "pattern1 0 0 1 0.645438\n",
      "pattern2 0 1 1 0.985374\n",
      "pattern3 1 0 -1 -0.594802\n",
      "pattern4 1 1 1 0.762798\n",
      " modified Weights  [-1.45250279  1.68793676] 0.7674389993668658\n",
      " Training with pattern  2  weights  [-1.45250279  1.68793676] 0.7453786975924076   weights  [-1.45250279  1.68797923]  bias  0.767481471328947\n",
      "pattern1 0 0 1 0.645463\n",
      "pattern2 0 1 1 0.985376\n",
      "pattern3 1 0 -1 -0.594774\n",
      "pattern4 1 1 1 0.762834\n",
      " modified Weights  [-1.45250279  1.68797923] 0.767481471328947\n",
      " Training with pattern  3  weights  [-1.45250279  1.68793676] 0.7453786975924076   weights  [-1.47869026  1.68797923]  bias  0.7412939979898285\n",
      "pattern1 0 0 1 0.629926\n",
      "pattern2 0 1 1 0.984596\n",
      "pattern3 1 0 -1 -0.627569\n",
      "pattern4 1 1 1 0.740047\n",
      " modified Weights  [-1.47869026  1.68797923] 0.7412939979898285\n",
      " Training with pattern  4  weights  [-1.45250279  1.68793676] 0.7453786975924076   weights  [-1.46693178  1.69973771]  bias  0.7530524752383092\n",
      "pattern1 0 0 1 0.636966\n",
      "pattern2 0 1 1 0.985299\n",
      "pattern3 1 0 -1 -0.613104\n",
      "pattern4 1 1 1 0.755591\n",
      " modified Weights  [-1.46693178  1.69973771] 0.7530524752383092\n",
      "+++++++++++Epoch  43  cost=  0.3414340858784171\n",
      " Training with pattern  1  weights  [-1.46693178  1.69973771] 0.7530524752383092   weights  [-1.46693178  1.69973771]  bias  0.7746266020037673\n",
      "pattern1 0 0 1 0.649612\n",
      "pattern2 0 1 1 0.985915\n",
      "pattern3 1 0 -1 -0.599461\n",
      "pattern4 1 1 1 0.764698\n",
      " modified Weights  [-1.46693178  1.69973771] 0.7746266020037673\n",
      " Training with pattern  2  weights  [-1.46693178  1.69973771] 0.7530524752383092   weights  [-1.46693178  1.6997771 ]  bias  0.7746659997105876\n",
      "pattern1 0 0 1 0.649634\n",
      "pattern2 0 1 1 0.985917\n",
      "pattern3 1 0 -1 -0.599436\n",
      "pattern4 1 1 1 0.764731\n",
      " modified Weights  [-1.46693178  1.6997771 ] 0.7746659997105876\n",
      " Training with pattern  3  weights  [-1.46693178  1.69973771] 0.7530524752383092   weights  [-1.49259502  1.6997771 ]  bias  0.7490027622569675\n",
      "pattern1 0 0 1 0.634554\n",
      "pattern2 0 1 1 0.985181\n",
      "pattern3 1 0 -1 -0.631311\n",
      "pattern4 1 1 1 0.74257\n",
      " modified Weights  [-1.49259502  1.6997771 ] 0.7490027622569675\n",
      " Training with pattern  4  weights  [-1.46693178  1.69973771] 0.7530524752383092   weights  [-1.481047    1.71132513]  bias  0.7605507866872929\n",
      "pattern1 0 0 1 0.641401\n",
      "pattern2 0 1 1 0.985845\n",
      "pattern3 1 0 -1 -0.617217\n",
      "pattern4 1 1 1 0.757716\n",
      " modified Weights  [-1.481047    1.71132513] 0.7605507866872929\n",
      "+++++++++++Epoch  44  cost=  0.33401830918855535\n",
      " Training with pattern  1  weights  [-1.481047    1.71132513] 0.7605507866872929   weights  [-1.481047    1.71132513]  bias  0.7816580659819273\n",
      "pattern1 0 0 1 0.653657\n",
      "pattern2 0 1 1 0.986426\n",
      "pattern3 1 0 -1 -0.60398\n",
      "pattern4 1 1 1 0.766562\n",
      " modified Weights  [-1.481047    1.71132513] 0.7816580659819273\n",
      " Training with pattern  2  weights  [-1.481047    1.71132513] 0.7605507866872929   weights  [-1.481047    1.71136173]  bias  0.7816946643787548\n",
      "pattern1 0 0 1 0.653678\n",
      "pattern2 0 1 1 0.986428\n",
      "pattern3 1 0 -1 -0.603957\n",
      "pattern4 1 1 1 0.766592\n",
      " modified Weights  [-1.481047    1.71136173] 0.7816946643787548\n",
      " Training with pattern  3  weights  [-1.481047    1.71132513] 0.7605507866872929   weights  [-1.50620512  1.71136173]  bias  0.7565365355749654\n",
      "pattern1 0 0 1 0.639032\n",
      "pattern2 0 1 1 0.985733\n",
      "pattern3 1 0 -1 -0.634951\n",
      "pattern4 1 1 1 0.745031\n",
      " modified Weights  [-1.50620512  1.71136173] 0.7565365355749654\n",
      " Training with pattern  4  weights  [-1.481047    1.71132513] 0.7605507866872929   weights  [-1.49486083  1.72270602]  bias  0.7678808290940304\n",
      "pattern1 0 0 1 0.645696\n",
      "pattern2 0 1 1 0.986362\n",
      "pattern3 1 0 -1 -0.621214\n",
      "pattern4 1 1 1 0.759793\n",
      " modified Weights  [-1.49486083  1.72270602] 0.7678808290940304\n",
      "+++++++++++Epoch  45  cost=  0.3268955518157067\n",
      " Training with pattern  1  weights  [-1.49486083  1.72270602] 0.7678808290940304   weights  [-1.49486083  1.72270602]  bias  0.7885395209450469\n",
      "pattern1 0 0 1 0.657581\n",
      "pattern2 0 1 1 0.98691\n",
      "pattern3 1 0 -1 -0.608365\n",
      "pattern4 1 1 1 0.76839\n",
      " modified Weights  [-1.49486083  1.72270602] 0.7885395209450469\n",
      " Training with pattern  2  weights  [-1.49486083  1.72270602] 0.7678808290940304   weights  [-1.49486083  1.72274007]  bias  0.7885735660199195\n",
      "pattern1 0 0 1 0.6576\n",
      "pattern2 0 1 1 0.986912\n",
      "pattern3 1 0 -1 -0.608343\n",
      "pattern4 1 1 1 0.768418\n",
      " modified Weights  [-1.49486083  1.72274007] 0.7885735660199195\n",
      " Training with pattern  3  weights  [-1.49486083  1.72270602] 0.7678808290940304   weights  [-1.519532    1.72274007]  bias  0.7639023991030783\n",
      "pattern1 0 0 1 0.64337\n",
      "pattern2 0 1 1 0.986254\n",
      "pattern3 1 0 -1 -0.638495\n",
      "pattern4 1 1 1 0.747432\n",
      " modified Weights  [-1.519532    1.72274007] 0.7639023991030783\n",
      " Training with pattern  4  weights  [-1.49486083  1.72270602] 0.7678808290940304   weights  [-1.50838501  1.73388706]  bias  0.7750493917708939\n",
      "pattern1 0 0 1 0.649856\n",
      "pattern2 0 1 1 0.98685\n",
      "pattern3 1 0 -1 -0.625102\n",
      "pattern4 1 1 1 0.761826\n",
      " modified Weights  [-1.50838501  1.73388706] 0.7750493917708939\n",
      "+++++++++++Epoch  46  cost=  0.3200494271390899\n",
      " Training with pattern  1  weights  [-1.50838501  1.73388706] 0.7750493917708939   weights  [-1.50838501  1.73388706]  bias  0.7952767619903715\n",
      "pattern1 0 0 1 0.661388\n",
      "pattern2 0 1 1 0.987368\n",
      "pattern3 1 0 -1 -0.612622\n",
      "pattern4 1 1 1 0.770184\n",
      " modified Weights  [-1.50838501  1.73388706] 0.7952767619903715\n",
      " Training with pattern  2  weights  [-1.50838501  1.73388706] 0.7750493917708939   weights  [-1.50838501  1.73391877]  bias  0.7953084742559229\n",
      "pattern1 0 0 1 0.661406\n",
      "pattern2 0 1 1 0.98737\n",
      "pattern3 1 0 -1 -0.612602\n",
      "pattern4 1 1 1 0.770209\n",
      " modified Weights  [-1.50838501  1.73391877] 0.7953084742559229\n",
      " Training with pattern  3  weights  [-1.50838501  1.73388706] 0.7750493917708939   weights  [-1.53258644  1.73391877]  bias  0.7711070395773435\n",
      "pattern1 0 0 1 0.647573\n",
      "pattern2 0 1 1 0.986747\n",
      "pattern3 1 0 -1 -0.641948\n",
      "pattern4 1 1 1 0.749774\n",
      " modified Weights  [-1.53258644  1.73391877] 0.7711070395773435\n",
      " Training with pattern  4  weights  [-1.50838501  1.73388706] 0.7750493917708939   weights  [-1.52163059  1.74487462]  bias  0.7820628847301918\n",
      "pattern1 0 0 1 0.653889\n",
      "pattern2 0 1 1 0.987312\n",
      "pattern3 1 0 -1 -0.628884\n",
      "pattern4 1 1 1 0.763814\n",
      " modified Weights  [-1.52163059  1.74487462] 0.7820628847301918\n",
      "+++++++++++Epoch  47  cost=  0.313464717339648\n",
      " Training with pattern  1  weights  [-1.52163059  1.74487462] 0.7820628847301918   weights  [-1.52163059  1.74487462]  bias  0.8018752723582143\n",
      "pattern1 0 0 1 0.665084\n",
      "pattern2 0 1 1 0.987802\n",
      "pattern3 1 0 -1 -0.616758\n",
      "pattern4 1 1 1 0.771943\n",
      " modified Weights  [-1.52163059  1.74487462] 0.8018752723582143\n",
      " Training with pattern  2  weights  [-1.52163059  1.74487462] 0.7820628847301918   weights  [-1.52163059  1.74490419]  bias  0.8019048498658005\n",
      "pattern1 0 0 1 0.6651\n",
      "pattern2 0 1 1 0.987803\n",
      "pattern3 1 0 -1 -0.616739\n",
      "pattern4 1 1 1 0.771967\n",
      " modified Weights  [-1.52163059  1.74490419] 0.8019048498658005\n",
      " Training with pattern  3  weights  [-1.52163059  1.74487462] 0.7820628847301918   weights  [-1.54537867  1.74490419]  bias  0.7781567763882248\n",
      "pattern1 0 0 1 0.651647\n",
      "pattern2 0 1 1 0.987214\n",
      "pattern3 1 0 -1 -0.645311\n",
      "pattern4 1 1 1 0.752061\n",
      " modified Weights  [-1.54537867  1.74490419] 0.7781567763882248\n",
      " Training with pattern  4  weights  [-1.52163059  1.74487462] 0.7820628847301918   weights  [-1.53460808  1.75567478]  bias  0.7889273649261869\n",
      "pattern1 0 0 1 0.657801\n",
      "pattern2 0 1 1 0.98775\n",
      "pattern3 1 0 -1 -0.632565\n",
      "pattern4 1 1 1 0.76576\n",
      " modified Weights  [-1.53460808  1.75567478] 0.7889273649261869\n",
      "+++++++++++Epoch  48  cost=  0.3071272730411626\n",
      " Training with pattern  1  weights  [-1.53460808  1.75567478] 0.7889273649261869   weights  [-1.53460808  1.75567478]  bias  0.8083402443374526\n",
      "pattern1 0 0 1 0.668674\n",
      "pattern2 0 1 1 0.988213\n",
      "pattern3 1 0 -1 -0.620777\n",
      "pattern4 1 1 1 0.77367\n",
      " modified Weights  [-1.53460808  1.75567478] 0.8083402443374526\n",
      " Training with pattern  2  weights  [-1.53460808  1.75567478] 0.7889273649261869   weights  [-1.53460808  1.7557024 ]  bias  0.8083678652926427\n",
      "pattern1 0 0 1 0.668689\n",
      "pattern2 0 1 1 0.988215\n",
      "pattern3 1 0 -1 -0.62076\n",
      "pattern4 1 1 1 0.773693\n",
      " modified Weights  [-1.53460808  1.7557024 ] 0.8083678652926427\n",
      " Training with pattern  3  weights  [-1.53460808  1.75567478] 0.7889273649261869   weights  [-1.55791836  1.7557024 ]  bias  0.7850575865191093\n",
      "pattern1 0 0 1 0.6556\n",
      "pattern2 0 1 1 0.987656\n",
      "pattern3 1 0 -1 -0.64859\n",
      "pattern4 1 1 1 0.754293\n",
      " modified Weights  [-1.55791836  1.7557024 ] 0.7850575865191093\n",
      " Training with pattern  4  weights  [-1.53460808  1.75567478] 0.7889273649261869   weights  [-1.54732738  1.76629338]  bias  0.7956485603975241\n",
      "pattern1 0 0 1 0.661597\n",
      "pattern2 0 1 1 0.988165\n",
      "pattern3 1 0 -1 -0.636149\n",
      "pattern4 1 1 1 0.767664\n",
      " modified Weights  [-1.54732738  1.76629338] 0.7956485603975241\n",
      "+++++++++++Epoch  49  cost=  0.30102392294752\n",
      " Training with pattern  1  weights  [-1.54732738  1.76629338] 0.7956485603975241   weights  [-1.54732738  1.76629338]  bias  0.8146765985400226\n",
      "pattern1 0 0 1 0.672162\n",
      "pattern2 0 1 1 0.988604\n",
      "pattern3 1 0 -1 -0.624684\n",
      "pattern4 1 1 1 0.775365\n",
      " modified Weights  [-1.54732738  1.76629338] 0.8146765985400226\n",
      " Training with pattern  2  weights  [-1.54732738  1.76629338] 0.7956485603975241   weights  [-1.54732738  1.7663192 ]  bias  0.8147024235774464\n",
      "pattern1 0 0 1 0.672176\n",
      "pattern2 0 1 1 0.988605\n",
      "pattern3 1 0 -1 -0.624669\n",
      "pattern4 1 1 1 0.775386\n",
      " modified Weights  [-1.54732738  1.7663192 ] 0.8147024235774464\n",
      " Training with pattern  3  weights  [-1.54732738  1.76629338] 0.7956485603975241   weights  [-1.57021468  1.7663192 ]  bias  0.7918151275287314\n",
      "pattern1 0 0 1 0.659436\n",
      "pattern2 0 1 1 0.988075\n",
      "pattern3 1 0 -1 -0.651787\n",
      "pattern4 1 1 1 0.756474\n",
      " modified Weights  [-1.57021468  1.7663192 ] 0.7918151275287314\n",
      " Training with pattern  4  weights  [-1.54732738  1.76629338] 0.7956485603975241   weights  [-1.55979792  1.77673597]  bias  0.8022318924934151\n",
      "pattern1 0 0 1 0.665283\n",
      "pattern2 0 1 1 0.988559\n",
      "pattern3 1 0 -1 -0.639641\n",
      "pattern4 1 1 1 0.769528\n",
      " modified Weights  [-1.55979792  1.77673597] 0.8022318924934151\n",
      "+++++++++++Epoch  50  cost=  0.295142392350803\n",
      " Training with pattern  1  weights  [-1.55979792  1.77673597] 0.8022318924934151   weights  [-1.55979792  1.77673597]  bias  0.8208890016843464\n",
      "pattern1 0 0 1 0.675553\n",
      "pattern2 0 1 1 0.988975\n",
      "pattern3 1 0 -1 -0.628486\n",
      "pattern4 1 1 1 0.777029\n",
      " modified Weights  [-1.55979792  1.77673597] 0.8208890016843464\n",
      " Training with pattern  2  weights  [-1.55979792  1.77673597] 0.8022318924934151   weights  [-1.55979792  1.77676014]  bias  0.8209131758507231\n",
      "pattern1 0 0 1 0.675567\n",
      "pattern2 0 1 1 0.988977\n",
      "pattern3 1 0 -1 -0.628471\n",
      "pattern4 1 1 1 0.777048\n",
      " modified Weights  [-1.55979792  1.77676014] 0.8209131758507231\n",
      " Training with pattern  3  weights  [-1.55979792  1.77673597] 0.8022318924934151   weights  [-1.58227633  1.77676014]  bias  0.798434758745045\n",
      "pattern1 0 0 1 0.663161\n",
      "pattern2 0 1 1 0.988473\n",
      "pattern3 1 0 -1 -0.654906\n",
      "pattern4 1 1 1 0.758604\n",
      " modified Weights  [-1.58227633  1.77676014] 0.798434758745045\n",
      " Training with pattern  4  weights  [-1.55979792  1.77673597] 0.8022318924934151   weights  [-1.5720286   1.78700788]  bias  0.8086824963507505\n",
      "pattern1 0 0 1 0.668863\n",
      "pattern2 0 1 1 0.988933\n",
      "pattern3 1 0 -1 -0.643044\n",
      "pattern4 1 1 1 0.771354\n",
      " modified Weights  [-1.5720286   1.78700788] 0.8086824963507505\n",
      "+++++++++++Epoch  51  cost=  0.289471229525318\n",
      " *********Epoch  50 Error  0.289471229525318\n",
      " Training with pattern  1  weights  [-1.5720286   1.78700788] 0.8086824963507505   weights  [-1.5720286   1.78700788]  bias  0.8269818830153742\n",
      "pattern1 0 0 1 0.678852\n",
      "pattern2 0 1 1 0.989329\n",
      "pattern3 1 0 -1 -0.632185\n",
      "pattern4 1 1 1 0.778661\n",
      " modified Weights  [-1.5720286   1.78700788] 0.8269818830153742\n",
      " Training with pattern  2  weights  [-1.5720286   1.78700788] 0.8086824963507505   weights  [-1.5720286   1.78703053]  bias  0.8270045375019445\n",
      "pattern1 0 0 1 0.678864\n",
      "pattern2 0 1 1 0.98933\n",
      "pattern3 1 0 -1 -0.632171\n",
      "pattern4 1 1 1 0.778679\n",
      " modified Weights  [-1.5720286   1.78703053] 0.8270045375019445\n",
      " Training with pattern  3  weights  [-1.5720286   1.78700788] 0.8086824963507505   weights  [-1.59411157  1.78703053]  bias  0.8049215608235268\n",
      "pattern1 0 0 1 0.666779\n",
      "pattern2 0 1 1 0.98885\n",
      "pattern3 1 0 -1 -0.65795\n",
      "pattern4 1 1 1 0.760686\n",
      " modified Weights  [-1.59411157  1.78703053] 0.8049215608235268\n",
      " Training with pattern  4  weights  [-1.5720286   1.78700788] 0.8086824963507505   weights  [-1.58402789  1.79711421]  bias  0.8150052397743097\n",
      "pattern1 0 0 1 0.672342\n",
      "pattern2 0 1 1 0.989289\n",
      "pattern3 1 0 -1 -0.646361\n",
      "pattern4 1 1 1 0.773142\n",
      " modified Weights  [-1.58402789  1.79711421] 0.8150052397743097\n",
      "+++++++++++Epoch  52  cost=  0.28399973914396837\n",
      " Training with pattern  1  weights  [-1.58402789  1.79711421] 0.8150052397743097   weights  [-1.58402789  1.79711421]  bias  0.8329594494775742\n",
      "pattern1 0 0 1 0.682062\n",
      "pattern2 0 1 1 0.989665\n",
      "pattern3 1 0 -1 -0.635786\n",
      "pattern4 1 1 1 0.780264\n",
      " modified Weights  [-1.58402789  1.79711421] 0.8329594494775742\n",
      " Training with pattern  2  weights  [-1.58402789  1.79711421] 0.8150052397743097   weights  [-1.58402789  1.79713547]  bias  0.8329807031368216\n",
      "pattern1 0 0 1 0.682073\n",
      "pattern2 0 1 1 0.989665\n",
      "pattern3 1 0 -1 -0.635773\n",
      "pattern4 1 1 1 0.780281\n",
      " modified Weights  [-1.58402789  1.79713547] 0.8329807031368216\n",
      " Training with pattern  3  weights  [-1.58402789  1.79711421] 0.8150052397743097   weights  [-1.60572824  1.79713547]  bias  0.8112803538094019\n",
      "pattern1 0 0 1 0.670296\n",
      "pattern2 0 1 1 0.98921\n",
      "pattern3 1 0 -1 -0.660921\n",
      "pattern4 1 1 1 0.762721\n",
      " modified Weights  [-1.60572824  1.79713547] 0.8112803538094019\n",
      " Training with pattern  4  weights  [-1.58402789  1.79711421] 0.8150052397743097   weights  [-1.59580386  1.80705985]  bias  0.8212047406584362\n",
      "pattern1 0 0 1 0.675725\n",
      "pattern2 0 1 1 0.989627\n",
      "pattern3 1 0 -1 -0.649596\n",
      "pattern4 1 1 1 0.774893\n",
      " modified Weights  [-1.59580386  1.80705985] 0.8212047406584362\n",
      "+++++++++++Epoch  53  cost=  0.27871792195834627\n",
      " Training with pattern  1  weights  [-1.59580386  1.80705985] 0.8212047406584362   weights  [-1.59580386  1.80705985]  bias  0.8388256997467665\n",
      "pattern1 0 0 1 0.685187\n",
      "pattern2 0 1 1 0.989985\n",
      "pattern3 1 0 -1 -0.639294\n",
      "pattern4 1 1 1 0.781838\n",
      " modified Weights  [-1.59580386  1.80705985] 0.8388256997467665\n",
      " Training with pattern  2  weights  [-1.59580386  1.80705985] 0.8212047406584362   weights  [-1.59580386  1.80707981]  bias  0.8388456604230331\n",
      "pattern1 0 0 1 0.685197\n",
      "pattern2 0 1 1 0.989986\n",
      "pattern3 1 0 -1 -0.639282\n",
      "pattern4 1 1 1 0.781854\n",
      " modified Weights  [-1.59580386  1.80707981] 0.8388456604230331\n",
      " Training with pattern  3  weights  [-1.59580386  1.80705985] 0.8212047406584362   weights  [-1.6171338   1.80707981]  bias  0.8175157138308728\n",
      "pattern1 0 0 1 0.673715\n",
      "pattern2 0 1 1 0.989551\n",
      "pattern3 1 0 -1 -0.663823\n",
      "pattern4 1 1 1 0.76471\n",
      " modified Weights  [-1.6171338   1.80707981] 0.8175157138308728\n",
      " Training with pattern  4  weights  [-1.59580386  1.80705985] 0.8212047406584362   weights  [-1.60736413  1.81684948]  bias  0.8272853830759114\n",
      "pattern1 0 0 1 0.679016\n",
      "pattern2 0 1 1 0.98995\n",
      "pattern3 1 0 -1 -0.652752\n",
      "pattern4 1 1 1 0.77661\n",
      " modified Weights  [-1.60736413  1.81684948] 0.8272853830759114\n",
      "+++++++++++Epoch  54  cost=  0.27361642007494646\n",
      " Training with pattern  1  weights  [-1.60736413  1.81684948] 0.8272853830759114   weights  [-1.60736413  1.81684948]  bias  0.8445844372171407\n",
      "pattern1 0 0 1 0.68823\n",
      "pattern2 0 1 1 0.99029\n",
      "pattern3 1 0 -1 -0.642711\n",
      "pattern4 1 1 1 0.783384\n",
      " modified Weights  [-1.60736413  1.81684948] 0.8445844372171407\n",
      " Training with pattern  2  weights  [-1.60736413  1.81684948] 0.8272853830759114   weights  [-1.60736413  1.81686825]  bias  0.8446032029163186\n",
      "pattern1 0 0 1 0.68824\n",
      "pattern2 0 1 1 0.990291\n",
      "pattern3 1 0 -1 -0.6427\n",
      "pattern4 1 1 1 0.783398\n",
      " modified Weights  [-1.60736413  1.81686825] 0.8446032029163186\n",
      " Training with pattern  3  weights  [-1.60736413  1.81684948] 0.8272853830759114   weights  [-1.62833535  1.81686825]  bias  0.8236319885390513\n",
      "pattern1 0 0 1 0.677042\n",
      "pattern2 0 1 1 0.989877\n",
      "pattern3 1 0 -1 -0.666658\n",
      "pattern4 1 1 1 0.766656\n",
      " modified Weights  [-1.62833535  1.81686825] 0.8236319885390513\n",
      " Training with pattern  4  weights  [-1.60736413  1.81684948] 0.8272853830759114   weights  [-1.618716    1.82648759]  bias  0.8332513321482352\n",
      "pattern1 0 0 1 0.682218\n",
      "pattern2 0 1 1 0.990257\n",
      "pattern3 1 0 -1 -0.655832\n",
      "pattern4 1 1 1 0.778292\n",
      " modified Weights  [-1.618716    1.82648759] 0.8332513321482352\n",
      "+++++++++++Epoch  55  cost=  0.26868646723897743\n",
      " Training with pattern  1  weights  [-1.618716    1.82648759] 0.8332513321482352   weights  [-1.618716    1.82648759]  bias  0.8502392820310875\n",
      "pattern1 0 0 1 0.691194\n",
      "pattern2 0 1 1 0.990581\n",
      "pattern3 1 0 -1 -0.646043\n",
      "pattern4 1 1 1 0.784901\n",
      " modified Weights  [-1.618716    1.82648759] 0.8502392820310875\n",
      " Training with pattern  2  weights  [-1.618716    1.82648759] 0.8332513321482352   weights  [-1.618716    1.82650525]  bias  0.8502569419508573\n",
      "pattern1 0 0 1 0.691204\n",
      "pattern2 0 1 1 0.990582\n",
      "pattern3 1 0 -1 -0.646033\n",
      "pattern4 1 1 1 0.784915\n",
      " modified Weights  [-1.618716    1.82650525] 0.8502569419508573\n",
      " Training with pattern  3  weights  [-1.618716    1.82648759] 0.8332513321482352   weights  [-1.63933963  1.82650525]  bias  0.8296333113998905\n",
      "pattern1 0 0 1 0.680279\n",
      "pattern2 0 1 1 0.990187\n",
      "pattern3 1 0 -1 -0.669428\n",
      "pattern4 1 1 1 0.76856\n",
      " modified Weights  [-1.63933963  1.82650525] 0.8296333113998905\n",
      " Training with pattern  4  weights  [-1.618716    1.82648759] 0.8332513321482352   weights  [-1.6298664   1.83597849]  bias  0.8391065478010382\n",
      "pattern1 0 0 1 0.685336\n",
      "pattern2 0 1 1 0.99055\n",
      "pattern3 1 0 -1 -0.658839\n",
      "pattern4 1 1 1 0.779941\n",
      " modified Weights  [-1.6298664   1.83597849] 0.8391065478010382\n",
      "+++++++++++Epoch  56  cost=  0.26391984360606763\n",
      " Training with pattern  1  weights  [-1.6298664   1.83597849] 0.8391065478010382   weights  [-1.6298664   1.83597849]  bias  0.8557936822315408\n",
      "pattern1 0 0 1 0.694084\n",
      "pattern2 0 1 1 0.990859\n",
      "pattern3 1 0 -1 -0.649291\n",
      "pattern4 1 1 1 0.786392\n",
      " modified Weights  [-1.6298664   1.83597849] 0.8557936822315408\n",
      " Training with pattern  2  weights  [-1.6298664   1.83597849] 0.8391065478010382   weights  [-1.6298664   1.83599512]  bias  0.8558103176705075\n",
      "pattern1 0 0 1 0.694093\n",
      "pattern2 0 1 1 0.99086\n",
      "pattern3 1 0 -1 -0.649282\n",
      "pattern4 1 1 1 0.786405\n",
      " modified Weights  [-1.6298664   1.83599512] 0.8558103176705075\n",
      " Training with pattern  3  weights  [-1.6298664   1.83597849] 0.8391065478010382   weights  [-1.6501531   1.83599512]  bias  0.8355236149339486\n",
      "pattern1 0 0 1 0.683431\n",
      "pattern2 0 1 1 0.990483\n",
      "pattern3 1 0 -1 -0.672136\n",
      "pattern4 1 1 1 0.770422\n",
      " modified Weights  [-1.6501531   1.83599512] 0.8355236149339486\n",
      " Training with pattern  4  weights  [-1.6298664   1.83597849] 0.8391065478010382   weights  [-1.64082192  1.84532631]  bias  0.8448547974988365\n",
      "pattern1 0 0 1 0.688372\n",
      "pattern2 0 1 1 0.99083\n",
      "pattern3 1 0 -1 -0.661776\n",
      "pattern4 1 1 1 0.781557\n",
      " modified Weights  [-1.64082192  1.84532631] 0.8448547974988365\n",
      "+++++++++++Epoch  57  cost=  0.2593088345421674\n",
      " Training with pattern  1  weights  [-1.64082192  1.84532631] 0.8448547974988365   weights  [-1.64082192  1.84532631]  bias  0.8612509241093366\n",
      "pattern1 0 0 1 0.696902\n",
      "pattern2 0 1 1 0.991124\n",
      "pattern3 1 0 -1 -0.65246\n",
      "pattern4 1 1 1 0.787857\n",
      " modified Weights  [-1.64082192  1.84532631] 0.8612509241093366\n",
      " Training with pattern  2  weights  [-1.64082192  1.84532631] 0.8448547974988365   weights  [-1.64082192  1.84534199]  bias  0.8612666092707816\n",
      "pattern1 0 0 1 0.69691\n",
      "pattern2 0 1 1 0.991125\n",
      "pattern3 1 0 -1 -0.652451\n",
      "pattern4 1 1 1 0.787869\n",
      " modified Weights  [-1.64082192  1.84534199] 0.8612666092707816\n",
      " Training with pattern  3  weights  [-1.64082192  1.84532631] 0.8448547974988365   weights  [-1.66078188  1.84534199]  bias  0.8413066429911943\n",
      "pattern1 0 0 1 0.686501\n",
      "pattern2 0 1 1 0.990765\n",
      "pattern3 1 0 -1 -0.674784\n",
      "pattern4 1 1 1 0.772245\n",
      " modified Weights  [-1.66078188  1.84534199] 0.8413066429911943\n",
      " Training with pattern  4  weights  [-1.64082192  1.84532631] 0.8448547974988365   weights  [-1.65158886  1.85453502]  bias  0.8504996680447184\n",
      "pattern1 0 0 1 0.69133\n",
      "pattern2 0 1 1 0.991097\n",
      "pattern3 1 0 -1 -0.664645\n",
      "pattern4 1 1 1 0.783142\n",
      " modified Weights  [-1.65158886  1.85453502] 0.8504996680447184\n",
      "+++++++++++Epoch  58  cost=  0.2548461930443626\n",
      " Training with pattern  1  weights  [-1.65158886  1.85453502] 0.8504996680447184   weights  [-1.65158886  1.85453502]  bias  0.866614141811559\n",
      "pattern1 0 0 1 0.69965\n",
      "pattern2 0 1 1 0.991378\n",
      "pattern3 1 0 -1 -0.655553\n",
      "pattern4 1 1 1 0.789296\n",
      " modified Weights  [-1.65158886  1.85453502] 0.866614141811559\n",
      " Training with pattern  2  weights  [-1.65158886  1.85453502] 0.8504996680447184   weights  [-1.65158886  1.85454982]  bias  0.866628944515303\n",
      "pattern1 0 0 1 0.699657\n",
      "pattern2 0 1 1 0.991379\n",
      "pattern3 1 0 -1 -0.655544\n",
      "pattern4 1 1 1 0.789307\n",
      " modified Weights  [-1.65158886  1.85454982] 0.866628944515303\n",
      " Training with pattern  3  weights  [-1.65158886  1.85453502] 0.8504996680447184   weights  [-1.67123184  1.85454982]  bias  0.846985962140244\n",
      "pattern1 0 0 1 0.689492\n",
      "pattern2 0 1 1 0.991035\n",
      "pattern3 1 0 -1 -0.677374\n",
      "pattern4 1 1 1 0.77403\n",
      " modified Weights  [-1.67123184  1.85454982] 0.846985962140244\n",
      " Training with pattern  4  weights  [-1.65158886  1.85453502] 0.8504996680447184   weights  [-1.66217323  1.86360843]  bias  0.8560445765227406\n",
      "pattern1 0 0 1 0.694214\n",
      "pattern2 0 1 1 0.991353\n",
      "pattern3 1 0 -1 -0.667449\n",
      "pattern4 1 1 1 0.784697\n",
      " modified Weights  [-1.66217323  1.86360843] 0.8560445765227406\n",
      "+++++++++++Epoch  59  cost=  0.2505251054211699\n",
      " Training with pattern  1  weights  [-1.66217323  1.86360843] 0.8560445765227406   weights  [-1.66217323  1.86360843]  bias  0.8718863262709321\n",
      "pattern1 0 0 1 0.702331\n",
      "pattern2 0 1 1 0.991621\n",
      "pattern3 1 0 -1 -0.658572\n",
      "pattern4 1 1 1 0.790709\n",
      " modified Weights  [-1.66217323  1.86360843] 0.8718863262709321\n",
      " Training with pattern  2  weights  [-1.66217323  1.86360843] 0.8560445765227406   weights  [-1.66217323  1.86362242]  bias  0.8719003085849175\n",
      "pattern1 0 0 1 0.702338\n",
      "pattern2 0 1 1 0.991622\n",
      "pattern3 1 0 -1 -0.658564\n",
      "pattern4 1 1 1 0.79072\n",
      " modified Weights  [-1.66217323  1.86362242] 0.8719003085849175\n",
      " Training with pattern  3  weights  [-1.66217323  1.86360843] 0.8560445765227406   weights  [-1.68150856  1.86362242]  bias  0.8525649722443156\n",
      "pattern1 0 0 1 0.692407\n",
      "pattern2 0 1 1 0.991293\n",
      "pattern3 1 0 -1 -0.679908\n",
      "pattern4 1 1 1 0.775778\n",
      " modified Weights  [-1.68150856  1.86362242] 0.8525649722443156\n",
      " Training with pattern  4  weights  [-1.66217323  1.86360843] 0.8560445765227406   weights  [-1.67258076  1.87255022]  bias  0.8614927804537446\n",
      "pattern1 0 0 1 0.697026\n",
      "pattern2 0 1 1 0.991597\n",
      "pattern3 1 0 -1 -0.67019\n",
      "pattern4 1 1 1 0.786223\n",
      " modified Weights  [-1.67258076  1.87255022] 0.8614927804537446\n",
      "+++++++++++Epoch  60  cost=  0.24633915991108565\n",
      " Training with pattern  1  weights  [-1.67258076  1.87255022] 0.8614927804537446   weights  [-1.67258076  1.87255022]  bias  0.8770703335109522\n",
      "pattern1 0 0 1 0.704949\n",
      "pattern2 0 1 1 0.991854\n",
      "pattern3 1 0 -1 -0.661519\n",
      "pattern4 1 1 1 0.792099\n",
      " modified Weights  [-1.67258076  1.87255022] 0.8770703335109522\n",
      " Training with pattern  2  weights  [-1.67258076  1.87255022] 0.8614927804537446   weights  [-1.67258076  1.87256344]  bias  0.8770835523125557\n",
      "pattern1 0 0 1 0.704955\n",
      "pattern2 0 1 1 0.991854\n",
      "pattern3 1 0 -1 -0.661512\n",
      "pattern4 1 1 1 0.792109\n",
      " modified Weights  [-1.67258076  1.87256344] 0.8770835523125557\n",
      " Training with pattern  3  weights  [-1.67258076  1.87255022] 0.8614927804537446   weights  [-1.69161739  1.87256344]  bias  0.8580469162897479\n",
      "pattern1 0 0 1 0.69525\n",
      "pattern2 0 1 1 0.991539\n",
      "pattern3 1 0 -1 -0.682389\n",
      "pattern4 1 1 1 0.77749\n",
      " modified Weights  [-1.69161739  1.87256344] 0.8580469162897479\n",
      " Training with pattern  4  weights  [-1.67258076  1.87255022] 0.8614927804537446   weights  [-1.68281692  1.88136391]  bias  0.8668473872289144\n",
      "pattern1 0 0 1 0.699769\n",
      "pattern2 0 1 1 0.991831\n",
      "pattern3 1 0 -1 -0.67287\n",
      "pattern4 1 1 1 0.78772\n",
      " modified Weights  [-1.68281692  1.88136391] 0.8668473872289144\n",
      "+++++++++++Epoch  61  cost=  0.24228231795343996\n",
      " *********Epoch  60 Error  0.24228231795343996\n",
      " Training with pattern  1  weights  [-1.68281692  1.88136391] 0.8668473872289144   weights  [-1.68281692  1.88136391]  bias  0.8821688923766059\n",
      "pattern1 0 0 1 0.707504\n",
      "pattern2 0 1 1 0.992076\n",
      "pattern3 1 0 -1 -0.664399\n",
      "pattern4 1 1 1 0.793464\n",
      " modified Weights  [-1.68281692  1.88136391] 0.8821688923766059\n",
      " Training with pattern  2  weights  [-1.68281692  1.88136391] 0.8668473872289144   weights  [-1.68281692  1.88137642]  bias  0.8821813998523264\n",
      "pattern1 0 0 1 0.70751\n",
      "pattern2 0 1 1 0.992077\n",
      "pattern3 1 0 -1 -0.664392\n",
      "pattern4 1 1 1 0.793474\n",
      " modified Weights  [-1.68281692  1.88137642] 0.8821813998523264\n",
      " Training with pattern  3  weights  [-1.68281692  1.88136391] 0.8668473872289144   weights  [-1.70156343  1.88137642]  bias  0.8634348895270948\n",
      "pattern1 0 0 1 0.698023\n",
      "pattern2 0 1 1 0.991775\n",
      "pattern3 1 0 -1 -0.684817\n",
      "pattern4 1 1 1 0.779167\n",
      " modified Weights  [-1.70156343  1.88137642] 0.8634348895270948\n",
      " Training with pattern  4  weights  [-1.68281692  1.88136391] 0.8668473872289144   weights  [-1.69288696  1.89005289]  bias  0.8721113628796099\n",
      "pattern1 0 0 1 0.702445\n",
      "pattern2 0 1 1 0.992055\n",
      "pattern3 1 0 -1 -0.675492\n",
      "pattern4 1 1 1 0.789189\n",
      " modified Weights  [-1.69288696  1.89005289] 0.8721113628796099\n",
      "+++++++++++Epoch  62  cost=  0.23834888785664182\n",
      " Training with pattern  1  weights  [-1.69288696  1.89005289] 0.8721113628796099   weights  [-1.69288696  1.89005289]  bias  0.8871846117361175\n",
      "pattern1 0 0 1 0.71\n",
      "pattern2 0 1 1 0.99229\n",
      "pattern3 1 0 -1 -0.667213\n",
      "pattern4 1 1 1 0.794807\n",
      " modified Weights  [-1.69288696  1.89005289] 0.8871846117361175\n",
      " Training with pattern  2  weights  [-1.69288696  1.89005289] 0.8721113628796099   weights  [-1.69288696  1.89006474]  bias  0.8871964558271259\n",
      "pattern1 0 0 1 0.710006\n",
      "pattern2 0 1 1 0.99229\n",
      "pattern3 1 0 -1 -0.667206\n",
      "pattern4 1 1 1 0.794816\n",
      " modified Weights  [-1.69288696  1.89006474] 0.8871964558271259\n",
      " Training with pattern  3  weights  [-1.69288696  1.89005289] 0.8721113628796099   weights  [-1.71135157  1.89006474]  bias  0.8687318479795124\n",
      "pattern1 0 0 1 0.700729\n",
      "pattern2 0 1 1 0.992001\n",
      "pattern3 1 0 -1 -0.687194\n",
      "pattern4 1 1 1 0.780811\n",
      " modified Weights  [-1.71135157  1.89006474] 0.8687318479795124\n",
      " Training with pattern  4  weights  [-1.69288696  1.89005289] 0.8721113628796099   weights  [-1.70279587  1.89862043]  bias  0.8772875402367855\n",
      "pattern1 0 0 1 0.705058\n",
      "pattern2 0 1 1 0.992269\n",
      "pattern3 1 0 -1 -0.678057\n",
      "pattern4 1 1 1 0.790631\n",
      " modified Weights  [-1.70279587  1.89862043] 0.8772875402367855\n",
      "+++++++++++Epoch  63  cost=  0.23453350063623454\n",
      " Training with pattern  1  weights  [-1.70279587  1.89862043] 0.8772875402367855   weights  [-1.70279587  1.89862043]  bias  0.8921199871951973\n",
      "pattern1 0 0 1 0.712439\n",
      "pattern2 0 1 1 0.992494\n",
      "pattern3 1 0 -1 -0.669963\n",
      "pattern4 1 1 1 0.796127\n",
      " modified Weights  [-1.70279587  1.89862043] 0.8921199871951973\n",
      " Training with pattern  2  weights  [-1.70279587  1.89862043] 0.8772875402367855   weights  [-1.70279587  1.89863165]  bias  0.8921312119952399\n",
      "pattern1 0 0 1 0.712445\n",
      "pattern2 0 1 1 0.992495\n",
      "pattern3 1 0 -1 -0.669957\n",
      "pattern4 1 1 1 0.796135\n",
      " modified Weights  [-1.70279587  1.89863165] 0.8921312119952399\n",
      " Training with pattern  3  weights  [-1.70279587  1.89862043] 0.8772875402367855   weights  [-1.72098647  1.89863165]  bias  0.8739406163683642\n",
      "pattern1 0 0 1 0.703371\n",
      "pattern2 0 1 1 0.992218\n",
      "pattern3 1 0 -1 -0.689523\n",
      "pattern4 1 1 1 0.782422\n",
      " modified Weights  [-1.72098647  1.89863165] 0.8739406163683642\n",
      " Training with pattern  4  weights  [-1.70279587  1.89862043] 0.8772875402367855   weights  [-1.71254846  1.90706967]  bias  0.8823786265285689\n",
      "pattern1 0 0 1 0.707609\n",
      "pattern2 0 1 1 0.992475\n",
      "pattern3 1 0 -1 -0.680567\n",
      "pattern4 1 1 1 0.792047\n",
      " modified Weights  [-1.71254846  1.90706967] 0.8823786265285689\n",
      "+++++++++++Epoch  64  cost=  0.23083108781928202\n",
      " Training with pattern  1  weights  [-1.71254846  1.90706967] 0.8823786265285689   weights  [-1.71254846  1.90706967]  bias  0.8969774073616423\n",
      "pattern1 0 0 1 0.714823\n",
      "pattern2 0 1 1 0.992691\n",
      "pattern3 1 0 -1 -0.672652\n",
      "pattern4 1 1 1 0.797424\n",
      " modified Weights  [-1.71254846  1.90706967] 0.8969774073616423\n",
      " Training with pattern  2  weights  [-1.71254846  1.90706967] 0.8823786265285689   weights  [-1.71254846  1.90708031]  bias  0.8969880534729393\n",
      "pattern1 0 0 1 0.714828\n",
      "pattern2 0 1 1 0.992691\n",
      "pattern3 1 0 -1 -0.672646\n",
      "pattern4 1 1 1 0.797432\n",
      " modified Weights  [-1.71254846  1.90708031] 0.8969880534729393\n",
      " Training with pattern  3  weights  [-1.71254846  1.90706967] 0.8823786265285689   weights  [-1.73047262  1.90708031]  bias  0.8790638955016142\n",
      "pattern1 0 0 1 0.70595\n",
      "pattern2 0 1 1 0.992425\n",
      "pattern3 1 0 -1 -0.691805\n",
      "pattern4 1 1 1 0.784002\n",
      " modified Weights  [-1.73047262  1.90708031] 0.8790638955016142\n",
      " Training with pattern  4  weights  [-1.71254846  1.90706967] 0.8823786265285689   weights  [-1.7221493   1.91540363]  bias  0.8873872104602956\n",
      "pattern1 0 0 1 0.710101\n",
      "pattern2 0 1 1 0.992672\n",
      "pattern3 1 0 -1 -0.683025\n",
      "pattern4 1 1 1 0.793437\n",
      " modified Weights  [-1.7221493   1.91540363] 0.8873872104602956\n",
      "+++++++++++Epoch  65  cost=  0.22723686103292107\n",
      " Training with pattern  1  weights  [-1.7221493   1.91540363] 0.8873872104602956   weights  [-1.7221493   1.91540363]  bias  0.9017591596948876\n",
      "pattern1 0 0 1 0.717153\n",
      "pattern2 0 1 1 0.992879\n",
      "pattern3 1 0 -1 -0.675282\n",
      "pattern4 1 1 1 0.798701\n",
      " modified Weights  [-1.7221493   1.91540363] 0.9017591596948876\n",
      " Training with pattern  2  weights  [-1.7221493   1.91540363] 0.8873872104602956   weights  [-1.7221493   1.91541373]  bias  0.9017692645469373\n",
      "pattern1 0 0 1 0.717158\n",
      "pattern2 0 1 1 0.99288\n",
      "pattern3 1 0 -1 -0.675277\n",
      "pattern4 1 1 1 0.798708\n",
      " modified Weights  [-1.7221493   1.91541373] 0.9017692645469373\n",
      " Training with pattern  3  weights  [-1.7221493   1.91540363] 0.8873872104602956   weights  [-1.7398143   1.91541373]  bias  0.884104269166647\n",
      "pattern1 0 0 1 0.708469\n",
      "pattern2 0 1 1 0.992624\n",
      "pattern3 1 0 -1 -0.694041\n",
      "pattern4 1 1 1 0.78555\n",
      " modified Weights  [-1.7398143   1.91541373] 0.884104269166647\n",
      " Training with pattern  4  weights  [-1.7221493   1.91540363] 0.8873872104602956   weights  [-1.7316028   1.92362523]  bias  0.8923157688174193\n",
      "pattern1 0 0 1 0.712536\n",
      "pattern2 0 1 1 0.992862\n",
      "pattern3 1 0 -1 -0.685431\n",
      "pattern4 1 1 1 0.794802\n",
      " modified Weights  [-1.7316028   1.92362523] 0.8923157688174193\n",
      "+++++++++++Epoch  66  cost=  0.22374629321375175\n",
      " Training with pattern  1  weights  [-1.7316028   1.92362523] 0.8923157688174193   weights  [-1.7316028   1.92362523]  bias  0.9064674359721281\n",
      "pattern1 0 0 1 0.719432\n",
      "pattern2 0 1 1 0.99306\n",
      "pattern3 1 0 -1 -0.677855\n",
      "pattern4 1 1 1 0.799956\n",
      " modified Weights  [-1.7316028   1.92362523] 0.9064674359721281\n",
      " Training with pattern  2  weights  [-1.7316028   1.92362523] 0.8923157688174193   weights  [-1.7316028   1.92363483]  bias  0.9064770341077013\n",
      "pattern1 0 0 1 0.719437\n",
      "pattern2 0 1 1 0.993061\n",
      "pattern3 1 0 -1 -0.67785\n",
      "pattern4 1 1 1 0.799963\n",
      " modified Weights  [-1.7316028   1.92363483] 0.9064770341077013\n",
      " Training with pattern  3  weights  [-1.7316028   1.92362523] 0.8923157688174193   weights  [-1.74901562  1.92363483]  bias  0.8890642105655633\n",
      "pattern1 0 0 1 0.710931\n",
      "pattern2 0 1 1 0.992816\n",
      "pattern3 1 0 -1 -0.696233\n",
      "pattern4 1 1 1 0.78707\n",
      " modified Weights  [-1.74901562  1.92363483] 0.8890642105655633\n",
      " Training with pattern  4  weights  [-1.7316028   1.92362523] 0.8923157688174193   weights  [-1.74091316  1.93173729]  bias  0.8971666726282095\n",
      "pattern1 0 0 1 0.714915\n",
      "pattern2 0 1 1 0.993044\n",
      "pattern3 1 0 -1 -0.687788\n",
      "pattern4 1 1 1 0.796144\n",
      " modified Weights  [-1.74091316  1.93173729] 0.8971666726282095\n",
      "+++++++++++Epoch  67  cost=  0.220355101291448\n",
      " Training with pattern  1  weights  [-1.74091316  1.93173729] 0.8971666726282095   weights  [-1.74091316  1.93173729]  bias  0.9111043373999529\n",
      "pattern1 0 0 1 0.721662\n",
      "pattern2 0 1 1 0.993235\n",
      "pattern3 1 0 -1 -0.680373\n",
      "pattern4 1 1 1 0.801191\n",
      " modified Weights  [-1.74091316  1.93173729] 0.9111043373999529\n",
      " Training with pattern  2  weights  [-1.74091316  1.93173729] 0.8971666726282095   weights  [-1.74091316  1.93174641]  bias  0.9111134607320195\n",
      "pattern1 0 0 1 0.721666\n",
      "pattern2 0 1 1 0.993235\n",
      "pattern3 1 0 -1 -0.680368\n",
      "pattern4 1 1 1 0.801197\n",
      " modified Weights  [-1.74091316  1.93174641] 0.9111134607320195\n",
      " Training with pattern  3  weights  [-1.74091316  1.93173729] 0.8971666726282095   weights  [-1.75808053  1.93174641]  bias  0.8939460883277698\n",
      "pattern1 0 0 1 0.713337\n",
      "pattern2 0 1 1 0.992999\n",
      "pattern3 1 0 -1 -0.698382\n",
      "pattern4 1 1 1 0.78856\n",
      " modified Weights  [-1.75808053  1.93174641] 0.8939460883277698\n",
      " Training with pattern  4  weights  [-1.74091316  1.93173729] 0.8971666726282095   weights  [-1.75008443  1.93974252]  bias  0.9019421929199667\n",
      "pattern1 0 0 1 0.717242\n",
      "pattern2 0 1 1 0.993219\n",
      "pattern3 1 0 -1 -0.690098\n",
      "pattern4 1 1 1 0.797461\n",
      " modified Weights  [-1.75008443  1.93974252] 0.9019421929199667\n",
      "+++++++++++Epoch  68  cost=  0.21705923021478873\n",
      " Training with pattern  1  weights  [-1.75008443  1.93974252] 0.9019421929199667   weights  [-1.75008443  1.93974252]  bias  0.9156718793979893\n",
      "pattern1 0 0 1 0.723843\n",
      "pattern2 0 1 1 0.993402\n",
      "pattern3 1 0 -1 -0.682838\n",
      "pattern4 1 1 1 0.802405\n",
      " modified Weights  [-1.75008443  1.93974252] 0.9156718793979893\n",
      " Training with pattern  2  weights  [-1.75008443  1.93974252] 0.9019421929199667   weights  [-1.75008443  1.9397512 ]  bias  0.9156805574408525\n",
      "pattern1 0 0 1 0.723848\n",
      "pattern2 0 1 1 0.993402\n",
      "pattern3 1 0 -1 -0.682834\n",
      "pattern4 1 1 1 0.802412\n",
      " modified Weights  [-1.75008443  1.9397512 ] 0.9156805574408525\n",
      " Training with pattern  3  weights  [-1.75008443  1.93974252] 0.9019421929199667   weights  [-1.76701281  1.9397512 ]  bias  0.8987521721317242\n",
      "pattern1 0 0 1 0.71569\n",
      "pattern2 0 1 1 0.993176\n",
      "pattern3 1 0 -1 -0.700489\n",
      "pattern4 1 1 1 0.790022\n",
      " modified Weights  [-1.76701281  1.9397512 ] 0.8987521721317242\n",
      " Training with pattern  4  weights  [-1.75008443  1.93974252] 0.9019421929199667   weights  [-1.75912048  1.94764353]  bias  0.9066445060996047\n",
      "pattern1 0 0 1 0.719518\n",
      "pattern2 0 1 1 0.993387\n",
      "pattern3 1 0 -1 -0.692361\n",
      "pattern4 1 1 1 0.798756\n",
      " modified Weights  [-1.75912048  1.94764353] 0.9066445060996047\n",
      "+++++++++++Epoch  69  cost=  0.21385483820148266\n",
      " Training with pattern  1  weights  [-1.75912048  1.94764353] 0.9066445060996047   weights  [-1.75912048  1.94764353]  bias  0.9201719960788374\n",
      "pattern1 0 0 1 0.725979\n",
      "pattern2 0 1 1 0.993563\n",
      "pattern3 1 0 -1 -0.685252\n",
      "pattern4 1 1 1 0.803601\n",
      " modified Weights  [-1.75912048  1.94764353] 0.9201719960788374\n",
      " Training with pattern  2  weights  [-1.75912048  1.94764353] 0.9066445060996047   weights  [-1.75912048  1.94765179]  bias  0.9201802561563468\n",
      "pattern1 0 0 1 0.725983\n",
      "pattern2 0 1 1 0.993563\n",
      "pattern3 1 0 -1 -0.685247\n",
      "pattern4 1 1 1 0.803606\n",
      " modified Weights  [-1.75912048  1.94765179] 0.9201802561563468\n",
      " Training with pattern  3  weights  [-1.75912048  1.94764353] 0.9066445060996047   weights  [-1.7758161   1.94765179]  bias  0.9034846379650262\n",
      "pattern1 0 0 1 0.71799\n",
      "pattern2 0 1 1 0.993345\n",
      "pattern3 1 0 -1 -0.702557\n",
      "pattern4 1 1 1 0.791457\n",
      " modified Weights  [-1.7758161   1.94765179] 0.9034846379650262\n",
      " Training with pattern  4  weights  [-1.75912048  1.94764353] 0.9066445060996047   weights  [-1.76802503  1.95544285]  bias  0.911275698986833\n",
      "pattern1 0 0 1 0.721744\n",
      "pattern2 0 1 1 0.993549\n",
      "pattern3 1 0 -1 -0.694579\n",
      "pattern4 1 1 1 0.800029\n",
      " modified Weights  [-1.76802503  1.95544285] 0.911275698986833\n",
      "+++++++++++Epoch  70  cost=  0.21073828310488862\n",
      " Training with pattern  1  weights  [-1.76802503  1.95544285] 0.911275698986833   weights  [-1.76802503  1.95544285]  bias  0.9246065444465638\n",
      "pattern1 0 0 1 0.728069\n",
      "pattern2 0 1 1 0.993718\n",
      "pattern3 1 0 -1 -0.687615\n",
      "pattern4 1 1 1 0.804777\n",
      " modified Weights  [-1.76802503  1.95544285] 0.9246065444465638\n",
      " Training with pattern  2  weights  [-1.76802503  1.95544285] 0.911275698986833   weights  [-1.76802503  1.95545072]  bias  0.9246144118799298\n",
      "pattern1 0 0 1 0.728073\n",
      "pattern2 0 1 1 0.993718\n",
      "pattern3 1 0 -1 -0.687611\n",
      "pattern4 1 1 1 0.804782\n",
      " modified Weights  [-1.76802503  1.95545072] 0.9246144118799298\n",
      " Training with pattern  3  weights  [-1.76802503  1.95544285] 0.911275698986833   weights  [-1.78449387  1.95545072]  bias  0.9081455730496136\n",
      "pattern1 0 0 1 0.720241\n",
      "pattern2 0 1 1 0.993509\n",
      "pattern3 1 0 -1 -0.704585\n",
      "pattern4 1 1 1 0.792866\n",
      " modified Weights  [-1.78449387  1.95545072] 0.9081455730496136\n",
      " Training with pattern  4  weights  [-1.76802503  1.95544285] 0.911275698986833   weights  [-1.77680167  1.96314292]  bias  0.9158377735258012\n",
      "pattern1 0 0 1 0.723922\n",
      "pattern2 0 1 1 0.993705\n",
      "pattern3 1 0 -1 -0.696754\n",
      "pattern4 1 1 1 0.80128\n",
      " modified Weights  [-1.77680167  1.96314292] 0.9158377735258012\n",
      "+++++++++++Epoch  71  cost=  0.20770610980116636\n",
      " *********Epoch  70 Error  0.20770610980116636\n",
      " Training with pattern  1  weights  [-1.77680167  1.96314292] 0.9158377735258012   weights  [-1.77680167  1.96314292]  bias  0.9289773083341928\n",
      "pattern1 0 0 1 0.730117\n",
      "pattern2 0 1 1 0.993868\n",
      "pattern3 1 0 -1 -0.689931\n",
      "pattern4 1 1 1 0.805934\n",
      " modified Weights  [-1.77680167  1.96314292] 0.9289773083341928\n",
      " Training with pattern  2  weights  [-1.77680167  1.96314292] 0.9158377735258012   weights  [-1.77680167  1.96315042]  bias  0.928984806611619\n",
      "pattern1 0 0 1 0.73012\n",
      "pattern2 0 1 1 0.993868\n",
      "pattern3 1 0 -1 -0.689927\n",
      "pattern4 1 1 1 0.80594\n",
      " modified Weights  [-1.77680167  1.96315042] 0.928984806611619\n",
      " Training with pattern  3  weights  [-1.77680167  1.96314292] 0.9158377735258012   weights  [-1.7930495   1.96315042]  bias  0.9127369804566086\n",
      "pattern1 0 0 1 0.722443\n",
      "pattern2 0 1 1 0.993666\n",
      "pattern3 1 0 -1 -0.706576\n",
      "pattern4 1 1 1 0.794249\n",
      " modified Weights  [-1.7930495   1.96315042] 0.9127369804566086\n",
      " Training with pattern  4  weights  [-1.77680167  1.96314292] 0.9158377735258012   weights  [-1.78545383  1.97074609]  bias  0.9203326511989092\n",
      "pattern1 0 0 1 0.726055\n",
      "pattern2 0 1 1 0.993855\n",
      "pattern3 1 0 -1 -0.698887\n",
      "pattern4 1 1 1 0.80251\n",
      " modified Weights  [-1.78545383  1.97074609] 0.9203326511989092\n",
      "+++++++++++Epoch  72  cost=  0.20475503850972596\n",
      " Training with pattern  1  weights  [-1.78545383  1.97074609] 0.9203326511989092   weights  [-1.78545383  1.97074609]  bias  0.9332860020989645\n",
      "pattern1 0 0 1 0.732122\n",
      "pattern2 0 1 1 0.994012\n",
      "pattern3 1 0 -1 -0.6922\n",
      "pattern4 1 1 1 0.807074\n",
      " modified Weights  [-1.78545383  1.97074609] 0.9332860020989645\n",
      " Training with pattern  2  weights  [-1.78545383  1.97074609] 0.9203326511989092   weights  [-1.78545383  1.97075324]  bias  0.9332931530290527\n",
      "pattern1 0 0 1 0.732126\n",
      "pattern2 0 1 1 0.994012\n",
      "pattern3 1 0 -1 -0.692197\n",
      "pattern4 1 1 1 0.807079\n",
      " modified Weights  [-1.78545383  1.97075324] 0.9332931530290527\n",
      " Training with pattern  3  weights  [-1.78545383  1.97074609] 0.9203326511989092   weights  [-1.8014862   1.97075324]  bias  0.9172607834333506\n",
      "pattern1 0 0 1 0.724599\n",
      "pattern2 0 1 1 0.993817\n",
      "pattern3 1 0 -1 -0.70853\n",
      "pattern4 1 1 1 0.795607\n",
      " modified Weights  [-1.8014862   1.97075324] 0.9172607834333506\n",
      " Training with pattern  4  weights  [-1.78545383  1.97074609] 0.9203326511989092   weights  [-1.7939848   1.97825463]  bias  0.924762177164531\n",
      "pattern1 0 0 1 0.728142\n",
      "pattern2 0 1 1 0.993999\n",
      "pattern3 1 0 -1 -0.700979\n",
      "pattern4 1 1 1 0.80372\n",
      " modified Weights  [-1.7939848   1.97825463] 0.924762177164531\n",
      "+++++++++++Epoch  73  cost=  0.20188195396816566\n",
      " Training with pattern  1  weights  [-1.7939848   1.97825463] 0.924762177164531   weights  [-1.7939848   1.97825463]  bias  0.9375342740926135\n",
      "pattern1 0 0 1 0.734087\n",
      "pattern2 0 1 1 0.99415\n",
      "pattern3 1 0 -1 -0.694424\n",
      "pattern4 1 1 1 0.808196\n",
      " modified Weights  [-1.7939848   1.97825463] 0.9375342740926135\n",
      " Training with pattern  2  weights  [-1.7939848   1.97825463] 0.924762177164531   weights  [-1.7939848   1.97826146]  bias  0.9375410979432641\n",
      "pattern1 0 0 1 0.73409\n",
      "pattern2 0 1 1 0.99415\n",
      "pattern3 1 0 -1 -0.694421\n",
      "pattern4 1 1 1 0.8082\n",
      " modified Weights  [-1.7939848   1.97826146] 0.9375410979432641\n",
      " Training with pattern  3  weights  [-1.7939848   1.97825463] 0.924762177164531   weights  [-1.80980707  1.97826146]  bias  0.9217188294633158\n",
      "pattern1 0 0 1 0.72671\n",
      "pattern2 0 1 1 0.993963\n",
      "pattern3 1 0 -1 -0.710448\n",
      "pattern4 1 1 1 0.796941\n",
      " modified Weights  [-1.80980707  1.97826146] 0.9217188294633158\n",
      " Training with pattern  4  weights  [-1.7939848   1.97825463] 0.924762177164531   weights  [-1.80239778  1.98567075]  bias  0.9291281241386141\n",
      "pattern1 0 0 1 0.730187\n",
      "pattern2 0 1 1 0.994139\n",
      "pattern3 1 0 -1 -0.703032\n",
      "pattern4 1 1 1 0.80491\n",
      " modified Weights  [-1.80239778  1.98567075] 0.9291281241386141\n",
      "+++++++++++Epoch  74  cost=  0.19908389539033938\n",
      " Training with pattern  1  weights  [-1.80239778  1.98567075] 0.9291281241386141   weights  [-1.80239778  1.98567075]  bias  0.9417237099225383\n",
      "pattern1 0 0 1 0.736013\n",
      "pattern2 0 1 1 0.994284\n",
      "pattern3 1 0 -1 -0.696605\n",
      "pattern4 1 1 1 0.8093\n",
      " modified Weights  [-1.80239778  1.98567075] 0.9417237099225383\n",
      " Training with pattern  2  weights  [-1.80239778  1.98567075] 0.9291281241386141   weights  [-1.80239778  1.98567727]  bias  0.9417302255468706\n",
      "pattern1 0 0 1 0.736016\n",
      "pattern2 0 1 1 0.994284\n",
      "pattern3 1 0 -1 -0.696601\n",
      "pattern4 1 1 1 0.809304\n",
      " modified Weights  [-1.80239778  1.98567727] 0.9417302255468706\n",
      " Training with pattern  3  weights  [-1.80239778  1.98567075] 0.9291281241386141   weights  [-1.81801511  1.98567727]  bias  0.9261128940779596\n",
      "pattern1 0 0 1 0.728776\n",
      "pattern2 0 1 1 0.994103\n",
      "pattern3 1 0 -1 -0.712332\n",
      "pattern4 1 1 1 0.798252\n",
      " modified Weights  [-1.81801511  1.98567727] 0.9261128940779596\n",
      " Training with pattern  4  weights  [-1.80239778  1.98567075] 0.9291281241386141   weights  [-1.81069581  1.99299657]  bias  0.9334321960384984\n",
      "pattern1 0 0 1 0.73219\n",
      "pattern2 0 1 1 0.994273\n",
      "pattern3 1 0 -1 -0.705046\n",
      "pattern4 1 1 1 0.80608\n",
      " modified Weights  [-1.81069581  1.99299657] 0.9334321960384984\n",
      "+++++++++++Epoch  75  cost=  0.19635804714286656\n",
      " Training with pattern  1  weights  [-1.81069581  1.99299657] 0.9334321960384984   weights  [-1.81069581  1.99299657]  bias  0.9458558355184741\n",
      "pattern1 0 0 1 0.737901\n",
      "pattern2 0 1 1 0.994413\n",
      "pattern3 1 0 -1 -0.698743\n",
      "pattern4 1 1 1 0.810387\n",
      " modified Weights  [-1.81069581  1.99299657] 0.9458558355184741\n",
      " Training with pattern  2  weights  [-1.81069581  1.99299657] 0.9334321960384984   weights  [-1.81069581  1.99300279]  bias  0.9458620604691123\n",
      "pattern1 0 0 1 0.737904\n",
      "pattern2 0 1 1 0.994413\n",
      "pattern3 1 0 -1 -0.69874\n",
      "pattern4 1 1 1 0.810392\n",
      " modified Weights  [-1.81069581  1.99300279] 0.9458620604691123\n",
      " Training with pattern  3  weights  [-1.81069581  1.99299657] 0.9334321960384984   weights  [-1.82611318  1.99300279]  bias  0.9304446844379912\n",
      "pattern1 0 0 1 0.730801\n",
      "pattern2 0 1 1 0.994239\n",
      "pattern3 1 0 -1 -0.714182\n",
      "pattern4 1 1 1 0.799539\n",
      " modified Weights  [-1.82611318  1.99300279] 0.9304446844379912\n",
      " Training with pattern  4  weights  [-1.81069581  1.99299657] 0.9334321960384984   weights  [-1.81888184  2.00023414]  bias  0.9376760314058205\n",
      "pattern1 0 0 1 0.734153\n",
      "pattern2 0 1 1 0.994403\n",
      "pattern3 1 0 -1 -0.707023\n",
      "pattern4 1 1 1 0.807231\n",
      " modified Weights  [-1.81888184  2.00023414] 0.9376760314058205\n",
      "+++++++++++Epoch  76  cost=  0.1937017300813858\n",
      " Training with pattern  1  weights  [-1.81888184  2.00023414] 0.9376760314058205   weights  [-1.81888184  2.00023414]  bias  0.9499321200181262\n",
      "pattern1 0 0 1 0.739752\n",
      "pattern2 0 1 1 0.994538\n",
      "pattern3 1 0 -1 -0.70084\n",
      "pattern4 1 1 1 0.811458\n",
      " modified Weights  [-1.81888184  2.00023414] 0.9499321200181262\n",
      " Training with pattern  2  weights  [-1.81888184  2.00023414] 0.9376760314058205   weights  [-1.81888184  2.00024009]  bias  0.9499380706510472\n",
      "pattern1 0 0 1 0.739755\n",
      "pattern2 0 1 1 0.994538\n",
      "pattern3 1 0 -1 -0.700837\n",
      "pattern4 1 1 1 0.811462\n",
      " modified Weights  [-1.81888184  2.00024009] 0.9499380706510472\n",
      " Training with pattern  3  weights  [-1.81888184  2.00023414] 0.9376760314058205   weights  [-1.83410406  2.00024009]  bias  0.9347158427002069\n",
      "pattern1 0 0 1 0.732785\n",
      "pattern2 0 1 1 0.99437\n",
      "pattern3 1 0 -1 -0.716\n",
      "pattern4 1 1 1 0.800805\n",
      " modified Weights  [-1.83410406  2.00024009] 0.9347158427002069\n",
      " Training with pattern  4  weights  [-1.81888184  2.00023414] 0.9376760314058205   weights  [-1.8269587   2.00738546]  bias  0.941861206624021\n",
      "pattern1 0 0 1 0.736076\n",
      "pattern2 0 1 1 0.994528\n",
      "pattern3 1 0 -1 -0.708964\n",
      "pattern4 1 1 1 0.808363\n",
      " modified Weights  [-1.8269587   2.00738546] 0.941861206624021\n",
      "+++++++++++Epoch  77  cost=  0.19111239349322376\n",
      " Training with pattern  1  weights  [-1.8269587   2.00738546] 0.941861206624021   weights  [-1.8269587   2.00738546]  bias  0.9539539784841738\n",
      "pattern1 0 0 1 0.741568\n",
      "pattern2 0 1 1 0.994658\n",
      "pattern3 1 0 -1 -0.702898\n",
      "pattern4 1 1 1 0.812513\n",
      " modified Weights  [-1.8269587   2.00738546] 0.9539539784841738\n",
      " Training with pattern  2  weights  [-1.8269587   2.00738546] 0.941861206624021   weights  [-1.8269587   2.00739115]  bias  0.9539596700531755\n",
      "pattern1 0 0 1 0.74157\n",
      "pattern2 0 1 1 0.994658\n",
      "pattern3 1 0 -1 -0.702895\n",
      "pattern4 1 1 1 0.812517\n",
      " modified Weights  [-1.8269587   2.00739115] 0.9539596700531755\n",
      " Training with pattern  3  weights  [-1.8269587   2.00738546] 0.941861206624021   weights  [-1.84199042  2.00739115]  bias  0.9389279491847344\n",
      "pattern1 0 0 1 0.734729\n",
      "pattern2 0 1 1 0.994496\n",
      "pattern3 1 0 -1 -0.717786\n",
      "pattern4 1 1 1 0.802049\n",
      " modified Weights  [-1.84199042  2.00739115] 0.9389279491847344\n",
      " Training with pattern  4  weights  [-1.8269587   2.00738546] 0.941861206624021   weights  [-1.83492913  2.01445244]  bias  0.9459892389447468\n",
      "pattern1 0 0 1 0.737962\n",
      "pattern2 0 1 1 0.994649\n",
      "pattern3 1 0 -1 -0.71087\n",
      "pattern4 1 1 1 0.809478\n",
      " modified Weights  [-1.83492913  2.01445244] 0.9459892389447468\n",
      "+++++++++++Epoch  78  cost=  0.1885876075979798\n",
      " Training with pattern  1  weights  [-1.83492913  2.01445244] 0.9459892389447468   weights  [-1.83492913  2.01445244]  bias  0.9579227744640937\n",
      "pattern1 0 0 1 0.743349\n",
      "pattern2 0 1 1 0.994775\n",
      "pattern3 1 0 -1 -0.704916\n",
      "pattern4 1 1 1 0.813552\n",
      " modified Weights  [-1.83492913  2.01445244] 0.9579227744640937\n",
      " Training with pattern  2  weights  [-1.83492913  2.01445244] 0.9459892389447468   weights  [-1.83492913  2.01445788]  bias  0.9579282212068257\n",
      "pattern1 0 0 1 0.743351\n",
      "pattern2 0 1 1 0.994775\n",
      "pattern3 1 0 -1 -0.704914\n",
      "pattern4 1 1 1 0.813556\n",
      " modified Weights  [-1.83492913  2.01445788] 0.9579282212068257\n",
      " Training with pattern  3  weights  [-1.83492913  2.01445244] 0.9459892389447468   weights  [-1.84977483  2.01445788]  bias  0.9430825253563897\n",
      "pattern1 0 0 1 0.736635\n",
      "pattern2 0 1 1 0.994618\n",
      "pattern3 1 0 -1 -0.719541\n",
      "pattern4 1 1 1 0.803271\n",
      " modified Weights  [-1.84977483  2.01445788] 0.9430825253563897\n",
      " Training with pattern  4  weights  [-1.83492913  2.01445244] 0.9459892389447468   weights  [-1.84279576  2.02143695]  bias  0.9500615893363182\n",
      "pattern1 0 0 1 0.739811\n",
      "pattern2 0 1 1 0.994765\n",
      "pattern3 1 0 -1 -0.712742\n",
      "pattern4 1 1 1 0.810575\n",
      " modified Weights  [-1.84279576  2.02143695] 0.9500615893363182\n",
      "+++++++++++Epoch  79  cost=  0.18612505656188172\n",
      " Training with pattern  1  weights  [-1.84279576  2.02143695] 0.9500615893363182   weights  [-1.84279576  2.02143695]  bias  0.9618398224033732\n",
      "pattern1 0 0 1 0.745096\n",
      "pattern2 0 1 1 0.994887\n",
      "pattern3 1 0 -1 -0.706898\n",
      "pattern4 1 1 1 0.814576\n",
      " modified Weights  [-1.84279576  2.02143695] 0.9618398224033732\n",
      " Training with pattern  2  weights  [-1.84279576  2.02143695] 0.9500615893363182   weights  [-1.84279576  2.02144216]  bias  0.9618450376197691\n",
      "pattern1 0 0 1 0.745099\n",
      "pattern2 0 1 1 0.994887\n",
      "pattern3 1 0 -1 -0.706895\n",
      "pattern4 1 1 1 0.81458\n",
      " modified Weights  [-1.84279576  2.02144216] 0.9618450376197691\n",
      " Training with pattern  3  weights  [-1.84279576  2.02143695] 0.9500615893363182   weights  [-1.85745976  2.02144216]  bias  0.9471810366327847\n",
      "pattern1 0 0 1 0.738504\n",
      "pattern2 0 1 1 0.994735\n",
      "pattern3 1 0 -1 -0.721266\n",
      "pattern4 1 1 1 0.804473\n",
      " modified Weights  [-1.85745976  2.02144216] 0.9471810366327847\n",
      " Training with pattern  4  weights  [-1.84279576  2.02143695] 0.9500615893363182   weights  [-1.85056114  2.02834079]  bias  0.9540796651664072\n",
      "pattern1 0 0 1 0.741624\n",
      "pattern2 0 1 1 0.994878\n",
      "pattern3 1 0 -1 -0.71458\n",
      "pattern4 1 1 1 0.811655\n",
      " modified Weights  [-1.85056114  2.02834079] 0.9540796651664072\n",
      "+++++++++++Epoch  80  cost=  0.18372253198567312\n",
      " Training with pattern  1  weights  [-1.85056114  2.02834079] 0.9540796651664072   weights  [-1.85056114  2.02834079]  bias  0.9657063899218822\n",
      "pattern1 0 0 1 0.746811\n",
      "pattern2 0 1 1 0.994996\n",
      "pattern3 1 0 -1 -0.708843\n",
      "pattern4 1 1 1 0.815585\n",
      " modified Weights  [-1.85056114  2.02834079] 0.9657063899218822\n",
      " Training with pattern  2  weights  [-1.85056114  2.02834079] 0.9540796651664072   weights  [-1.85056114  2.02834579]  bias  0.9657113860457384\n",
      "pattern1 0 0 1 0.746814\n",
      "pattern2 0 1 1 0.994996\n",
      "pattern3 1 0 -1 -0.708841\n",
      "pattern4 1 1 1 0.815588\n",
      " modified Weights  [-1.85056114  2.02834579] 0.9657113860457384\n",
      " Training with pattern  3  weights  [-1.85056114  2.02834079] 0.9540796651664072   weights  [-1.86504763  2.02834579]  bias  0.9512248950308574\n",
      "pattern1 0 0 1 0.740337\n",
      "pattern2 0 1 1 0.994849\n",
      "pattern3 1 0 -1 -0.722962\n",
      "pattern4 1 1 1 0.805655\n",
      " modified Weights  [-1.86504763  2.02834579] 0.9512248950308574\n",
      " Training with pattern  4  weights  [-1.85056114  2.02834079] 0.9540796651664072   weights  [-1.8582277   2.03516572]  bias  0.958044822730137\n",
      "pattern1 0 0 1 0.743403\n",
      "pattern2 0 1 1 0.994987\n",
      "pattern3 1 0 -1 -0.716387\n",
      "pattern4 1 1 1 0.812718\n",
      " modified Weights  [-1.8582277   2.03516572] 0.958044822730137\n",
      "+++++++++++Epoch  81  cost=  0.18137792682933992\n",
      " *********Epoch  80 Error  0.18137792682933992\n",
      " Training with pattern  1  weights  [-1.8582277   2.03516572] 0.958044822730137   weights  [-1.8582277   2.03516572]  bias  0.9695236999624327\n",
      "pattern1 0 0 1 0.748495\n",
      "pattern2 0 1 1 0.995101\n",
      "pattern3 1 0 -1 -0.710753\n",
      "pattern4 1 1 1 0.816579\n",
      " modified Weights  [-1.8582277   2.03516572] 0.9695236999624327\n",
      " Training with pattern  2  weights  [-1.8582277   2.03516572] 0.958044822730137   weights  [-1.8582277  2.0351705]  bias  0.9695284886268011\n",
      "pattern1 0 0 1 0.748497\n",
      "pattern2 0 1 1 0.995101\n",
      "pattern3 1 0 -1 -0.710751\n",
      "pattern4 1 1 1 0.816582\n",
      " modified Weights  [-1.8582277  2.0351705] 0.9695284886268011\n",
      " Training with pattern  3  weights  [-1.8582277   2.03516572] 0.958044822730137   weights  [-1.87254073  2.0351705 ]  bias  0.9552154616626084\n",
      "pattern1 0 0 1 0.742135\n",
      "pattern2 0 1 1 0.994959\n",
      "pattern3 1 0 -1 -0.72463\n",
      "pattern4 1 1 1 0.806818\n",
      " modified Weights  [-1.87254073  2.0351705 ] 0.9552154616626084\n",
      " Training with pattern  4  weights  [-1.8582277   2.03516572] 0.958044822730137   weights  [-1.86579782  2.04191341]  bias  0.9619583696339561\n",
      "pattern1 0 0 1 0.745149\n",
      "pattern2 0 1 1 0.995093\n",
      "pattern3 1 0 -1 -0.718162\n",
      "pattern4 1 1 1 0.813765\n",
      " modified Weights  [-1.86579782  2.04191341] 0.9619583696339561\n",
      "+++++++++++Epoch  82  cost=  0.17908922974015795\n",
      " Training with pattern  1  weights  [-1.86579782  2.04191341] 0.9619583696339561   weights  [-1.86579782  2.04191341]  bias  0.9732929328198836\n",
      "pattern1 0 0 1 0.750148\n",
      "pattern2 0 1 1 0.995203\n",
      "pattern3 1 0 -1 -0.712629\n",
      "pattern4 1 1 1 0.817558\n",
      " modified Weights  [-1.86579782  2.04191341] 0.9732929328198836\n",
      " Training with pattern  2  weights  [-1.86579782  2.04191341] 0.9619583696339561   weights  [-1.86579782  2.041918  ]  bias  0.9732975249168729\n",
      "pattern1 0 0 1 0.75015\n",
      "pattern2 0 1 1 0.995203\n",
      "pattern3 1 0 -1 -0.712626\n",
      "pattern4 1 1 1 0.817561\n",
      " modified Weights  [-1.86579782  2.041918  ] 0.9732975249168729\n",
      " Training with pattern  3  weights  [-1.86579782  2.04191341] 0.9619583696339561   weights  [-1.87994129  2.041918  ]  bias  0.9591540490900178\n",
      "pattern1 0 0 1 0.743899\n",
      "pattern2 0 1 1 0.995065\n",
      "pattern3 1 0 -1 -0.72627\n",
      "pattern4 1 1 1 0.807962\n",
      " modified Weights  [-1.87994129  2.041918  ] 0.9591540490900178\n",
      " Training with pattern  4  weights  [-1.86579782  2.04191341] 0.9619583696339561   weights  [-1.87327378  2.04858552]  bias  0.965821567044857\n",
      "pattern1 0 0 1 0.746862\n",
      "pattern2 0 1 1 0.995195\n",
      "pattern3 1 0 -1 -0.719907\n",
      "pattern4 1 1 1 0.814795\n",
      " modified Weights  [-1.87327378  2.04858552] 0.965821567044857\n",
      "+++++++++++Epoch  83  cost=  0.1768545197534433\n",
      " Training with pattern  1  weights  [-1.87327378  2.04858552] 0.965821567044857   weights  [-1.87327378  2.04858552]  bias  0.9770152280585286\n",
      "pattern1 0 0 1 0.751771\n",
      "pattern2 0 1 1 0.995301\n",
      "pattern3 1 0 -1 -0.714471\n",
      "pattern4 1 1 1 0.818523\n",
      " modified Weights  [-1.87327378  2.04858552] 0.9770152280585286\n",
      " Training with pattern  2  weights  [-1.87327378  2.04858552] 0.965821567044857   weights  [-1.87327378  2.04858993]  bias  0.9770196337940463\n",
      "pattern1 0 0 1 0.751773\n",
      "pattern2 0 1 1 0.995301\n",
      "pattern3 1 0 -1 -0.714469\n",
      "pattern4 1 1 1 0.818526\n",
      " modified Weights  [-1.87327378  2.04858993] 0.9770196337940463\n",
      " Training with pattern  3  weights  [-1.87327378  2.04858552] 0.965821567044857   weights  [-1.88725149  2.04858993]  bias  0.9630419235483679\n",
      "pattern1 0 0 1 0.745631\n",
      "pattern2 0 1 1 0.995168\n",
      "pattern3 1 0 -1 -0.727883\n",
      "pattern4 1 1 1 0.809087\n",
      " modified Weights  [-1.88725149  2.04858993] 0.9630419235483679\n",
      " Training with pattern  4  weights  [-1.87327378  2.04858552] 0.965821567044857   weights  [-1.88065778  2.05518364]  bias  0.9696356318137903\n",
      "pattern1 0 0 1 0.748544\n",
      "pattern2 0 1 1 0.995294\n",
      "pattern3 1 0 -1 -0.721622\n",
      "pattern4 1 1 1 0.815811\n",
      " modified Weights  [-1.88065778  2.05518364] 0.9696356318137903\n",
      "+++++++++++Epoch  84  cost=  0.174671961337985\n",
      " Training with pattern  1  weights  [-1.88065778  2.05518364] 0.9696356318137903   weights  [-1.88065778  2.05518364]  bias  0.9806916863249363\n",
      "pattern1 0 0 1 0.753365\n",
      "pattern2 0 1 1 0.995396\n",
      "pattern3 1 0 -1 -0.716281\n",
      "pattern4 1 1 1 0.819475\n",
      " modified Weights  [-1.88065778  2.05518364] 0.9806916863249363\n",
      " Training with pattern  2  weights  [-1.88065778  2.05518364] 0.9696356318137903   weights  [-1.88065778  2.05518787]  bias  0.9806959152688481\n",
      "pattern1 0 0 1 0.753367\n",
      "pattern2 0 1 1 0.995396\n",
      "pattern3 1 0 -1 -0.716279\n",
      "pattern4 1 1 1 0.819478\n",
      " modified Weights  [-1.88065778  2.05518787] 0.9806959152688481\n",
      " Training with pattern  3  weights  [-1.88065778  2.05518364] 0.9696356318137903   weights  [-1.89447339  2.05518787]  bias  0.9668803070465192\n",
      "pattern1 0 0 1 0.74733\n",
      "pattern2 0 1 1 0.995268\n",
      "pattern3 1 0 -1 -0.72947\n",
      "pattern4 1 1 1 0.810194\n",
      " modified Weights  [-1.89447339  2.05518787] 0.9668803070465192\n",
      " Training with pattern  4  weights  [-1.88065778  2.05518364] 0.9696356318137903   weights  [-1.88795196  2.0617093 ]  bias  0.9734017384814677\n",
      "pattern1 0 0 1 0.750195\n",
      "pattern2 0 1 1 0.995389\n",
      "pattern3 1 0 -1 -0.723309\n",
      "pattern4 1 1 1 0.816811\n",
      " modified Weights  [-1.88795196  2.0617093 ] 0.9734017384814677\n",
      "+++++++++++Epoch  85  cost=  0.17253979976050443\n",
      " Training with pattern  1  weights  [-1.88795196  2.0617093 ] 0.9734017384814677   weights  [-1.88795196  2.0617093 ]  bias  0.9843233710628909\n",
      "pattern1 0 0 1 0.754931\n",
      "pattern2 0 1 1 0.995489\n",
      "pattern3 1 0 -1 -0.71806\n",
      "pattern4 1 1 1 0.820413\n",
      " modified Weights  [-1.88795196  2.0617093 ] 0.9843233710628909\n",
      " Training with pattern  2  weights  [-1.88795196  2.0617093 ] 0.9734017384814677   weights  [-1.88795196  2.06171336]  bias  0.9843274321950245\n",
      "pattern1 0 0 1 0.754933\n",
      "pattern2 0 1 1 0.995489\n",
      "pattern3 1 0 -1 -0.718058\n",
      "pattern4 1 1 1 0.820416\n",
      " modified Weights  [-1.88795196  2.06171336] 0.9843274321950245\n",
      " Training with pattern  3  weights  [-1.88795196  2.0617093 ] 0.9734017384814677   weights  [-1.90160901  2.06171336]  bias  0.9706703793520528\n",
      "pattern1 0 0 1 0.748999\n",
      "pattern2 0 1 1 0.995364\n",
      "pattern3 1 0 -1 -0.731031\n",
      "pattern4 1 1 1 0.811284\n",
      " modified Weights  [-1.90160901  2.06171336] 0.9706703793520528\n",
      " Training with pattern  4  weights  [-1.88795196  2.0617093 ] 0.9734017384814677   weights  [-1.89515837  2.068164  ]  bias  0.9771210211741417\n",
      "pattern1 0 0 1 0.751817\n",
      "pattern2 0 1 1 0.995482\n",
      "pattern3 1 0 -1 -0.724968\n",
      "pattern4 1 1 1 0.817796\n",
      " modified Weights  [-1.89515837  2.068164  ] 0.9771210211741417\n",
      "+++++++++++Epoch  86  cost=  0.17045635674563975\n",
      " Training with pattern  1  weights  [-1.89515837  2.068164  ] 0.9771210211741417   weights  [-1.89515837  2.068164  ]  bias  0.9879113101366023\n",
      "pattern1 0 0 1 0.75647\n",
      "pattern2 0 1 1 0.995578\n",
      "pattern3 1 0 -1 -0.719808\n",
      "pattern4 1 1 1 0.821338\n",
      " modified Weights  [-1.89515837  2.068164  ] 0.9879113101366023\n",
      " Training with pattern  2  weights  [-1.89515837  2.068164  ] 0.9771210211741417   weights  [-1.89515837  2.0681679 ]  bias  0.9879152118889793\n",
      "pattern1 0 0 1 0.756472\n",
      "pattern2 0 1 1 0.995578\n",
      "pattern3 1 0 -1 -0.719806\n",
      "pattern4 1 1 1 0.821341\n",
      " modified Weights  [-1.89515837  2.0681679 ] 0.9879152118889793\n",
      " Training with pattern  3  weights  [-1.89515837  2.068164  ] 0.9771210211741417   weights  [-1.9086603  2.0681679]  bias  0.9744132798686259\n",
      "pattern1 0 0 1 0.750637\n",
      "pattern2 0 1 1 0.995458\n",
      "pattern3 1 0 -1 -0.732568\n",
      "pattern4 1 1 1 0.812357\n",
      " modified Weights  [-1.9086603  2.0681679] 0.9744132798686259\n",
      " Training with pattern  4  weights  [-1.89515837  2.068164  ] 0.9771210211741417   weights  [-1.902279   2.0745492]  bias  0.9807945753963959\n",
      "pattern1 0 0 1 0.75341\n",
      "pattern2 0 1 1 0.995572\n",
      "pattern3 1 0 -1 -0.726599\n",
      "pattern4 1 1 1 0.818767\n",
      " modified Weights  [-1.902279   2.0745492] 0.9807945753963959\n",
      "+++++++++++Epoch  87  cost=  0.16842002640988013\n",
      " Training with pattern  1  weights  [-1.902279   2.0745492] 0.9807945753963959   weights  [-1.902279   2.0745492]  bias  0.9914564973679123\n",
      "pattern1 0 0 1 0.757983\n",
      "pattern2 0 1 1 0.995665\n",
      "pattern3 1 0 -1 -0.721527\n",
      "pattern4 1 1 1 0.822251\n",
      " modified Weights  [-1.902279   2.0745492] 0.9914564973679123\n",
      " Training with pattern  2  weights  [-1.902279   2.0745492] 0.9807945753963959   weights  [-1.902279    2.07455295]  bias  0.9914602476635529\n",
      "pattern1 0 0 1 0.757984\n",
      "pattern2 0 1 1 0.995665\n",
      "pattern3 1 0 -1 -0.721525\n",
      "pattern4 1 1 1 0.822253\n",
      " modified Weights  [-1.902279    2.07455295] 0.9914602476635529\n",
      " Training with pattern  3  weights  [-1.902279   2.0745492] 0.9807945753963959   weights  [-1.91562914  2.07455295]  bias  0.9781101094123458\n",
      "pattern1 0 0 1 0.752247\n",
      "pattern2 0 1 1 0.995548\n",
      "pattern3 1 0 -1 -0.73408\n",
      "pattern4 1 1 1 0.813413\n",
      " modified Weights  [-1.91562914  2.07455295] 0.9781101094123458\n",
      " Training with pattern  4  weights  [-1.902279   2.0745492] 0.9807945753963959   weights  [-1.90931579  2.0808663 ]  bias  0.9844234597274699\n",
      "pattern1 0 0 1 0.754974\n",
      "pattern2 0 1 1 0.995659\n",
      "pattern3 1 0 -1 -0.728204\n",
      "pattern4 1 1 1 0.819723\n",
      " modified Weights  [-1.90931579  2.0808663 ] 0.9844234597274699\n",
      "+++++++++++Epoch  88  cost=  0.16642927144966074\n",
      " Training with pattern  1  weights  [-1.90931579  2.0808663 ] 0.9844234597274699   weights  [-1.90931579  2.0808663 ]  bias  0.9949598939928178\n",
      "pattern1 0 0 1 0.759469\n",
      "pattern2 0 1 1 0.995749\n",
      "pattern3 1 0 -1 -0.723216\n",
      "pattern4 1 1 1 0.82315\n",
      " modified Weights  [-1.90931579  2.0808663 ] 0.9949598939928178\n",
      " Training with pattern  2  weights  [-1.90931579  2.0808663 ] 0.9844234597274699   weights  [-1.90931579  2.0808699 ]  bias  0.9949635002814275\n",
      "pattern1 0 0 1 0.759471\n",
      "pattern2 0 1 1 0.995749\n",
      "pattern3 1 0 -1 -0.723215\n",
      "pattern4 1 1 1 0.823153\n",
      " modified Weights  [-1.90931579  2.0808699 ] 0.9949635002814275\n",
      " Training with pattern  3  weights  [-1.90931579  2.0808663 ] 0.9844234597274699   weights  [-1.92251736  2.0808699 ]  bias  0.9817619318934899\n",
      "pattern1 0 0 1 0.753828\n",
      "pattern2 0 1 1 0.995636\n",
      "pattern3 1 0 -1 -0.735569\n",
      "pattern4 1 1 1 0.814453\n",
      " modified Weights  [-1.92251736  2.0808699 ] 0.9817619318934899\n",
      " Training with pattern  4  weights  [-1.90931579  2.0808663 ] 0.9844234597274699   weights  [-1.91627059  2.08711667]  bias  0.9880086974271732\n",
      "pattern1 0 0 1 0.756512\n",
      "pattern2 0 1 1 0.995743\n",
      "pattern3 1 0 -1 -0.729783\n",
      "pattern4 1 1 1 0.820666\n",
      " modified Weights  [-1.91627059  2.08711667] 0.9880086974271732\n",
      "+++++++++++Epoch  89  cost=  0.1644826195654201\n",
      " Training with pattern  1  weights  [-1.91627059  2.08711667] 0.9880086974271732   weights  [-1.91627059  2.08711667]  bias  0.9984224300422596\n",
      "pattern1 0 0 1 0.760931\n",
      "pattern2 0 1 1 0.995831\n",
      "pattern3 1 0 -1 -0.724878\n",
      "pattern4 1 1 1 0.824038\n",
      " modified Weights  [-1.91627059  2.08711667] 0.9984224300422596\n",
      " Training with pattern  2  weights  [-1.91627059  2.08711667] 0.9880086974271732   weights  [-1.91627059  2.08712014]  bias  0.9984258993330781\n",
      "pattern1 0 0 1 0.760932\n",
      "pattern2 0 1 1 0.995831\n",
      "pattern3 1 0 -1 -0.724876\n",
      "pattern4 1 1 1 0.82404\n",
      " modified Weights  [-1.91627059  2.08712014] 0.9984258993330781\n",
      " Training with pattern  3  weights  [-1.91627059  2.08711667] 0.9880086974271732   weights  [-1.92932672  2.08712014]  bias  0.9853697759094456\n",
      "pattern1 0 0 1 0.755381\n",
      "pattern2 0 1 1 0.995721\n",
      "pattern3 1 0 -1 -0.737035\n",
      "pattern4 1 1 1 0.815476\n",
      " modified Weights  [-1.92932672  2.08712014] 0.9853697759094456\n",
      " Training with pattern  4  weights  [-1.91627059  2.08711667] 0.9880086974271732   weights  [-1.92314521  2.09330164]  bias  0.9915512779570115\n",
      "pattern1 0 0 1 0.758023\n",
      "pattern2 0 1 1 0.995825\n",
      "pattern3 1 0 -1 -0.731336\n",
      "pattern4 1 1 1 0.821596\n",
      " modified Weights  [-1.92314521  2.09330164] 0.9915512779570115\n",
      "+++++++++++Epoch  90  cost=  0.1625786601048985\n",
      " Training with pattern  1  weights  [-1.92314521  2.09330164] 0.9915512779570115   weights  [-1.92314521  2.09330164]  bias  1.0018450056517767\n",
      "pattern1 0 0 1 0.762368\n",
      "pattern2 0 1 1 0.99591\n",
      "pattern3 1 0 -1 -0.726512\n",
      "pattern4 1 1 1 0.824913\n",
      " modified Weights  [-1.92314521  2.09330164] 1.0018450056517767\n",
      " Training with pattern  2  weights  [-1.92314521  2.09330164] 0.9915512779570115   weights  [-1.92314521  2.09330498]  bias  1.00184834454384\n",
      "pattern1 0 0 1 0.762369\n",
      "pattern2 0 1 1 0.99591\n",
      "pattern3 1 0 -1 -0.72651\n",
      "pattern4 1 1 1 0.824915\n",
      " modified Weights  [-1.92314521  2.09330498] 1.00184834454384\n",
      " Training with pattern  3  weights  [-1.92314521  2.09330164] 0.9915512779570115   weights  [-1.93605892  2.09330498]  bias  0.9889346362543313\n",
      "pattern1 0 0 1 0.756908\n",
      "pattern2 0 1 1 0.995803\n",
      "pattern3 1 0 -1 -0.738478\n",
      "pattern4 1 1 1 0.816485\n",
      " modified Weights  [-1.93605892  2.09330498] 0.9889346362543313\n",
      " Training with pattern  4  weights  [-1.92314521  2.09330164] 0.9915512779570115   weights  [-1.9299414  2.0994225]  bias  0.9950521584217531\n",
      "pattern1 0 0 1 0.759508\n",
      "pattern2 0 1 1 0.995904\n",
      "pattern3 1 0 -1 -0.732865\n",
      "pattern4 1 1 1 0.822512\n",
      " modified Weights  [-1.9299414  2.0994225] 0.9950521584217531\n",
      "+++++++++++Epoch  91  cost=  0.16071604091027564\n",
      " *********Epoch  90 Error  0.16071604091027564\n",
      " Training with pattern  1  weights  [-1.9299414  2.0994225] 0.9950521584217531   weights  [-1.9299414  2.0994225]  bias  1.0052284923043147\n",
      "pattern1 0 0 1 0.763781\n",
      "pattern2 0 1 1 0.995987\n",
      "pattern3 1 0 -1 -0.728119\n",
      "pattern4 1 1 1 0.825776\n",
      " modified Weights  [-1.9299414  2.0994225] 1.0052284923043147\n",
      " Training with pattern  2  weights  [-1.9299414  2.0994225] 0.9950521584217531   weights  [-1.9299414   2.09942572]  bias  1.0052317070143573\n",
      "pattern1 0 0 1 0.763783\n",
      "pattern2 0 1 1 0.995987\n",
      "pattern3 1 0 -1 -0.728118\n",
      "pattern4 1 1 1 0.825778\n",
      " modified Weights  [-1.9299414   2.09942572] 1.0052317070143573\n",
      " Training with pattern  3  weights  [-1.9299414  2.0994225] 0.9950521584217531   weights  [-1.94271563  2.09942572]  bias  0.9924574753503814\n",
      "pattern1 0 0 1 0.758408\n",
      "pattern2 0 1 1 0.995883\n",
      "pattern3 1 0 -1 -0.7399\n",
      "pattern4 1 1 1 0.817478\n",
      " modified Weights  [-1.94271563  2.09942572] 0.9924574753503814\n",
      " Training with pattern  4  weights  [-1.9299414  2.0994225] 0.9950521584217531   weights  [-1.93666084  2.10548051]  bias  0.998512264936296\n",
      "pattern1 0 0 1 0.760969\n",
      "pattern2 0 1 1 0.995982\n",
      "pattern3 1 0 -1 -0.73437\n",
      "pattern4 1 1 1 0.823415\n",
      " modified Weights  [-1.93666084  2.10548051] 0.998512264936296\n",
      "+++++++++++Epoch  92  cost=  0.15889346535496673\n",
      " Training with pattern  1  weights  [-1.93666084  2.10548051] 0.998512264936296   weights  [-1.93666084  2.10548051]  bias  1.0085737340101735\n",
      "pattern1 0 0 1 0.765171\n",
      "pattern2 0 1 1 0.996061\n",
      "pattern3 1 0 -1 -0.729701\n",
      "pattern4 1 1 1 0.826628\n",
      " modified Weights  [-1.93666084  2.10548051] 1.0085737340101735\n",
      " Training with pattern  2  weights  [-1.93666084  2.10548051] 0.998512264936296   weights  [-1.93666084  2.1054836 ]  bias  1.0085768303983766\n",
      "pattern1 0 0 1 0.765173\n",
      "pattern2 0 1 1 0.996061\n",
      "pattern3 1 0 -1 -0.729699\n",
      "pattern4 1 1 1 0.82663\n",
      " modified Weights  [-1.93666084  2.1054836 ] 1.0085768303983766\n",
      " Training with pattern  3  weights  [-1.93666084  2.10548051] 0.998512264936296   weights  [-1.94929845  2.1054836 ]  bias  0.9959392246058206\n",
      "pattern1 0 0 1 0.759883\n",
      "pattern2 0 1 1 0.995961\n",
      "pattern3 1 0 -1 -0.7413\n",
      "pattern4 1 1 1 0.818457\n",
      " modified Weights  [-1.94929845  2.1054836 ] 0.9959392246058206\n",
      " Training with pattern  4  weights  [-1.93666084  2.10548051] 0.998512264936296   weights  [-1.94330518  2.11147687]  bias  1.0019324939223548\n",
      "pattern1 0 0 1 0.762405\n",
      "pattern2 0 1 1 0.996056\n",
      "pattern3 1 0 -1 -0.735852\n",
      "pattern4 1 1 1 0.824306\n",
      " modified Weights  [-1.94330518  2.11147687] 1.0019324939223548\n",
      "+++++++++++Epoch  93  cost=  0.1571096895570096\n",
      " Training with pattern  1  weights  [-1.94330518  2.11147687] 1.0019324939223548   weights  [-1.94330518  2.11147687]  bias  1.0118815484278194\n",
      "pattern1 0 0 1 0.766539\n",
      "pattern2 0 1 1 0.996134\n",
      "pattern3 1 0 -1 -0.731257\n",
      "pattern4 1 1 1 0.827468\n",
      " modified Weights  [-1.94330518  2.11147687] 1.0118815484278194\n",
      " Training with pattern  2  weights  [-1.94330518  2.11147687] 1.0019324939223548   weights  [-1.94330518  2.11147986]  bias  1.0118845320215908\n",
      "pattern1 0 0 1 0.76654\n",
      "pattern2 0 1 1 0.996134\n",
      "pattern3 1 0 -1 -0.731256\n",
      "pattern4 1 1 1 0.82747\n",
      " modified Weights  [-1.94330518  2.11147986] 1.0118845320215908\n",
      " Training with pattern  3  weights  [-1.94330518  2.11147687] 1.0019324939223548   weights  [-1.95580893  2.11147986]  bias  0.9993807857036366\n",
      "pattern1 0 0 1 0.761334\n",
      "pattern2 0 1 1 0.996036\n",
      "pattern3 1 0 -1 -0.742679\n",
      "pattern4 1 1 1 0.819421\n",
      " modified Weights  [-1.95580893  2.11147986] 0.9993807857036366\n",
      " Training with pattern  4  weights  [-1.94330518  2.11147687] 1.0019324939223548   weights  [-1.949876    2.11741278]  bias  1.005313713339186\n",
      "pattern1 0 0 1 0.763817\n",
      "pattern2 0 1 1 0.996129\n",
      "pattern3 1 0 -1 -0.737311\n",
      "pattern4 1 1 1 0.825184\n",
      " modified Weights  [-1.949876    2.11741278] 1.005313713339186\n",
      "+++++++++++Epoch  94  cost=  0.1553635197569752\n",
      " Training with pattern  1  weights  [-1.949876    2.11741278] 1.005313713339186   weights  [-1.949876    2.11741278]  bias  1.0151527279290269\n",
      "pattern1 0 0 1 0.767885\n",
      "pattern2 0 1 1 0.996204\n",
      "pattern3 1 0 -1 -0.732788\n",
      "pattern4 1 1 1 0.828298\n",
      " modified Weights  [-1.949876    2.11741278] 1.0151527279290269\n",
      " Training with pattern  2  weights  [-1.949876    2.11741278] 1.005313713339186   weights  [-1.949876    2.11741566]  bias  1.0151556039449785\n",
      "pattern1 0 0 1 0.767886\n",
      "pattern2 0 1 1 0.996204\n",
      "pattern3 1 0 -1 -0.732787\n",
      "pattern4 1 1 1 0.8283\n",
      " modified Weights  [-1.949876    2.11741566] 1.0151556039449785\n",
      " Training with pattern  3  weights  [-1.949876    2.11741278] 1.005313713339186   weights  [-1.96224857  2.11741566]  bias  1.002783031825352\n",
      "pattern1 0 0 1 0.76276\n",
      "pattern2 0 1 1 0.996109\n",
      "pattern3 1 0 -1 -0.744038\n",
      "pattern4 1 1 1 0.820371\n",
      " modified Weights  [-1.96224857  2.11741566] 1.002783031825352\n",
      " Training with pattern  4  weights  [-1.949876    2.11741278] 1.005313713339186   weights  [-1.95637484  2.12328939]  bias  1.008656763852268\n",
      "pattern1 0 0 1 0.765206\n",
      "pattern2 0 1 1 0.9962\n",
      "pattern3 1 0 -1 -0.738748\n",
      "pattern4 1 1 1 0.82605\n",
      " modified Weights  [-1.95637484  2.12328939] 1.008656763852268\n",
      "+++++++++++Epoch  95  cost=  0.15365380984927526\n",
      " Training with pattern  1  weights  [-1.95637484  2.12328939] 1.008656763852268   weights  [-1.95637484  2.12328939]  bias  1.0183880406115886\n",
      "pattern1 0 0 1 0.769209\n",
      "pattern2 0 1 1 0.996273\n",
      "pattern3 1 0 -1 -0.734296\n",
      "pattern4 1 1 1 0.829116\n",
      " modified Weights  [-1.95637484  2.12328939] 1.0183880406115886\n",
      " Training with pattern  2  weights  [-1.95637484  2.12328939] 1.008656763852268   weights  [-1.95637484  2.12329216]  bias  1.0183908139758668\n",
      "pattern1 0 0 1 0.76921\n",
      "pattern2 0 1 1 0.996273\n",
      "pattern3 1 0 -1 -0.734295\n",
      "pattern4 1 1 1 0.829118\n",
      " modified Weights  [-1.95637484  2.12329216] 1.0183908139758668\n",
      " Training with pattern  3  weights  [-1.95637484  2.12328939] 1.008656763852268   weights  [-1.96861884  2.12329216]  bias  1.0061468088136252\n",
      "pattern1 0 0 1 0.764164\n",
      "pattern2 0 1 1 0.996181\n",
      "pattern3 1 0 -1 -0.745377\n",
      "pattern4 1 1 1 0.821307\n",
      " modified Weights  [-1.96861884  2.12329216] 1.0061468088136252\n",
      " Training with pattern  4  weights  [-1.95637484  2.12328939] 1.008656763852268   weights  [-1.96280319  2.12910782]  bias  1.0119624599436006\n",
      "pattern1 0 0 1 0.766572\n",
      "pattern2 0 1 1 0.996268\n",
      "pattern3 1 0 -1 -0.740163\n",
      "pattern4 1 1 1 0.826904\n",
      " modified Weights  [-1.96280319  2.12910782] 1.0119624599436006\n",
      "+++++++++++Epoch  96  cost=  0.15197945905657392\n",
      " Training with pattern  1  weights  [-1.96280319  2.12910782] 1.0119624599436006   weights  [-1.96280319  2.12910782]  bias  1.021588231262618\n",
      "pattern1 0 0 1 0.770513\n",
      "pattern2 0 1 1 0.996339\n",
      "pattern3 1 0 -1 -0.73578\n",
      "pattern4 1 1 1 0.829924\n",
      " modified Weights  [-1.96280319  2.12910782] 1.021588231262618\n",
      " Training with pattern  2  weights  [-1.96280319  2.12910782] 1.0119624599436006   weights  [-1.96280319  2.12911049]  bias  1.0215909066297224\n",
      "pattern1 0 0 1 0.770514\n",
      "pattern2 0 1 1 0.996339\n",
      "pattern3 1 0 -1 -0.735779\n",
      "pattern4 1 1 1 0.829926\n",
      " modified Weights  [-1.96280319  2.12911049] 1.0215909066297224\n",
      " Training with pattern  3  weights  [-1.96280319  2.12910782] 1.0119624599436006   weights  [-1.97492116  2.12911049]  bias  1.0094729362772548\n",
      "pattern1 0 0 1 0.765544\n",
      "pattern2 0 1 1 0.99625\n",
      "pattern3 1 0 -1 -0.746697\n",
      "pattern4 1 1 1 0.82223\n",
      " modified Weights  [-1.97492116  2.12911049] 1.0094729362772548\n",
      " Training with pattern  4  weights  [-1.96280319  2.12910782] 1.0119624599436006   weights  [-1.96916251  2.13486915]  bias  1.0152315909670337\n",
      "pattern1 0 0 1 0.767917\n",
      "pattern2 0 1 1 0.996335\n",
      "pattern3 1 0 -1 -0.741557\n",
      "pattern4 1 1 1 0.827747\n",
      " modified Weights  [-1.96916251  2.13486915] 1.0152315909670337\n",
      "+++++++++++Epoch  97  cost=  0.15033940973779675\n",
      " Training with pattern  1  weights  [-1.96916251  2.13486915] 1.0152315909670337   weights  [-1.96916251  2.13486915]  bias  1.024754022275267\n",
      "pattern1 0 0 1 0.771796\n",
      "pattern2 0 1 1 0.996404\n",
      "pattern3 1 0 -1 -0.737241\n",
      "pattern4 1 1 1 0.830722\n",
      " modified Weights  [-1.96916251  2.13486915] 1.024754022275267\n",
      " Training with pattern  2  weights  [-1.96916251  2.13486915] 1.0152315909670337   weights  [-1.96916251  2.13487173]  bias  1.024756604045484\n",
      "pattern1 0 0 1 0.771797\n",
      "pattern2 0 1 1 0.996404\n",
      "pattern3 1 0 -1 -0.73724\n",
      "pattern4 1 1 1 0.830723\n",
      " modified Weights  [-1.96916251  2.13487173] 1.024756604045484\n",
      " Training with pattern  3  weights  [-1.96916251  2.13486915] 1.0152315909670337   weights  [-1.9811569   2.13487173]  bias  1.0127622086419155\n",
      "pattern1 0 0 1 0.766902\n",
      "pattern2 0 1 1 0.996317\n",
      "pattern3 1 0 -1 -0.747998\n",
      "pattern4 1 1 1 0.82314\n",
      " modified Weights  [-1.9811569   2.13487173] 1.0127622086419155\n",
      " Training with pattern  4  weights  [-1.96916251  2.13486915] 1.0152315909670337   weights  [-1.97545419  2.14057444]  bias  1.0184649221518116\n",
      "pattern1 0 0 1 0.769241\n",
      "pattern2 0 1 1 0.9964\n",
      "pattern3 1 0 -1 -0.742931\n",
      "pattern4 1 1 1 0.828579\n",
      " modified Weights  [-1.97545419  2.14057444] 1.0184649221518116\n",
      "+++++++++++Epoch  98  cost=  0.14873264532093516\n",
      " Training with pattern  1  weights  [-1.97545419  2.14057444] 1.0184649221518116   weights  [-1.97545419  2.14057444]  bias  1.0278861145214968\n",
      "pattern1 0 0 1 0.773059\n",
      "pattern2 0 1 1 0.996467\n",
      "pattern3 1 0 -1 -0.73868\n",
      "pattern4 1 1 1 0.831509\n",
      " modified Weights  [-1.97545419  2.14057444] 1.0278861145214968\n",
      " Training with pattern  2  weights  [-1.97545419  2.14057444] 1.0184649221518116   weights  [-1.97545419  2.14057693]  bias  1.0278886068570627\n",
      "pattern1 0 0 1 0.77306\n",
      "pattern2 0 1 1 0.996467\n",
      "pattern3 1 0 -1 -0.738679\n",
      "pattern4 1 1 1 0.83151\n",
      " modified Weights  [-1.97545419  2.14057693] 1.0278886068570627\n",
      " Training with pattern  3  weights  [-1.97545419  2.14057444] 1.0184649221518116   weights  [-1.9873274   2.14057693]  bias  1.0160153961497458\n",
      "pattern1 0 0 1 0.768239\n",
      "pattern2 0 1 1 0.996382\n",
      "pattern3 1 0 -1 -0.74928\n",
      "pattern4 1 1 1 0.824036\n",
      " modified Weights  [-1.9873274   2.14057693] 1.0160153961497458\n",
      " Training with pattern  4  weights  [-1.97545419  2.14057444] 1.0184649221518116   weights  [-1.9816796   2.14622473]  bias  1.0216631955573081\n",
      "pattern1 0 0 1 0.770543\n",
      "pattern2 0 1 1 0.996463\n",
      "pattern3 1 0 -1 -0.744284\n",
      "pattern4 1 1 1 0.829399\n",
      " modified Weights  [-1.9816796   2.14622473] 1.0216631955573081\n",
      "+++++++++++Epoch  99  cost=  0.14715818835249658\n",
      " Training with pattern  1  weights  [-1.9816796   2.14622473] 1.0216631955573081   weights  [-1.9816796   2.14622473]  bias  1.0309851881833785\n",
      "pattern1 0 0 1 0.774303\n",
      "pattern2 0 1 1 0.996528\n",
      "pattern3 1 0 -1 -0.740097\n",
      "pattern4 1 1 1 0.832286\n",
      " modified Weights  [-1.9816796   2.14622473] 1.0309851881833785\n",
      " Training with pattern  2  weights  [-1.9816796   2.14622473] 1.0216631955573081   weights  [-1.9816796   2.14622714]  bias  1.0309875950234724\n",
      "pattern1 0 0 1 0.774304\n",
      "pattern2 0 1 1 0.996528\n",
      "pattern3 1 0 -1 -0.740096\n",
      "pattern4 1 1 1 0.832288\n",
      " modified Weights  [-1.9816796   2.14622714] 1.0309875950234724\n",
      " Training with pattern  3  weights  [-1.9816796   2.14622473] 1.0216631955573081   weights  [-1.99343395  2.14622714]  bias  1.019233245810698\n",
      "pattern1 0 0 1 0.769554\n",
      "pattern2 0 1 1 0.996446\n",
      "pattern3 1 0 -1 -0.750544\n",
      "pattern4 1 1 1 0.824921\n",
      " modified Weights  [-1.99343395  2.14622714] 1.019233245810698\n",
      " Training with pattern  4  weights  [-1.9816796   2.14622473] 1.0216631955573081   weights  [-1.98784007  2.15182102]  bias  1.0248271309817336\n",
      "pattern1 0 0 1 0.771825\n",
      "pattern2 0 1 1 0.996524\n",
      "pattern3 1 0 -1 -0.745618\n",
      "pattern4 1 1 1 0.830209\n",
      " modified Weights  [-1.98784007  2.15182102] 1.0248271309817336\n",
      "+++++++++++Epoch  100  cost=  0.14561509865605526\n",
      " Training with pattern  1  weights  [-1.98784007  2.15182102] 1.0248271309817336   weights  [-1.98784007  2.15182102]  bias  1.0340519035452251\n",
      "pattern1 0 0 1 0.775528\n",
      "pattern2 0 1 1 0.996587\n",
      "pattern3 1 0 -1 -0.741493\n",
      "pattern4 1 1 1 0.833054\n",
      " modified Weights  [-1.98784007  2.15182102] 1.0340519035452251\n",
      " Training with pattern  2  weights  [-1.98784007  2.15182102] 1.0248271309817336   weights  [-1.98784007  2.15182335]  bias  1.0340542286198904\n",
      "pattern1 0 0 1 0.775529\n",
      "pattern2 0 1 1 0.996588\n",
      "pattern3 1 0 -1 -0.741492\n",
      "pattern4 1 1 1 0.833055\n",
      " modified Weights  [-1.98784007  2.15182335] 1.0340542286198904\n",
      " Training with pattern  3  weights  [-1.98784007  2.15182102] 1.0248271309817336   weights  [-1.99947781  2.15182335]  bias  1.0224164823083717\n",
      "pattern1 0 0 1 0.770849\n",
      "pattern2 0 1 1 0.996507\n",
      "pattern3 1 0 -1 -0.751791\n",
      "pattern4 1 1 1 0.825793\n",
      " modified Weights  [-1.99947781  2.15182335] 1.0224164823083717\n",
      " Training with pattern  4  weights  [-1.98784007  2.15182102] 1.0248271309817336   weights  [-1.99393687  2.15736429]  bias  1.027957426827413\n",
      "pattern1 0 0 1 0.773088\n",
      "pattern2 0 1 1 0.996584\n",
      "pattern3 1 0 -1 -0.746932\n",
      "pattern4 1 1 1 0.831008\n",
      " modified Weights  [-1.99393687  2.15736429] 1.027957426827413\n",
      "+++++++++++Epoch  101  cost=  0.14410247159289785\n",
      " *********Epoch  100 Error  0.14410247159289785\n",
      " Training with pattern  1  weights  [-1.99393687  2.15736429] 1.027957426827413   weights  [-1.99393687  2.15736429]  bias  1.0370869017487283\n",
      "pattern1 0 0 1 0.776735\n",
      "pattern2 0 1 1 0.996645\n",
      "pattern3 1 0 -1 -0.742868\n",
      "pattern4 1 1 1 0.833811\n",
      " modified Weights  [-1.99393687  2.15736429] 1.0370869017487283\n",
      " Training with pattern  2  weights  [-1.99393687  2.15736429] 1.027957426827413   weights  [-1.99393687  2.15736654]  bias  1.037089148591805\n",
      "pattern1 0 0 1 0.776736\n",
      "pattern2 0 1 1 0.996645\n",
      "pattern3 1 0 -1 -0.742867\n",
      "pattern4 1 1 1 0.833813\n",
      " modified Weights  [-1.99393687  2.15736654] 1.037089148591805\n",
      " Training with pattern  3  weights  [-1.99393687  2.15736429] 1.027957426827413   weights  [-2.00546021  2.15736654]  bias  1.0255658088628814\n",
      "pattern1 0 0 1 0.772124\n",
      "pattern2 0 1 1 0.996567\n",
      "pattern3 1 0 -1 -0.75302\n",
      "pattern4 1 1 1 0.826653\n",
      " modified Weights  [-2.00546021  2.15736654] 1.0255658088628814\n",
      " Training with pattern  4  weights  [-1.99393687  2.15736429] 1.027957426827413   weights  [-1.99997125  2.16285549]  bias  1.0310547609250698\n",
      "pattern1 0 0 1 0.774331\n",
      "pattern2 0 1 1 0.996642\n",
      "pattern3 1 0 -1 -0.748228\n",
      "pattern4 1 1 1 0.831797\n",
      " modified Weights  [-1.99997125  2.16285549] 1.0310547609250698\n",
      "+++++++++++Epoch  102  cost=  0.14261943641827377\n",
      " Training with pattern  1  weights  [-1.99997125  2.16285549] 1.0310547609250698   weights  [-1.99997125  2.16285549]  bias  1.0400908055131202\n",
      "pattern1 0 0 1 0.777924\n",
      "pattern2 0 1 1 0.996702\n",
      "pattern3 1 0 -1 -0.744224\n",
      "pattern4 1 1 1 0.83456\n",
      " modified Weights  [-1.99997125  2.16285549] 1.0400908055131202\n",
      " Training with pattern  2  weights  [-1.99997125  2.16285549] 1.0310547609250698   weights  [-1.99997125  2.16285767]  bias  1.0400929774742684\n",
      "pattern1 0 0 1 0.777925\n",
      "pattern2 0 1 1 0.996702\n",
      "pattern3 1 0 -1 -0.744223\n",
      "pattern4 1 1 1 0.834561\n",
      " modified Weights  [-1.99997125  2.16285767] 1.0400929774742684\n",
      " Training with pattern  3  weights  [-1.99997125  2.16285549] 1.0310547609250698   weights  [-2.01138232  2.16285767]  bias  1.0286819080531395\n",
      "pattern1 0 0 1 0.773379\n",
      "pattern2 0 1 1 0.996626\n",
      "pattern3 1 0 -1 -0.754233\n",
      "pattern4 1 1 1 0.827501\n",
      " modified Weights  [-2.01138232  2.16285767] 1.0286819080531395\n",
      " Training with pattern  4  weights  [-1.99997125  2.16285549] 1.0310547609250698   weights  [-2.00594444  2.16829555]  bias  1.0341197913193882\n",
      "pattern1 0 0 1 0.775555\n",
      "pattern2 0 1 1 0.996698\n",
      "pattern3 1 0 -1 -0.749505\n",
      "pattern4 1 1 1 0.832575\n",
      " modified Weights  [-2.00594444  2.16829555] 1.0341197913193882\n",
      "+++++++++++Epoch  103  cost=  0.14116515472721952\n",
      " Training with pattern  1  weights  [-2.00594444  2.16829555] 1.0341197913193882   weights  [-2.00594444  2.16829555]  bias  1.0430642198222664\n",
      "pattern1 0 0 1 0.779095\n",
      "pattern2 0 1 1 0.996757\n",
      "pattern3 1 0 -1 -0.745559\n",
      "pattern4 1 1 1 0.835299\n",
      " modified Weights  [-2.00594444  2.16829555] 1.0430642198222664\n",
      " Training with pattern  2  weights  [-2.00594444  2.16829555] 1.0341197913193882   weights  [-2.00594444  2.16829765]  bias  1.0430663200781516\n",
      "pattern1 0 0 1 0.779096\n",
      "pattern2 0 1 1 0.996757\n",
      "pattern3 1 0 -1 -0.745558\n",
      "pattern4 1 1 1 0.8353\n",
      " modified Weights  [-2.00594444  2.16829765] 1.0430663200781516\n",
      " Training with pattern  3  weights  [-2.00594444  2.16829555] 1.0341197913193882   weights  [-2.01724532  2.16829765]  bias  1.0317654426007958\n",
      "pattern1 0 0 1 0.774615\n",
      "pattern2 0 1 1 0.996683\n",
      "pattern3 1 0 -1 -0.755428\n",
      "pattern4 1 1 1 0.828338\n",
      " modified Weights  [-2.01724532  2.16829765] 1.0317654426007958\n",
      " Training with pattern  4  weights  [-2.00594444  2.16829555] 1.0341197913193882   weights  [-2.0118576   2.17368536]  bias  1.0371531570179942\n",
      "pattern1 0 0 1 0.776761\n",
      "pattern2 0 1 1 0.996753\n",
      "pattern3 1 0 -1 -0.750764\n",
      "pattern4 1 1 1 0.833344\n",
      " modified Weights  [-2.0118576   2.17368536] 1.0371531570179942\n",
      "+++++++++++Epoch  104  cost=  0.13973881898435314\n",
      " Training with pattern  1  weights  [-2.0118576   2.17368536] 1.0371531570179942   weights  [-2.0118576   2.17368536]  bias  1.0460077325804706\n",
      "pattern1 0 0 1 0.780249\n",
      "pattern2 0 1 1 0.99681\n",
      "pattern3 1 0 -1 -0.746875\n",
      "pattern4 1 1 1 0.836029\n",
      " modified Weights  [-2.0118576   2.17368536] 1.0460077325804706\n",
      " Training with pattern  2  weights  [-2.0118576   2.17368536] 1.0371531570179942   weights  [-2.0118576   2.17368739]  bias  1.0460097641451755\n",
      "pattern1 0 0 1 0.78025\n",
      "pattern2 0 1 1 0.99681\n",
      "pattern3 1 0 -1 -0.746874\n",
      "pattern4 1 1 1 0.83603\n",
      " modified Weights  [-2.0118576   2.17368739] 1.0460097641451755\n",
      " Training with pattern  3  weights  [-2.0118576   2.17368536] 1.0371531570179942   weights  [-2.02305031  2.17368739]  bias  1.0348170561179204\n",
      "pattern1 0 0 1 0.775833\n",
      "pattern2 0 1 1 0.996738\n",
      "pattern3 1 0 -1 -0.756608\n",
      "pattern4 1 1 1 0.829164\n",
      " modified Weights  [-2.02305031  2.17368739] 1.0348170561179204\n",
      " Training with pattern  4  weights  [-2.0118576   2.17368536] 1.0371531570179942   weights  [-2.01771189  2.17902582]  bias  1.0401554787058438\n",
      "pattern1 0 0 1 0.777949\n",
      "pattern2 0 1 1 0.996807\n",
      "pattern3 1 0 -1 -0.752006\n",
      "pattern4 1 1 1 0.834102\n",
      " modified Weights  [-2.01771189  2.17902582] 1.0401554787058438\n",
      "+++++++++++Epoch  105  cost=  0.13833965113243635\n",
      " Training with pattern  1  weights  [-2.01771189  2.17902582] 1.0401554787058438   weights  [-2.01771189  2.17902582]  bias  1.0489219152386628\n",
      "pattern1 0 0 1 0.781387\n",
      "pattern2 0 1 1 0.996862\n",
      "pattern3 1 0 -1 -0.748172\n",
      "pattern4 1 1 1 0.83675\n",
      " modified Weights  [-2.01771189  2.17902582] 1.0489219152386628\n",
      " Training with pattern  2  weights  [-2.01771189  2.17902582] 1.0401554787058438   weights  [-2.01771189  2.17902778]  bias  1.0489238809733872\n",
      "pattern1 0 0 1 0.781388\n",
      "pattern2 0 1 1 0.996862\n",
      "pattern3 1 0 -1 -0.748171\n",
      "pattern4 1 1 1 0.836751\n",
      " modified Weights  [-2.01771189  2.17902778] 1.0489238809733872\n",
      " Training with pattern  3  weights  [-2.01771189  2.17902582] 1.0401554787058438   weights  [-2.0287984   2.17902778]  bias  1.0378373738203988\n",
      "pattern1 0 0 1 0.777033\n",
      "pattern2 0 1 1 0.996792\n",
      "pattern3 1 0 -1 -0.757772\n",
      "pattern4 1 1 1 0.829978\n",
      " modified Weights  [-2.0287984   2.17902778] 1.0378373738203988\n",
      " Training with pattern  4  weights  [-2.01771189  2.17902582] 1.0401554787058438   weights  [-2.02350841  2.18431777]  bias  1.0431273594269024\n",
      "pattern1 0 0 1 0.77912\n",
      "pattern2 0 1 1 0.996859\n",
      "pattern3 1 0 -1 -0.753231\n",
      "pattern4 1 1 1 0.834851\n",
      " modified Weights  [-2.02350841  2.18431777] 1.0431273594269024\n",
      "+++++++++++Epoch  106  cost=  0.13696690127485506\n",
      " Training with pattern  1  weights  [-2.02350841  2.18431777] 1.0431273594269024   weights  [-2.02350841  2.18431777]  bias  1.0518073233925447\n",
      "pattern1 0 0 1 0.782508\n",
      "pattern2 0 1 1 0.996913\n",
      "pattern3 1 0 -1 -0.749451\n",
      "pattern4 1 1 1 0.837463\n",
      " modified Weights  [-2.02350841  2.18431777] 1.0518073233925447\n",
      " Training with pattern  2  weights  [-2.02350841  2.18431777] 1.0431273594269024   weights  [-2.02350841  2.18431967]  bias  1.051809226014646\n",
      "pattern1 0 0 1 0.782509\n",
      "pattern2 0 1 1 0.996913\n",
      "pattern3 1 0 -1 -0.74945\n",
      "pattern4 1 1 1 0.837464\n",
      " modified Weights  [-2.02350841  2.18431967] 1.051809226014646\n",
      " Training with pattern  3  weights  [-2.02350841  2.18431777] 1.0431273594269024   weights  [-2.03449063  2.18431967]  bias  1.0408270032088809\n",
      "pattern1 0 0 1 0.778214\n",
      "pattern2 0 1 1 0.996845\n",
      "pattern3 1 0 -1 -0.75892\n",
      "pattern4 1 1 1 0.830782\n",
      " modified Weights  [-2.03449063  2.18431967] 1.0408270032088809\n",
      " Training with pattern  4  weights  [-2.02350841  2.18431777] 1.0431273594269024   weights  [-2.02924825  2.18956205]  bias  1.0460693852348677\n",
      "pattern1 0 0 1 0.780274\n",
      "pattern2 0 1 1 0.99691\n",
      "pattern3 1 0 -1 -0.754439\n",
      "pattern4 1 1 1 0.835591\n",
      " modified Weights  [-2.02924825  2.18956205] 1.0460693852348677\n",
      "+++++++++++Epoch  107  cost=  0.1356198464275132\n",
      " Training with pattern  1  weights  [-2.02924825  2.18956205] 1.0460693852348677   weights  [-2.02924825  2.18956205]  bias  1.0546644973541655\n",
      "pattern1 0 0 1 0.783613\n",
      "pattern2 0 1 1 0.996963\n",
      "pattern3 1 0 -1 -0.750712\n",
      "pattern4 1 1 1 0.838167\n",
      " modified Weights  [-2.02924825  2.18956205] 1.0546644973541655\n",
      " Training with pattern  2  weights  [-2.02924825  2.18956205] 1.0460693852348677   weights  [-2.02924825  2.1895639 ]  bias  1.0546663394455917\n",
      "pattern1 0 0 1 0.783614\n",
      "pattern2 0 1 1 0.996963\n",
      "pattern3 1 0 -1 -0.750711\n",
      "pattern4 1 1 1 0.838168\n",
      " modified Weights  [-2.02924825  2.1895639 ] 1.0546663394455917\n",
      " Training with pattern  3  weights  [-2.02924825  2.18956205] 1.0460693852348677   weights  [-2.04012806  2.1895639 ]  bias  1.0437865347190138\n",
      "pattern1 0 0 1 0.779379\n",
      "pattern2 0 1 1 0.996896\n",
      "pattern3 1 0 -1 -0.760053\n",
      "pattern4 1 1 1 0.831576\n",
      " modified Weights  [-2.04012806  2.1895639 ] 1.0437865347190138\n",
      " Training with pattern  4  weights  [-2.02924825  2.18956205] 1.0460693852348677   weights  [-2.03493247  2.19475949]  bias  1.0489821258145884\n",
      "pattern1 0 0 1 0.78141\n",
      "pattern2 0 1 1 0.99696\n",
      "pattern3 1 0 -1 -0.75563\n",
      "pattern4 1 1 1 0.836322\n",
      " modified Weights  [-2.03493247  2.19475949] 1.0489821258145884\n",
      "+++++++++++Epoch  108  cost=  0.13429778933594153\n",
      " Training with pattern  1  weights  [-2.03493247  2.19475949] 1.0489821258145884   weights  [-2.03493247  2.19475949]  bias  1.0574939626983162\n",
      "pattern1 0 0 1 0.784703\n",
      "pattern2 0 1 1 0.997011\n",
      "pattern3 1 0 -1 -0.751955\n",
      "pattern4 1 1 1 0.838862\n",
      " modified Weights  [-2.03493247  2.19475949] 1.0574939626983162\n",
      " Training with pattern  2  weights  [-2.03493247  2.19475949] 1.0489821258145884   weights  [-2.03493247  2.19476127]  bias  1.0574957467134747\n",
      "pattern1 0 0 1 0.784704\n",
      "pattern2 0 1 1 0.997011\n",
      "pattern3 1 0 -1 -0.751954\n",
      "pattern4 1 1 1 0.838863\n",
      " modified Weights  [-2.03493247  2.19476127] 1.0574957467134747\n",
      " Training with pattern  3  weights  [-2.03493247  2.19475949] 1.0489821258145884   weights  [-2.04571167  2.19476127]  bias  1.0467165423425795\n",
      "pattern1 0 0 1 0.780527\n",
      "pattern2 0 1 1 0.996946\n",
      "pattern3 1 0 -1 -0.761172\n",
      "pattern4 1 1 1 0.832359\n",
      " modified Weights  [-2.04571167  2.19476127] 1.0467165423425795\n",
      " Training with pattern  4  weights  [-2.03493247  2.19475949] 1.0489821258145884   weights  [-2.04056208  2.19991086]  bias  1.0518661350757261\n",
      "pattern1 0 0 1 0.782531\n",
      "pattern2 0 1 1 0.997008\n",
      "pattern3 1 0 -1 -0.756806\n",
      "pattern4 1 1 1 0.837044\n",
      " modified Weights  [-2.04056208  2.19991086] 1.0518661350757261\n",
      "+++++++++++Epoch  109  cost=  0.13300005735370618\n",
      " Training with pattern  1  weights  [-2.04056208  2.19991086] 1.0518661350757261   weights  [-2.04056208  2.19991086]  bias  1.0602962307850463\n",
      "pattern1 0 0 1 0.785777\n",
      "pattern2 0 1 1 0.997058\n",
      "pattern3 1 0 -1 -0.753181\n",
      "pattern4 1 1 1 0.839549\n",
      " modified Weights  [-2.04056208  2.19991086] 1.0602962307850463\n",
      " Training with pattern  2  weights  [-2.04056208  2.19991086] 1.0518661350757261   weights  [-2.04056208  2.19991259]  bias  1.0602979590581532\n",
      "pattern1 0 0 1 0.785778\n",
      "pattern2 0 1 1 0.997058\n",
      "pattern3 1 0 -1 -0.75318\n",
      "pattern4 1 1 1 0.83955\n",
      " modified Weights  [-2.04056208  2.19991259] 1.0602979590581532\n",
      " Training with pattern  3  weights  [-2.04056208  2.19991086] 1.0518661350757261   weights  [-2.05124245  2.19991259]  bias  1.0496175842210702\n",
      "pattern1 0 0 1 0.781658\n",
      "pattern2 0 1 1 0.996995\n",
      "pattern3 1 0 -1 -0.762276\n",
      "pattern4 1 1 1 0.833132\n",
      " modified Weights  [-2.05124245  2.19991259] 1.0496175842210702\n",
      " Training with pattern  4  weights  [-2.04056208  2.19991086] 1.0518661350757261   weights  [-2.04613808  2.20501696]  bias  1.054721951720121\n",
      "pattern1 0 0 1 0.783635\n",
      "pattern2 0 1 1 0.997055\n",
      "pattern3 1 0 -1 -0.757966\n",
      "pattern4 1 1 1 0.837756\n",
      " modified Weights  [-2.04613808  2.20501696] 1.054721951720121\n",
      "+++++++++++Epoch  110  cost=  0.1317260013784711\n",
      " Training with pattern  1  weights  [-2.04613808  2.20501696] 1.054721951720121   weights  [-2.04613808  2.20501696]  bias  1.0630717992595278\n",
      "pattern1 0 0 1 0.786837\n",
      "pattern2 0 1 1 0.997104\n",
      "pattern3 1 0 -1 -0.75439\n",
      "pattern4 1 1 1 0.840229\n",
      " modified Weights  [-2.04613808  2.20501696] 1.0630717992595278\n",
      " Training with pattern  2  weights  [-2.04613808  2.20501696] 1.054721951720121   weights  [-2.04613808  2.20501863]  bias  1.0630734740114745\n",
      "pattern1 0 0 1 0.786837\n",
      "pattern2 0 1 1 0.997104\n",
      "pattern3 1 0 -1 -0.754389\n",
      "pattern4 1 1 1 0.84023\n",
      " modified Weights  [-2.04613808  2.20501863] 1.0630734740114745\n",
      " Training with pattern  3  weights  [-2.04613808  2.20501696] 1.054721951720121   weights  [-2.05672136  2.20501863]  bias  1.0524902032131302\n",
      "pattern1 0 0 1 0.782773\n",
      "pattern2 0 1 1 0.997042\n",
      "pattern3 1 0 -1 -0.763365\n",
      "pattern4 1 1 1 0.833895\n",
      " modified Weights  [-2.05672136  2.20501863] 1.0524902032131302\n",
      " Training with pattern  4  weights  [-2.04613808  2.20501696] 1.054721951720121   weights  [-2.05166146  2.21007853]  bias  1.057550099784224\n",
      "pattern1 0 0 1 0.784724\n",
      "pattern2 0 1 1 0.997101\n",
      "pattern3 1 0 -1 -0.75911\n",
      "pattern4 1 1 1 0.838461\n",
      " modified Weights  [-2.05166146  2.21007853] 1.057550099784224\n",
      "+++++++++++Epoch  111  cost=  0.13047499484230868\n",
      " *********Epoch  110 Error  0.13047499484230868\n",
      " Training with pattern  1  weights  [-2.05166146  2.21007853] 1.057550099784224   weights  [-2.05166146  2.21007853]  bias  1.0658211525304244\n",
      "pattern1 0 0 1 0.787882\n",
      "pattern2 0 1 1 0.997149\n",
      "pattern3 1 0 -1 -0.755583\n",
      "pattern4 1 1 1 0.8409\n",
      " modified Weights  [-2.05166146  2.21007853] 1.0658211525304244\n",
      " Training with pattern  2  weights  [-2.05166146  2.21007853] 1.057550099784224   weights  [-2.05166146  2.21008015]  bias  1.0658227758751975\n",
      "pattern1 0 0 1 0.787882\n",
      "pattern2 0 1 1 0.997149\n",
      "pattern3 1 0 -1 -0.755582\n",
      "pattern4 1 1 1 0.840901\n",
      " modified Weights  [-2.05166146  2.21008015] 1.0658227758751975\n",
      " Training with pattern  3  weights  [-2.05166146  2.21007853] 1.057550099784224   weights  [-2.06214931  2.21008015]  bias  1.055334927437218\n",
      "pattern1 0 0 1 0.783872\n",
      "pattern2 0 1 1 0.997089\n",
      "pattern3 1 0 -1 -0.764441\n",
      "pattern4 1 1 1 0.834648\n",
      " modified Weights  [-2.06214931  2.21008015] 1.055334927437218\n",
      " Training with pattern  4  weights  [-2.05166146  2.21007853] 1.057550099784224   weights  [-2.05713315  2.21509632]  bias  1.0603510891578882\n",
      "pattern1 0 0 1 0.785798\n",
      "pattern2 0 1 1 0.997146\n",
      "pattern3 1 0 -1 -0.760239\n",
      "pattern4 1 1 1 0.839156\n",
      " modified Weights  [-2.05713315  2.21509632] 1.0603510891578882\n",
      "+++++++++++Epoch  112  cost=  0.1292464327530834\n",
      " Training with pattern  1  weights  [-2.05713315  2.21509632] 1.0603510891578882   weights  [-2.05713315  2.21509632]  bias  1.0685447622278506\n",
      "pattern1 0 0 1 0.788912\n",
      "pattern2 0 1 1 0.997193\n",
      "pattern3 1 0 -1 -0.75676\n",
      "pattern4 1 1 1 0.841563\n",
      " modified Weights  [-2.05713315  2.21509632] 1.0685447622278506\n",
      " Training with pattern  2  weights  [-2.05713315  2.21509632] 1.0603510891578882   weights  [-2.05713315  2.21509789]  bias  1.0685463361785377\n",
      "pattern1 0 0 1 0.788913\n",
      "pattern2 0 1 1 0.997193\n",
      "pattern3 1 0 -1 -0.756759\n",
      "pattern4 1 1 1 0.841564\n",
      " modified Weights  [-2.05713315  2.21509789] 1.0685463361785377\n",
      " Training with pattern  3  weights  [-2.05713315  2.21509632] 1.0603510891578882   weights  [-2.06752721  2.21509789]  bias  1.0581522707907558\n",
      "pattern1 0 0 1 0.784956\n",
      "pattern2 0 1 1 0.997134\n",
      "pattern3 1 0 -1 -0.765503\n",
      "pattern4 1 1 1 0.835392\n",
      " modified Weights  [-2.06752721  2.21509789] 1.0581522707907558\n",
      " Training with pattern  4  weights  [-2.05713315  2.21509632] 1.0603510891578882   weights  [-2.06255407  2.22007103]  bias  1.0631254160807273\n",
      "pattern1 0 0 1 0.786857\n",
      "pattern2 0 1 1 0.99719\n",
      "pattern3 1 0 -1 -0.761354\n",
      "pattern4 1 1 1 0.839844\n",
      " modified Weights  [-2.06255407  2.22007103] 1.0631254160807273\n",
      "+++++++++++Epoch  113  cost=  0.12803973078393846\n",
      " Training with pattern  1  weights  [-2.06255407  2.22007103] 1.0631254160807273   weights  [-2.06255407  2.22007103]  bias  1.0712430876419456\n",
      "pattern1 0 0 1 0.789929\n",
      "pattern2 0 1 1 0.997235\n",
      "pattern3 1 0 -1 -0.757921\n",
      "pattern4 1 1 1 0.842219\n",
      " modified Weights  [-2.06255407  2.22007103] 1.0712430876419456\n",
      " Training with pattern  2  weights  [-2.06255407  2.22007103] 1.0631254160807273   weights  [-2.06255407  2.22007256]  bias  1.0712446141163563\n",
      "pattern1 0 0 1 0.78993\n",
      "pattern2 0 1 1 0.997235\n",
      "pattern3 1 0 -1 -0.75792\n",
      "pattern4 1 1 1 0.84222\n",
      " modified Weights  [-2.06255407  2.22007256] 1.0712446141163563\n",
      " Training with pattern  3  weights  [-2.06255407  2.22007103] 1.0631254160807273   weights  [-2.07285595  2.22007256]  bias  1.0609427334469659\n",
      "pattern1 0 0 1 0.786024\n",
      "pattern2 0 1 1 0.997178\n",
      "pattern3 1 0 -1 -0.766552\n",
      "pattern4 1 1 1 0.836127\n",
      " modified Weights  [-2.07285595  2.22007256] 1.0609427334469659\n",
      " Training with pattern  4  weights  [-2.06255407  2.22007103] 1.0631254160807273   weights  [-2.06792512  2.22500339]  bias  1.0658735636171823\n",
      "pattern1 0 0 1 0.787902\n",
      "pattern2 0 1 1 0.997233\n",
      "pattern3 1 0 -1 -0.762454\n",
      "pattern4 1 1 1 0.840523\n",
      " modified Weights  [-2.06792512  2.22500339] 1.0658735636171823\n",
      "+++++++++++Epoch  114  cost=  0.1268543244081129\n",
      " Training with pattern  1  weights  [-2.06792512  2.22500339] 1.0658735636171823   weights  [-2.06792512  2.22500339]  bias  1.073916576143029\n",
      "pattern1 0 0 1 0.790932\n",
      "pattern2 0 1 1 0.997277\n",
      "pattern3 1 0 -1 -0.759066\n",
      "pattern4 1 1 1 0.842868\n",
      " modified Weights  [-2.06792512  2.22500339] 1.073916576143029\n",
      " Training with pattern  2  weights  [-2.06792512  2.22500339] 1.0658735636171823   weights  [-2.06792512  2.22500487]  bias  1.0739180569689597\n",
      "pattern1 0 0 1 0.790933\n",
      "pattern2 0 1 1 0.997277\n",
      "pattern3 1 0 -1 -0.759066\n",
      "pattern4 1 1 1 0.842869\n",
      " modified Weights  [-2.06792512  2.22500487] 1.0739180569689597\n",
      " Training with pattern  3  weights  [-2.06792512  2.22500339] 1.0658735636171823   weights  [-2.07813637  2.22500487]  bias  1.0637068023305152\n",
      "pattern1 0 0 1 0.787078\n",
      "pattern2 0 1 1 0.997221\n",
      "pattern3 1 0 -1 -0.767588\n",
      "pattern4 1 1 1 0.836852\n",
      " modified Weights  [-2.07813637  2.22500487] 1.0637068023305152\n",
      " Training with pattern  4  weights  [-2.06792512  2.22500339] 1.0658735636171823   weights  [-2.07324717  2.22989407]  bias  1.068596002111371\n",
      "pattern1 0 0 1 0.788932\n",
      "pattern2 0 1 1 0.997275\n",
      "pattern3 1 0 -1 -0.763541\n",
      "pattern4 1 1 1 0.841194\n",
      " modified Weights  [-2.07324717  2.22989407] 1.068596002111371\n",
      "+++++++++++Epoch  115  cost=  0.12568966807649817\n",
      " Training with pattern  1  weights  [-2.07324717  2.22989407] 1.068596002111371   weights  [-2.07324717  2.22989407]  bias  1.0765656635842453\n",
      "pattern1 0 0 1 0.791922\n",
      "pattern2 0 1 1 0.997318\n",
      "pattern3 1 0 -1 -0.760197\n",
      "pattern4 1 1 1 0.843509\n",
      " modified Weights  [-2.07324717  2.22989407] 1.0765656635842453\n",
      " Training with pattern  2  weights  [-2.07324717  2.22989407] 1.068596002111371   weights  [-2.07324717  2.22989551]  bias  1.0765671005044122\n",
      "pattern1 0 0 1 0.791923\n",
      "pattern2 0 1 1 0.997318\n",
      "pattern3 1 0 -1 -0.760196\n",
      "pattern4 1 1 1 0.843509\n",
      " modified Weights  [-2.07324717  2.22989551] 1.0765671005044122\n",
      " Training with pattern  3  weights  [-2.07324717  2.22989407] 1.068596002111371   weights  [-2.08336932  2.22989551]  bias  1.0664449515730337\n",
      "pattern1 0 0 1 0.788118\n",
      "pattern2 0 1 1 0.997263\n",
      "pattern3 1 0 -1 -0.768611\n",
      "pattern4 1 1 1 0.837569\n",
      " modified Weights  [-2.08336932  2.22989551] 1.0664449515730337\n",
      " Training with pattern  4  weights  [-2.07324717  2.22989407] 1.068596002111371   weights  [-2.07852108  2.23474375]  bias  1.071293189622731\n",
      "pattern1 0 0 1 0.789948\n",
      "pattern2 0 1 1 0.997316\n",
      "pattern3 1 0 -1 -0.764613\n",
      "pattern4 1 1 1 0.841857\n",
      " modified Weights  [-2.07852108  2.23474375] 1.071293189622731\n",
      "+++++++++++Epoch  116  cost=  0.1245452344355043\n",
      " Training with pattern  1  weights  [-2.07852108  2.23474375] 1.071293189622731   weights  [-2.07852108  2.23474375]  bias  1.079190774687561\n",
      "pattern1 0 0 1 0.792899\n",
      "pattern2 0 1 1 0.997358\n",
      "pattern3 1 0 -1 -0.761313\n",
      "pattern4 1 1 1 0.844142\n",
      " modified Weights  [-2.07852108  2.23474375] 1.079190774687561\n",
      " Training with pattern  2  weights  [-2.07852108  2.23474375] 1.071293189622731   weights  [-2.07852108  2.23474514]  bias  1.0791921693642246\n",
      "pattern1 0 0 1 0.792899\n",
      "pattern2 0 1 1 0.997358\n",
      "pattern3 1 0 -1 -0.761312\n",
      "pattern4 1 1 1 0.844143\n",
      " modified Weights  [-2.07852108  2.23474514] 1.0791921693642246\n",
      " Training with pattern  3  weights  [-2.07852108  2.23474375] 1.071293189622731   weights  [-2.08855561  2.23474514]  bias  1.0691576429495044\n",
      "pattern1 0 0 1 0.789144\n",
      "pattern2 0 1 1 0.997304\n",
      "pattern3 1 0 -1 -0.769621\n",
      "pattern4 1 1 1 0.838276\n",
      " modified Weights  [-2.08855561  2.23474514] 1.0691576429495044\n",
      " Training with pattern  4  weights  [-2.07852108  2.23474375] 1.071293189622731   weights  [-2.08374768  2.23955307]  bias  1.0739655723434112\n",
      "pattern1 0 0 1 0.790951\n",
      "pattern2 0 1 1 0.997355\n",
      "pattern3 1 0 -1 -0.765672\n",
      "pattern4 1 1 1 0.842513\n",
      " modified Weights  [-2.08374768  2.23955307] 1.0739655723434112\n",
      "+++++++++++Epoch  117  cost=  0.12342051358296695\n",
      " Training with pattern  1  weights  [-2.08374768  2.23955307] 1.0739655723434112   weights  [-2.08374768  2.23955307]  bias  1.0817923234139195\n",
      "pattern1 0 0 1 0.793863\n",
      "pattern2 0 1 1 0.997396\n",
      "pattern3 1 0 -1 -0.762414\n",
      "pattern4 1 1 1 0.844769\n",
      " modified Weights  [-2.08374768  2.23955307] 1.0817923234139195\n",
      " Training with pattern  2  weights  [-2.08374768  2.23955307] 1.0739655723434112   weights  [-2.08374768  2.23955442]  bias  1.0817936774332229\n",
      "pattern1 0 0 1 0.793863\n",
      "pattern2 0 1 1 0.997396\n",
      "pattern3 1 0 -1 -0.762414\n",
      "pattern4 1 1 1 0.84477\n",
      " modified Weights  [-2.08374768  2.23955442] 1.0817936774332229\n",
      " Training with pattern  3  weights  [-2.08374768  2.23955307] 1.0739655723434112   weights  [-2.09369603  2.23955442]  bias  1.0718453262964696\n",
      "pattern1 0 0 1 0.790155\n",
      "pattern2 0 1 1 0.997344\n",
      "pattern3 1 0 -1 -0.770619\n",
      "pattern4 1 1 1 0.838976\n",
      " modified Weights  [-2.09369603  2.23955442] 1.0718453262964696\n",
      " Training with pattern  4  weights  [-2.08374768  2.23955307] 1.0739655723434112   weights  [-2.08892777  2.24432268]  bias  1.0766135849983114\n",
      "pattern1 0 0 1 0.79194\n",
      "pattern2 0 1 1 0.997394\n",
      "pattern3 1 0 -1 -0.766717\n",
      "pattern4 1 1 1 0.843161\n",
      " modified Weights  [-2.08892777  2.24432268] 1.0766135849983114\n",
      "+++++++++++Epoch  118  cost=  0.12231501235997004\n",
      " Training with pattern  1  weights  [-2.08892777  2.24432268] 1.0766135849983114   weights  [-2.08892777  2.24432268]  bias  1.0843707133183234\n",
      "pattern1 0 0 1 0.794814\n",
      "pattern2 0 1 1 0.997434\n",
      "pattern3 1 0 -1 -0.763501\n",
      "pattern4 1 1 1 0.845389\n",
      " modified Weights  [-2.08892777  2.24432268] 1.0843707133183234\n",
      " Training with pattern  2  weights  [-2.08892777  2.24432268] 1.0766135849983114   weights  [-2.08892777  2.244324  ]  bias  1.0843720281943645\n",
      "pattern1 0 0 1 0.794815\n",
      "pattern2 0 1 1 0.997434\n",
      "pattern3 1 0 -1 -0.763501\n",
      "pattern4 1 1 1 0.845389\n",
      " modified Weights  [-2.08892777  2.244324  ] 1.0843720281943645\n",
      " Training with pattern  3  weights  [-2.08892777  2.24432268] 1.0766135849983114   weights  [-2.09879136  2.244324  ]  bias  1.0745084399129452\n",
      "pattern1 0 0 1 0.791154\n",
      "pattern2 0 1 1 0.997383\n",
      "pattern3 1 0 -1 -0.771605\n",
      "pattern4 1 1 1 0.839666\n",
      " modified Weights  [-2.09879136  2.244324  ] 1.0745084399129452\n",
      " Training with pattern  4  weights  [-2.08892777  2.24432268] 1.0766135849983114   weights  [-2.09406215  2.24905321]  bias  1.0792376512286197\n",
      "pattern1 0 0 1 0.792916\n",
      "pattern2 0 1 1 0.997432\n",
      "pattern3 1 0 -1 -0.76775\n",
      "pattern4 1 1 1 0.843802\n",
      " modified Weights  [-2.09406215  2.24905321] 1.0792376512286197\n",
      "+++++++++++Epoch  119  cost=  0.12122825367658836\n",
      " Training with pattern  1  weights  [-2.09406215  2.24905321] 1.0792376512286197   weights  [-2.09406215  2.24905321]  bias  1.0869263378905658\n",
      "pattern1 0 0 1 0.795754\n",
      "pattern2 0 1 1 0.997471\n",
      "pattern3 1 0 -1 -0.764575\n",
      "pattern4 1 1 1 0.846002\n",
      " modified Weights  [-2.09406215  2.24905321] 1.0869263378905658\n",
      " Training with pattern  2  weights  [-2.09406215  2.24905321] 1.0792376512286197   weights  [-2.09406215  2.24905449]  bias  1.0869276150692202\n",
      "pattern1 0 0 1 0.795754\n",
      "pattern2 0 1 1 0.997471\n",
      "pattern3 1 0 -1 -0.764574\n",
      "pattern4 1 1 1 0.846002\n",
      " modified Weights  [-2.09406215  2.24905449] 1.0869276150692202\n",
      " Training with pattern  3  weights  [-2.09406215  2.24905321] 1.0792376512286197   weights  [-2.10384235  2.24905449]  bias  1.0771474109448793\n",
      "pattern1 0 0 1 0.792139\n",
      "pattern2 0 1 1 0.997421\n",
      "pattern3 1 0 -1 -0.772579\n",
      "pattern4 1 1 1 0.840349\n",
      " modified Weights  [-2.10384235  2.24905449] 1.0771474109448793\n",
      " Training with pattern  4  weights  [-2.09406215  2.24905321] 1.0792376512286197   weights  [-2.09915158  2.25374526]  bias  1.081838183959644\n",
      "pattern1 0 0 1 0.79388\n",
      "pattern2 0 1 1 0.997469\n",
      "pattern3 1 0 -1 -0.76877\n",
      "pattern4 1 1 1 0.844435\n",
      " modified Weights  [-2.09915158  2.25374526] 1.081838183959644\n",
      "+++++++++++Epoch  120  cost=  0.12015977586968538\n",
      " Training with pattern  1  weights  [-2.09915158  2.25374526] 1.081838183959644   weights  [-2.09915158  2.25374526]  bias  1.0894595808822922\n",
      "pattern1 0 0 1 0.796681\n",
      "pattern2 0 1 1 0.997508\n",
      "pattern3 1 0 -1 -0.765635\n",
      "pattern4 1 1 1 0.846608\n",
      " modified Weights  [-2.09915158  2.25374526] 1.0894595808822922\n",
      " Training with pattern  2  weights  [-2.09915158  2.25374526] 1.081838183959644   weights  [-2.09915158  2.2537465 ]  bias  1.0894608217448052\n",
      "pattern1 0 0 1 0.796681\n",
      "pattern2 0 1 1 0.997508\n",
      "pattern3 1 0 -1 -0.765634\n",
      "pattern4 1 1 1 0.846608\n",
      " modified Weights  [-2.09915158  2.2537465 ] 1.0894608217448052\n",
      " Training with pattern  3  weights  [-2.09915158  2.25374526] 1.081838183959644   weights  [-2.10884975  2.2537465 ]  bias  1.0797626557539541\n",
      "pattern1 0 0 1 0.793111\n",
      "pattern2 0 1 1 0.997459\n",
      "pattern3 1 0 -1 -0.773542\n",
      "pattern4 1 1 1 0.841023\n",
      " modified Weights  [-2.10884975  2.2537465 ] 1.0797626557539541\n",
      " Training with pattern  4  weights  [-2.09915158  2.25374526] 1.081838183959644   weights  [-2.10419682  2.25839943]  bias  1.0844155857537043\n",
      "pattern1 0 0 1 0.794831\n",
      "pattern2 0 1 1 0.997506\n",
      "pattern3 1 0 -1 -0.769777\n",
      "pattern4 1 1 1 0.845061\n",
      " modified Weights  [-2.10419682  2.25839943] 1.0844155857537043\n",
      "+++++++++++Epoch  121  cost=  0.11910913209101034\n",
      " *********Epoch  120 Error  0.11910913209101034\n",
      " Training with pattern  1  weights  [-2.10419682  2.25839943] 1.0844155857537043   weights  [-2.10419682  2.25839943]  bias  1.0919708166210422\n",
      "pattern1 0 0 1 0.797596\n",
      "pattern2 0 1 1 0.997543\n",
      "pattern3 1 0 -1 -0.766681\n",
      "pattern4 1 1 1 0.847207\n",
      " modified Weights  [-2.10419682  2.25839943] 1.0919708166210422\n",
      " Training with pattern  2  weights  [-2.10419682  2.25839943] 1.0844155857537043   weights  [-2.10419682  2.25840064]  bias  1.0919720224874052\n",
      "pattern1 0 0 1 0.797597\n",
      "pattern2 0 1 1 0.997543\n",
      "pattern3 1 0 -1 -0.766681\n",
      "pattern4 1 1 1 0.847208\n",
      " modified Weights  [-2.10419682  2.25840064] 1.0919720224874052\n",
      " Training with pattern  3  weights  [-2.10419682  2.25839943] 1.0844155857537043   weights  [-2.11381426  2.25840064]  bias  1.0823545802714774\n",
      "pattern1 0 0 1 0.794071\n",
      "pattern2 0 1 1 0.997495\n",
      "pattern3 1 0 -1 -0.774493\n",
      "pattern4 1 1 1 0.84169\n",
      " modified Weights  [-2.11381426  2.25840064] 1.0823545802714774\n",
      " Training with pattern  4  weights  [-2.10419682  2.25839943] 1.0844155857537043   weights  [-2.10919859  2.26301631]  bias  1.0869702491487903\n",
      "pattern1 0 0 1 0.79577\n",
      "pattern2 0 1 1 0.997541\n",
      "pattern3 1 0 -1 -0.770773\n",
      "pattern4 1 1 1 0.84568\n",
      " modified Weights  [-2.10919859  2.26301631] 1.0869702491487903\n",
      "+++++++++++Epoch  122  cost=  0.11807588972395622\n",
      " Training with pattern  1  weights  [-2.10919859  2.26301631] 1.0869702491487903   weights  [-2.10919859  2.26301631]  bias  1.094460410311879\n",
      "pattern1 0 0 1 0.7985\n",
      "pattern2 0 1 1 0.997578\n",
      "pattern3 1 0 -1 -0.767715\n",
      "pattern4 1 1 1 0.8478\n",
      " modified Weights  [-2.10919859  2.26301631] 1.094460410311879\n",
      " Training with pattern  2  weights  [-2.10919859  2.26301631] 1.0869702491487903   weights  [-2.10919859  2.26301748]  bias  1.094461582444004\n",
      "pattern1 0 0 1 0.798501\n",
      "pattern2 0 1 1 0.997578\n",
      "pattern3 1 0 -1 -0.767714\n",
      "pattern4 1 1 1 0.847801\n",
      " modified Weights  [-2.10919859  2.26301748] 1.094461582444004\n",
      " Training with pattern  3  weights  [-2.10919859  2.26301631] 1.0869702491487903   weights  [-2.11873659  2.26301748]  bias  1.0849235803380735\n",
      "pattern1 0 0 1 0.795018\n",
      "pattern2 0 1 1 0.997531\n",
      "pattern3 1 0 -1 -0.775433\n",
      "pattern4 1 1 1 0.842348\n",
      " modified Weights  [-2.11873659  2.26301748] 1.0849235803380735\n",
      " Training with pattern  4  weights  [-2.10919859  2.26301631] 1.0869702491487903   weights  [-2.11415761  2.26759645]  bias  1.0895025569836665\n",
      "pattern1 0 0 1 0.796697\n",
      "pattern2 0 1 1 0.997576\n",
      "pattern3 1 0 -1 -0.771756\n",
      "pattern4 1 1 1 0.846292\n",
      " modified Weights  [-2.11415761  2.26759645] 1.0895025569836665\n",
      "+++++++++++Epoch  123  cost=  0.11705962982742961\n",
      " Training with pattern  1  weights  [-2.11415761  2.26759645] 1.0895025569836665   weights  [-2.11415761  2.26759645]  bias  1.0969287183271856\n",
      "pattern1 0 0 1 0.799393\n",
      "pattern2 0 1 1 0.997612\n",
      "pattern3 1 0 -1 -0.768735\n",
      "pattern4 1 1 1 0.848387\n",
      " modified Weights  [-2.11415761  2.26759645] 1.0969287183271856\n",
      " Training with pattern  2  weights  [-2.11415761  2.26759645] 1.0895025569836665   weights  [-2.11415761  2.26759759]  bias  1.0969298579318936\n",
      "pattern1 0 0 1 0.799394\n",
      "pattern2 0 1 1 0.997612\n",
      "pattern3 1 0 -1 -0.768735\n",
      "pattern4 1 1 1 0.848387\n",
      " modified Weights  [-2.11415761  2.26759759] 1.0969298579318936\n",
      " Training with pattern  3  weights  [-2.11415761  2.26759645] 1.0895025569836665   weights  [-2.12361743  2.26759759]  bias  1.0874700420298447\n",
      "pattern1 0 0 1 0.795953\n",
      "pattern2 0 1 1 0.997566\n",
      "pattern3 1 0 -1 -0.776362\n",
      "pattern4 1 1 1 0.842999\n",
      " modified Weights  [-2.12361743  2.26759759] 1.0874700420298447\n",
      " Training with pattern  4  weights  [-2.11415761  2.26759645] 1.0895025569836665   weights  [-2.11907459  2.27214043]  bias  1.0920128827100621\n",
      "pattern1 0 0 1 0.797612\n",
      "pattern2 0 1 1 0.99761\n",
      "pattern3 1 0 -1 -0.772727\n",
      "pattern4 1 1 1 0.846898\n",
      " modified Weights  [-2.11907459  2.27214043] 1.0920128827100621\n",
      "+++++++++++Epoch  124  cost=  0.11605994660538582\n",
      " Training with pattern  1  weights  [-2.11907459  2.27214043] 1.0920128827100621   weights  [-2.11907459  2.27214043]  bias  1.0993760884851775\n",
      "pattern1 0 0 1 0.800275\n",
      "pattern2 0 1 1 0.997645\n",
      "pattern3 1 0 -1 -0.769744\n",
      "pattern4 1 1 1 0.848967\n",
      " modified Weights  [-2.11907459  2.27214043] 1.0993760884851775\n",
      " Training with pattern  2  weights  [-2.11907459  2.27214043] 1.0920128827100621   weights  [-2.11907459  2.27214154]  bias  1.0993771967170094\n",
      "pattern1 0 0 1 0.800275\n",
      "pattern2 0 1 1 0.997645\n",
      "pattern3 1 0 -1 -0.769743\n",
      "pattern4 1 1 1 0.848968\n",
      " modified Weights  [-2.11907459  2.27214154] 1.0993771967170094\n",
      " Training with pattern  3  weights  [-2.11907459  2.27214043] 1.0920128827100621   weights  [-2.12845744  2.27214154]  bias  1.0899943419716365\n",
      "pattern1 0 0 1 0.796876\n",
      "pattern2 0 1 1 0.9976\n",
      "pattern3 1 0 -1 -0.77728\n",
      "pattern4 1 1 1 0.843643\n",
      " modified Weights  [-2.12845744  2.27214154] 1.0899943419716365\n",
      " Training with pattern  4  weights  [-2.11907459  2.27214043] 1.0920128827100621   weights  [-2.1239502   2.27664879]  bias  1.0945015906925488\n",
      "pattern1 0 0 1 0.798515\n",
      "pattern2 0 1 1 0.997643\n",
      "pattern3 1 0 -1 -0.773687\n",
      "pattern4 1 1 1 0.847497\n",
      " modified Weights  [-2.1239502   2.27664879] 1.0945015906925488\n",
      "+++++++++++Epoch  125  cost=  0.11507644690066736\n",
      " Training with pattern  1  weights  [-2.1239502   2.27664879] 1.0945015906925488   weights  [-2.1239502   2.27664879]  bias  1.1018028603176446\n",
      "pattern1 0 0 1 0.801146\n",
      "pattern2 0 1 1 0.997677\n",
      "pattern3 1 0 -1 -0.77074\n",
      "pattern4 1 1 1 0.849541\n",
      " modified Weights  [-2.1239502   2.27664879] 1.1018028603176446\n",
      " Training with pattern  2  weights  [-2.1239502   2.27664879] 1.0945015906925488   weights  [-2.1239502   2.27664987]  bias  1.1018039382815101\n",
      "pattern1 0 0 1 0.801146\n",
      "pattern2 0 1 1 0.997677\n",
      "pattern3 1 0 -1 -0.770739\n",
      "pattern4 1 1 1 0.849542\n",
      " modified Weights  [-2.1239502   2.27664987] 1.1018039382815101\n",
      " Training with pattern  3  weights  [-2.1239502   2.27664879] 1.0945015906925488   weights  [-2.13325729  2.27664987]  bias  1.092496847638006\n",
      "pattern1 0 0 1 0.797788\n",
      "pattern2 0 1 1 0.997633\n",
      "pattern3 1 0 -1 -0.778188\n",
      "pattern4 1 1 1 0.844279\n",
      " modified Weights  [-2.13325729  2.27664987] 1.092496847638006\n",
      " Training with pattern  4  weights  [-2.1239502   2.27664879] 1.0945015906925488   weights  [-2.1287851   2.28112206]  bias  1.096969036496682\n",
      "pattern1 0 0 1 0.799408\n",
      "pattern2 0 1 1 0.997675\n",
      "pattern3 1 0 -1 -0.774636\n",
      "pattern4 1 1 1 0.848089\n",
      " modified Weights  [-2.1287851   2.28112206] 1.096969036496682\n",
      "+++++++++++Epoch  126  cost=  0.11410874971186323\n",
      " Training with pattern  1  weights  [-2.1287851   2.28112206] 1.096969036496682   weights  [-2.1287851   2.28112206]  bias  1.1042093653274194\n",
      "pattern1 0 0 1 0.802006\n",
      "pattern2 0 1 1 0.997709\n",
      "pattern3 1 0 -1 -0.771724\n",
      "pattern4 1 1 1 0.850109\n",
      " modified Weights  [-2.1287851   2.28112206] 1.1042093653274194\n",
      " Training with pattern  2  weights  [-2.1287851   2.28112206] 1.096969036496682   weights  [-2.1287851   2.28112311]  bias  1.1042104140810922\n",
      "pattern1 0 0 1 0.802006\n",
      "pattern2 0 1 1 0.997709\n",
      "pattern3 1 0 -1 -0.771723\n",
      "pattern4 1 1 1 0.85011\n",
      " modified Weights  [-2.1287851   2.28112311] 1.1042104140810922\n",
      " Training with pattern  3  weights  [-2.1287851   2.28112206] 1.096969036496682   weights  [-2.13801759  2.28112311]  bias  1.0949779176424634\n",
      "pattern1 0 0 1 0.798688\n",
      "pattern2 0 1 1 0.997666\n",
      "pattern3 1 0 -1 -0.779086\n",
      "pattern4 1 1 1 0.844908\n",
      " modified Weights  [-2.13801759  2.28112311] 1.0949779176424634\n",
      " Training with pattern  4  weights  [-2.1287851   2.28112206] 1.096969036496682   weights  [-2.13357994  2.28556076]  bias  1.0994155671659425\n",
      "pattern1 0 0 1 0.800289\n",
      "pattern2 0 1 1 0.997707\n",
      "pattern3 1 0 -1 -0.775573\n",
      "pattern4 1 1 1 0.848675\n",
      " modified Weights  [-2.13357994  2.28556076] 1.0994155671659425\n",
      "+++++++++++Epoch  127  cost=  0.11315648573198546\n",
      " Training with pattern  1  weights  [-2.13357994  2.28556076] 1.0994155671659425   weights  [-2.13357994  2.28556076]  bias  1.1065959272360315\n",
      "pattern1 0 0 1 0.802856\n",
      "pattern2 0 1 1 0.99774\n",
      "pattern3 1 0 -1 -0.772696\n",
      "pattern4 1 1 1 0.850671\n",
      " modified Weights  [-2.13357994  2.28556076] 1.1065959272360315\n",
      " Training with pattern  2  weights  [-2.13357994  2.28556076] 1.0994155671659425   weights  [-2.13357994  2.28556178]  bias  1.1065969477925008\n",
      "pattern1 0 0 1 0.802856\n",
      "pattern2 0 1 1 0.99774\n",
      "pattern3 1 0 -1 -0.772695\n",
      "pattern4 1 1 1 0.850672\n",
      " modified Weights  [-2.13357994  2.28556178] 1.1065969477925008\n",
      " Training with pattern  3  weights  [-2.13357994  2.28556076] 1.0994155671659425   weights  [-2.14273899  2.28556178]  bias  1.097437902015522\n",
      "pattern1 0 0 1 0.799577\n",
      "pattern2 0 1 1 0.997698\n",
      "pattern3 1 0 -1 -0.779973\n",
      "pattern4 1 1 1 0.84553\n",
      " modified Weights  [-2.14273899  2.28556178] 1.097437902015522\n",
      " Training with pattern  4  weights  [-2.13357994  2.28556076] 1.0994155671659425   weights  [-2.13833537  2.2899654 ]  bias  1.101841521487994\n",
      "pattern1 0 0 1 0.80116\n",
      "pattern2 0 1 1 0.997738\n",
      "pattern3 1 0 -1 -0.7765\n",
      "pattern4 1 1 1 0.849254\n",
      " modified Weights  [-2.13833537  2.2899654 ] 1.101841521487994\n",
      "+++++++++++Epoch  128  cost=  0.11221929690783014\n",
      " Training with pattern  1  weights  [-2.13833537  2.2899654 ] 1.101841521487994   weights  [-2.13833537  2.2899654 ]  bias  1.1089628622219923\n",
      "pattern1 0 0 1 0.803695\n",
      "pattern2 0 1 1 0.99777\n",
      "pattern3 1 0 -1 -0.773657\n",
      "pattern4 1 1 1 0.851227\n",
      " modified Weights  [-2.13833537  2.2899654 ] 1.1089628622219923\n",
      " Training with pattern  2  weights  [-2.13833537  2.2899654 ] 1.101841521487994   weights  [-2.13833537  2.28996639]  bias  1.1089638555516812\n",
      "pattern1 0 0 1 0.803696\n",
      "pattern2 0 1 1 0.99777\n",
      "pattern3 1 0 -1 -0.773656\n",
      "pattern4 1 1 1 0.851228\n",
      " modified Weights  [-2.13833537  2.28996639] 1.1089638555516812\n",
      " Training with pattern  3  weights  [-2.13833537  2.2899654 ] 1.101841521487994   weights  [-2.14742208  2.28996639]  bias  1.099877142472069\n",
      "pattern1 0 0 1 0.800455\n",
      "pattern2 0 1 1 0.997729\n",
      "pattern3 1 0 -1 -0.78085\n",
      "pattern4 1 1 1 0.846145\n",
      " modified Weights  [-2.14742208  2.28996639] 1.099877142472069\n",
      " Training with pattern  4  weights  [-2.13833537  2.2899654 ] 1.101841521487994   weights  [-2.143052    2.29433648]  bias  1.1042472302507442\n",
      "pattern1 0 0 1 0.802019\n",
      "pattern2 0 1 1 0.997769\n",
      "pattern3 1 0 -1 -0.777416\n",
      "pattern4 1 1 1 0.849828\n",
      " modified Weights  [-2.143052    2.29433648] 1.1042472302507442\n",
      "+++++++++++Epoch  129  cost=  0.11129683601895496\n",
      " Training with pattern  1  weights  [-2.143052    2.29433648] 1.1042472302507442   weights  [-2.143052    2.29433648]  bias  1.111310479150128\n",
      "pattern1 0 0 1 0.804525\n",
      "pattern2 0 1 1 0.9978\n",
      "pattern3 1 0 -1 -0.774606\n",
      "pattern4 1 1 1 0.851778\n",
      " modified Weights  [-2.143052    2.29433648] 1.111310479150128\n",
      " Training with pattern  2  weights  [-2.143052    2.29433648] 1.1042472302507442   weights  [-2.143052    2.29433744]  bias  1.1113114461829863\n",
      "pattern1 0 0 1 0.804525\n",
      "pattern2 0 1 1 0.9978\n",
      "pattern3 1 0 -1 -0.774605\n",
      "pattern4 1 1 1 0.851778\n",
      " modified Weights  [-2.143052    2.29433744] 1.1113114461829863\n",
      " Training with pattern  3  weights  [-2.143052    2.29433648] 1.1042472302507442   weights  [-2.15206747  2.29433744]  bias  1.1022959726685377\n",
      "pattern1 0 0 1 0.801322\n",
      "pattern2 0 1 1 0.99776\n",
      "pattern3 1 0 -1 -0.781718\n",
      "pattern4 1 1 1 0.846753\n",
      " modified Weights  [-2.15206747  2.29433744] 1.1022959726685377\n",
      " Training with pattern  4  weights  [-2.143052    2.29433648] 1.1042472302507442   weights  [-2.14773043  2.29867449]  bias  1.1066330164886653\n",
      "pattern1 0 0 1 0.802869\n",
      "pattern2 0 1 1 0.997798\n",
      "pattern3 1 0 -1 -0.778321\n",
      "pattern4 1 1 1 0.850395\n",
      " modified Weights  [-2.14773043  2.29867449] 1.1066330164886653\n",
      "+++++++++++Epoch  130  cost=  0.110388766275268\n",
      " Training with pattern  1  weights  [-2.14773043  2.29867449] 1.1066330164886653   weights  [-2.14773043  2.29867449]  bias  1.1136390797923563\n",
      "pattern1 0 0 1 0.805345\n",
      "pattern2 0 1 1 0.997829\n",
      "pattern3 1 0 -1 -0.775544\n",
      "pattern4 1 1 1 0.852323\n",
      " modified Weights  [-2.14773043  2.29867449] 1.1136390797923563\n",
      " Training with pattern  2  weights  [-2.14773043  2.29867449] 1.1066330164886653   weights  [-2.14773043  2.29867543]  bias  1.113640021419835\n",
      "pattern1 0 0 1 0.805345\n",
      "pattern2 0 1 1 0.997829\n",
      "pattern3 1 0 -1 -0.775544\n",
      "pattern4 1 1 1 0.852323\n",
      " modified Weights  [-2.14773043  2.29867543] 1.113640021419835\n",
      " Training with pattern  3  weights  [-2.14773043  2.29867449] 1.1066330164886653   weights  [-2.15667573  2.29867543]  bias  1.1046947184503417\n",
      "pattern1 0 0 1 0.802179\n",
      "pattern2 0 1 1 0.99779\n",
      "pattern3 1 0 -1 -0.782575\n",
      "pattern4 1 1 1 0.847354\n",
      " modified Weights  [-2.15667573  2.29867543] 1.1046947184503417\n",
      " Training with pattern  4  weights  [-2.14773043  2.29867449] 1.1066330164886653   weights  [-2.15237125  2.30297991]  bias  1.1089991957198149\n",
      "pattern1 0 0 1 0.803708\n",
      "pattern2 0 1 1 0.997828\n",
      "pattern3 1 0 -1 -0.779216\n",
      "pattern4 1 1 1 0.850956\n",
      " modified Weights  [-2.15237125  2.30297991] 1.1089991957198149\n",
      "+++++++++++Epoch  131  cost=  0.1094947609322838\n",
      " *********Epoch  130 Error  0.1094947609322838\n",
      " Training with pattern  1  weights  [-2.15237125  2.30297991] 1.1089991957198149   weights  [-2.15237125  2.30297991]  bias  1.1159489590402847\n",
      "pattern1 0 0 1 0.806155\n",
      "pattern2 0 1 1 0.997858\n",
      "pattern3 1 0 -1 -0.776471\n",
      "pattern4 1 1 1 0.852862\n",
      " modified Weights  [-2.15237125  2.30297991] 1.1159489590402847\n",
      " Training with pattern  2  weights  [-2.15237125  2.30297991] 1.1089991957198149   weights  [-2.15237125  2.30298082]  bias  1.115949876117202\n",
      "pattern1 0 0 1 0.806156\n",
      "pattern2 0 1 1 0.997858\n",
      "pattern3 1 0 -1 -0.776471\n",
      "pattern4 1 1 1 0.852862\n",
      " modified Weights  [-2.15237125  2.30298082] 1.115949876117202\n",
      " Training with pattern  3  weights  [-2.15237125  2.30297991] 1.1089991957198149   weights  [-2.16124743  2.30298082]  bias  1.1070736980900033\n",
      "pattern1 0 0 1 0.803026\n",
      "pattern2 0 1 1 0.997819\n",
      "pattern3 1 0 -1 -0.783424\n",
      "pattern4 1 1 1 0.847949\n",
      " modified Weights  [-2.16124743  2.30298082] 1.1070736980900033\n",
      " Training with pattern  4  weights  [-2.15237125  2.30297991] 1.1089991957198149   weights  [-2.15697505  2.3072532 ]  bias  1.1113460761739695\n",
      "pattern1 0 0 1 0.804538\n",
      "pattern2 0 1 1 0.997856\n",
      "pattern3 1 0 -1 -0.780101\n",
      "pattern4 1 1 1 0.851511\n",
      " modified Weights  [-2.15697505  2.3072532 ] 1.1113460761739695\n",
      "+++++++++++Epoch  132  cost=  0.10861450292314936\n",
      " Training with pattern  1  weights  [-2.15697505  2.3072532 ] 1.1113460761739695   weights  [-2.15697505  2.3072532 ]  bias  1.1182404051099877\n",
      "pattern1 0 0 1 0.806956\n",
      "pattern2 0 1 1 0.997885\n",
      "pattern3 1 0 -1 -0.777388\n",
      "pattern4 1 1 1 0.853396\n",
      " modified Weights  [-2.15697505  2.3072532 ] 1.1182404051099877\n",
      " Training with pattern  2  weights  [-2.15697505  2.3072532 ] 1.1113460761739695   weights  [-2.15697505  2.3072541 ]  bias  1.1182412984562902\n",
      "pattern1 0 0 1 0.806956\n",
      "pattern2 0 1 1 0.997885\n",
      "pattern3 1 0 -1 -0.777388\n",
      "pattern4 1 1 1 0.853396\n",
      " modified Weights  [-2.15697505  2.3072541 ] 1.1182412984562902\n",
      " Training with pattern  3  weights  [-2.15697505  2.3072532 ] 1.1113460761739695   weights  [-2.16578313  2.3072541 ]  bias  1.1094332225163894\n",
      "pattern1 0 0 1 0.803862\n",
      "pattern2 0 1 1 0.997848\n",
      "pattern3 1 0 -1 -0.784263\n",
      "pattern4 1 1 1 0.848537\n",
      " modified Weights  [-2.16578313  2.3072541 ] 1.1094332225163894\n",
      " Training with pattern  4  weights  [-2.15697505  2.3072532 ] 1.1113460761739695   weights  [-2.16154239  2.31149483]  bias  1.113673959012264\n",
      "pattern1 0 0 1 0.805357\n",
      "pattern2 0 1 1 0.997884\n",
      "pattern3 1 0 -1 -0.780976\n",
      "pattern4 1 1 1 0.852061\n",
      " modified Weights  [-2.16154239  2.31149483] 1.113673959012264\n",
      "+++++++++++Epoch  133  cost=  0.10774768450660362\n",
      " Training with pattern  1  weights  [-2.16154239  2.31149483] 1.113673959012264   weights  [-2.16154239  2.31149483]  bias  1.1205136997393015\n",
      "pattern1 0 0 1 0.807748\n",
      "pattern2 0 1 1 0.997913\n",
      "pattern3 1 0 -1 -0.778294\n",
      "pattern4 1 1 1 0.853924\n",
      " modified Weights  [-2.16154239  2.31149483] 1.1205136997393015\n",
      " Training with pattern  2  weights  [-2.16154239  2.31149483] 1.113673959012264   weights  [-2.16154239  2.3114957 ]  bias  1.1205145701417296\n",
      "pattern1 0 0 1 0.807748\n",
      "pattern2 0 1 1 0.997913\n",
      "pattern3 1 0 -1 -0.778294\n",
      "pattern4 1 1 1 0.853924\n",
      " modified Weights  [-2.16154239  2.3114957 ] 1.1205145701417296\n",
      " Training with pattern  3  weights  [-2.16154239  2.31149483] 1.113673959012264   weights  [-2.17028336  2.3114957 ]  bias  1.1117735955354462\n",
      "pattern1 0 0 1 0.804688\n",
      "pattern2 0 1 1 0.997876\n",
      "pattern3 1 0 -1 -0.785093\n",
      "pattern4 1 1 1 0.849119\n",
      " modified Weights  [-2.17028336  2.3114957 ] 1.1117735955354462\n",
      " Training with pattern  4  weights  [-2.16154239  2.31149483] 1.113673959012264   weights  [-2.16607382  2.31570525]  bias  1.1159831385387107\n",
      "pattern1 0 0 1 0.806167\n",
      "pattern2 0 1 1 0.997911\n",
      "pattern3 1 0 -1 -0.781842\n",
      "pattern4 1 1 1 0.852605\n",
      " modified Weights  [-2.16607382  2.31570525] 1.1159831385387107\n",
      "+++++++++++Epoch  134  cost=  0.1068940069300727\n",
      " Training with pattern  1  weights  [-2.16607382  2.31570525] 1.1159831385387107   weights  [-2.16607382  2.31570525]  bias  1.1227691183779616\n",
      "pattern1 0 0 1 0.80853\n",
      "pattern2 0 1 1 0.99794\n",
      "pattern3 1 0 -1 -0.77919\n",
      "pattern4 1 1 1 0.854447\n",
      " modified Weights  [-2.16607382  2.31570525] 1.1227691183779616\n",
      " Training with pattern  2  weights  [-2.16607382  2.31570525] 1.1159831385387107   weights  [-2.16607382  2.31570609]  bias  1.122769966591624\n",
      "pattern1 0 0 1 0.80853\n",
      "pattern2 0 1 1 0.99794\n",
      "pattern3 1 0 -1 -0.779189\n",
      "pattern4 1 1 1 0.854447\n",
      " modified Weights  [-2.16607382  2.31570609] 1.122769966591624\n",
      " Training with pattern  3  weights  [-2.16607382  2.31570525] 1.1159831385387107   weights  [-2.17474867  2.31570609]  bias  1.114095114042804\n",
      "pattern1 0 0 1 0.805505\n",
      "pattern2 0 1 1 0.997904\n",
      "pattern3 1 0 -1 -0.785914\n",
      "pattern4 1 1 1 0.849694\n",
      " modified Weights  [-2.17474867  2.31570609] 1.114095114042804\n",
      " Training with pattern  4  weights  [-2.16607382  2.31570525] 1.1159831385387107   weights  [-2.17056989  2.31988488]  bias  1.118273902403951\n",
      "pattern1 0 0 1 0.806968\n",
      "pattern2 0 1 1 0.997938\n",
      "pattern3 1 0 -1 -0.782697\n",
      "pattern4 1 1 1 0.853143\n",
      " modified Weights  [-2.17056989  2.31988488] 1.118273902403951\n",
      "+++++++++++Epoch  135  cost=  0.10605318010715466\n",
      " Training with pattern  1  weights  [-2.17056989  2.31988488] 1.118273902403951   weights  [-2.17056989  2.31988488]  bias  1.125006930370886\n",
      "pattern1 0 0 1 0.809303\n",
      "pattern2 0 1 1 0.997966\n",
      "pattern3 1 0 -1 -0.780075\n",
      "pattern4 1 1 1 0.854965\n",
      " modified Weights  [-2.17056989  2.31988488] 1.125006930370886\n",
      " Training with pattern  2  weights  [-2.17056989  2.31988488] 1.118273902403951   weights  [-2.17056989  2.31988571]  bias  1.1250077571207484\n",
      "pattern1 0 0 1 0.809304\n",
      "pattern2 0 1 1 0.997966\n",
      "pattern3 1 0 -1 -0.780075\n",
      "pattern4 1 1 1 0.854965\n",
      " modified Weights  [-2.17056989  2.31988571] 1.1250077571207484\n",
      " Training with pattern  3  weights  [-2.17056989  2.31988488] 1.118273902403951   weights  [-2.17917958  2.31988571]  bias  1.116398068228605\n",
      "pattern1 0 0 1 0.806312\n",
      "pattern2 0 1 1 0.997931\n",
      "pattern3 1 0 -1 -0.786726\n",
      "pattern4 1 1 1 0.850264\n",
      " modified Weights  [-2.17917958  2.31988571] 1.116398068228605\n",
      " Training with pattern  4  weights  [-2.17056989  2.31988488] 1.118273902403951   weights  [-2.17503111  2.32403417]  bias  1.1205465318015781\n",
      "pattern1 0 0 1 0.807759\n",
      "pattern2 0 1 1 0.997965\n",
      "pattern3 1 0 -1 -0.783544\n",
      "pattern4 1 1 1 0.853676\n",
      " modified Weights  [-2.17503111  2.32403417] 1.1205465318015781\n",
      "+++++++++++Epoch  136  cost=  0.10522492230878312\n",
      " Training with pattern  1  weights  [-2.17503111  2.32403417] 1.1205465318015781   weights  [-2.17503111  2.32403417]  bias  1.1272273991348993\n",
      "pattern1 0 0 1 0.810068\n",
      "pattern2 0 1 1 0.997992\n",
      "pattern3 1 0 -1 -0.780951\n",
      "pattern4 1 1 1 0.855477\n",
      " modified Weights  [-2.17503111  2.32403417] 1.1272273991348993\n",
      " Training with pattern  2  weights  [-2.17503111  2.32403417] 1.1205465318015781   weights  [-2.17503111  2.32403498]  bias  1.1272282051171936\n",
      "pattern1 0 0 1 0.810068\n",
      "pattern2 0 1 1 0.997992\n",
      "pattern3 1 0 -1 -0.780951\n",
      "pattern4 1 1 1 0.855478\n",
      " modified Weights  [-2.17503111  2.32403498] 1.1272282051171936\n",
      " Training with pattern  3  weights  [-2.17503111  2.32403417] 1.1205465318015781   weights  [-2.18357657  2.32403498]  bias  1.11868274177489\n",
      "pattern1 0 0 1 0.80711\n",
      "pattern2 0 1 1 0.997957\n",
      "pattern3 1 0 -1 -0.78753\n",
      "pattern4 1 1 1 0.850827\n",
      " modified Weights  [-2.18357657  2.32403498] 1.11868274177489\n",
      " Training with pattern  4  weights  [-2.17503111  2.32403417] 1.1205465318015781   weights  [-2.17945801  2.32815354]  bias  1.1228013016573486\n",
      "pattern1 0 0 1 0.808541\n",
      "pattern2 0 1 1 0.99799\n",
      "pattern3 1 0 -1 -0.784381\n",
      "pattern4 1 1 1 0.854203\n",
      " modified Weights  [-2.17945801  2.32815354] 1.1228013016573486\n",
      "+++++++++++Epoch  137  cost=  0.10440895986740548\n",
      " Training with pattern  1  weights  [-2.17945801  2.32815354] 1.1228013016573486   weights  [-2.17945801  2.32815354]  bias  1.1294307823291727\n",
      "pattern1 0 0 1 0.810824\n",
      "pattern2 0 1 1 0.998017\n",
      "pattern3 1 0 -1 -0.781817\n",
      "pattern4 1 1 1 0.855985\n",
      " modified Weights  [-2.17945801  2.32815354] 1.1294307823291727\n",
      " Training with pattern  2  weights  [-2.17945801  2.32815354] 1.1228013016573486   weights  [-2.17945801  2.32815432]  bias  1.1294315682127305\n",
      "pattern1 0 0 1 0.810825\n",
      "pattern2 0 1 1 0.998017\n",
      "pattern3 1 0 -1 -0.781817\n",
      "pattern4 1 1 1 0.855985\n",
      " modified Weights  [-2.17945801  2.32815432] 1.1294315682127305\n",
      " Training with pattern  3  weights  [-2.17945801  2.32815354] 1.1228013016573486   weights  [-2.18794017  2.32815432]  bias  1.120949412045861\n",
      "pattern1 0 0 1 0.807899\n",
      "pattern2 0 1 1 0.997983\n",
      "pattern3 1 0 -1 -0.788325\n",
      "pattern4 1 1 1 0.851385\n",
      " modified Weights  [-2.18794017  2.32815432] 1.120949412045861\n",
      " Training with pattern  4  weights  [-2.17945801  2.32815354] 1.1228013016573486   weights  [-2.1838511   2.33224339]  bias  1.1250384808115876\n",
      "pattern1 0 0 1 0.809314\n",
      "pattern2 0 1 1 0.998016\n",
      "pattern3 1 0 -1 -0.785209\n",
      "pattern4 1 1 1 0.854725\n",
      " modified Weights  [-2.1838511   2.33224339] 1.1250384808115876\n",
      "+++++++++++Epoch  138  cost=  0.10360502689354066\n",
      " Training with pattern  1  weights  [-2.1838511   2.33224339] 1.1250384808115876   weights  [-2.1838511   2.33224339]  bias  1.131617332019645\n",
      "pattern1 0 0 1 0.811572\n",
      "pattern2 0 1 1 0.998041\n",
      "pattern3 1 0 -1 -0.782673\n",
      "pattern4 1 1 1 0.856487\n",
      " modified Weights  [-2.1838511   2.33224339] 1.131617332019645\n",
      " Training with pattern  2  weights  [-2.1838511   2.33224339] 1.1250384808115876   weights  [-2.1838511   2.33224416]  bias  1.1316180984471609\n",
      "pattern1 0 0 1 0.811572\n",
      "pattern2 0 1 1 0.998041\n",
      "pattern3 1 0 -1 -0.782673\n",
      "pattern4 1 1 1 0.856488\n",
      " modified Weights  [-2.1838511   2.33224416] 1.1316180984471609\n",
      " Training with pattern  3  weights  [-2.1838511   2.33224339] 1.1250384808115876   weights  [-2.19227085  2.33224416]  bias  1.1231983502713252\n",
      "pattern1 0 0 1 0.808679\n",
      "pattern2 0 1 1 0.998008\n",
      "pattern3 1 0 -1 -0.789112\n",
      "pattern4 1 1 1 0.851936\n",
      " modified Weights  [-2.19227085  2.33224416] 1.1231983502713252\n",
      " Training with pattern  4  weights  [-2.1838511   2.33224339] 1.1250384808115876   weights  [-2.18821087  2.33630414]  bias  1.127258332195078\n",
      "pattern1 0 0 1 0.810079\n",
      "pattern2 0 1 1 0.99804\n",
      "pattern3 1 0 -1 -0.786028\n",
      "pattern4 1 1 1 0.855241\n",
      " modified Weights  [-2.18821087  2.33630414] 1.127258332195078\n",
      "+++++++++++Epoch  139  cost=  0.10281286500412358\n",
      " Training with pattern  1  weights  [-2.18821087  2.33630414] 1.127258332195078   weights  [-2.18821087  2.33630414]  bias  1.1337872948376744\n",
      "pattern1 0 0 1 0.812311\n",
      "pattern2 0 1 1 0.998066\n",
      "pattern3 1 0 -1 -0.78352\n",
      "pattern4 1 1 1 0.856985\n",
      " modified Weights  [-2.18821087  2.33630414] 1.1337872948376744\n",
      " Training with pattern  2  weights  [-2.18821087  2.33630414] 1.127258332195078   weights  [-2.18821087  2.33630489]  bias  1.1337880424269022\n",
      "pattern1 0 0 1 0.812312\n",
      "pattern2 0 1 1 0.998066\n",
      "pattern3 1 0 -1 -0.78352\n",
      "pattern4 1 1 1 0.856986\n",
      " modified Weights  [-2.18821087  2.33630489] 1.1337880424269022\n",
      " Training with pattern  3  weights  [-2.18821087  2.33630414] 1.127258332195078   weights  [-2.19656909  2.33630489]  bias  1.1254298217236074\n",
      "pattern1 0 0 1 0.809449\n",
      "pattern2 0 1 1 0.998033\n",
      "pattern3 1 0 -1 -0.78989\n",
      "pattern4 1 1 1 0.852482\n",
      " modified Weights  [-2.19656909  2.33630489] 1.1254298217236074\n",
      " Training with pattern  4  weights  [-2.18821087  2.33630414] 1.127258332195078   weights  [-2.1925378   2.34033618]  bias  1.1294611129987056\n",
      "pattern1 0 0 1 0.810835\n",
      "pattern2 0 1 1 0.998065\n",
      "pattern3 1 0 -1 -0.786839\n",
      "pattern4 1 1 1 0.855753\n",
      " modified Weights  [-2.1925378   2.34033618] 1.1294611129987056\n",
      "+++++++++++Epoch  140  cost=  0.10203222306206716\n",
      " Training with pattern  1  weights  [-2.1925378   2.34033618] 1.1294611129987056   weights  [-2.1925378   2.34033618]  bias  1.1359409121331632\n",
      "pattern1 0 0 1 0.813043\n",
      "pattern2 0 1 1 0.998089\n",
      "pattern3 1 0 -1 -0.784358\n",
      "pattern4 1 1 1 0.857478\n",
      " modified Weights  [-2.1925378   2.34033618] 1.1359409121331632\n",
      " Training with pattern  2  weights  [-2.1925378   2.34033618] 1.1294611129987056   weights  [-2.1925378   2.34033691]  bias  1.13594164147805\n",
      "pattern1 0 0 1 0.813043\n",
      "pattern2 0 1 1 0.998089\n",
      "pattern3 1 0 -1 -0.784358\n",
      "pattern4 1 1 1 0.857478\n",
      " modified Weights  [-2.1925378   2.34033691] 1.13594164147805\n",
      " Training with pattern  3  weights  [-2.1925378   2.34033618] 1.1294611129987056   weights  [-2.20083535  2.34033691]  bias  1.1276440858882049\n",
      "pattern1 0 0 1 0.810211\n",
      "pattern2 0 1 1 0.998058\n",
      "pattern3 1 0 -1 -0.790661\n",
      "pattern4 1 1 1 0.853022\n",
      " modified Weights  [-2.20083535  2.34033691] 1.1276440858882049\n",
      " Training with pattern  4  weights  [-2.1925378   2.34033618] 1.1294611129987056   weights  [-2.19683236  2.3443399 ]  bias  1.1316470748371252\n",
      "pattern1 0 0 1 0.811582\n",
      "pattern2 0 1 1 0.998088\n",
      "pattern3 1 0 -1 -0.78764\n",
      "pattern4 1 1 1 0.85626\n",
      " modified Weights  [-2.19683236  2.3443399 ] 1.1316470748371252\n",
      "+++++++++++Epoch  141  cost=  0.10126285692651421\n",
      " *********Epoch  140 Error  0.10126285692651421\n",
      " Training with pattern  1  weights  [-2.19683236  2.3443399 ] 1.1316470748371252   weights  [-2.19683236  2.3443399 ]  bias  1.1380784201223786\n",
      "pattern1 0 0 1 0.813766\n",
      "pattern2 0 1 1 0.998113\n",
      "pattern3 1 0 -1 -0.785186\n",
      "pattern4 1 1 1 0.857966\n",
      " modified Weights  [-2.19683236  2.3443399 ] 1.1380784201223786\n",
      " Training with pattern  2  weights  [-2.19683236  2.3443399 ] 1.1316470748371252   weights  [-2.19683236  2.34434061]  bias  1.1380791317941394\n",
      "pattern1 0 0 1 0.813766\n",
      "pattern2 0 1 1 0.998113\n",
      "pattern3 1 0 -1 -0.785186\n",
      "pattern4 1 1 1 0.857966\n",
      " modified Weights  [-2.19683236  2.34434061] 1.1380791317941394\n",
      " Training with pattern  3  weights  [-2.19683236  2.3443399 ] 1.1316470748371252   weights  [-2.2050701   2.34434061]  bias  1.1298413966284455\n",
      "pattern1 0 0 1 0.810965\n",
      "pattern2 0 1 1 0.998081\n",
      "pattern3 1 0 -1 -0.791423\n",
      "pattern4 1 1 1 0.853557\n",
      " modified Weights  [-2.2050701   2.34434061] 1.1298413966284455\n",
      " Training with pattern  4  weights  [-2.19683236  2.3443399 ] 1.1316470748371252   weights  [-2.20109503  2.34831568]  bias  1.1338164639066934\n",
      "pattern1 0 0 1 0.812321\n",
      "pattern2 0 1 1 0.998112\n",
      "pattern3 1 0 -1 -0.788434\n",
      "pattern4 1 1 1 0.856761\n",
      " modified Weights  [-2.20109503  2.34831568] 1.1338164639066934\n",
      "+++++++++++Epoch  142  cost=  0.10050452921326838\n",
      " Training with pattern  1  weights  [-2.20109503  2.34831568] 1.1338164639066934   weights  [-2.20109503  2.34831568]  bias  1.1402000500306888\n",
      "pattern1 0 0 1 0.814481\n",
      "pattern2 0 1 1 0.998136\n",
      "pattern3 1 0 -1 -0.786006\n",
      "pattern4 1 1 1 0.85845\n",
      " modified Weights  [-2.20109503  2.34831568] 1.1402000500306888\n",
      " Training with pattern  2  weights  [-2.20109503  2.34831568] 1.1338164639066934   weights  [-2.20109503  2.34831637]  bias  1.1402007445788263\n",
      "pattern1 0 0 1 0.814482\n",
      "pattern2 0 1 1 0.998136\n",
      "pattern3 1 0 -1 -0.786006\n",
      "pattern4 1 1 1 0.85845\n",
      " modified Weights  [-2.20109503  2.34831637] 1.1402007445788263\n",
      " Training with pattern  3  weights  [-2.20109503  2.34831568] 1.1338164639066934   weights  [-2.20927377  2.34831637]  bias  1.1320220023443999\n",
      "pattern1 0 0 1 0.81171\n",
      "pattern2 0 1 1 0.998105\n",
      "pattern3 1 0 -1 -0.792178\n",
      "pattern4 1 1 1 0.854086\n",
      " modified Weights  [-2.20927377  2.34831637] 1.1320220023443999\n",
      " Training with pattern  4  weights  [-2.20109503  2.34831568] 1.1338164639066934   weights  [-2.20532626  2.35226389]  bias  1.1359695211379086\n",
      "pattern1 0 0 1 0.813052\n",
      "pattern2 0 1 1 0.998135\n",
      "pattern3 1 0 -1 -0.789219\n",
      "pattern4 1 1 1 0.857258\n",
      " modified Weights  [-2.20532626  2.35226389] 1.1359695211379086\n",
      "+++++++++++Epoch  143  cost=  0.09975700906493071\n",
      " Training with pattern  1  weights  [-2.20532626  2.35226389] 1.1359695211379086   weights  [-2.20532626  2.35226389]  bias  1.142306028230424\n",
      "pattern1 0 0 1 0.815189\n",
      "pattern2 0 1 1 0.998158\n",
      "pattern3 1 0 -1 -0.786817\n",
      "pattern4 1 1 1 0.858928\n",
      " modified Weights  [-2.20532626  2.35226389] 1.142306028230424\n",
      " Training with pattern  2  weights  [-2.20532626  2.35226389] 1.1359695211379086   weights  [-2.20532626  2.35226457]  bias  1.1423067061836956\n",
      "pattern1 0 0 1 0.815189\n",
      "pattern2 0 1 1 0.998158\n",
      "pattern3 1 0 -1 -0.786817\n",
      "pattern4 1 1 1 0.858929\n",
      " modified Weights  [-2.20532626  2.35226457] 1.1423067061836956\n",
      " Training with pattern  3  weights  [-2.20532626  2.35226389] 1.1359695211379086   weights  [-2.21344682  2.35226457]  bias  1.134186146126281\n",
      "pattern1 0 0 1 0.812447\n",
      "pattern2 0 1 1 0.998128\n",
      "pattern3 1 0 -1 -0.792925\n",
      "pattern4 1 1 1 0.85461\n",
      " modified Weights  [-2.21344682  2.35226457] 1.134186146126281\n",
      " Training with pattern  4  weights  [-2.20532626  2.35226389] 1.1359695211379086   weights  [-2.20952648  2.35618491]  bias  1.1381064823425802\n",
      "pattern1 0 0 1 0.813776\n",
      "pattern2 0 1 1 0.998157\n",
      "pattern3 1 0 -1 -0.789996\n",
      "pattern4 1 1 1 0.857749\n",
      " modified Weights  [-2.20952648  2.35618491] 1.1381064823425802\n",
      "+++++++++++Epoch  144  cost=  0.09902007193028564\n",
      " Training with pattern  1  weights  [-2.20952648  2.35618491] 1.1381064823425802   weights  [-2.20952648  2.35618491]  bias  1.1443965763740538\n",
      "pattern1 0 0 1 0.815889\n",
      "pattern2 0 1 1 0.99818\n",
      "pattern3 1 0 -1 -0.787619\n",
      "pattern4 1 1 1 0.859403\n",
      " modified Weights  [-2.20952648  2.35618491] 1.1443965763740538\n",
      " Training with pattern  2  weights  [-2.20952648  2.35618491] 1.1381064823425802   weights  [-2.20952648  2.35618557]  bias  1.144397238241389\n",
      "pattern1 0 0 1 0.815889\n",
      "pattern2 0 1 1 0.99818\n",
      "pattern3 1 0 -1 -0.787619\n",
      "pattern4 1 1 1 0.859403\n",
      " modified Weights  [-2.20952648  2.35618557] 1.144397238241389\n",
      " Training with pattern  3  weights  [-2.20952648  2.35618491] 1.1381064823425802   weights  [-2.21758965  2.35618557]  bias  1.1363340659025591\n",
      "pattern1 0 0 1 0.813176\n",
      "pattern2 0 1 1 0.99815\n",
      "pattern3 1 0 -1 -0.793664\n",
      "pattern4 1 1 1 0.855128\n",
      " modified Weights  [-2.21758965  2.35618557] 1.1363340659025591\n",
      " Training with pattern  4  weights  [-2.20952648  2.35618491] 1.1381064823425802   weights  [-2.21369614  2.36007908]  bias  1.1402275783559457\n",
      "pattern1 0 0 1 0.814491\n",
      "pattern2 0 1 1 0.998179\n",
      "pattern3 1 0 -1 -0.790764\n",
      "pattern4 1 1 1 0.858236\n",
      " modified Weights  [-2.21369614  2.36007908] 1.1402275783559457\n",
      "+++++++++++Epoch  145  cost=  0.09829349935250964\n",
      " Training with pattern  1  weights  [-2.21369614  2.36007908] 1.1402275783559457   weights  [-2.21369614  2.36007908]  bias  1.1464719115228712\n",
      "pattern1 0 0 1 0.816582\n",
      "pattern2 0 1 1 0.998202\n",
      "pattern3 1 0 -1 -0.788413\n",
      "pattern4 1 1 1 0.859872\n",
      " modified Weights  [-2.21369614  2.36007908] 1.1464719115228712\n",
      " Training with pattern  2  weights  [-2.21369614  2.36007908] 1.1402275783559457   weights  [-2.21369614  2.36007973]  bias  1.1464725577942443\n",
      "pattern1 0 0 1 0.816582\n",
      "pattern2 0 1 1 0.998202\n",
      "pattern3 1 0 -1 -0.788413\n",
      "pattern4 1 1 1 0.859873\n",
      " modified Weights  [-2.21369614  2.36007973] 1.1464725577942443\n",
      " Training with pattern  3  weights  [-2.21369614  2.36007908] 1.1402275783559457   weights  [-2.2217027   2.36007973]  bias  1.138465994583007\n",
      "pattern1 0 0 1 0.813897\n",
      "pattern2 0 1 1 0.998173\n",
      "pattern3 1 0 -1 -0.794396\n",
      "pattern4 1 1 1 0.855642\n",
      " modified Weights  [-2.2217027   2.36007973] 1.138465994583007\n",
      " Training with pattern  4  weights  [-2.21369614  2.36007908] 1.1402275783559457   weights  [-2.21783566  2.36394677]  bias  1.1423330351739385\n",
      "pattern1 0 0 1 0.815198\n",
      "pattern2 0 1 1 0.998201\n",
      "pattern3 1 0 -1 -0.791525\n",
      "pattern4 1 1 1 0.858719\n",
      " modified Weights  [-2.21783566  2.36394677] 1.1423330351739385\n",
      "+++++++++++Epoch  146  cost=  0.0975770787657956\n",
      " Training with pattern  1  weights  [-2.21783566  2.36394677] 1.1423330351739385   weights  [-2.21783566  2.36394677]  bias  1.1485322462713652\n",
      "pattern1 0 0 1 0.817267\n",
      "pattern2 0 1 1 0.998223\n",
      "pattern3 1 0 -1 -0.789199\n",
      "pattern4 1 1 1 0.860338\n",
      " modified Weights  [-2.21783566  2.36394677] 1.1485322462713652\n",
      " Training with pattern  2  weights  [-2.21783566  2.36394677] 1.1423330351739385   weights  [-2.21783566  2.3639474 ]  bias  1.1485328774186219\n",
      "pattern1 0 0 1 0.817267\n",
      "pattern2 0 1 1 0.998223\n",
      "pattern3 1 0 -1 -0.789198\n",
      "pattern4 1 1 1 0.860338\n",
      " modified Weights  [-2.21783566  2.3639474 ] 1.1485328774186219\n",
      " Training with pattern  3  weights  [-2.21783566  2.36394677] 1.1423330351739385   weights  [-2.22578638  2.3639474 ]  bias  1.1405821601968775\n",
      "pattern1 0 0 1 0.81461\n",
      "pattern2 0 1 1 0.998194\n",
      "pattern3 1 0 -1 -0.795121\n",
      "pattern4 1 1 1 0.85615\n",
      " modified Weights  [-2.22578638  2.3639474 ] 1.1405821601968775\n",
      " Training with pattern  4  weights  [-2.21783566  2.36394677] 1.1423330351739385   weights  [-2.22194547  2.36778831]  bias  1.1444230740858032\n",
      "pattern1 0 0 1 0.815898\n",
      "pattern2 0 1 1 0.998222\n",
      "pattern3 1 0 -1 -0.792279\n",
      "pattern4 1 1 1 0.859196\n",
      " modified Weights  [-2.22194547  2.36778831] 1.1444230740858032\n",
      "+++++++++++Epoch  147  cost=  0.09687060330000664\n",
      " Training with pattern  1  weights  [-2.22194547  2.36778831] 1.1444230740858032   weights  [-2.22194547  2.36778831]  bias  1.1505777888674489\n",
      "pattern1 0 0 1 0.817945\n",
      "pattern2 0 1 1 0.998244\n",
      "pattern3 1 0 -1 -0.789976\n",
      "pattern4 1 1 1 0.860799\n",
      " modified Weights  [-2.22194547  2.36778831] 1.1505777888674489\n",
      " Training with pattern  2  weights  [-2.22194547  2.36778831] 1.1444230740858032   weights  [-2.22194547  2.36778893]  bias  1.150578405345093\n",
      "pattern1 0 0 1 0.817946\n",
      "pattern2 0 1 1 0.998244\n",
      "pattern3 1 0 -1 -0.789976\n",
      "pattern4 1 1 1 0.860799\n",
      " modified Weights  [-2.22194547  2.36778893] 1.150578405345093\n",
      " Training with pattern  3  weights  [-2.22194547  2.36778831] 1.1444230740858032   weights  [-2.22984108  2.36778893]  bias  1.142682786026414\n",
      "pattern1 0 0 1 0.815315\n",
      "pattern2 0 1 1 0.998216\n",
      "pattern3 1 0 -1 -0.795839\n",
      "pattern4 1 1 1 0.856653\n",
      " modified Weights  [-2.22984108  2.36778893] 1.142682786026414\n",
      " Training with pattern  4  weights  [-2.22194547  2.36778831] 1.1444230740858032   weights  [-2.22602596  2.37160405]  bias  1.1464979118022427\n",
      "pattern1 0 0 1 0.816591\n",
      "pattern2 0 1 1 0.998243\n",
      "pattern3 1 0 -1 -0.793024\n",
      "pattern4 1 1 1 0.859669\n",
      " modified Weights  [-2.22602596  2.37160405] 1.1464979118022427\n",
      "+++++++++++Epoch  148  cost=  0.09617387159299726\n",
      " Training with pattern  1  weights  [-2.22602596  2.37160405] 1.1464979118022427   weights  [-2.22602596  2.37160405]  bias  1.1526087433287076\n",
      "pattern1 0 0 1 0.818616\n",
      "pattern2 0 1 1 0.998264\n",
      "pattern3 1 0 -1 -0.790745\n",
      "pattern4 1 1 1 0.861256\n",
      " modified Weights  [-2.22602596  2.37160405] 1.1526087433287076\n",
      " Training with pattern  2  weights  [-2.22602596  2.37160405] 1.1464979118022427   weights  [-2.22602596  2.37160466]  bias  1.1526093455746482\n",
      "pattern1 0 0 1 0.818617\n",
      "pattern2 0 1 1 0.998264\n",
      "pattern3 1 0 -1 -0.790745\n",
      "pattern4 1 1 1 0.861256\n",
      " modified Weights  [-2.22602596  2.37160466] 1.1526093455746482\n",
      " Training with pattern  3  weights  [-2.22602596  2.37160405] 1.1464979118022427   weights  [-2.23386721  2.37160466]  bias  1.144768090735874\n",
      "pattern1 0 0 1 0.816013\n",
      "pattern2 0 1 1 0.998237\n",
      "pattern3 1 0 -1 -0.796549\n",
      "pattern4 1 1 1 0.857151\n",
      " modified Weights  [-2.23386721  2.37160466] 1.144768090735874\n",
      " Training with pattern  4  weights  [-2.22602596  2.37160405] 1.1464979118022427   weights  [-2.23007754  2.37539433]  bias  1.1485577605792785\n",
      "pattern1 0 0 1 0.817276\n",
      "pattern2 0 1 1 0.998263\n",
      "pattern3 1 0 -1 -0.793762\n",
      "pattern4 1 1 1 0.860138\n",
      " modified Weights  [-2.23007754  2.37539433] 1.1485577605792785\n",
      "+++++++++++Epoch  149  cost=  0.09548668761024941\n",
      " Training with pattern  1  weights  [-2.23007754  2.37539433] 1.1485577605792785   weights  [-2.23007754  2.37539433]  bias  1.1546253095548247\n",
      "pattern1 0 0 1 0.819281\n",
      "pattern2 0 1 1 0.998284\n",
      "pattern3 1 0 -1 -0.791507\n",
      "pattern4 1 1 1 0.861708\n",
      " modified Weights  [-2.23007754  2.37539433] 1.1546253095548247\n",
      " Training with pattern  2  weights  [-2.23007754  2.37539433] 1.1485577605792785   weights  [-2.23007754  2.37539491]  bias  1.1546258979910873\n",
      "pattern1 0 0 1 0.819281\n",
      "pattern2 0 1 1 0.998284\n",
      "pattern3 1 0 -1 -0.791506\n",
      "pattern4 1 1 1 0.861709\n",
      " modified Weights  [-2.23007754  2.37539491] 1.1546258979910873\n",
      " Training with pattern  3  weights  [-2.23007754  2.37539433] 1.1485577605792785   weights  [-2.23786515  2.37539491]  bias  1.146838288496249\n",
      "pattern1 0 0 1 0.816704\n",
      "pattern2 0 1 1 0.998257\n",
      "pattern3 1 0 -1 -0.797253\n",
      "pattern4 1 1 1 0.857644\n",
      " modified Weights  [-2.23786515  2.37539491] 1.146838288496249\n",
      " Training with pattern  4  weights  [-2.23007754  2.37539433] 1.1485577605792785   weights  [-2.23410061  2.37915945]  bias  1.1506028283379899\n",
      "pattern1 0 0 1 0.817954\n",
      "pattern2 0 1 1 0.998283\n",
      "pattern3 1 0 -1 -0.794493\n",
      "pattern4 1 1 1 0.860602\n",
      " modified Weights  [-2.23410061  2.37915945] 1.1506028283379899\n",
      "+++++++++++Epoch  150  cost=  0.09480886047150135\n",
      " Training with pattern  1  weights  [-2.23410061  2.37915945] 1.1506028283379899   weights  [-2.23410061  2.37915945]  bias  1.15662768343633\n",
      "pattern1 0 0 1 0.819938\n",
      "pattern2 0 1 1 0.998304\n",
      "pattern3 1 0 -1 -0.79226\n",
      "pattern4 1 1 1 0.862157\n",
      " modified Weights  [-2.23410061  2.37915945] 1.15662768343633\n",
      " Training with pattern  2  weights  [-2.23410061  2.37915945] 1.1506028283379899   weights  [-2.23410061  2.37916003]  bias  1.1566282584697314\n",
      "pattern1 0 0 1 0.819938\n",
      "pattern2 0 1 1 0.998304\n",
      "pattern3 1 0 -1 -0.79226\n",
      "pattern4 1 1 1 0.862157\n",
      " modified Weights  [-2.23410061  2.37916003] 1.1566282584697314\n",
      " Training with pattern  3  weights  [-2.23410061  2.37915945] 1.1506028283379899   weights  [-2.24183528  2.37916003]  bias  1.1488935891058463\n",
      "pattern1 0 0 1 0.817387\n",
      "pattern2 0 1 1 0.998277\n",
      "pattern3 1 0 -1 -0.797949\n",
      "pattern4 1 1 1 0.858133\n",
      " modified Weights  [-2.24183528  2.37916003] 1.1488935891058463\n",
      " Training with pattern  4  weights  [-2.23410061  2.37915945] 1.1506028283379899   weights  [-2.23809555  2.38289976]  bias  1.152633318780297\n",
      "pattern1 0 0 1 0.818625\n",
      "pattern2 0 1 1 0.998303\n",
      "pattern3 1 0 -1 -0.795216\n",
      "pattern4 1 1 1 0.861062\n",
      " modified Weights  [-2.23809555  2.38289976] 1.152633318780297\n",
      "+++++++++++Epoch  151  cost=  0.09414020428405243\n",
      " *********Epoch  150 Error  0.09414020428405243\n",
      " Training with pattern  1  weights  [-2.23809555  2.38289976] 1.152633318780297   weights  [-2.23809555  2.38289976]  bias  1.1586160569598172\n",
      "pattern1 0 0 1 0.820588\n",
      "pattern2 0 1 1 0.998323\n",
      "pattern3 1 0 -1 -0.793006\n",
      "pattern4 1 1 1 0.862601\n",
      " modified Weights  [-2.23809555  2.38289976] 1.1586160569598172\n",
      " Training with pattern  2  weights  [-2.23809555  2.38289976] 1.152633318780297   weights  [-2.23809555  2.38290032]  bias  1.1586166189826084\n",
      "pattern1 0 0 1 0.820589\n",
      "pattern2 0 1 1 0.998323\n",
      "pattern3 1 0 -1 -0.793006\n",
      "pattern4 1 1 1 0.862601\n",
      " modified Weights  [-2.23809555  2.38290032] 1.1586166189826084\n",
      " Training with pattern  3  weights  [-2.23809555  2.38289976] 1.152633318780297   weights  [-2.24577797  2.38290032]  bias  1.150934198106898\n",
      "pattern1 0 0 1 0.818063\n",
      "pattern2 0 1 1 0.998297\n",
      "pattern3 1 0 -1 -0.798639\n",
      "pattern4 1 1 1 0.858617\n",
      " modified Weights  [-2.24577797  2.38290032] 1.150934198106898\n",
      " Training with pattern  4  weights  [-2.23809555  2.38289976] 1.152633318780297   weights  [-2.24206274  2.38661555]  bias  1.154649431500941\n",
      "pattern1 0 0 1 0.819288\n",
      "pattern2 0 1 1 0.998322\n",
      "pattern3 1 0 -1 -0.795932\n",
      "pattern4 1 1 1 0.861518\n",
      " modified Weights  [-2.24206274  2.38661555] 1.154649431500941\n",
      "+++++++++++Epoch  152  cost=  0.09348053798244949\n",
      " Training with pattern  1  weights  [-2.24206274  2.38661555] 1.154649431500941   weights  [-2.24206274  2.38661555]  bias  1.1605906183097627\n",
      "pattern1 0 0 1 0.821232\n",
      "pattern2 0 1 1 0.998342\n",
      "pattern3 1 0 -1 -0.793744\n",
      "pattern4 1 1 1 0.863041\n",
      " modified Weights  [-2.24206274  2.38661555] 1.1605906183097627\n",
      " Training with pattern  2  weights  [-2.24206274  2.38661555] 1.154649431500941   weights  [-2.24206274  2.3866161 ]  bias  1.160591167700241\n",
      "pattern1 0 0 1 0.821232\n",
      "pattern2 0 1 1 0.998342\n",
      "pattern3 1 0 -1 -0.793744\n",
      "pattern4 1 1 1 0.863042\n",
      " modified Weights  [-2.24206274  2.3866161 ] 1.160591167700241\n",
      " Training with pattern  3  weights  [-2.24206274  2.38661555] 1.154649431500941   weights  [-2.24969359  2.3866161 ]  bias  1.1529603168983487\n",
      "pattern1 0 0 1 0.818732\n",
      "pattern2 0 1 1 0.998316\n",
      "pattern3 1 0 -1 -0.799323\n",
      "pattern4 1 1 1 0.859096\n",
      " modified Weights  [-2.24969359  2.3866161 ] 1.1529603168983487\n",
      " Training with pattern  4  weights  [-2.24206274  2.38661555] 1.154649431500941   weights  [-2.24600255  2.39030715]  bias  1.1566513620958088\n",
      "pattern1 0 0 1 0.819946\n",
      "pattern2 0 1 1 0.998341\n",
      "pattern3 1 0 -1 -0.796641\n",
      "pattern4 1 1 1 0.861969\n",
      " modified Weights  [-2.24600255  2.39030715] 1.1566513620958088\n",
      "+++++++++++Epoch  153  cost=  0.09282968517427234\n",
      " Training with pattern  1  weights  [-2.24600255  2.39030715] 1.1566513620958088   weights  [-2.24600255  2.39030715]  bias  1.1625515519670782\n",
      "pattern1 0 0 1 0.82187\n",
      "pattern2 0 1 1 0.998361\n",
      "pattern3 1 0 -1 -0.794475\n",
      "pattern4 1 1 1 0.863478\n",
      " modified Weights  [-2.24600255  2.39030715] 1.1625515519670782\n",
      " Training with pattern  2  weights  [-2.24600255  2.39030715] 1.1566513620958088   weights  [-2.24600255  2.39030769]  bias  1.1625520890901693\n",
      "pattern1 0 0 1 0.82187\n",
      "pattern2 0 1 1 0.998361\n",
      "pattern3 1 0 -1 -0.794475\n",
      "pattern4 1 1 1 0.863478\n",
      " modified Weights  [-2.24600255  2.39030769] 1.1625520890901693\n",
      " Training with pattern  3  weights  [-2.24600255  2.39030715] 1.1566513620958088   weights  [-2.25358249  2.39030769]  bias  1.1549721428449748\n",
      "pattern1 0 0 1 0.819395\n",
      "pattern2 0 1 1 0.998336\n",
      "pattern3 1 0 -1 -0.799999\n",
      "pattern4 1 1 1 0.85957\n",
      " modified Weights  [-2.25358249  2.39030769] 1.1549721428449748\n",
      " Training with pattern  4  weights  [-2.24600255  2.39030715] 1.1566513620958088   weights  [-2.24991533  2.39397485]  bias  1.1586393022667452\n",
      "pattern1 0 0 1 0.820596\n",
      "pattern2 0 1 1 0.99836\n",
      "pattern3 1 0 -1 -0.797343\n",
      "pattern4 1 1 1 0.862416\n",
      " modified Weights  [-2.24991533  2.39397485] 1.1586393022667452\n",
      "+++++++++++Epoch  154  cost=  0.09218747399175176\n",
      " Training with pattern  1  weights  [-2.24991533  2.39397485] 1.1586393022667452   weights  [-2.24991533  2.39397485]  bias  1.1644990388045187\n",
      "pattern1 0 0 1 0.822501\n",
      "pattern2 0 1 1 0.998379\n",
      "pattern3 1 0 -1 -0.795199\n",
      "pattern4 1 1 1 0.86391\n",
      " modified Weights  [-2.24991533  2.39397485] 1.1644990388045187\n",
      " Training with pattern  2  weights  [-2.24991533  2.39397485] 1.1586393022667452   weights  [-2.24991533  2.39397537]  bias  1.1644995640123312\n",
      "pattern1 0 0 1 0.822501\n",
      "pattern2 0 1 1 0.998379\n",
      "pattern3 1 0 -1 -0.795199\n",
      "pattern4 1 1 1 0.86391\n",
      " modified Weights  [-2.24991533  2.39397537] 1.1644995640123312\n",
      " Training with pattern  3  weights  [-2.24991533  2.39397485] 1.1586393022667452   weights  [-2.25744503  2.39397537]  bias  1.1569698693829689\n",
      "pattern1 0 0 1 0.82005\n",
      "pattern2 0 1 1 0.998354\n",
      "pattern3 1 0 -1 -0.80067\n",
      "pattern4 1 1 1 0.86004\n",
      " modified Weights  [-2.25744503  2.39397537] 1.1569698693829689\n",
      " Training with pattern  4  weights  [-2.24991533  2.39397485] 1.1586393022667452   weights  [-2.25380146  2.39761894]  bias  1.1606134399229848\n",
      "pattern1 0 0 1 0.82124\n",
      "pattern2 0 1 1 0.998378\n",
      "pattern3 1 0 -1 -0.798039\n",
      "pattern4 1 1 1 0.862859\n",
      " modified Weights  [-2.25380146  2.39761894] 1.1606134399229848\n",
      "+++++++++++Epoch  155  cost=  0.09155373694896518\n",
      " Training with pattern  1  weights  [-2.25380146  2.39761894] 1.1606134399229848   weights  [-2.25380146  2.39761894]  bias  1.1664332561790662\n",
      "pattern1 0 0 1 0.823125\n",
      "pattern2 0 1 1 0.998397\n",
      "pattern3 1 0 -1 -0.795916\n",
      "pattern4 1 1 1 0.864339\n",
      " modified Weights  [-2.25380146  2.39761894] 1.1664332561790662\n",
      " Training with pattern  2  weights  [-2.25380146  2.39761894] 1.1606134399229848   weights  [-2.25380146  2.39761945]  bias  1.1664337698114202\n",
      "pattern1 0 0 1 0.823126\n",
      "pattern2 0 1 1 0.998397\n",
      "pattern3 1 0 -1 -0.795915\n",
      "pattern4 1 1 1 0.864339\n",
      " modified Weights  [-2.25380146  2.39761945] 1.1664337698114202\n",
      " Training with pattern  3  weights  [-2.25380146  2.39761894] 1.1606134399229848   weights  [-2.26128154  2.39761945]  bias  1.1589536861221308\n",
      "pattern1 0 0 1 0.820699\n",
      "pattern2 0 1 1 0.998373\n",
      "pattern3 1 0 -1 -0.801334\n",
      "pattern4 1 1 1 0.860506\n",
      " modified Weights  [-2.26128154  2.39761945] 1.1589536861221308\n",
      " Training with pattern  4  weights  [-2.25380146  2.39761894] 1.1606134399229848   weights  [-2.25766127  2.40123973]  bias  1.162573959279333\n",
      "pattern1 0 0 1 0.821877\n",
      "pattern2 0 1 1 0.998396\n",
      "pattern3 1 0 -1 -0.798727\n",
      "pattern4 1 1 1 0.863299\n",
      " modified Weights  [-2.25766127  2.40123973] 1.162573959279333\n",
      "+++++++++++Epoch  156  cost=  0.09092831080436883\n",
      " Training with pattern  1  weights  [-2.25766127  2.40123973] 1.162573959279333   weights  [-2.25766127  2.40123973]  bias  1.1683543780214014\n",
      "pattern1 0 0 1 0.823744\n",
      "pattern2 0 1 1 0.998414\n",
      "pattern3 1 0 -1 -0.796625\n",
      "pattern4 1 1 1 0.864764\n",
      " modified Weights  [-2.25766127  2.40123973] 1.1683543780214014\n",
      " Training with pattern  2  weights  [-2.25766127  2.40123973] 1.162573959279333   weights  [-2.25766127  2.40124023]  bias  1.1683548804063308\n",
      "pattern1 0 0 1 0.823744\n",
      "pattern2 0 1 1 0.998414\n",
      "pattern3 1 0 -1 -0.796625\n",
      "pattern4 1 1 1 0.864764\n",
      " modified Weights  [-2.25766127  2.40124023] 1.1683548804063308\n",
      " Training with pattern  3  weights  [-2.25766127  2.40123973] 1.162573959279333   weights  [-2.26509237  2.40124023]  bias  1.1609237789447924\n",
      "pattern1 0 0 1 0.821341\n",
      "pattern2 0 1 1 0.998391\n",
      "pattern3 1 0 -1 -0.801991\n",
      "pattern4 1 1 1 0.860967\n",
      " modified Weights  [-2.26509237  2.40124023] 1.1609237789447924\n",
      " Training with pattern  4  weights  [-2.25766127  2.40123973] 1.162573959279333   weights  [-2.26149511  2.40483749]  bias  1.164521040951222\n",
      "pattern1 0 0 1 0.822508\n",
      "pattern2 0 1 1 0.998414\n",
      "pattern3 1 0 -1 -0.799409\n",
      "pattern4 1 1 1 0.863734\n",
      " modified Weights  [-2.26149511  2.40483749] 1.164521040951222\n",
      "+++++++++++Epoch  157  cost=  0.09031103642843527\n",
      " Training with pattern  1  weights  [-2.26149511  2.40483749] 1.164521040951222   weights  [-2.26149511  2.40483749]  bias  1.170262574922575\n",
      "pattern1 0 0 1 0.824356\n",
      "pattern2 0 1 1 0.998432\n",
      "pattern3 1 0 -1 -0.797328\n",
      "pattern4 1 1 1 0.865185\n",
      " modified Weights  [-2.26149511  2.40483749] 1.170262574922575\n",
      " Training with pattern  2  weights  [-2.26149511  2.40483749] 1.164521040951222   weights  [-2.26149511  2.40483798]  bias  1.170263066376808\n",
      "pattern1 0 0 1 0.824356\n",
      "pattern2 0 1 1 0.998432\n",
      "pattern3 1 0 -1 -0.797327\n",
      "pattern4 1 1 1 0.865185\n",
      " modified Weights  [-2.26149511  2.40483798] 1.170263066376808\n",
      " Training with pattern  3  weights  [-2.26149511  2.40483749] 1.164521040951222   weights  [-2.26887784  2.40483798]  bias  1.1628803301015995\n",
      "pattern1 0 0 1 0.821976\n",
      "pattern2 0 1 1 0.998409\n",
      "pattern3 1 0 -1 -0.802643\n",
      "pattern4 1 1 1 0.861424\n",
      " modified Weights  [-2.26887784  2.40483798] 1.1628803301015995\n",
      " Training with pattern  4  weights  [-2.26149511  2.40483749] 1.164521040951222   weights  [-2.26530331  2.40841252]  bias  1.1664548620467572\n",
      "pattern1 0 0 1 0.823132\n",
      "pattern2 0 1 1 0.998431\n",
      "pattern3 1 0 -1 -0.800085\n",
      "pattern4 1 1 1 0.864165\n",
      " modified Weights  [-2.26530331  2.40841252] 1.1664548620467572\n",
      "+++++++++++Epoch  158  cost=  0.08970175867617967\n",
      " Training with pattern  1  weights  [-2.26530331  2.40841252] 1.1664548620467572   weights  [-2.26530331  2.40841252]  bias  1.1721580142179766\n",
      "pattern1 0 0 1 0.824963\n",
      "pattern2 0 1 1 0.998449\n",
      "pattern3 1 0 -1 -0.798023\n",
      "pattern4 1 1 1 0.865602\n",
      " modified Weights  [-2.26530331  2.40841252] 1.1721580142179766\n",
      " Training with pattern  2  weights  [-2.26530331  2.40841252] 1.1664548620467572   weights  [-2.26530331  2.408413  ]  bias  1.1721584950473931\n",
      "pattern1 0 0 1 0.824963\n",
      "pattern2 0 1 1 0.998449\n",
      "pattern3 1 0 -1 -0.798023\n",
      "pattern4 1 1 1 0.865602\n",
      " modified Weights  [-2.26530331  2.408413  ] 1.1721584950473931\n",
      " Training with pattern  3  weights  [-2.26530331  2.40841252] 1.1664548620467572   weights  [-2.27263829  2.408413  ]  bias  1.1648235183042666\n",
      "pattern1 0 0 1 0.822606\n",
      "pattern2 0 1 1 0.998426\n",
      "pattern3 1 0 -1 -0.803289\n",
      "pattern4 1 1 1 0.861877\n",
      " modified Weights  [-2.27263829  2.408413  ] 1.1648235183042666\n",
      " Training with pattern  4  weights  [-2.26530331  2.40841252] 1.1664548620467572   weights  [-2.26908621  2.41196507]  bias  1.1683755962558644\n",
      "pattern1 0 0 1 0.823751\n",
      "pattern2 0 1 1 0.998448\n",
      "pattern3 1 0 -1 -0.800754\n",
      "pattern4 1 1 1 0.864592\n",
      " modified Weights  [-2.26908621  2.41196507] 1.1683755962558644\n",
      "+++++++++++Epoch  159  cost=  0.08910032626436479\n",
      " Training with pattern  1  weights  [-2.26908621  2.41196507] 1.1683755962558644   weights  [-2.26908621  2.41196507]  bias  1.1740408600687076\n",
      "pattern1 0 0 1 0.825563\n",
      "pattern2 0 1 1 0.998466\n",
      "pattern3 1 0 -1 -0.798712\n",
      "pattern4 1 1 1 0.866016\n",
      " modified Weights  [-2.26908621  2.41196507] 1.1740408600687076\n",
      " Training with pattern  2  weights  [-2.26908621  2.41196507] 1.1683755962558644   weights  [-2.26908621  2.41196555]  bias  1.1740413305687745\n",
      "pattern1 0 0 1 0.825563\n",
      "pattern2 0 1 1 0.998466\n",
      "pattern3 1 0 -1 -0.798712\n",
      "pattern4 1 1 1 0.866016\n",
      " modified Weights  [-2.26908621  2.41196555] 1.1740413305687745\n",
      " Training with pattern  3  weights  [-2.26908621  2.41196507] 1.1683755962558644   weights  [-2.27637402  2.41196555]  bias  1.1667535188154217\n",
      "pattern1 0 0 1 0.823229\n",
      "pattern2 0 1 1 0.998443\n",
      "pattern3 1 0 -1 -0.803928\n",
      "pattern4 1 1 1 0.862326\n",
      " modified Weights  [-2.27637402  2.41196555] 1.1667535188154217\n",
      " Training with pattern  4  weights  [-2.26908621  2.41196507] 1.1683755962558644   weights  [-2.27284413  2.41549544]  bias  1.1702834139366527\n",
      "pattern1 0 0 1 0.824363\n",
      "pattern2 0 1 1 0.998465\n",
      "pattern3 1 0 -1 -0.801417\n",
      "pattern4 1 1 1 0.865016\n",
      " modified Weights  [-2.27284413  2.41549544] 1.1702834139366527\n",
      "+++++++++++Epoch  160  cost=  0.0885065916531877\n",
      " Training with pattern  1  weights  [-2.27284413  2.41549544] 1.1702834139366527   weights  [-2.27284413  2.41549544]  bias  1.1759112735404478\n",
      "pattern1 0 0 1 0.826158\n",
      "pattern2 0 1 1 0.998482\n",
      "pattern3 1 0 -1 -0.799395\n",
      "pattern4 1 1 1 0.866426\n",
      " modified Weights  [-2.27284413  2.41549544] 1.1759112735404478\n",
      " Training with pattern  2  weights  [-2.27284413  2.41549544] 1.1702834139366527   weights  [-2.27284413  2.4154959 ]  bias  1.175911733996636\n",
      "pattern1 0 0 1 0.826158\n",
      "pattern2 0 1 1 0.998482\n",
      "pattern3 1 0 -1 -0.799394\n",
      "pattern4 1 1 1 0.866426\n",
      " modified Weights  [-2.27284413  2.4154959 ] 1.175911733996636\n",
      " Training with pattern  3  weights  [-2.27284413  2.41549544] 1.1702834139366527   weights  [-2.28008536  2.4154959 ]  bias  1.168670503535646\n",
      "pattern1 0 0 1 0.823845\n",
      "pattern2 0 1 1 0.99846\n",
      "pattern3 1 0 -1 -0.804562\n",
      "pattern4 1 1 1 0.86277\n",
      " modified Weights  [-2.28008536  2.4154959 ] 1.168670503535646\n",
      " Training with pattern  4  weights  [-2.27284413  2.41549544] 1.1702834139366527   weights  [-2.27657738  2.41900388]  bias  1.1721784821990882\n",
      "pattern1 0 0 1 0.824969\n",
      "pattern2 0 1 1 0.998481\n",
      "pattern3 1 0 -1 -0.802074\n",
      "pattern4 1 1 1 0.865436\n",
      " modified Weights  [-2.27657738  2.41900388] 1.1721784821990882\n",
      "+++++++++++Epoch  161  cost=  0.08792041093225963\n",
      " *********Epoch  160 Error  0.08792041093225963\n",
      " Training with pattern  1  weights  [-2.27657738  2.41900388] 1.1721784821990882   weights  [-2.27657738  2.41900388]  bias  1.17776941267991\n",
      "pattern1 0 0 1 0.826747\n",
      "pattern2 0 1 1 0.998498\n",
      "pattern3 1 0 -1 -0.80007\n",
      "pattern4 1 1 1 0.866833\n",
      " modified Weights  [-2.27657738  2.41900388] 1.17776941267991\n",
      " Training with pattern  2  weights  [-2.27657738  2.41900388] 1.1721784821990882   weights  [-2.27657738  2.41900433]  bias  1.177769863368091\n",
      "pattern1 0 0 1 0.826747\n",
      "pattern2 0 1 1 0.998498\n",
      "pattern3 1 0 -1 -0.80007\n",
      "pattern4 1 1 1 0.866833\n",
      " modified Weights  [-2.27657738  2.41900433] 1.177769863368091\n",
      " Training with pattern  3  weights  [-2.27657738  2.41900388] 1.1721784821990882   weights  [-2.2837726   2.41900433]  bias  1.1705746410878128\n",
      "pattern1 0 0 1 0.824456\n",
      "pattern2 0 1 1 0.998477\n",
      "pattern3 1 0 -1 -0.80519\n",
      "pattern4 1 1 1 0.86321\n",
      " modified Weights  [-2.2837726   2.41900433] 1.1705746410878128\n",
      " Training with pattern  4  weights  [-2.27657738  2.41900388] 1.1721784821990882   weights  [-2.28028628  2.42249065]  bias  1.174060964986084\n",
      "pattern1 0 0 1 0.82557\n",
      "pattern2 0 1 1 0.998498\n",
      "pattern3 1 0 -1 -0.802724\n",
      "pattern4 1 1 1 0.865852\n",
      " modified Weights  [-2.28028628  2.42249065] 1.174060964986084\n",
      "+++++++++++Epoch  162  cost=  0.0873416437106986\n",
      " Training with pattern  1  weights  [-2.28028628  2.42249065] 1.174060964986084   weights  [-2.28028628  2.42249065]  bias  1.17961543258897\n",
      "pattern1 0 0 1 0.82733\n",
      "pattern2 0 1 1 0.998514\n",
      "pattern3 1 0 -1 -0.80074\n",
      "pattern4 1 1 1 0.867236\n",
      " modified Weights  [-2.28028628  2.42249065] 1.17961543258897\n",
      " Training with pattern  2  weights  [-2.28028628  2.42249065] 1.174060964986084   weights  [-2.28028628  2.4224911 ]  bias  1.1796158737757951\n",
      "pattern1 0 0 1 0.82733\n",
      "pattern2 0 1 1 0.998514\n",
      "pattern3 1 0 -1 -0.80074\n",
      "pattern4 1 1 1 0.867236\n",
      " modified Weights  [-2.28028628  2.4224911 ] 1.1796158737757951\n",
      " Training with pattern  3  weights  [-2.28028628  2.42249065] 1.174060964986084   weights  [-2.28743605  2.4224911 ]  bias  1.1724660968988265\n",
      "pattern1 0 0 1 0.825061\n",
      "pattern2 0 1 1 0.998493\n",
      "pattern3 1 0 -1 -0.805812\n",
      "pattern4 1 1 1 0.863647\n",
      " modified Weights  [-2.28743605  2.4224911 ] 1.1724660968988265\n",
      " Training with pattern  4  weights  [-2.28028628  2.42249065] 1.174060964986084   weights  [-2.28397113  2.42595602]  bias  1.1759310231520959\n",
      "pattern1 0 0 1 0.826164\n",
      "pattern2 0 1 1 0.998514\n",
      "pattern3 1 0 -1 -0.803369\n",
      "pattern4 1 1 1 0.866265\n",
      " modified Weights  [-2.28397113  2.42595602] 1.1759310231520959\n",
      "+++++++++++Epoch  163  cost=  0.08677015301116449\n",
      " Training with pattern  1  weights  [-2.28397113  2.42595602] 1.1759310231520959   weights  [-2.28397113  2.42595602]  bias  1.1814494854965532\n",
      "pattern1 0 0 1 0.827908\n",
      "pattern2 0 1 1 0.99853\n",
      "pattern3 1 0 -1 -0.801403\n",
      "pattern4 1 1 1 0.867635\n",
      " modified Weights  [-2.28397113  2.42595602] 1.1814494854965532\n",
      " Training with pattern  2  weights  [-2.28397113  2.42595602] 1.1759310231520959   weights  [-2.28397113  2.42595645]  bias  1.1814499174398148\n",
      "pattern1 0 0 1 0.827908\n",
      "pattern2 0 1 1 0.99853\n",
      "pattern3 1 0 -1 -0.801403\n",
      "pattern4 1 1 1 0.867636\n",
      " modified Weights  [-2.28397113  2.42595645] 1.1814499174398148\n",
      " Training with pattern  3  weights  [-2.28397113  2.42595602] 1.1759310231520959   weights  [-2.29107601  2.42595645]  bias  1.1743450332788519\n",
      "pattern1 0 0 1 0.82566\n",
      "pattern2 0 1 1 0.998509\n",
      "pattern3 1 0 -1 -0.806429\n",
      "pattern4 1 1 1 0.864079\n",
      " modified Weights  [-2.29107601  2.42595645] 1.1743450332788519\n",
      " Training with pattern  4  weights  [-2.28397113  2.42595602] 1.1759310231520959   weights  [-2.28763223  2.42940023]  bias  1.1777888145393185\n",
      "pattern1 0 0 1 0.826753\n",
      "pattern2 0 1 1 0.998529\n",
      "pattern3 1 0 -1 -0.804007\n",
      "pattern4 1 1 1 0.866674\n",
      " modified Weights  [-2.28763223  2.42940023] 1.1777888145393185\n",
      "+++++++++++Epoch  164  cost=  0.08620580516767315\n",
      " Training with pattern  1  weights  [-2.28763223  2.42940023] 1.1777888145393185   weights  [-2.28763223  2.42940023]  bias  1.1832717208283603\n",
      "pattern1 0 0 1 0.82848\n",
      "pattern2 0 1 1 0.998545\n",
      "pattern3 1 0 -1 -0.80206\n",
      "pattern4 1 1 1 0.868032\n",
      " modified Weights  [-2.28763223  2.42940023] 1.1832717208283603\n",
      " Training with pattern  2  weights  [-2.28763223  2.42940023] 1.1777888145393185   weights  [-2.28763223  2.42940066]  bias  1.1832721437773381\n",
      "pattern1 0 0 1 0.828481\n",
      "pattern2 0 1 1 0.998545\n",
      "pattern3 1 0 -1 -0.80206\n",
      "pattern4 1 1 1 0.868032\n",
      " modified Weights  [-2.28763223  2.42940066] 1.1832721437773381\n",
      " Training with pattern  3  weights  [-2.28763223  2.42940023] 1.1777888145393185   weights  [-2.29469277  2.42940066]  bias  1.176211609498131\n",
      "pattern1 0 0 1 0.826253\n",
      "pattern2 0 1 1 0.998525\n",
      "pattern3 1 0 -1 -0.80704\n",
      "pattern4 1 1 1 0.864508\n",
      " modified Weights  [-2.29469277  2.42940066] 1.176211609498131\n",
      " Training with pattern  4  weights  [-2.28763223  2.42940023] 1.1777888145393185   weights  [-2.29126988  2.43282354]  bias  1.1796344940515655\n",
      "pattern1 0 0 1 0.827336\n",
      "pattern2 0 1 1 0.998545\n",
      "pattern3 1 0 -1 -0.80464\n",
      "pattern4 1 1 1 0.867079\n",
      " modified Weights  [-2.29126988  2.43282354] 1.1796344940515655\n",
      "+++++++++++Epoch  165  cost=  0.08564846972703422\n",
      " Training with pattern  1  weights  [-2.29126988  2.43282354] 1.1796344940515655   weights  [-2.29126988  2.43282354]  bias  1.18508228527451\n",
      "pattern1 0 0 1 0.829047\n",
      "pattern2 0 1 1 0.99856\n",
      "pattern3 1 0 -1 -0.802711\n",
      "pattern4 1 1 1 0.868425\n",
      " modified Weights  [-2.29126988  2.43282354] 1.18508228527451\n",
      " Training with pattern  2  weights  [-2.29126988  2.43282354] 1.1796344940515655   weights  [-2.29126988  2.43282396]  bias  1.185082699470301\n",
      "pattern1 0 0 1 0.829048\n",
      "pattern2 0 1 1 0.99856\n",
      "pattern3 1 0 -1 -0.80271\n",
      "pattern4 1 1 1 0.868425\n",
      " modified Weights  [-2.29126988  2.43282396] 1.185082699470301\n",
      " Training with pattern  3  weights  [-2.29126988  2.43282354] 1.1796344940515655   weights  [-2.2982866   2.43282396]  bias  1.178065981861469\n",
      "pattern1 0 0 1 0.826841\n",
      "pattern2 0 1 1 0.99854\n",
      "pattern3 1 0 -1 -0.807646\n",
      "pattern4 1 1 1 0.864933\n",
      " modified Weights  [-2.2982866   2.43282396] 1.178065981861469\n",
      " Training with pattern  4  weights  [-2.29126988  2.43282354] 1.1796344940515655   weights  [-2.29488437  2.43622619]  bias  1.1814682137259207\n",
      "pattern1 0 0 1 0.827914\n",
      "pattern2 0 1 1 0.99856\n",
      "pattern3 1 0 -1 -0.805267\n",
      "pattern4 1 1 1 0.867481\n",
      " modified Weights  [-2.29488437  2.43622619] 1.1814682137259207\n",
      "+++++++++++Epoch  166  cost=  0.08509801935376379\n",
      " Training with pattern  1  weights  [-2.29488437  2.43622619] 1.1814682137259207   weights  [-2.29488437  2.43622619]  bias  1.1868813228551687\n",
      "pattern1 0 0 1 0.829609\n",
      "pattern2 0 1 1 0.998575\n",
      "pattern3 1 0 -1 -0.803355\n",
      "pattern4 1 1 1 0.868814\n",
      " modified Weights  [-2.29488437  2.43622619] 1.1868813228551687\n",
      " Training with pattern  2  weights  [-2.29488437  2.43622619] 1.1814682137259207   weights  [-2.29488437  2.43622659]  bias  1.1868817285310023\n",
      "pattern1 0 0 1 0.829609\n",
      "pattern2 0 1 1 0.998575\n",
      "pattern3 1 0 -1 -0.803355\n",
      "pattern4 1 1 1 0.868815\n",
      " modified Weights  [-2.29488437  2.43622659] 1.1868817285310023\n",
      " Training with pattern  3  weights  [-2.29488437  2.43622619] 1.1814682137259207   weights  [-2.30185779  2.43622659]  bias  1.179908303780476\n",
      "pattern1 0 0 1 0.827423\n",
      "pattern2 0 1 1 0.998555\n",
      "pattern3 1 0 -1 -0.808246\n",
      "pattern4 1 1 1 0.865354\n",
      " modified Weights  [-2.30185779  2.43622659] 1.179908303780476\n",
      " Training with pattern  4  weights  [-2.29488437  2.43622619] 1.1814682137259207   weights  [-2.29847597  2.43960841]  bias  1.183290122802235\n",
      "pattern1 0 0 1 0.828486\n",
      "pattern2 0 1 1 0.998575\n",
      "pattern3 1 0 -1 -0.805888\n",
      "pattern4 1 1 1 0.86788\n",
      " modified Weights  [-2.29847597  2.43960841] 1.183290122802235\n",
      "+++++++++++Epoch  167  cost=  0.08455432973833266\n",
      " Training with pattern  1  weights  [-2.29847597  2.43960841] 1.183290122802235   weights  [-2.29847597  2.43960841]  bias  1.1886689749842425\n",
      "pattern1 0 0 1 0.830166\n",
      "pattern2 0 1 1 0.99859\n",
      "pattern3 1 0 -1 -0.803994\n",
      "pattern4 1 1 1 0.869201\n",
      " modified Weights  [-2.29847597  2.43960841] 1.1886689749842425\n",
      " Training with pattern  2  weights  [-2.29847597  2.43960841] 1.183290122802235   weights  [-2.29847597  2.43960881]  bias  1.1886693723657824\n",
      "pattern1 0 0 1 0.830166\n",
      "pattern2 0 1 1 0.99859\n",
      "pattern3 1 0 -1 -0.803994\n",
      "pattern4 1 1 1 0.869201\n",
      " modified Weights  [-2.29847597  2.43960881] 1.1886693723657824\n",
      " Training with pattern  3  weights  [-2.29847597  2.43960841] 1.183290122802235   weights  [-2.30540662  2.43960881]  bias  1.1817387258436447\n",
      "pattern1 0 0 1 0.827999\n",
      "pattern2 0 1 1 0.99857\n",
      "pattern3 1 0 -1 -0.808841\n",
      "pattern4 1 1 1 0.865771\n",
      " modified Weights  [-2.30540662  2.43960881] 1.1817387258436447\n",
      " Training with pattern  4  weights  [-2.29847597  2.43960841] 1.183290122802235   weights  [-2.30204498  2.44297045]  bias  1.1851003677905503\n",
      "pattern1 0 0 1 0.829053\n",
      "pattern2 0 1 1 0.998589\n",
      "pattern3 1 0 -1 -0.806504\n",
      "pattern4 1 1 1 0.868275\n",
      " modified Weights  [-2.30204498  2.44297045] 1.1851003677905503\n",
      "+++++++++++Epoch  168  cost=  0.08401727950861175\n",
      " Training with pattern  1  weights  [-2.30204498  2.44297045] 1.1851003677905503   weights  [-2.30204498  2.44297045]  bias  1.1904453805311954\n",
      "pattern1 0 0 1 0.830717\n",
      "pattern2 0 1 1 0.998604\n",
      "pattern3 1 0 -1 -0.804627\n",
      "pattern4 1 1 1 0.869584\n",
      " modified Weights  [-2.30204498  2.44297045] 1.1904453805311954\n",
      " Training with pattern  2  weights  [-2.30204498  2.44297045] 1.1851003677905503   weights  [-2.30204498  2.44297084]  bias  1.190445769836828\n",
      "pattern1 0 0 1 0.830717\n",
      "pattern2 0 1 1 0.998604\n",
      "pattern3 1 0 -1 -0.804627\n",
      "pattern4 1 1 1 0.869584\n",
      " modified Weights  [-2.30204498  2.44297084] 1.190445769836828\n",
      " Training with pattern  3  weights  [-2.30204498  2.44297045] 1.1851003677905503   weights  [-2.30893335  2.44297084]  bias  1.183557395884337\n",
      "pattern1 0 0 1 0.82857\n",
      "pattern2 0 1 1 0.998585\n",
      "pattern3 1 0 -1 -0.809431\n",
      "pattern4 1 1 1 0.866185\n",
      " modified Weights  [-2.30893335  2.44297084] 1.183557395884337\n",
      " Training with pattern  4  weights  [-2.30204498  2.44297045] 1.1851003677905503   weights  [-2.30559165  2.44631254]  bias  1.186899092536522\n",
      "pattern1 0 0 1 0.829615\n",
      "pattern2 0 1 1 0.998604\n",
      "pattern3 1 0 -1 -0.807114\n",
      "pattern4 1 1 1 0.868666\n",
      " modified Weights  [-2.30559165  2.44631254] 1.186899092536522\n",
      "+++++++++++Epoch  169  cost=  0.0834867501443895\n",
      " Training with pattern  1  weights  [-2.30559165  2.44631254] 1.186899092536522   weights  [-2.30559165  2.44631254]  bias  1.1922106758810627\n",
      "pattern1 0 0 1 0.831263\n",
      "pattern2 0 1 1 0.998619\n",
      "pattern3 1 0 -1 -0.805254\n",
      "pattern4 1 1 1 0.869964\n",
      " modified Weights  [-2.30559165  2.44631254] 1.1922106758810627\n",
      " Training with pattern  2  weights  [-2.30559165  2.44631254] 1.186899092536522   weights  [-2.30559165  2.44631292]  bias  1.1922110573221723\n",
      "pattern1 0 0 1 0.831263\n",
      "pattern2 0 1 1 0.998619\n",
      "pattern3 1 0 -1 -0.805254\n",
      "pattern4 1 1 1 0.869964\n",
      " modified Weights  [-2.30559165  2.44631292] 1.1922110573221723\n",
      " Training with pattern  3  weights  [-2.30559165  2.44631254] 1.186899092536522   weights  [-2.31243825  2.44631292]  bias  1.1853644590467587\n",
      "pattern1 0 0 1 0.829136\n",
      "pattern2 0 1 1 0.998599\n",
      "pattern3 1 0 -1 -0.810015\n",
      "pattern4 1 1 1 0.866595\n",
      " modified Weights  [-2.31243825  2.44631292] 1.1853644590467587\n",
      " Training with pattern  4  weights  [-2.30559165  2.44631254] 1.186899092536522   weights  [-2.30911627  2.4496349 ]  bias  1.1886864382849085\n",
      "pattern1 0 0 1 0.830171\n",
      "pattern2 0 1 1 0.998618\n",
      "pattern3 1 0 -1 -0.807718\n",
      "pattern4 1 1 1 0.869055\n",
      " modified Weights  [-2.30911627  2.4496349 ] 1.1886864382849085\n",
      "+++++++++++Epoch  170  cost=  0.0829626258948368\n",
      " Training with pattern  1  weights  [-2.30911627  2.4496349 ] 1.1886864382849085   weights  [-2.30911627  2.4496349 ]  bias  1.1939649949927185\n",
      "pattern1 0 0 1 0.831805\n",
      "pattern2 0 1 1 0.998632\n",
      "pattern3 1 0 -1 -0.805876\n",
      "pattern4 1 1 1 0.870341\n",
      " modified Weights  [-2.30911627  2.4496349 ] 1.1939649949927185\n",
      " Training with pattern  2  weights  [-2.30911627  2.4496349 ] 1.1886864382849085   weights  [-2.30911627  2.44963527]  bias  1.1939653687739518\n",
      "pattern1 0 0 1 0.831805\n",
      "pattern2 0 1 1 0.998632\n",
      "pattern3 1 0 -1 -0.805876\n",
      "pattern4 1 1 1 0.870341\n",
      " modified Weights  [-2.30911627  2.44963527] 1.1939653687739518\n",
      " Training with pattern  3  weights  [-2.30911627  2.4496349 ] 1.1886864382849085   weights  [-2.31592158  2.44963527]  bias  1.1871600578499892\n",
      "pattern1 0 0 1 0.829696\n",
      "pattern2 0 1 1 0.998614\n",
      "pattern3 1 0 -1 -0.810595\n",
      "pattern4 1 1 1 0.867001\n",
      " modified Weights  [-2.31592158  2.44963527] 1.1871600578499892\n",
      " Training with pattern  4  weights  [-2.30911627  2.4496349 ] 1.1886864382849085   weights  [-2.3126191   2.45293776]  bias  1.1904625437411993\n",
      "pattern1 0 0 1 0.830722\n",
      "pattern2 0 1 1 0.998632\n",
      "pattern3 1 0 -1 -0.808318\n",
      "pattern4 1 1 1 0.86944\n",
      " modified Weights  [-2.3126191   2.45293776] 1.1904625437411993\n",
      "+++++++++++Epoch  171  cost=  0.08244479369880185\n",
      " *********Epoch  170 Error  0.08244479369880185\n",
      " Training with pattern  1  weights  [-2.3126191   2.45293776] 1.1904625437411993   weights  [-2.3126191   2.45293776]  bias  1.1957084694554598\n",
      "pattern1 0 0 1 0.832341\n",
      "pattern2 0 1 1 0.998646\n",
      "pattern3 1 0 -1 -0.806492\n",
      "pattern4 1 1 1 0.870715\n",
      " modified Weights  [-2.3126191   2.45293776] 1.1957084694554598\n",
      " Training with pattern  2  weights  [-2.3126191   2.45293776] 1.1904625437411993   weights  [-2.3126191   2.45293812]  bias  1.1957088357749772\n",
      "pattern1 0 0 1 0.832341\n",
      "pattern2 0 1 1 0.998646\n",
      "pattern3 1 0 -1 -0.806492\n",
      "pattern4 1 1 1 0.870715\n",
      " modified Weights  [-2.3126191   2.45293812] 1.1957088357749772\n",
      " Training with pattern  3  weights  [-2.3126191   2.45293776] 1.1904625437411993   weights  [-2.3193836   2.45293812]  bias  1.188944332250134\n",
      "pattern1 0 0 1 0.830251\n",
      "pattern2 0 1 1 0.998628\n",
      "pattern3 1 0 -1 -0.81117\n",
      "pattern4 1 1 1 0.867404\n",
      " modified Weights  [-2.3193836   2.45293812] 1.188944332250134\n",
      " Training with pattern  4  weights  [-2.3126191   2.45293776] 1.1904625437411993   weights  [-2.31610039  2.45622134]  bias  1.1922275451314415\n",
      "pattern1 0 0 1 0.831268\n",
      "pattern2 0 1 1 0.998646\n",
      "pattern3 1 0 -1 -0.808912\n",
      "pattern4 1 1 1 0.869822\n",
      " modified Weights  [-2.31610039  2.45622134] 1.1922275451314415\n",
      "+++++++++++Epoch  172  cost=  0.08193314310782411\n",
      " Training with pattern  1  weights  [-2.31610039  2.45622134] 1.1922275451314415   weights  [-2.31610039  2.45622134]  bias  1.197441228543964\n",
      "pattern1 0 0 1 0.832872\n",
      "pattern2 0 1 1 0.99866\n",
      "pattern3 1 0 -1 -0.807102\n",
      "pattern4 1 1 1 0.871085\n",
      " modified Weights  [-2.31610039  2.45622134] 1.197441228543964\n",
      " Training with pattern  2  weights  [-2.31610039  2.45622134] 1.1922275451314415   weights  [-2.31610039  2.4562217 ]  bias  1.1974415875936821\n",
      "pattern1 0 0 1 0.832873\n",
      "pattern2 0 1 1 0.99866\n",
      "pattern3 1 0 -1 -0.807102\n",
      "pattern4 1 1 1 0.871086\n",
      " modified Weights  [-2.31610039  2.4562217 ] 1.1974415875936821\n",
      " Training with pattern  3  weights  [-2.31610039  2.45622134] 1.1922275451314415   weights  [-2.32282456  2.4562217 ]  bias  1.1907174197006678\n",
      "pattern1 0 0 1 0.830801\n",
      "pattern2 0 1 1 0.998642\n",
      "pattern3 1 0 -1 -0.811739\n",
      "pattern4 1 1 1 0.867804\n",
      " modified Weights  [-2.32282456  2.4562217 ] 1.1907174197006678\n",
      " Training with pattern  4  weights  [-2.31610039  2.45622134] 1.1922275451314415   weights  [-2.3195604   2.45948585]  bias  1.1939815762603325\n",
      "pattern1 0 0 1 0.83181\n",
      "pattern2 0 1 1 0.998659\n",
      "pattern3 1 0 -1 -0.809501\n",
      "pattern4 1 1 1 0.870201\n",
      " modified Weights  [-2.3195604   2.45948585] 1.1939815762603325\n",
      "+++++++++++Epoch  173  cost=  0.08142756621175942\n",
      " Training with pattern  1  weights  [-2.3195604   2.45948585] 1.1939815762603325   weights  [-2.3195604   2.45948585]  bias  1.199163399271676\n",
      "pattern1 0 0 1 0.833399\n",
      "pattern2 0 1 1 0.998673\n",
      "pattern3 1 0 -1 -0.807707\n",
      "pattern4 1 1 1 0.871453\n",
      " modified Weights  [-2.3195604   2.45948585] 1.199163399271676\n",
      " Training with pattern  2  weights  [-2.3195604   2.45948585] 1.1939815762603325   weights  [-2.3195604   2.45948621]  bias  1.1991637512374986\n",
      "pattern1 0 0 1 0.833399\n",
      "pattern2 0 1 1 0.998673\n",
      "pattern3 1 0 -1 -0.807707\n",
      "pattern4 1 1 1 0.871453\n",
      " modified Weights  [-2.3195604   2.45948621] 1.1991637512374986\n",
      " Training with pattern  3  weights  [-2.3195604   2.45948585] 1.1939815762603325   weights  [-2.3262447   2.45948621]  bias  1.1924794552110278\n",
      "pattern1 0 0 1 0.831346\n",
      "pattern2 0 1 1 0.998655\n",
      "pattern3 1 0 -1 -0.812304\n",
      "pattern4 1 1 1 0.8682\n",
      " modified Weights  [-2.3262447   2.45948621] 1.1924794552110278\n",
      " Training with pattern  4  weights  [-2.3195604   2.45948585] 1.1939815762603325   weights  [-2.32299938  2.46273152]  bias  1.1957247685676342\n",
      "pattern1 0 0 1 0.832346\n",
      "pattern2 0 1 1 0.998672\n",
      "pattern3 1 0 -1 -0.810084\n",
      "pattern4 1 1 1 0.870577\n",
      " modified Weights  [-2.32299938  2.46273152] 1.1957247685676342\n",
      "+++++++++++Epoch  174  cost=  0.08092795756691393\n",
      " Training with pattern  1  weights  [-2.32299938  2.46273152] 1.1957247685676342   weights  [-2.32299938  2.46273152]  bias  1.2008751064426766\n",
      "pattern1 0 0 1 0.833921\n",
      "pattern2 0 1 1 0.998686\n",
      "pattern3 1 0 -1 -0.808307\n",
      "pattern4 1 1 1 0.871818\n",
      " modified Weights  [-2.32299938  2.46273152] 1.2008751064426766\n",
      " Training with pattern  2  weights  [-2.32299938  2.46273152] 1.1957247685676342   weights  [-2.32299938  2.46273186]  bias  1.2008754515047158\n",
      "pattern1 0 0 1 0.833921\n",
      "pattern2 0 1 1 0.998686\n",
      "pattern3 1 0 -1 -0.808306\n",
      "pattern4 1 1 1 0.871818\n",
      " modified Weights  [-2.32299938  2.46273186] 1.2008754515047158\n",
      " Training with pattern  3  weights  [-2.32299938  2.46273152] 1.1957247685676342   weights  [-2.32964426  2.46273186]  bias  1.1942305714035177\n",
      "pattern1 0 0 1 0.831886\n",
      "pattern2 0 1 1 0.998668\n",
      "pattern3 1 0 -1 -0.812864\n",
      "pattern4 1 1 1 0.868592\n",
      " modified Weights  [-2.32964426  2.46273186] 1.1942305714035177\n",
      " Training with pattern  4  weights  [-2.32299938  2.46273152] 1.1957247685676342   weights  [-2.32641758  2.46595854]  bias  1.1974572511829666\n",
      "pattern1 0 0 1 0.832877\n",
      "pattern2 0 1 1 0.998686\n",
      "pattern3 1 0 -1 -0.810663\n",
      "pattern4 1 1 1 0.870949\n",
      " modified Weights  [-2.32641758  2.46595854] 1.1974572511829666\n",
      "+++++++++++Epoch  175  cost=  0.0804342141265907\n",
      " Training with pattern  1  weights  [-2.32641758  2.46595854] 1.1974572511829666   weights  [-2.32641758  2.46595854]  bias  1.2025764727020838\n",
      "pattern1 0 0 1 0.834439\n",
      "pattern2 0 1 1 0.998699\n",
      "pattern3 1 0 -1 -0.808901\n",
      "pattern4 1 1 1 0.87218\n",
      " modified Weights  [-2.32641758  2.46595854] 1.2025764727020838\n",
      " Training with pattern  2  weights  [-2.32641758  2.46595854] 1.1974572511829666   weights  [-2.32641758  2.46595888]  bias  1.202576811034872\n",
      "pattern1 0 0 1 0.834439\n",
      "pattern2 0 1 1 0.998699\n",
      "pattern3 1 0 -1 -0.808901\n",
      "pattern4 1 1 1 0.87218\n",
      " modified Weights  [-2.32641758  2.46595888] 1.202576811034872\n",
      " Training with pattern  3  weights  [-2.32641758  2.46595854] 1.1974572511829666   weights  [-2.3330235   2.46595888]  bias  1.1959708985685824\n",
      "pattern1 0 0 1 0.832422\n",
      "pattern2 0 1 1 0.998682\n",
      "pattern3 1 0 -1 -0.813419\n",
      "pattern4 1 1 1 0.868982\n",
      " modified Weights  [-2.3330235   2.46595888] 1.1959708985685824\n",
      " Training with pattern  4  weights  [-2.32641758  2.46595854] 1.1974572511829666   weights  [-2.32981524  2.46916713]  bias  1.1991791509790388\n",
      "pattern1 0 0 1 0.833404\n",
      "pattern2 0 1 1 0.998698\n",
      "pattern3 1 0 -1 -0.811237\n",
      "pattern4 1 1 1 0.871319\n",
      " modified Weights  [-2.32981524  2.46916713] 1.1991791509790388\n",
      "+++++++++++Epoch  176  cost=  0.079946235173954\n",
      " Training with pattern  1  weights  [-2.32981524  2.46916713] 1.1991791509790388   weights  [-2.32981524  2.46916713]  bias  1.204267618585038\n",
      "pattern1 0 0 1 0.834952\n",
      "pattern2 0 1 1 0.998712\n",
      "pattern3 1 0 -1 -0.80949\n",
      "pattern4 1 1 1 0.872539\n",
      " modified Weights  [-2.32981524  2.46916713] 1.204267618585038\n",
      " Training with pattern  2  weights  [-2.32981524  2.46916713] 1.1991791509790388   weights  [-2.32981524  2.46916747]  bias  1.2042679503577316\n",
      "pattern1 0 0 1 0.834952\n",
      "pattern2 0 1 1 0.998712\n",
      "pattern3 1 0 -1 -0.80949\n",
      "pattern4 1 1 1 0.872539\n",
      " modified Weights  [-2.32981524  2.46916747] 1.2042679503577316\n",
      " Training with pattern  3  weights  [-2.32981524  2.46916713] 1.1991791509790388   weights  [-2.33638263  2.46916747]  bias  1.197700564718505\n",
      "pattern1 0 0 1 0.832952\n",
      "pattern2 0 1 1 0.998695\n",
      "pattern3 1 0 -1 -0.81397\n",
      "pattern4 1 1 1 0.869368\n",
      " modified Weights  [-2.33638263  2.46916747] 1.197700564718505\n",
      " Training with pattern  4  weights  [-2.32981524  2.46916713] 1.1991791509790388   weights  [-2.3331926   2.47235749]  bias  1.2008905926233682\n",
      "pattern1 0 0 1 0.833926\n",
      "pattern2 0 1 1 0.998711\n",
      "pattern3 1 0 -1 -0.811806\n",
      "pattern4 1 1 1 0.871686\n",
      " modified Weights  [-2.3331926   2.47235749] 1.2008905926233682\n",
      "+++++++++++Epoch  177  cost=  0.07946392225712148\n",
      " Training with pattern  1  weights  [-2.3331926   2.47235749] 1.2008905926233682   weights  [-2.3331926   2.47235749]  bias  1.2059486625643172\n",
      "pattern1 0 0 1 0.83546\n",
      "pattern2 0 1 1 0.998724\n",
      "pattern3 1 0 -1 -0.810074\n",
      "pattern4 1 1 1 0.872895\n",
      " modified Weights  [-2.3331926   2.47235749] 1.2059486625643172\n",
      " Training with pattern  2  weights  [-2.3331926   2.47235749] 1.2008905926233682   weights  [-2.3331926   2.47235782]  bias  1.2059489879408907\n",
      "pattern1 0 0 1 0.83546\n",
      "pattern2 0 1 1 0.998724\n",
      "pattern3 1 0 -1 -0.810074\n",
      "pattern4 1 1 1 0.872895\n",
      " modified Weights  [-2.3331926   2.47235782] 1.2059489879408907\n",
      " Training with pattern  3  weights  [-2.3331926   2.47235749] 1.2008905926233682   weights  [-2.33972189  2.47235782]  bias  1.199419695639583\n",
      "pattern1 0 0 1 0.833478\n",
      "pattern2 0 1 1 0.998707\n",
      "pattern3 1 0 -1 -0.814516\n",
      "pattern4 1 1 1 0.869751\n",
      " modified Weights  [-2.33972189  2.47235782] 1.199419695639583\n",
      " Training with pattern  4  weights  [-2.3331926   2.47235749] 1.2008905926233682   weights  [-2.33654989  2.47552982]  bias  1.2025916986285368\n",
      "pattern1 0 0 1 0.834443\n",
      "pattern2 0 1 1 0.998724\n",
      "pattern3 1 0 -1 -0.81237\n",
      "pattern4 1 1 1 0.872049\n",
      " modified Weights  [-2.33654989  2.47552982] 1.2025916986285368\n",
      "+++++++++++Epoch  178  cost=  0.07898717912640203\n",
      " Training with pattern  1  weights  [-2.33654989  2.47552982] 1.2025916986285368   weights  [-2.33654989  2.47552982]  bias  1.207619721096624\n",
      "pattern1 0 0 1 0.835964\n",
      "pattern2 0 1 1 0.998736\n",
      "pattern3 1 0 -1 -0.810653\n",
      "pattern4 1 1 1 0.873248\n",
      " modified Weights  [-2.33654989  2.47552982] 1.207619721096624\n",
      " Training with pattern  2  weights  [-2.33654989  2.47552982] 1.2025916986285368   weights  [-2.33654989  2.47553014]  bias  1.2076200402360568\n",
      "pattern1 0 0 1 0.835964\n",
      "pattern2 0 1 1 0.998736\n",
      "pattern3 1 0 -1 -0.810653\n",
      "pattern4 1 1 1 0.873248\n",
      " modified Weights  [-2.33654989  2.47553014] 1.2076200402360568\n",
      " Training with pattern  3  weights  [-2.33654989  2.47552982] 1.2025916986285368   weights  [-2.34304152  2.47553014]  bias  1.2011284149428314\n",
      "pattern1 0 0 1 0.833998\n",
      "pattern2 0 1 1 0.99872\n",
      "pattern3 1 0 -1 -0.815057\n",
      "pattern4 1 1 1 0.870131\n",
      " modified Weights  [-2.34304152  2.47553014] 1.2011284149428314\n",
      " Training with pattern  4  weights  [-2.33654989  2.47552982] 1.2025916986285368   weights  [-2.33988734  2.47868432]  bias  1.2042825894010387\n",
      "pattern1 0 0 1 0.834956\n",
      "pattern2 0 1 1 0.998736\n",
      "pattern3 1 0 -1 -0.812929\n",
      "pattern4 1 1 1 0.87241\n",
      " modified Weights  [-2.33988734  2.47868432] 1.2042825894010387\n",
      "+++++++++++Epoch  179  cost=  0.07851591167359326\n",
      " Training with pattern  1  weights  [-2.33988734  2.47868432] 1.2042825894010387   weights  [-2.33988734  2.47868432]  bias  1.2092809086675962\n",
      "pattern1 0 0 1 0.836464\n",
      "pattern2 0 1 1 0.998748\n",
      "pattern3 1 0 -1 -0.811227\n",
      "pattern4 1 1 1 0.873599\n",
      " modified Weights  [-2.33988734  2.47868432] 1.2092809086675962\n",
      " Training with pattern  2  weights  [-2.33988734  2.47868432] 1.2042825894010387   weights  [-2.33988734  2.47868463]  bias  1.2092812217240518\n",
      "pattern1 0 0 1 0.836464\n",
      "pattern2 0 1 1 0.998748\n",
      "pattern3 1 0 -1 -0.811227\n",
      "pattern4 1 1 1 0.873599\n",
      " modified Weights  [-2.33988734  2.47868463] 1.2092812217240518\n",
      " Training with pattern  3  weights  [-2.33988734  2.47868432] 1.2042825894010387   weights  [-2.34634172  2.47868463]  bias  1.2028268441132646\n",
      "pattern1 0 0 1 0.834515\n",
      "pattern2 0 1 1 0.998732\n",
      "pattern3 1 0 -1 -0.815594\n",
      "pattern4 1 1 1 0.870507\n",
      " modified Weights  [-2.34634172  2.47868463] 1.2028268441132646\n",
      " Training with pattern  4  weights  [-2.33988734  2.47868432] 1.2042825894010387   weights  [-2.34320518  2.48182117]  bias  1.2059633832887606\n",
      "pattern1 0 0 1 0.835465\n",
      "pattern2 0 1 1 0.998748\n",
      "pattern3 1 0 -1 -0.813483\n",
      "pattern4 1 1 1 0.872768\n",
      " modified Weights  [-2.34320518  2.48182117] 1.2059633832887606\n",
      "+++++++++++Epoch  180  cost=  0.07805002787326402\n",
      " Training with pattern  1  weights  [-2.34320518  2.48182117] 1.2059633832887606   weights  [-2.34320518  2.48182117]  bias  1.2109323378355745\n",
      "pattern1 0 0 1 0.836959\n",
      "pattern2 0 1 1 0.99876\n",
      "pattern3 1 0 -1 -0.811796\n",
      "pattern4 1 1 1 0.873947\n",
      " modified Weights  [-2.34320518  2.48182117] 1.2109323378355745\n",
      " Training with pattern  2  weights  [-2.34320518  2.48182117] 1.2059633832887606   weights  [-2.34320518  2.48182148]  bias  1.210932644958572\n",
      "pattern1 0 0 1 0.836959\n",
      "pattern2 0 1 1 0.99876\n",
      "pattern3 1 0 -1 -0.811796\n",
      "pattern4 1 1 1 0.873947\n",
      " modified Weights  [-2.34320518  2.48182148] 1.210932644958572\n",
      " Training with pattern  3  weights  [-2.34320518  2.48182117] 1.2059633832887606   weights  [-2.34962272  2.48182148]  bias  1.204515102557803\n",
      "pattern1 0 0 1 0.835027\n",
      "pattern2 0 1 1 0.998744\n",
      "pattern3 1 0 -1 -0.816127\n",
      "pattern4 1 1 1 0.870881\n",
      " modified Weights  [-2.34962272  2.48182148] 1.204515102557803\n",
      " Training with pattern  4  weights  [-2.34320518  2.48182117] 1.2059633832887606   weights  [-2.34650363  2.48494057]  bias  1.2076341966271438\n",
      "pattern1 0 0 1 0.835968\n",
      "pattern2 0 1 1 0.99876\n",
      "pattern3 1 0 -1 -0.814033\n",
      "pattern4 1 1 1 0.873123\n",
      " modified Weights  [-2.34650363  2.48494057] 1.2076341966271438\n",
      "+++++++++++Epoch  181  cost=  0.07758943772594531\n",
      " *********Epoch  180 Error  0.07758943772594531\n",
      " Training with pattern  1  weights  [-2.34650363  2.48494057] 1.2076341966271438   weights  [-2.34650363  2.48494057]  bias  1.2125741192741741\n",
      "pattern1 0 0 1 0.83745\n",
      "pattern2 0 1 1 0.998772\n",
      "pattern3 1 0 -1 -0.81236\n",
      "pattern4 1 1 1 0.874292\n",
      " modified Weights  [-2.34650363  2.48494057] 1.2125741192741741\n",
      " Training with pattern  2  weights  [-2.34650363  2.48494057] 1.2076341966271438   weights  [-2.34650363  2.48494087]  bias  1.2125744206087519\n",
      "pattern1 0 0 1 0.83745\n",
      "pattern2 0 1 1 0.998772\n",
      "pattern3 1 0 -1 -0.81236\n",
      "pattern4 1 1 1 0.874292\n",
      " modified Weights  [-2.34650363  2.48494087] 1.2125744206087519\n",
      " Training with pattern  3  weights  [-2.34650363  2.48494057] 1.2076341966271438   weights  [-2.35288474  2.48494087]  bias  1.206193307651849\n",
      "pattern1 0 0 1 0.835534\n",
      "pattern2 0 1 1 0.998756\n",
      "pattern3 1 0 -1 -0.816655\n",
      "pattern4 1 1 1 0.871251\n",
      " modified Weights  [-2.35288474  2.48494087] 1.206193307651849\n",
      " Training with pattern  4  weights  [-2.34650363  2.48494057] 1.2076341966271438   weights  [-2.3497829   2.48804271]  bias  1.2092951437840684\n",
      "pattern1 0 0 1 0.836468\n",
      "pattern2 0 1 1 0.998772\n",
      "pattern3 1 0 -1 -0.814578\n",
      "pattern4 1 1 1 0.873475\n",
      " modified Weights  [-2.3497829   2.48804271] 1.2092951437840684\n",
      "+++++++++++Epoch  182  cost=  0.07713405320315814\n",
      " Training with pattern  1  weights  [-2.3497829   2.48804271] 1.2092951437840684   weights  [-2.3497829   2.48804271]  bias  1.2142063618136947\n",
      "pattern1 0 0 1 0.837937\n",
      "pattern2 0 1 1 0.998784\n",
      "pattern3 1 0 -1 -0.812919\n",
      "pattern4 1 1 1 0.874634\n",
      " modified Weights  [-2.3497829   2.48804271] 1.2142063618136947\n",
      " Training with pattern  2  weights  [-2.3497829   2.48804271] 1.2092951437840684   weights  [-2.3497829  2.488043 ]  bias  1.2142066575005692\n",
      "pattern1 0 0 1 0.837937\n",
      "pattern2 0 1 1 0.998784\n",
      "pattern3 1 0 -1 -0.812919\n",
      "pattern4 1 1 1 0.874634\n",
      " modified Weights  [-2.3497829  2.488043 ] 1.2142066575005692\n",
      " Training with pattern  3  weights  [-2.3497829   2.48804271] 1.2092951437840684   weights  [-2.35612799  2.488043  ]  bias  1.2078615747845796\n",
      "pattern1 0 0 1 0.836037\n",
      "pattern2 0 1 1 0.998768\n",
      "pattern3 1 0 -1 -0.817179\n",
      "pattern4 1 1 1 0.871619\n",
      " modified Weights  [-2.35612799  2.488043  ] 1.2078615747845796\n",
      " Training with pattern  4  weights  [-2.3497829   2.48804271] 1.2092951437840684   weights  [-2.35304322  2.49112776]  bias  1.210946337203506\n",
      "pattern1 0 0 1 0.836963\n",
      "pattern2 0 1 1 0.998783\n",
      "pattern3 1 0 -1 -0.815119\n",
      "pattern4 1 1 1 0.873824\n",
      " modified Weights  [-2.35304322  2.49112776] 1.210946337203506\n",
      "+++++++++++Epoch  183  cost=  0.07668378819421034\n",
      " Training with pattern  1  weights  [-2.35304322  2.49112776] 1.210946337203506   weights  [-2.35304322  2.49112776]  bias  1.2158291724814094\n",
      "pattern1 0 0 1 0.83842\n",
      "pattern2 0 1 1 0.998795\n",
      "pattern3 1 0 -1 -0.813474\n",
      "pattern4 1 1 1 0.874974\n",
      " modified Weights  [-2.35304322  2.49112776] 1.2158291724814094\n",
      " Training with pattern  2  weights  [-2.35304322  2.49112776] 1.210946337203506   weights  [-2.35304322  2.49112805]  bias  1.2158294626571267\n",
      "pattern1 0 0 1 0.83842\n",
      "pattern2 0 1 1 0.998795\n",
      "pattern3 1 0 -1 -0.813474\n",
      "pattern4 1 1 1 0.874974\n",
      " modified Weights  [-2.35304322  2.49112805] 1.2158294626571267\n",
      " Training with pattern  3  weights  [-2.35304322  2.49112776] 1.210946337203506   weights  [-2.35935267  2.49112805]  bias  1.2095200174029919\n",
      "pattern1 0 0 1 0.836535\n",
      "pattern2 0 1 1 0.99878\n",
      "pattern3 1 0 -1 -0.817699\n",
      "pattern4 1 1 1 0.871983\n",
      " modified Weights  [-2.35935267  2.49112805] 1.2095200174029919\n",
      " Training with pattern  4  weights  [-2.35304322  2.49112776] 1.210946337203506   weights  [-2.3562848   2.49419593]  bias  1.2125878874479763\n",
      "pattern1 0 0 1 0.837454\n",
      "pattern2 0 1 1 0.998795\n",
      "pattern3 1 0 -1 -0.815655\n",
      "pattern4 1 1 1 0.874171\n",
      " modified Weights  [-2.3562848   2.49419593] 1.2125878874479763\n",
      "+++++++++++Epoch  184  cost=  0.07623855845469636\n",
      " Training with pattern  1  weights  [-2.3562848   2.49419593] 1.2125878874479763   weights  [-2.3562848   2.49419593]  bias  1.2174426565407674\n",
      "pattern1 0 0 1 0.838898\n",
      "pattern2 0 1 1 0.998806\n",
      "pattern3 1 0 -1 -0.814024\n",
      "pattern4 1 1 1 0.875311\n",
      " modified Weights  [-2.3562848   2.49419593] 1.2174426565407674\n",
      " Training with pattern  2  weights  [-2.3562848   2.49419593] 1.2125878874479763   weights  [-2.3562848   2.49419621]  bias  1.2174429413378476\n",
      "pattern1 0 0 1 0.838898\n",
      "pattern2 0 1 1 0.998806\n",
      "pattern3 1 0 -1 -0.814024\n",
      "pattern4 1 1 1 0.875311\n",
      " modified Weights  [-2.3562848   2.49419621] 1.2174429413378476\n",
      " Training with pattern  3  weights  [-2.3562848   2.49419593] 1.2125878874479763   weights  [-2.36255899  2.49419621]  bias  1.211168747054747\n",
      "pattern1 0 0 1 0.83703\n",
      "pattern2 0 1 1 0.998791\n",
      "pattern3 1 0 -1 -0.818214\n",
      "pattern4 1 1 1 0.872345\n",
      " modified Weights  [-2.36255899  2.49419621] 1.211168747054747\n",
      " Training with pattern  4  weights  [-2.3562848   2.49419593] 1.2125878874479763   weights  [-2.35950784  2.49724737]  bias  1.214219903239847\n",
      "pattern1 0 0 1 0.837941\n",
      "pattern2 0 1 1 0.998806\n",
      "pattern3 1 0 -1 -0.816187\n",
      "pattern4 1 1 1 0.874515\n",
      " modified Weights  [-2.35950784  2.49724737] 1.214219903239847\n",
      "+++++++++++Epoch  185  cost=  0.0757982815566362\n",
      " Training with pattern  1  weights  [-2.35950784  2.49724737] 1.214219903239847   weights  [-2.35950784  2.49724737]  bias  1.219046917529544\n",
      "pattern1 0 0 1 0.839373\n",
      "pattern2 0 1 1 0.998817\n",
      "pattern3 1 0 -1 -0.814569\n",
      "pattern4 1 1 1 0.875646\n",
      " modified Weights  [-2.35950784  2.49724737] 1.219046917529544\n",
      " Training with pattern  2  weights  [-2.35950784  2.49724737] 1.214219903239847   weights  [-2.35950784  2.49724765]  bias  1.219047197076622\n",
      "pattern1 0 0 1 0.839373\n",
      "pattern2 0 1 1 0.998817\n",
      "pattern3 1 0 -1 -0.814569\n",
      "pattern4 1 1 1 0.875646\n",
      " modified Weights  [-2.35950784  2.49724765] 1.219047197076622\n",
      " Training with pattern  3  weights  [-2.35950784  2.49724737] 1.214219903239847   weights  [-2.36574716  2.49724765]  bias  1.21280787342985\n",
      "pattern1 0 0 1 0.83752\n",
      "pattern2 0 1 1 0.998803\n",
      "pattern3 1 0 -1 -0.818725\n",
      "pattern4 1 1 1 0.872703\n",
      " modified Weights  [-2.36574716  2.49724765] 1.21280787342985\n",
      " Training with pattern  4  weights  [-2.35950784  2.49724737] 1.214219903239847   weights  [-2.36271254  2.50028226]  bias  1.2158424915015198\n",
      "pattern1 0 0 1 0.838424\n",
      "pattern2 0 1 1 0.998817\n",
      "pattern3 1 0 -1 -0.816715\n",
      "pattern4 1 1 1 0.874856\n",
      " modified Weights  [-2.36271254  2.50028226] 1.2158424915015198\n",
      "+++++++++++Epoch  186  cost=  0.07536287684019584\n",
      " Training with pattern  1  weights  [-2.36271254  2.50028226] 1.2158424915015198   weights  [-2.36271254  2.50028226]  bias  1.2206420572969747\n",
      "pattern1 0 0 1 0.839843\n",
      "pattern2 0 1 1 0.998828\n",
      "pattern3 1 0 -1 -0.81511\n",
      "pattern4 1 1 1 0.875978\n",
      " modified Weights  [-2.36271254  2.50028226] 1.2206420572969747\n",
      " Training with pattern  2  weights  [-2.36271254  2.50028226] 1.2158424915015198   weights  [-2.36271254  2.50028254]  bias  1.220642331718933\n",
      "pattern1 0 0 1 0.839844\n",
      "pattern2 0 1 1 0.998828\n",
      "pattern3 1 0 -1 -0.81511\n",
      "pattern4 1 1 1 0.875978\n",
      " modified Weights  [-2.36271254  2.50028254] 1.220642331718933\n",
      " Training with pattern  3  weights  [-2.36271254  2.50028226] 1.2158424915015198   weights  [-2.36891737  2.50028254]  bias  1.2144375044012012\n",
      "pattern1 0 0 1 0.838006\n",
      "pattern2 0 1 1 0.998814\n",
      "pattern3 1 0 -1 -0.819233\n",
      "pattern4 1 1 1 0.873059\n",
      " modified Weights  [-2.36891737  2.50028254] 1.2144375044012012\n",
      " Training with pattern  4  weights  [-2.36271254  2.50028226] 1.2158424915015198   weights  [-2.36589912  2.50330079]  bias  1.21745575739453\n",
      "pattern1 0 0 1 0.838902\n",
      "pattern2 0 1 1 0.998828\n",
      "pattern3 1 0 -1 -0.817238\n",
      "pattern4 1 1 1 0.875195\n",
      " modified Weights  [-2.36589912  2.50330079] 1.21745575739453\n",
      "+++++++++++Epoch  187  cost=  0.07493226536692725\n",
      " Training with pattern  1  weights  [-2.36589912  2.50330079] 1.21745575739453   weights  [-2.36589912  2.50330079]  bias  1.2222281760399016\n",
      "pattern1 0 0 1 0.84031\n",
      "pattern2 0 1 1 0.998839\n",
      "pattern3 1 0 -1 -0.815647\n",
      "pattern4 1 1 1 0.876307\n",
      " modified Weights  [-2.36589912  2.50330079] 1.2222281760399016\n",
      " Training with pattern  2  weights  [-2.36589912  2.50330079] 1.21745575739453   weights  [-2.36589912  2.50330106]  bias  1.2222284454580001\n",
      "pattern1 0 0 1 0.84031\n",
      "pattern2 0 1 1 0.998839\n",
      "pattern3 1 0 -1 -0.815646\n",
      "pattern4 1 1 1 0.876307\n",
      " modified Weights  [-2.36589912  2.50330106] 1.2222284454580001\n",
      " Training with pattern  3  weights  [-2.36589912  2.50330079] 1.21745575739453   weights  [-2.37206982  2.50330106]  bias  1.2160577460640585\n",
      "pattern1 0 0 1 0.838487\n",
      "pattern2 0 1 1 0.998825\n",
      "pattern3 1 0 -1 -0.819736\n",
      "pattern4 1 1 1 0.873412\n",
      " modified Weights  [-2.37206982  2.50330106] 1.2160577460640585\n",
      " Training with pattern  4  weights  [-2.36589912  2.50330079] 1.21745575739453   weights  [-2.36906776  2.50630312]  bias  1.2190598043576004\n",
      "pattern1 0 0 1 0.839377\n",
      "pattern2 0 1 1 0.998839\n",
      "pattern3 1 0 -1 -0.817757\n",
      "pattern4 1 1 1 0.875531\n",
      " modified Weights  [-2.36906776  2.50630312] 1.2190598043576004\n",
      "+++++++++++Epoch  188  cost=  0.07450636987447713\n",
      " Training with pattern  1  weights  [-2.36906776  2.50630312] 1.2190598043576004   weights  [-2.36906776  2.50630312]  bias  1.223805372337966\n",
      "pattern1 0 0 1 0.840773\n",
      "pattern2 0 1 1 0.99885\n",
      "pattern3 1 0 -1 -0.816179\n",
      "pattern4 1 1 1 0.876634\n",
      " modified Weights  [-2.36906776  2.50630312] 1.223805372337966\n",
      " Training with pattern  2  weights  [-2.36906776  2.50630312] 1.2190598043576004   weights  [-2.36906776  2.50630338]  bias  1.2238056368699652\n",
      "pattern1 0 0 1 0.840773\n",
      "pattern2 0 1 1 0.99885\n",
      "pattern3 1 0 -1 -0.816178\n",
      "pattern4 1 1 1 0.876634\n",
      " modified Weights  [-2.36906776  2.50630338] 1.2238056368699652\n",
      " Training with pattern  3  weights  [-2.36906776  2.50630312] 1.2190598043576004   weights  [-2.37520469  2.50630338]  bias  1.2176687027744417\n",
      "pattern1 0 0 1 0.838965\n",
      "pattern2 0 1 1 0.998835\n",
      "pattern3 1 0 -1 -0.820235\n",
      "pattern4 1 1 1 0.873762\n",
      " modified Weights  [-2.37520469  2.50630338] 1.2176687027744417\n",
      " Training with pattern  4  weights  [-2.36906776  2.50630312] 1.2190598043576004   weights  [-2.37221866  2.50928941]  bias  1.2206547341436815\n",
      "pattern1 0 0 1 0.839847\n",
      "pattern2 0 1 1 0.998849\n",
      "pattern3 1 0 -1 -0.818272\n",
      "pattern4 1 1 1 0.875864\n",
      " modified Weights  [-2.37221866  2.50928941] 1.2206547341436815\n",
      "+++++++++++Epoch  189  cost=  0.0740851147327075\n",
      " Training with pattern  1  weights  [-2.37221866  2.50928941] 1.2206547341436815   weights  [-2.37221866  2.50928941]  bias  1.2253737431878755\n",
      "pattern1 0 0 1 0.841232\n",
      "pattern2 0 1 1 0.99886\n",
      "pattern3 1 0 -1 -0.816706\n",
      "pattern4 1 1 1 0.876959\n",
      " modified Weights  [-2.37221866  2.50928941] 1.2253737431878755\n",
      " Training with pattern  2  weights  [-2.37221866  2.50928941] 1.2206547341436815   weights  [-2.37221866  2.50928967]  bias  1.2253740029481552\n",
      "pattern1 0 0 1 0.841232\n",
      "pattern2 0 1 1 0.99886\n",
      "pattern3 1 0 -1 -0.816706\n",
      "pattern4 1 1 1 0.876959\n",
      " modified Weights  [-2.37221866  2.50928967] 1.2253740029481552\n",
      " Training with pattern  3  weights  [-2.37221866  2.50928941] 1.2206547341436815   weights  [-2.37832219  2.50928967]  bias  1.219270477186516\n",
      "pattern1 0 0 1 0.839439\n",
      "pattern2 0 1 1 0.998846\n",
      "pattern3 1 0 -1 -0.820731\n",
      "pattern4 1 1 1 0.874109\n",
      " modified Weights  [-2.37832219  2.50928967] 1.219270477186516\n",
      " Training with pattern  4  weights  [-2.37221866  2.50928941] 1.2206547341436815   weights  [-2.37535202  2.51225984]  bias  1.2222406468560074\n",
      "pattern1 0 0 1 0.840314\n",
      "pattern2 0 1 1 0.99886\n",
      "pattern3 1 0 -1 -0.818782\n",
      "pattern4 1 1 1 0.876195\n",
      " modified Weights  [-2.37535202  2.51225984] 1.2222406468560074\n",
      "+++++++++++Epoch  190  cost=  0.0736684259011796\n",
      " Training with pattern  1  weights  [-2.37535202  2.51225984] 1.2222406468560074   weights  [-2.37535202  2.51225984]  bias  1.2269333840367764\n",
      "pattern1 0 0 1 0.841688\n",
      "pattern2 0 1 1 0.99887\n",
      "pattern3 1 0 -1 -0.81723\n",
      "pattern4 1 1 1 0.877281\n",
      " modified Weights  [-2.37535202  2.51225984] 1.2269333840367764\n",
      " Training with pattern  2  weights  [-2.37535202  2.51225984] 1.2222406468560074   weights  [-2.37535202  2.5122601 ]  bias  1.2269336391364503\n",
      "pattern1 0 0 1 0.841688\n",
      "pattern2 0 1 1 0.99887\n",
      "pattern3 1 0 -1 -0.817229\n",
      "pattern4 1 1 1 0.877281\n",
      " modified Weights  [-2.37535202  2.5122601 ] 1.2269336391364503\n",
      " Training with pattern  3  weights  [-2.37535202  2.51225984] 1.2222406468560074   weights  [-2.38142249  2.5122601 ]  bias  1.2208631702889836\n",
      "pattern1 0 0 1 0.839909\n",
      "pattern2 0 1 1 0.998857\n",
      "pattern3 1 0 -1 -0.821222\n",
      "pattern4 1 1 1 0.874454\n",
      " modified Weights  [-2.38142249  2.5122601 ] 1.2208631702889836\n",
      " Training with pattern  4  weights  [-2.37535202  2.51225984] 1.2222406468560074   weights  [-2.37846802  2.51521457]  bias  1.223817640983202\n",
      "pattern1 0 0 1 0.840777\n",
      "pattern2 0 1 1 0.99887\n",
      "pattern3 1 0 -1 -0.819289\n",
      "pattern4 1 1 1 0.876524\n",
      " modified Weights  [-2.37846802  2.51521457] 1.223817640983202\n",
      "+++++++++++Epoch  191  cost=  0.0732562308879512\n",
      " *********Epoch  190 Error  0.0732562308879512\n",
      " Training with pattern  1  weights  [-2.37846802  2.51521457] 1.223817640983202   weights  [-2.37846802  2.51521457]  bias  1.2284843888147565\n",
      "pattern1 0 0 1 0.842139\n",
      "pattern2 0 1 1 0.99888\n",
      "pattern3 1 0 -1 -0.817749\n",
      "pattern4 1 1 1 0.877601\n",
      " modified Weights  [-2.37846802  2.51521457] 1.2284843888147565\n",
      " Training with pattern  2  weights  [-2.37846802  2.51521457] 1.223817640983202   weights  [-2.37846802  2.51521482]  bias  1.2284846393617812\n",
      "pattern1 0 0 1 0.842139\n",
      "pattern2 0 1 1 0.99888\n",
      "pattern3 1 0 -1 -0.817749\n",
      "pattern4 1 1 1 0.877601\n",
      " modified Weights  [-2.37846802  2.51521482] 1.2284846393617812\n",
      " Training with pattern  3  weights  [-2.37846802  2.51521457] 1.223817640983202   weights  [-2.38450577  2.51521482]  bias  1.2224468814405176\n",
      "pattern1 0 0 1 0.840374\n",
      "pattern2 0 1 1 0.998867\n",
      "pattern3 1 0 -1 -0.82171\n",
      "pattern4 1 1 1 0.874796\n",
      " modified Weights  [-2.38450577  2.51521482] 1.2224468814405176\n",
      " Training with pattern  4  weights  [-2.37846802  2.51521457] 1.223817640983202   weights  [-2.38156684  2.51815375]  bias  1.2253858134334625\n",
      "pattern1 0 0 1 0.841236\n",
      "pattern2 0 1 1 0.99888\n",
      "pattern3 1 0 -1 -0.819791\n",
      "pattern4 1 1 1 0.87685\n",
      " modified Weights  [-2.38156684  2.51815375] 1.2253858134334625\n",
      "+++++++++++Epoch  192  cost=  0.07284845870964071\n",
      " Training with pattern  1  weights  [-2.38156684  2.51815375] 1.2253858134334625   weights  [-2.38156684  2.51815375]  bias  1.2300268499665068\n",
      "pattern1 0 0 1 0.842587\n",
      "pattern2 0 1 1 0.99889\n",
      "pattern3 1 0 -1 -0.818264\n",
      "pattern4 1 1 1 0.877918\n",
      " modified Weights  [-2.38156684  2.51815375] 1.2300268499665068\n",
      " Training with pattern  2  weights  [-2.38156684  2.51815375] 1.2253858134334625   weights  [-2.38156684  2.518154  ]  bias  1.230027096065788\n",
      "pattern1 0 0 1 0.842587\n",
      "pattern2 0 1 1 0.99889\n",
      "pattern3 1 0 -1 -0.818264\n",
      "pattern4 1 1 1 0.877918\n",
      " modified Weights  [-2.38156684  2.518154  ] 1.230027096065788\n",
      " Training with pattern  3  weights  [-2.38156684  2.51815375] 1.2253858134334625   weights  [-2.38757223  2.518154  ]  bias  1.2240217084042653\n",
      "pattern1 0 0 1 0.840837\n",
      "pattern2 0 1 1 0.998877\n",
      "pattern3 1 0 -1 -0.822194\n",
      "pattern4 1 1 1 0.875135\n",
      " modified Weights  [-2.38757223  2.518154  ] 1.2240217084042653\n",
      " Training with pattern  4  weights  [-2.38156684  2.51815375] 1.2253858134334625   weights  [-2.38464868  2.52107755]  bias  1.2269452595678514\n",
      "pattern1 0 0 1 0.841691\n",
      "pattern2 0 1 1 0.99889\n",
      "pattern3 1 0 -1 -0.82029\n",
      "pattern4 1 1 1 0.877173\n",
      " modified Weights  [-2.38464868  2.52107755] 1.2269452595678514\n",
      "+++++++++++Epoch  193  cost=  0.07244503985271315\n",
      " Training with pattern  1  weights  [-2.38464868  2.52107755] 1.2269452595678514   weights  [-2.38464868  2.52107755]  bias  1.2315608584821685\n",
      "pattern1 0 0 1 0.843031\n",
      "pattern2 0 1 1 0.9989\n",
      "pattern3 1 0 -1 -0.818774\n",
      "pattern4 1 1 1 0.878233\n",
      " modified Weights  [-2.38464868  2.52107755] 1.2315608584821685\n",
      " Training with pattern  2  weights  [-2.38464868  2.52107755] 1.2269452595678514   weights  [-2.38464868  2.52107779]  bias  1.2315611002356621\n",
      "pattern1 0 0 1 0.843032\n",
      "pattern2 0 1 1 0.9989\n",
      "pattern3 1 0 -1 -0.818774\n",
      "pattern4 1 1 1 0.878233\n",
      " modified Weights  [-2.38464868  2.52107779] 1.2315611002356621\n",
      " Training with pattern  3  weights  [-2.38464868  2.52107755] 1.2269452595678514   weights  [-2.39062203  2.52107779]  bias  1.2255877473814516\n",
      "pattern1 0 0 1 0.841295\n",
      "pattern2 0 1 1 0.998887\n",
      "pattern3 1 0 -1 -0.822674\n",
      "pattern4 1 1 1 0.875472\n",
      " modified Weights  [-2.39062203  2.52107779] 1.2255877473814516\n",
      " Training with pattern  4  weights  [-2.38464868  2.52107755] 1.2269452595678514   weights  [-2.38771371  2.52398612]  bias  1.2284960732327206\n",
      "pattern1 0 0 1 0.842143\n",
      "pattern2 0 1 1 0.9989\n",
      "pattern3 1 0 -1 -0.820785\n",
      "pattern4 1 1 1 0.877494\n",
      " modified Weights  [-2.38771371  2.52398612] 1.2284960732327206\n",
      "+++++++++++Epoch  194  cost=  0.07204590623594408\n",
      " Training with pattern  1  weights  [-2.38771371  2.52398612] 1.2284960732327206   weights  [-2.38771371  2.52398612]  bias  1.233086503927388\n",
      "pattern1 0 0 1 0.843472\n",
      "pattern2 0 1 1 0.99891\n",
      "pattern3 1 0 -1 -0.819281\n",
      "pattern4 1 1 1 0.878546\n",
      " modified Weights  [-2.38771371  2.52398612] 1.233086503927388\n",
      " Training with pattern  2  weights  [-2.38771371  2.52398612] 1.2284960732327206   weights  [-2.38771371  2.52398635]  bias  1.2330867414341984\n",
      "pattern1 0 0 1 0.843472\n",
      "pattern2 0 1 1 0.99891\n",
      "pattern3 1 0 -1 -0.819281\n",
      "pattern4 1 1 1 0.878546\n",
      " modified Weights  [-2.38771371  2.52398635] 1.2330867414341984\n",
      " Training with pattern  3  weights  [-2.38771371  2.52398612] 1.2284960732327206   weights  [-2.39365535  2.52398635]  bias  1.2271450930441106\n",
      "pattern1 0 0 1 0.841749\n",
      "pattern2 0 1 1 0.998897\n",
      "pattern3 1 0 -1 -0.82315\n",
      "pattern4 1 1 1 0.875806\n",
      " modified Weights  [-2.39365535  2.52398635] 1.2271450930441106\n",
      " Training with pattern  4  weights  [-2.38771371  2.52398612] 1.2284960732327206   weights  [-2.3907621   2.52687961]  bias  1.230038346791301\n",
      "pattern1 0 0 1 0.84259\n",
      "pattern2 0 1 1 0.99891\n",
      "pattern3 1 0 -1 -0.821276\n",
      "pattern4 1 1 1 0.877813\n",
      " modified Weights  [-2.3907621   2.52687961] 1.230038346791301\n",
      "+++++++++++Epoch  195  cost=  0.07165099117402216\n",
      " Training with pattern  1  weights  [-2.3907621   2.52687961] 1.230038346791301   weights  [-2.3907621   2.52687961]  bias  1.2346038744726069\n",
      "pattern1 0 0 1 0.84391\n",
      "pattern2 0 1 1 0.99892\n",
      "pattern3 1 0 -1 -0.819784\n",
      "pattern4 1 1 1 0.878856\n",
      " modified Weights  [-2.3907621   2.52687961] 1.2346038744726069\n",
      " Training with pattern  2  weights  [-2.3907621   2.52687961] 1.230038346791301   weights  [-2.3907621   2.52687984]  bias  1.2346041078290801\n",
      "pattern1 0 0 1 0.84391\n",
      "pattern2 0 1 1 0.99892\n",
      "pattern3 1 0 -1 -0.819784\n",
      "pattern4 1 1 1 0.878857\n",
      " modified Weights  [-2.3907621   2.52687984] 1.2346041078290801\n",
      " Training with pattern  3  weights  [-2.3907621   2.52687961] 1.230038346791301   weights  [-2.39667237  2.52687984]  bias  1.2286938385669706\n",
      "pattern1 0 0 1 0.8422\n",
      "pattern2 0 1 1 0.998907\n",
      "pattern3 1 0 -1 -0.823623\n",
      "pattern4 1 1 1 0.876138\n",
      " modified Weights  [-2.39667237  2.52687984] 1.2286938385669706\n",
      " Training with pattern  4  weights  [-2.3907621   2.52687961] 1.230038346791301   weights  [-2.39379404  2.52975817]  bias  1.2315721711544751\n",
      "pattern1 0 0 1 0.843035\n",
      "pattern2 0 1 1 0.998919\n",
      "pattern3 1 0 -1 -0.821763\n",
      "pattern4 1 1 1 0.87813\n",
      " modified Weights  [-2.39379404  2.52975817] 1.2315721711544751\n",
      "+++++++++++Epoch  196  cost=  0.07126022934224764\n",
      " Training with pattern  1  weights  [-2.39379404  2.52975817] 1.2315721711544751   weights  [-2.39379404  2.52975817]  bias  1.2361130569216079\n",
      "pattern1 0 0 1 0.844343\n",
      "pattern2 0 1 1 0.998929\n",
      "pattern3 1 0 -1 -0.820283\n",
      "pattern4 1 1 1 0.879165\n",
      " modified Weights  [-2.39379404  2.52975817] 1.2361130569216079\n",
      " Training with pattern  2  weights  [-2.39379404  2.52975817] 1.2315721711544751   weights  [-2.39379404  2.5297584 ]  bias  1.236113286221422\n",
      "pattern1 0 0 1 0.844343\n",
      "pattern2 0 1 1 0.998929\n",
      "pattern3 1 0 -1 -0.820283\n",
      "pattern4 1 1 1 0.879165\n",
      " modified Weights  [-2.39379404  2.5297584 ] 1.236113286221422\n",
      " Training with pattern  3  weights  [-2.39379404  2.52975817] 1.2315721711544751   weights  [-2.39967325  2.5297584 ]  bias  1.2302340756585188\n",
      "pattern1 0 0 1 0.842647\n",
      "pattern2 0 1 1 0.998916\n",
      "pattern3 1 0 -1 -0.824092\n",
      "pattern4 1 1 1 0.876467\n",
      " modified Weights  [-2.39967325  2.5297584 ] 1.2302340756585188\n",
      " Training with pattern  4  weights  [-2.39379404  2.52975817] 1.2315721711544751   weights  [-2.39680969  2.53262196]  bias  1.2330976358107635\n",
      "pattern1 0 0 1 0.843475\n",
      "pattern2 0 1 1 0.998929\n",
      "pattern3 1 0 -1 -0.822246\n",
      "pattern4 1 1 1 0.878444\n",
      " modified Weights  [-2.39680969  2.53262196] 1.2330976358107635\n",
      "+++++++++++Epoch  197  cost=  0.07087355674229073\n",
      " Training with pattern  1  weights  [-2.39680969  2.53262196] 1.2330976358107635   weights  [-2.39680969  2.53262196]  bias  1.2376141367393376\n",
      "pattern1 0 0 1 0.844774\n",
      "pattern2 0 1 1 0.998938\n",
      "pattern3 1 0 -1 -0.820778\n",
      "pattern4 1 1 1 0.879471\n",
      " modified Weights  [-2.39680969  2.53262196] 1.2376141367393376\n",
      " Training with pattern  2  weights  [-2.39680969  2.53262196] 1.2330976358107635   weights  [-2.39680969  2.53262219]  bias  1.23761436207359\n",
      "pattern1 0 0 1 0.844774\n",
      "pattern2 0 1 1 0.998938\n",
      "pattern3 1 0 -1 -0.820777\n",
      "pattern4 1 1 1 0.879471\n",
      " modified Weights  [-2.39680969  2.53262219] 1.23761436207359\n",
      " Training with pattern  3  weights  [-2.39680969  2.53262196] 1.2330976358107635   weights  [-2.40265815  2.53262219]  bias  1.2317658945912735\n",
      "pattern1 0 0 1 0.843091\n",
      "pattern2 0 1 1 0.998926\n",
      "pattern3 1 0 -1 -0.824558\n",
      "pattern4 1 1 1 0.876794\n",
      " modified Weights  [-2.40265815  2.53262219] 1.2317658945912735\n",
      " Training with pattern  4  weights  [-2.39680969  2.53262196] 1.2330976358107635   weights  [-2.39980922  2.53547112]  bias  1.234614828855548\n",
      "pattern1 0 0 1 0.843913\n",
      "pattern2 0 1 1 0.998938\n",
      "pattern3 1 0 -1 -0.822725\n",
      "pattern4 1 1 1 0.878755\n",
      " modified Weights  [-2.39980922  2.53547112] 1.234614828855548\n",
      "+++++++++++Epoch  198  cost=  0.07049091066897252\n",
      " Training with pattern  1  weights  [-2.39980922  2.53547112] 1.234614828855548   weights  [-2.39980922  2.53547112]  bias  1.2391071980790351\n",
      "pattern1 0 0 1 0.845201\n",
      "pattern2 0 1 1 0.998947\n",
      "pattern3 1 0 -1 -0.821269\n",
      "pattern4 1 1 1 0.879775\n",
      " modified Weights  [-2.39980922  2.53547112] 1.2391071980790351\n",
      " Training with pattern  2  weights  [-2.39980922  2.53547112] 1.234614828855548   weights  [-2.39980922  2.53547134]  bias  1.2391074195363259\n",
      "pattern1 0 0 1 0.845201\n",
      "pattern2 0 1 1 0.998947\n",
      "pattern3 1 0 -1 -0.821268\n",
      "pattern4 1 1 1 0.879775\n",
      " modified Weights  [-2.39980922  2.53547134] 1.2391074195363259\n",
      " Training with pattern  3  weights  [-2.39980922  2.53547112] 1.234614828855548   weights  [-2.40562726  2.53547134]  bias  1.2332893842312826\n",
      "pattern1 0 0 1 0.843531\n",
      "pattern2 0 1 1 0.998935\n",
      "pattern3 1 0 -1 -0.82502\n",
      "pattern4 1 1 1 0.877118\n",
      " modified Weights  [-2.40562726  2.53547134] 1.2332893842312826\n",
      " Training with pattern  4  weights  [-2.39980922  2.53547112] 1.234614828855548   weights  [-2.4027928  2.5383058]  bias  1.2361238370195524\n",
      "pattern1 0 0 1 0.844346\n",
      "pattern2 0 1 1 0.998947\n",
      "pattern3 1 0 -1 -0.823201\n",
      "pattern4 1 1 1 0.879065\n",
      " modified Weights  [-2.4027928  2.5383058] 1.2361238370195524\n",
      "+++++++++++Epoch  199  cost=  0.07011222967803267\n",
      " Training with pattern  1  weights  [-2.4027928  2.5383058] 1.2361238370195524   weights  [-2.4027928  2.5383058]  bias  1.2405923238086758\n",
      "pattern1 0 0 1 0.845624\n",
      "pattern2 0 1 1 0.998956\n",
      "pattern3 1 0 -1 -0.821756\n",
      "pattern4 1 1 1 0.880076\n",
      " modified Weights  [-2.4027928  2.5383058] 1.2405923238086758\n",
      " Training with pattern  2  weights  [-2.4027928  2.5383058] 1.2361238370195524   weights  [-2.4027928   2.53830602]  bias  1.2405925414751888\n",
      "pattern1 0 0 1 0.845625\n",
      "pattern2 0 1 1 0.998956\n",
      "pattern3 1 0 -1 -0.821756\n",
      "pattern4 1 1 1 0.880076\n",
      " modified Weights  [-2.4027928   2.53830602] 1.2405925414751888\n",
      " Training with pattern  3  weights  [-2.4027928  2.5383058] 1.2361238370195524   weights  [-2.40858071  2.53830602]  bias  1.2348046320668773\n",
      "pattern1 0 0 1 0.843967\n",
      "pattern2 0 1 1 0.998944\n",
      "pattern3 1 0 -1 -0.825479\n",
      "pattern4 1 1 1 0.87744\n",
      " modified Weights  [-2.40858071  2.53830602] 1.2348046320668773\n",
      " Training with pattern  4  weights  [-2.4027928  2.5383058] 1.2361238370195524   weights  [-2.4057606   2.54112613]  bias  1.2376247456966045\n",
      "pattern1 0 0 1 0.844777\n",
      "pattern2 0 1 1 0.998956\n",
      "pattern3 1 0 -1 -0.823674\n",
      "pattern4 1 1 1 0.879372\n",
      " modified Weights  [-2.4057606   2.54112613] 1.2376247456966045\n",
      "+++++++++++Epoch  200  cost=  0.06973745355485068\n",
      " Training with pattern  1  weights  [-2.4057606   2.54112613] 1.2376247456966045   weights  [-2.4057606   2.54112613]  bias  1.2420695955367616\n",
      "pattern1 0 0 1 0.846045\n",
      "pattern2 0 1 1 0.998965\n",
      "pattern3 1 0 -1 -0.822239\n",
      "pattern4 1 1 1 0.880376\n",
      " modified Weights  [-2.4057606   2.54112613] 1.2420695955367616\n",
      " Training with pattern  2  weights  [-2.4057606   2.54112613] 1.2376247456966045   weights  [-2.4057606   2.54112634]  bias  1.2420698094963416\n",
      "pattern1 0 0 1 0.846045\n",
      "pattern2 0 1 1 0.998965\n",
      "pattern3 1 0 -1 -0.822239\n",
      "pattern4 1 1 1 0.880376\n",
      " modified Weights  [-2.4057606   2.54112634] 1.2420698094963416\n",
      " Training with pattern  3  weights  [-2.4057606   2.54112613] 1.2376247456966045   weights  [-2.41151868  2.54112634]  bias  1.2363117242366988\n",
      "pattern1 0 0 1 0.8444\n",
      "pattern2 0 1 1 0.998953\n",
      "pattern3 1 0 -1 -0.825934\n",
      "pattern4 1 1 1 0.877759\n",
      " modified Weights  [-2.41151868  2.54112634] 1.2363117242366988\n",
      " Training with pattern  4  weights  [-2.4057606   2.54112613] 1.2376247456966045   weights  [-2.40871277  2.54393226]  bias  1.2391176389707026\n",
      "pattern1 0 0 1 0.845204\n",
      "pattern2 0 1 1 0.998965\n",
      "pattern3 1 0 -1 -0.824142\n",
      "pattern4 1 1 1 0.879677\n",
      " modified Weights  [-2.40871277  2.54393226] 1.2391176389707026\n",
      "+++++++++++Epoch  201  cost=  0.06936652328408807\n",
      " *********Epoch  200 Error  0.06936652328408807\n",
      " Training with pattern  1  weights  [-2.40871277  2.54393226] 1.2391176389707026   weights  [-2.40871277  2.54393226]  bias  1.2435390936374704\n",
      "pattern1 0 0 1 0.846462\n",
      "pattern2 0 1 1 0.998974\n",
      "pattern3 1 0 -1 -0.822719\n",
      "pattern4 1 1 1 0.880673\n",
      " modified Weights  [-2.40871277  2.54393226] 1.2435390936374704\n",
      " Training with pattern  2  weights  [-2.40871277  2.54393226] 1.2391176389707026   weights  [-2.40871277  2.54393247]  bias  1.243539303971698\n",
      "pattern1 0 0 1 0.846462\n",
      "pattern2 0 1 1 0.998974\n",
      "pattern3 1 0 -1 -0.822719\n",
      "pattern4 1 1 1 0.880673\n",
      " modified Weights  [-2.40871277  2.54393247] 1.243539303971698\n",
      " Training with pattern  3  weights  [-2.40871277  2.54393226] 1.2391176389707026   weights  [-2.41444133  2.54393247]  bias  1.237810745557024\n",
      "pattern1 0 0 1 0.84483\n",
      "pattern2 0 1 1 0.998962\n",
      "pattern3 1 0 -1 -0.826386\n",
      "pattern4 1 1 1 0.878076\n",
      " modified Weights  [-2.41444133  2.54393247] 1.237810745557024\n",
      " Training with pattern  4  weights  [-2.40871277  2.54393226] 1.2391176389707026   weights  [-2.41164947  2.54672432]  bias  1.240602599642404\n",
      "pattern1 0 0 1 0.845627\n",
      "pattern2 0 1 1 0.998974\n",
      "pattern3 1 0 -1 -0.824607\n",
      "pattern4 1 1 1 0.87998\n",
      " modified Weights  [-2.41164947  2.54672432] 1.240602599642404\n",
      "+++++++++++Epoch  202  cost=  0.06899938102021978\n",
      " Training with pattern  1  weights  [-2.41164947  2.54672432] 1.240602599642404   weights  [-2.41164947  2.54672432]  bias  1.2450008972751858\n",
      "pattern1 0 0 1 0.846876\n",
      "pattern2 0 1 1 0.998983\n",
      "pattern3 1 0 -1 -0.823195\n",
      "pattern4 1 1 1 0.880968\n",
      " modified Weights  [-2.41164947  2.54672432] 1.2450008972751858\n",
      " Training with pattern  2  weights  [-2.41164947  2.54672432] 1.240602599642404   weights  [-2.41164947  2.54672453]  bias  1.2450011040634492\n",
      "pattern1 0 0 1 0.846876\n",
      "pattern2 0 1 1 0.998983\n",
      "pattern3 1 0 -1 -0.823195\n",
      "pattern4 1 1 1 0.880968\n",
      " modified Weights  [-2.41164947  2.54672453] 1.2450011040634492\n",
      " Training with pattern  3  weights  [-2.41164947  2.54672432] 1.240602599642404   weights  [-2.4173488   2.54672453]  bias  1.2393017795484065\n",
      "pattern1 0 0 1 0.845256\n",
      "pattern2 0 1 1 0.998971\n",
      "pattern3 1 0 -1 -0.826835\n",
      "pattern4 1 1 1 0.87839\n",
      " modified Weights  [-2.4173488   2.54672453] 1.2393017795484065\n",
      " Training with pattern  4  weights  [-2.41164947  2.54672432] 1.240602599642404   weights  [-2.41457087  2.54950246]  bias  1.2420797092545577\n",
      "pattern1 0 0 1 0.846048\n",
      "pattern2 0 1 1 0.998983\n",
      "pattern3 1 0 -1 -0.825069\n",
      "pattern4 1 1 1 0.88028\n",
      " modified Weights  [-2.41457087  2.54950246] 1.2420797092545577\n",
      "+++++++++++Epoch  203  cost=  0.0686359700589245\n",
      " Training with pattern  1  weights  [-2.41457087  2.54950246] 1.2420797092545577   weights  [-2.41457087  2.54950246]  bias  1.2464550844284235\n",
      "pattern1 0 0 1 0.847287\n",
      "pattern2 0 1 1 0.998991\n",
      "pattern3 1 0 -1 -0.823667\n",
      "pattern4 1 1 1 0.881261\n",
      " modified Weights  [-2.41457087  2.54950246] 1.2464550844284235\n",
      " Training with pattern  2  weights  [-2.41457087  2.54950246] 1.2420797092545577   weights  [-2.41457087  2.54950266]  bias  1.2464552877479884\n",
      "pattern1 0 0 1 0.847287\n",
      "pattern2 0 1 1 0.998991\n",
      "pattern3 1 0 -1 -0.823667\n",
      "pattern4 1 1 1 0.881261\n",
      " modified Weights  [-2.41457087  2.54950266] 1.2464552877479884\n",
      " Training with pattern  3  weights  [-2.41457087  2.54950246] 1.2420797092545577   weights  [-2.42024125  2.54950266]  bias  1.240784908461657\n",
      "pattern1 0 0 1 0.845679\n",
      "pattern2 0 1 1 0.99898\n",
      "pattern3 1 0 -1 -0.82728\n",
      "pattern4 1 1 1 0.878703\n",
      " modified Weights  [-2.42024125  2.54950266] 1.240784908461657\n",
      " Training with pattern  4  weights  [-2.41457087  2.54950246] 1.2420797092545577   weights  [-2.41747711  2.5522668 ]  bias  1.2435490481173999\n",
      "pattern1 0 0 1 0.846465\n",
      "pattern2 0 1 1 0.998991\n",
      "pattern3 1 0 -1 -0.825527\n",
      "pattern4 1 1 1 0.880579\n",
      " modified Weights  [-2.41747711  2.5522668 ] 1.2435490481173999\n",
      "+++++++++++Epoch  204  cost=  0.06827623480930663\n",
      " Training with pattern  1  weights  [-2.41747711  2.5522668 ] 1.2435490481173999   weights  [-2.41747711  2.5522668 ]  bias  1.2479017319131755\n",
      "pattern1 0 0 1 0.847694\n",
      "pattern2 0 1 1 0.999\n",
      "pattern3 1 0 -1 -0.824136\n",
      "pattern4 1 1 1 0.881553\n",
      " modified Weights  [-2.41747711  2.5522668 ] 1.2479017319131755\n",
      " Training with pattern  2  weights  [-2.41747711  2.5522668 ] 1.2435490481173999   weights  [-2.41747711  2.552267  ]  bias  1.2479019318392515\n",
      "pattern1 0 0 1 0.847694\n",
      "pattern2 0 1 1 0.999\n",
      "pattern3 1 0 -1 -0.824136\n",
      "pattern4 1 1 1 0.881553\n",
      " modified Weights  [-2.41747711  2.552267  ] 1.2479019318392515\n",
      " Training with pattern  3  weights  [-2.41747711  2.5522668 ] 1.2435490481173999   weights  [-2.42311883  2.552267  ]  bias  1.2422602133031797\n",
      "pattern1 0 0 1 0.846099\n",
      "pattern2 0 1 1 0.998989\n",
      "pattern3 1 0 -1 -0.827722\n",
      "pattern4 1 1 1 0.879013\n",
      " modified Weights  [-2.42311883  2.552267  ] 1.2422602133031797\n",
      " Training with pattern  4  weights  [-2.41747711  2.5522668 ] 1.2435490481173999   weights  [-2.42036834  2.55501748]  bias  1.245010695333032\n",
      "pattern1 0 0 1 0.846879\n",
      "pattern2 0 1 1 0.999\n",
      "pattern3 1 0 -1 -0.825982\n",
      "pattern4 1 1 1 0.880875\n",
      " modified Weights  [-2.42036834  2.55501748] 1.245010695333032\n",
      "+++++++++++Epoch  205  cost=  0.06792012076691907\n",
      " Training with pattern  1  weights  [-2.42036834  2.55501748] 1.245010695333032   weights  [-2.42036834  2.55501748]  bias  1.2493409154056854\n",
      "pattern1 0 0 1 0.848099\n",
      "pattern2 0 1 1 0.999008\n",
      "pattern3 1 0 -1 -0.824601\n",
      "pattern4 1 1 1 0.881842\n",
      " modified Weights  [-2.42036834  2.55501748] 1.2493409154056854\n",
      " Training with pattern  2  weights  [-2.42036834  2.55501748] 1.245010695333032   weights  [-2.42036834  2.55501768]  bias  1.2493411120114903\n",
      "pattern1 0 0 1 0.848099\n",
      "pattern2 0 1 1 0.999008\n",
      "pattern3 1 0 -1 -0.824601\n",
      "pattern4 1 1 1 0.881842\n",
      " modified Weights  [-2.42036834  2.55501768] 1.2493411120114903\n",
      " Training with pattern  3  weights  [-2.42036834  2.55501748] 1.245010695333032   weights  [-2.42598168  2.55501768]  bias  1.2437277738596875\n",
      "pattern1 0 0 1 0.846515\n",
      "pattern2 0 1 1 0.998997\n",
      "pattern3 1 0 -1 -0.828161\n",
      "pattern4 1 1 1 0.879321\n",
      " modified Weights  [-2.42598168  2.55501768] 1.2437277738596875\n",
      " Training with pattern  4  weights  [-2.42036834  2.55501748] 1.245010695333032   weights  [-2.42324473  2.55775464]  bias  1.2464647288192978\n",
      "pattern1 0 0 1 0.847289\n",
      "pattern2 0 1 1 0.999008\n",
      "pattern3 1 0 -1 -0.826434\n",
      "pattern4 1 1 1 0.881169\n",
      " modified Weights  [-2.42324473  2.55775464] 1.2464647288192978\n",
      "+++++++++++Epoch  206  cost=  0.06756757448756326\n",
      " Training with pattern  1  weights  [-2.42324473  2.55775464] 1.2464647288192978   weights  [-2.42324473  2.55775464]  bias  1.2507727094646726\n",
      "pattern1 0 0 1 0.8485\n",
      "pattern2 0 1 1 0.999017\n",
      "pattern3 1 0 -1 -0.825063\n",
      "pattern4 1 1 1 0.882129\n",
      " modified Weights  [-2.42324473  2.55775464] 1.2507727094646726\n",
      " Training with pattern  2  weights  [-2.42324473  2.55775464] 1.2464647288192978   weights  [-2.42324473  2.55775483]  bias  1.2507729028214951\n",
      "pattern1 0 0 1 0.8485\n",
      "pattern2 0 1 1 0.999017\n",
      "pattern3 1 0 -1 -0.825063\n",
      "pattern4 1 1 1 0.882129\n",
      " modified Weights  [-2.42324473  2.55775483] 1.2507729028214951\n",
      " Training with pattern  3  weights  [-2.42324473  2.55775464] 1.2464647288192978   weights  [-2.42882996  2.55775483]  bias  1.2451876687223078\n",
      "pattern1 0 0 1 0.846929\n",
      "pattern2 0 1 1 0.999005\n",
      "pattern3 1 0 -1 -0.828597\n",
      "pattern4 1 1 1 0.879626\n",
      " modified Weights  [-2.42882996  2.55775483] 1.2451876687223078\n",
      " Training with pattern  4  weights  [-2.42324473  2.55775464] 1.2464647288192978   weights  [-2.42610641  2.56047839]  bias  1.2479112253330773\n",
      "pattern1 0 0 1 0.847697\n",
      "pattern2 0 1 1 0.999016\n",
      "pattern3 1 0 -1 -0.826882\n",
      "pattern4 1 1 1 0.881462\n",
      " modified Weights  [-2.42610641  2.56047839] 1.2479112253330773\n",
      "+++++++++++Epoch  207  cost=  0.06721854356183807\n",
      " Training with pattern  1  weights  [-2.42610641  2.56047839] 1.2479112253330773   weights  [-2.42610641  2.56047839]  bias  1.2521971875530218\n",
      "pattern1 0 0 1 0.848899\n",
      "pattern2 0 1 1 0.999025\n",
      "pattern3 1 0 -1 -0.825521\n",
      "pattern4 1 1 1 0.882414\n",
      " modified Weights  [-2.42610641  2.56047839] 1.2521971875530218\n",
      " Training with pattern  2  weights  [-2.42610641  2.56047839] 1.2479112253330773   weights  [-2.42610641  2.56047858]  bias  1.2521973777302808\n",
      "pattern1 0 0 1 0.848899\n",
      "pattern2 0 1 1 0.999025\n",
      "pattern3 1 0 -1 -0.825521\n",
      "pattern4 1 1 1 0.882414\n",
      " modified Weights  [-2.42610641  2.56047858] 1.2521973777302808\n",
      " Training with pattern  3  weights  [-2.42610641  2.56047839] 1.2479112253330773   weights  [-2.43166381  2.56047858]  bias  1.2466399753101043\n",
      "pattern1 0 0 1 0.847339\n",
      "pattern2 0 1 1 0.999014\n",
      "pattern3 1 0 -1 -0.829029\n",
      "pattern4 1 1 1 0.879929\n",
      " modified Weights  [-2.43166381  2.56047858] 1.2466399753101043\n",
      " Training with pattern  4  weights  [-2.42610641  2.56047839] 1.2479112253330773   weights  [-2.42895352  2.56318886]  bias  1.2493502604930167\n",
      "pattern1 0 0 1 0.848101\n",
      "pattern2 0 1 1 0.999024\n",
      "pattern3 1 0 -1 -0.827326\n",
      "pattern4 1 1 1 0.881752\n",
      " modified Weights  [-2.42895352  2.56318886] 1.2493502604930167\n",
      "+++++++++++Epoch  208  cost=  0.06687297659041512\n",
      " Training with pattern  1  weights  [-2.42895352  2.56318886] 1.2493502604930167   weights  [-2.42895352  2.56318886]  bias  1.253614422058952\n",
      "pattern1 0 0 1 0.849294\n",
      "pattern2 0 1 1 0.999033\n",
      "pattern3 1 0 -1 -0.825976\n",
      "pattern4 1 1 1 0.882697\n",
      " modified Weights  [-2.42895352  2.56318886] 1.253614422058952\n",
      " Training with pattern  2  weights  [-2.42895352  2.56318886] 1.2493502604930167   weights  [-2.42895352  2.56318905]  bias  1.2536146091242548\n",
      "pattern1 0 0 1 0.849294\n",
      "pattern2 0 1 1 0.999033\n",
      "pattern3 1 0 -1 -0.825976\n",
      "pattern4 1 1 1 0.882697\n",
      " modified Weights  [-2.42895352  2.56318905] 1.2536146091242548\n",
      " Training with pattern  3  weights  [-2.42895352  2.56318886] 1.2493502604930167   weights  [-2.43448336  2.56318905]  bias  1.2480847698930249\n",
      "pattern1 0 0 1 0.847746\n",
      "pattern2 0 1 1 0.999022\n",
      "pattern3 1 0 -1 -0.829459\n",
      "pattern4 1 1 1 0.880231\n",
      " modified Weights  [-2.43448336  2.56318905] 1.2480847698930249\n",
      " Training with pattern  4  weights  [-2.42895352  2.56318886] 1.2493502604930167   weights  [-2.43178622  2.56588619]  bias  1.2507819088017071\n",
      "pattern1 0 0 1 0.848503\n",
      "pattern2 0 1 1 0.999032\n",
      "pattern3 1 0 -1 -0.827768\n",
      "pattern4 1 1 1 0.88204\n",
      " modified Weights  [-2.43178622  2.56588619] 1.2507819088017071\n",
      "+++++++++++Epoch  209  cost=  0.06653082316001348\n",
      " Training with pattern  1  weights  [-2.43178622  2.56588619] 1.2507819088017071   weights  [-2.43178622  2.56588619]  bias  1.255024484316682\n",
      "pattern1 0 0 1 0.849687\n",
      "pattern2 0 1 1 0.999041\n",
      "pattern3 1 0 -1 -0.826428\n",
      "pattern4 1 1 1 0.882978\n",
      " modified Weights  [-2.43178622  2.56588619] 1.255024484316682\n",
      " Training with pattern  2  weights  [-2.43178622  2.56588619] 1.2507819088017071   weights  [-2.43178622  2.56588637]  bias  1.2550246683358797\n",
      "pattern1 0 0 1 0.849687\n",
      "pattern2 0 1 1 0.999041\n",
      "pattern3 1 0 -1 -0.826428\n",
      "pattern4 1 1 1 0.882978\n",
      " modified Weights  [-2.43178622  2.56588637] 1.2550246683358797\n",
      " Training with pattern  3  weights  [-2.43178622  2.56588619] 1.2507819088017071   weights  [-2.43728876  2.56588637]  bias  1.2495221276142974\n",
      "pattern1 0 0 1 0.84815\n",
      "pattern2 0 1 1 0.99903\n",
      "pattern3 1 0 -1 -0.829885\n",
      "pattern4 1 1 1 0.88053\n",
      " modified Weights  [-2.43728876  2.56588637] 1.2495221276142974\n",
      " Training with pattern  4  weights  [-2.43178622  2.56588619] 1.2507819088017071   weights  [-2.43460465  2.56857049]  bias  1.2522062436673305\n",
      "pattern1 0 0 1 0.848901\n",
      "pattern2 0 1 1 0.99904\n",
      "pattern3 1 0 -1 -0.828206\n",
      "pattern4 1 1 1 0.882326\n",
      " modified Weights  [-2.43460465  2.56857049] 1.2522062436673305\n",
      "+++++++++++Epoch  210  cost=  0.06619203382005483\n",
      " Training with pattern  1  weights  [-2.43460465  2.56857049] 1.2522062436673305   weights  [-2.43460465  2.56857049]  bias  1.2564274446266013\n",
      "pattern1 0 0 1 0.850076\n",
      "pattern2 0 1 1 0.999048\n",
      "pattern3 1 0 -1 -0.826876\n",
      "pattern4 1 1 1 0.883257\n",
      " modified Weights  [-2.43460465  2.56857049] 1.2564274446266013\n",
      " Training with pattern  2  weights  [-2.43460465  2.56857049] 1.2522062436673305   weights  [-2.43460465  2.56857067]  bias  1.2564276256638425\n",
      "pattern1 0 0 1 0.850076\n",
      "pattern2 0 1 1 0.999048\n",
      "pattern3 1 0 -1 -0.826876\n",
      "pattern4 1 1 1 0.883257\n",
      " modified Weights  [-2.43460465  2.56857067] 1.2564276256638425\n",
      " Training with pattern  3  weights  [-2.43460465  2.56857049] 1.2522062436673305   weights  [-2.44008015  2.56857067]  bias  1.2509521225122842\n",
      "pattern1 0 0 1 0.84855\n",
      "pattern2 0 1 1 0.999038\n",
      "pattern3 1 0 -1 -0.830308\n",
      "pattern4 1 1 1 0.880826\n",
      " modified Weights  [-2.44008015  2.56857067] 1.2509521225122842\n",
      " Training with pattern  4  weights  [-2.43460465  2.56857049] 1.2522062436673305   weights  [-2.43740894  2.57124188]  bias  1.253623337424786\n",
      "pattern1 0 0 1 0.849297\n",
      "pattern2 0 1 1 0.999048\n",
      "pattern3 1 0 -1 -0.828642\n",
      "pattern4 1 1 1 0.88261\n",
      " modified Weights  [-2.43740894  2.57124188] 1.253623337424786\n",
      "+++++++++++Epoch  211  cost=  0.06585656005997322\n",
      " *********Epoch  210 Error  0.06585656005997322\n",
      " Training with pattern  1  weights  [-2.43740894  2.57124188] 1.253623337424786   weights  [-2.43740894  2.57124188]  bias  1.2578233722749683\n",
      "pattern1 0 0 1 0.850463\n",
      "pattern2 0 1 1 0.999056\n",
      "pattern3 1 0 -1 -0.827321\n",
      "pattern4 1 1 1 0.883535\n",
      " modified Weights  [-2.43740894  2.57124188] 1.2578233722749683\n",
      " Training with pattern  2  weights  [-2.43740894  2.57124188] 1.253623337424786   weights  [-2.43740894  2.57124206]  bias  1.257823550392751\n",
      "pattern1 0 0 1 0.850463\n",
      "pattern2 0 1 1 0.999056\n",
      "pattern3 1 0 -1 -0.827321\n",
      "pattern4 1 1 1 0.883535\n",
      " modified Weights  [-2.43740894  2.57124206] 1.257823550392751\n",
      " Training with pattern  3  weights  [-2.43740894  2.57124188] 1.253623337424786   weights  [-2.44285766  2.57124206]  bias  1.2523748275418152\n",
      "pattern1 0 0 1 0.848948\n",
      "pattern2 0 1 1 0.999046\n",
      "pattern3 1 0 -1 -0.830729\n",
      "pattern4 1 1 1 0.881121\n",
      " modified Weights  [-2.44285766  2.57124206] 1.2523748275418152\n",
      " Training with pattern  4  weights  [-2.43740894  2.57124188] 1.253623337424786   weights  [-2.44019922  2.57390049]  bias  1.255033261356314\n",
      "pattern1 0 0 1 0.849689\n",
      "pattern2 0 1 1 0.999056\n",
      "pattern3 1 0 -1 -0.829074\n",
      "pattern4 1 1 1 0.882892\n",
      " modified Weights  [-2.44019922  2.57390049] 1.255033261356314\n",
      "+++++++++++Epoch  212  cost=  0.06552435428716047\n",
      " Training with pattern  1  weights  [-2.44019922  2.57390049] 1.255033261356314   weights  [-2.44019922  2.57390049]  bias  1.2592123355531422\n",
      "pattern1 0 0 1 0.850847\n",
      "pattern2 0 1 1 0.999064\n",
      "pattern3 1 0 -1 -0.827763\n",
      "pattern4 1 1 1 0.88381\n",
      " modified Weights  [-2.44019922  2.57390049] 1.2592123355531422\n",
      " Training with pattern  2  weights  [-2.44019922  2.57390049] 1.255033261356314   weights  [-2.44019922  2.57390067]  bias  1.2592125108123644\n",
      "pattern1 0 0 1 0.850847\n",
      "pattern2 0 1 1 0.999064\n",
      "pattern3 1 0 -1 -0.827762\n",
      "pattern4 1 1 1 0.88381\n",
      " modified Weights  [-2.44019922  2.57390067] 1.2592125108123644\n",
      " Training with pattern  3  weights  [-2.44019922  2.57390049] 1.255033261356314   weights  [-2.44562142  2.57390067]  bias  1.2537903145950138\n",
      "pattern1 0 0 1 0.849343\n",
      "pattern2 0 1 1 0.999053\n",
      "pattern3 1 0 -1 -0.831146\n",
      "pattern4 1 1 1 0.881414\n",
      " modified Weights  [-2.44562142  2.57390067] 1.2537903145950138\n",
      " Training with pattern  4  weights  [-2.44019922  2.57390049] 1.255033261356314   weights  [-2.44297565  2.57654644]  bias  1.2564360857116303\n",
      "pattern1 0 0 1 0.850079\n",
      "pattern2 0 1 1 0.999063\n",
      "pattern3 1 0 -1 -0.829503\n",
      "pattern4 1 1 1 0.883172\n",
      " modified Weights  [-2.44297565  2.57654644] 1.2564360857116303\n",
      "+++++++++++Epoch  213  cost=  0.06519536980552562\n",
      " Training with pattern  1  weights  [-2.44297565  2.57654644] 1.2564360857116303   weights  [-2.44297565  2.57654644]  bias  1.2605944017763653\n",
      "pattern1 0 0 1 0.851228\n",
      "pattern2 0 1 1 0.999071\n",
      "pattern3 1 0 -1 -0.828201\n",
      "pattern4 1 1 1 0.884084\n",
      " modified Weights  [-2.44297565  2.57654644] 1.2605944017763653\n",
      " Training with pattern  2  weights  [-2.44297565  2.57654644] 1.2564360857116303   weights  [-2.44297565  2.57654661]  bias  1.2605945742363722\n",
      "pattern1 0 0 1 0.851228\n",
      "pattern2 0 1 1 0.999071\n",
      "pattern3 1 0 -1 -0.828201\n",
      "pattern4 1 1 1 0.884084\n",
      " modified Weights  [-2.44297565  2.57654661] 1.2605945742363722\n",
      " Training with pattern  3  weights  [-2.44297565  2.57654644] 1.2564360857116303   weights  [-2.44837157  2.57654661]  bias  1.2551986545216247\n",
      "pattern1 0 0 1 0.849735\n",
      "pattern2 0 1 1 0.999061\n",
      "pattern3 1 0 -1 -0.83156\n",
      "pattern4 1 1 1 0.881704\n",
      " modified Weights  [-2.44837157  2.57654661] 1.2551986545216247\n",
      " Training with pattern  4  weights  [-2.44297565  2.57654644] 1.2564360857116303   weights  [-2.44573834  2.57917984]  bias  1.2578318797275834\n",
      "pattern1 0 0 1 0.850465\n",
      "pattern2 0 1 1 0.999071\n",
      "pattern3 1 0 -1 -0.829928\n",
      "pattern4 1 1 1 0.883451\n",
      " modified Weights  [-2.44573834  2.57917984] 1.2578318797275834\n",
      "+++++++++++Epoch  214  cost=  0.06486956079464905\n",
      " Training with pattern  1  weights  [-2.44573834  2.57917984] 1.2578318797275834   weights  [-2.44573834  2.57917984]  bias  1.2619696373021065\n",
      "pattern1 0 0 1 0.851606\n",
      "pattern2 0 1 1 0.999079\n",
      "pattern3 1 0 -1 -0.828636\n",
      "pattern4 1 1 1 0.884356\n",
      " modified Weights  [-2.44573834  2.57917984] 1.2619696373021065\n",
      " Training with pattern  2  weights  [-2.44573834  2.57917984] 1.2578318797275834   weights  [-2.44573834  2.57918001]  bias  1.2619698070207384\n",
      "pattern1 0 0 1 0.851606\n",
      "pattern2 0 1 1 0.999079\n",
      "pattern3 1 0 -1 -0.828636\n",
      "pattern4 1 1 1 0.884356\n",
      " modified Weights  [-2.44573834  2.57918001] 1.2619698070207384\n",
      " Training with pattern  3  weights  [-2.44573834  2.57917984] 1.2578318797275834   weights  [-2.45110823  2.57918001]  bias  1.2565999171488662\n",
      "pattern1 0 0 1 0.850124\n",
      "pattern2 0 1 1 0.999069\n",
      "pattern3 1 0 -1 -0.831972\n",
      "pattern4 1 1 1 0.881993\n",
      " modified Weights  [-2.45110823  2.57918001] 1.2565999171488662\n",
      " Training with pattern  4  weights  [-2.44573834  2.57917984] 1.2578318797275834   weights  [-2.44848744  2.5818008 ]  bias  1.2592207116473508\n",
      "pattern1 0 0 1 0.850849\n",
      "pattern2 0 1 1 0.999078\n",
      "pattern3 1 0 -1 -0.830351\n",
      "pattern4 1 1 1 0.883727\n",
      " modified Weights  [-2.44848744  2.5818008 ] 1.2592207116473508\n",
      "+++++++++++Epoch  215  cost=  0.0645468822895116\n",
      " Training with pattern  1  weights  [-2.44848744  2.5818008 ] 1.2592207116473508   weights  [-2.44848744  2.5818008 ]  bias  1.26333810754798\n",
      "pattern1 0 0 1 0.851982\n",
      "pattern2 0 1 1 0.999086\n",
      "pattern3 1 0 -1 -0.829068\n",
      "pattern4 1 1 1 0.884626\n",
      " modified Weights  [-2.44848744  2.5818008 ] 1.26333810754798\n",
      " Training with pattern  2  weights  [-2.44848744  2.5818008 ] 1.2592207116473508   weights  [-2.44848744  2.58180097]  bias  1.2633382745816157\n",
      "pattern1 0 0 1 0.851982\n",
      "pattern2 0 1 1 0.999086\n",
      "pattern3 1 0 -1 -0.829068\n",
      "pattern4 1 1 1 0.884626\n",
      " modified Weights  [-2.44848744  2.58180097] 1.2633382745816157\n",
      " Training with pattern  3  weights  [-2.44848744  2.5818008 ] 1.2592207116473508   weights  [-2.45383154  2.58180097]  bias  1.2579941713008125\n",
      "pattern1 0 0 1 0.85051\n",
      "pattern2 0 1 1 0.999076\n",
      "pattern3 1 0 -1 -0.832381\n",
      "pattern4 1 1 1 0.88228\n",
      " modified Weights  [-2.45383154  2.58180097] 1.2579941713008125\n",
      " Training with pattern  4  weights  [-2.44848744  2.5818008 ] 1.2592207116473508   weights  [-2.45122307  2.58440945]  bias  1.2606026487391857\n",
      "pattern1 0 0 1 0.85123\n",
      "pattern2 0 1 1 0.999086\n",
      "pattern3 1 0 -1 -0.830771\n",
      "pattern4 1 1 1 0.884002\n",
      " modified Weights  [-2.45122307  2.58440945] 1.2606026487391857\n",
      "+++++++++++Epoch  216  cost=  0.06422729016078225\n",
      " Training with pattern  1  weights  [-2.45122307  2.58440945] 1.2606026487391857   weights  [-2.45122307  2.58440945]  bias  1.2646998770092484\n",
      "pattern1 0 0 1 0.852355\n",
      "pattern2 0 1 1 0.999093\n",
      "pattern3 1 0 -1 -0.829497\n",
      "pattern4 1 1 1 0.884894\n",
      " modified Weights  [-2.45122307  2.58440945] 1.2646998770092484\n",
      " Training with pattern  2  weights  [-2.45122307  2.58440945] 1.2606026487391857   weights  [-2.45122307  2.58440961]  bias  1.2647000414128506\n",
      "pattern1 0 0 1 0.852355\n",
      "pattern2 0 1 1 0.999093\n",
      "pattern3 1 0 -1 -0.829497\n",
      "pattern4 1 1 1 0.884894\n",
      " modified Weights  [-2.45122307  2.58440961] 1.2647000414128506\n",
      " Training with pattern  3  weights  [-2.45122307  2.58440945] 1.2606026487391857   weights  [-2.45654162  2.58440961]  bias  1.259381484817325\n",
      "pattern1 0 0 1 0.850894\n",
      "pattern2 0 1 1 0.999083\n",
      "pattern3 1 0 -1 -0.832786\n",
      "pattern4 1 1 1 0.882564\n",
      " modified Weights  [-2.45654162  2.58440961] 1.259381484817325\n",
      " Training with pattern  4  weights  [-2.45122307  2.58440945] 1.2606026487391857   weights  [-2.45394535  2.58700588]  bias  1.2619777573147268\n",
      "pattern1 0 0 1 0.851608\n",
      "pattern2 0 1 1 0.999093\n",
      "pattern3 1 0 -1 -0.831188\n",
      "pattern4 1 1 1 0.884274\n",
      " modified Weights  [-2.45394535  2.58700588] 1.2619777573147268\n",
      "+++++++++++Epoch  217  cost=  0.0639107410956431\n",
      " Training with pattern  1  weights  [-2.45394535  2.58700588] 1.2619777573147268   weights  [-2.45394535  2.58700588]  bias  1.266055009275924\n",
      "pattern1 0 0 1 0.852725\n",
      "pattern2 0 1 1 0.9991\n",
      "pattern3 1 0 -1 -0.829923\n",
      "pattern4 1 1 1 0.88516\n",
      " modified Weights  [-2.45394535  2.58700588] 1.266055009275924\n",
      " Training with pattern  2  weights  [-2.45394535  2.58700588] 1.2619777573147268   weights  [-2.45394535  2.58700605]  bias  1.2660551711030796\n",
      "pattern1 0 0 1 0.852725\n",
      "pattern2 0 1 1 0.9991\n",
      "pattern3 1 0 -1 -0.829923\n",
      "pattern4 1 1 1 0.88516\n",
      " modified Weights  [-2.45394535  2.58700605] 1.2660551711030796\n",
      " Training with pattern  3  weights  [-2.45394535  2.58700588] 1.2619777573147268   weights  [-2.4592386   2.58700605]  bias  1.2607619245725399\n",
      "pattern1 0 0 1 0.851274\n",
      "pattern2 0 1 1 0.999091\n",
      "pattern3 1 0 -1 -0.833189\n",
      "pattern4 1 1 1 0.882847\n",
      " modified Weights  [-2.4592386   2.58700605] 1.2607619245725399\n",
      " Training with pattern  4  weights  [-2.45394535  2.58700588] 1.2619777573147268   weights  [-2.45665442  2.58959022]  bias  1.2633461027468822\n",
      "pattern1 0 0 1 0.851984\n",
      "pattern2 0 1 1 0.9991\n",
      "pattern3 1 0 -1 -0.831602\n",
      "pattern4 1 1 1 0.884545\n",
      " modified Weights  [-2.45665442  2.58959022] 1.2633461027468822\n",
      "+++++++++++Epoch  218  cost=  0.06359719257913866\n",
      " Training with pattern  1  weights  [-2.45665442  2.58959022] 1.2633461027468822   weights  [-2.45665442  2.58959022]  bias  1.2674035670494783\n",
      "pattern1 0 0 1 0.853092\n",
      "pattern2 0 1 1 0.999107\n",
      "pattern3 1 0 -1 -0.830346\n",
      "pattern4 1 1 1 0.885425\n",
      " modified Weights  [-2.45665442  2.58959022] 1.2674035670494783\n",
      " Training with pattern  2  weights  [-2.45665442  2.58959022] 1.2633461027468822   weights  [-2.45665442  2.58959038]  bias  1.26740372635244\n",
      "pattern1 0 0 1 0.853092\n",
      "pattern2 0 1 1 0.999107\n",
      "pattern3 1 0 -1 -0.830346\n",
      "pattern4 1 1 1 0.885425\n",
      " modified Weights  [-2.45665442  2.58959038] 1.26740372635244\n",
      " Training with pattern  3  weights  [-2.45665442  2.58959022] 1.2633461027468822   weights  [-2.46192259  2.58959038]  bias  1.2621355564929302\n",
      "pattern1 0 0 1 0.851652\n",
      "pattern2 0 1 1 0.999098\n",
      "pattern3 1 0 -1 -0.83359\n",
      "pattern4 1 1 1 0.883128\n",
      " modified Weights  [-2.46192259  2.58959038] 1.2621355564929302\n",
      " Training with pattern  4  weights  [-2.45665442  2.58959022] 1.2633461027468822   weights  [-2.45935039  2.59216258]  bias  1.2647077494873018\n",
      "pattern1 0 0 1 0.852357\n",
      "pattern2 0 1 1 0.999107\n",
      "pattern3 1 0 -1 -0.832013\n",
      "pattern4 1 1 1 0.884814\n",
      " modified Weights  [-2.45935039  2.59216258] 1.2647077494873018\n",
      "+++++++++++Epoch  219  cost=  0.06328660287603012\n",
      " Training with pattern  1  weights  [-2.45935039  2.59216258] 1.2647077494873018   weights  [-2.45935039  2.59216258]  bias  1.2687456121591691\n",
      "pattern1 0 0 1 0.853457\n",
      "pattern2 0 1 1 0.999114\n",
      "pattern3 1 0 -1 -0.830766\n",
      "pattern4 1 1 1 0.885688\n",
      " modified Weights  [-2.45935039  2.59216258] 1.2687456121591691\n",
      " Training with pattern  2  weights  [-2.45935039  2.59216258] 1.2647077494873018   weights  [-2.45935039  2.59216273]  bias  1.268745768988894\n",
      "pattern1 0 0 1 0.853457\n",
      "pattern2 0 1 1 0.999114\n",
      "pattern3 1 0 -1 -0.830766\n",
      "pattern4 1 1 1 0.885688\n",
      " modified Weights  [-2.45935039  2.59216273] 1.268745768988894\n",
      " Training with pattern  3  weights  [-2.45935039  2.59216258] 1.2647077494873018   weights  [-2.46459372  2.59216273]  bias  1.2635024455749468\n",
      "pattern1 0 0 1 0.852027\n",
      "pattern2 0 1 1 0.999105\n",
      "pattern3 1 0 -1 -0.833987\n",
      "pattern4 1 1 1 0.883406\n",
      " modified Weights  [-2.46459372  2.59216273] 1.2635024455749468\n",
      " Training with pattern  4  weights  [-2.45935039  2.59216258] 1.2647077494873018   weights  [-2.4620334   2.59472305]  bias  1.2660627610834467\n",
      "pattern1 0 0 1 0.852727\n",
      "pattern2 0 1 1 0.999114\n",
      "pattern3 1 0 -1 -0.832421\n",
      "pattern4 1 1 1 0.885082\n",
      " modified Weights  [-2.4620334   2.59472305] 1.2660627610834467\n",
      "+++++++++++Epoch  220  cost=  0.06297893101313948\n",
      " Training with pattern  1  weights  [-2.4620334   2.59472305] 1.2660627610834467   weights  [-2.4620334   2.59472305]  bias  1.2700812055779982\n",
      "pattern1 0 0 1 0.85382\n",
      "pattern2 0 1 1 0.999121\n",
      "pattern3 1 0 -1 -0.831183\n",
      "pattern4 1 1 1 0.885949\n",
      " modified Weights  [-2.4620334   2.59472305] 1.2700812055779982\n",
      " Training with pattern  2  weights  [-2.4620334   2.59472305] 1.2660627610834467   weights  [-2.4620334  2.5947232]  bias  1.2700813599841854\n",
      "pattern1 0 0 1 0.85382\n",
      "pattern2 0 1 1 0.999121\n",
      "pattern3 1 0 -1 -0.831183\n",
      "pattern4 1 1 1 0.885949\n",
      " modified Weights  [-2.4620334  2.5947232] 1.2700813599841854\n",
      " Training with pattern  3  weights  [-2.4620334   2.59472305] 1.2660627610834467   weights  [-2.46725211  2.5947232 ]  bias  1.2648626559022573\n",
      "pattern1 0 0 1 0.852399\n",
      "pattern2 0 1 1 0.999112\n",
      "pattern3 1 0 -1 -0.834382\n",
      "pattern4 1 1 1 0.883683\n",
      " modified Weights  [-2.46725211  2.5947232 ] 1.2648626559022573\n",
      " Training with pattern  4  weights  [-2.4620334   2.59472305] 1.2660627610834467   weights  [-2.46470356  2.59727175]  bias  1.2674112001952675\n",
      "pattern1 0 0 1 0.853094\n",
      "pattern2 0 1 1 0.999121\n",
      "pattern3 1 0 -1 -0.832827\n",
      "pattern4 1 1 1 0.885347\n",
      " modified Weights  [-2.46470356  2.59727175] 1.2674112001952675\n",
      "+++++++++++Epoch  221  cost=  0.0626741367621696\n",
      " *********Epoch  220 Error  0.0626741367621696\n",
      " Training with pattern  1  weights  [-2.46470356  2.59727175] 1.2674112001952675   weights  [-2.46470356  2.59727175]  bias  1.271410407438307\n",
      "pattern1 0 0 1 0.854179\n",
      "pattern2 0 1 1 0.999128\n",
      "pattern3 1 0 -1 -0.831597\n",
      "pattern4 1 1 1 0.886209\n",
      " modified Weights  [-2.46470356  2.59727175] 1.271410407438307\n",
      " Training with pattern  2  weights  [-2.46470356  2.59727175] 1.2674112001952675   weights  [-2.46470356  2.5972719 ]  bias  1.2714105594694354\n",
      "pattern1 0 0 1 0.854179\n",
      "pattern2 0 1 1 0.999128\n",
      "pattern3 1 0 -1 -0.831597\n",
      "pattern4 1 1 1 0.886209\n",
      " modified Weights  [-2.46470356  2.5972719 ] 1.2714105594694354\n",
      " Training with pattern  3  weights  [-2.46470356  2.59727175] 1.2674112001952675   weights  [-2.46989787  2.5972719 ]  bias  1.266216250662589\n",
      "pattern1 0 0 1 0.852769\n",
      "pattern2 0 1 1 0.999119\n",
      "pattern3 1 0 -1 -0.834774\n",
      "pattern4 1 1 1 0.883958\n",
      " modified Weights  [-2.46989787  2.5972719 ] 1.266216250662589\n",
      " Training with pattern  4  weights  [-2.46470356  2.59727175] 1.2674112001952675   weights  [-2.46736099  2.59980878]  bias  1.2687531286115052\n",
      "pattern1 0 0 1 0.853459\n",
      "pattern2 0 1 1 0.999128\n",
      "pattern3 1 0 -1 -0.833229\n",
      "pattern4 1 1 1 0.885611\n",
      " modified Weights  [-2.46736099  2.59980878] 1.2687531286115052\n",
      "+++++++++++Epoch  222  cost=  0.06237218062298246\n",
      " Training with pattern  1  weights  [-2.46736099  2.59980878] 1.2687531286115052   weights  [-2.46736099  2.59980878]  bias  1.2727332770470232\n",
      "pattern1 0 0 1 0.854537\n",
      "pattern2 0 1 1 0.999135\n",
      "pattern3 1 0 -1 -0.832009\n",
      "pattern4 1 1 1 0.886466\n",
      " modified Weights  [-2.46736099  2.59980878] 1.2727332770470232\n",
      " Training with pattern  2  weights  [-2.46736099  2.59980878] 1.2687531286115052   weights  [-2.46736099  2.59980893]  bias  1.2727334267503858\n",
      "pattern1 0 0 1 0.854537\n",
      "pattern2 0 1 1 0.999135\n",
      "pattern3 1 0 -1 -0.832009\n",
      "pattern4 1 1 1 0.886466\n",
      " modified Weights  [-2.46736099  2.59980893] 1.2727334267503858\n",
      " Training with pattern  3  weights  [-2.46736099  2.59980878] 1.2687531286115052   weights  [-2.47253113  2.59980893]  bias  1.2675632921641884\n",
      "pattern1 0 0 1 0.853136\n",
      "pattern2 0 1 1 0.999126\n",
      "pattern3 1 0 -1 -0.835164\n",
      "pattern4 1 1 1 0.884231\n",
      " modified Weights  [-2.47253113  2.59980893] 1.2675632921641884\n",
      " Training with pattern  4  weights  [-2.46736099  2.59980878] 1.2687531286115052   weights  [-2.47000581  2.60233424]  bias  1.2700886072656183\n",
      "pattern1 0 0 1 0.853822\n",
      "pattern2 0 1 1 0.999134\n",
      "pattern3 1 0 -1 -0.833629\n",
      "pattern4 1 1 1 0.885873\n",
      " modified Weights  [-2.47000581  2.60233424] 1.2700886072656183\n",
      "+++++++++++Epoch  223  cost=  0.062073023807325156\n",
      " Training with pattern  1  weights  [-2.47000581  2.60233424] 1.2700886072656183   weights  [-2.47000581  2.60233424]  bias  1.2740498729005632\n",
      "pattern1 0 0 1 0.854892\n",
      "pattern2 0 1 1 0.999141\n",
      "pattern3 1 0 -1 -0.832417\n",
      "pattern4 1 1 1 0.886723\n",
      " modified Weights  [-2.47000581  2.60233424] 1.2740498729005632\n",
      " Training with pattern  2  weights  [-2.47000581  2.60233424] 1.2700886072656183   weights  [-2.47000581  2.60233439]  bias  1.2740500203223013\n",
      "pattern1 0 0 1 0.854892\n",
      "pattern2 0 1 1 0.999141\n",
      "pattern3 1 0 -1 -0.832417\n",
      "pattern4 1 1 1 0.886723\n",
      " modified Weights  [-2.47000581  2.60233439] 1.2740500203223013\n",
      " Training with pattern  3  weights  [-2.47000581  2.60233424] 1.2700886072656183   weights  [-2.47515199  2.60233439]  bias  1.2689038418519063\n",
      "pattern1 0 0 1 0.8535\n",
      "pattern2 0 1 1 0.999132\n",
      "pattern3 1 0 -1 -0.835551\n",
      "pattern4 1 1 1 0.884503\n",
      " modified Weights  [-2.47515199  2.60233439] 1.2689038418519063\n",
      " Training with pattern  4  weights  [-2.47000581  2.60233424] 1.2700886072656183   weights  [-2.47263814  2.60484824]  bias  1.2714176962513524\n",
      "pattern1 0 0 1 0.854181\n",
      "pattern2 0 1 1 0.999141\n",
      "pattern3 1 0 -1 -0.834026\n",
      "pattern4 1 1 1 0.886133\n",
      " modified Weights  [-2.47263814  2.60484824] 1.2714176962513524\n",
      "+++++++++++Epoch  224  cost=  0.06177662822298634\n",
      " Training with pattern  1  weights  [-2.47263814  2.60484824] 1.2714176962513524   weights  [-2.47263814  2.60484824]  bias  1.2753602526994021\n",
      "pattern1 0 0 1 0.855244\n",
      "pattern2 0 1 1 0.999148\n",
      "pattern3 1 0 -1 -0.832822\n",
      "pattern4 1 1 1 0.886977\n",
      " modified Weights  [-2.47263814  2.60484824] 1.2753602526994021\n",
      " Training with pattern  2  weights  [-2.47263814  2.60484824] 1.2714176962513524   weights  [-2.47263814  2.60484839]  bias  1.2753603978845391\n",
      "pattern1 0 0 1 0.855244\n",
      "pattern2 0 1 1 0.999148\n",
      "pattern3 1 0 -1 -0.832822\n",
      "pattern4 1 1 1 0.886977\n",
      " modified Weights  [-2.47263814  2.60484839] 1.2753603978845391\n",
      " Training with pattern  3  weights  [-2.47263814  2.60484824] 1.2714176962513524   weights  [-2.47776057  2.60484839]  bias  1.2702379603229208\n",
      "pattern1 0 0 1 0.853862\n",
      "pattern2 0 1 1 0.999139\n",
      "pattern3 1 0 -1 -0.835935\n",
      "pattern4 1 1 1 0.884772\n",
      " modified Weights  [-2.47776057  2.60484839] 1.2702379603229208\n",
      " Training with pattern  4  weights  [-2.47263814  2.60484824] 1.2714176962513524   weights  [-2.47525808  2.60735088]  bias  1.2727404548379588\n",
      "pattern1 0 0 1 0.854539\n",
      "pattern2 0 1 1 0.999148\n",
      "pattern3 1 0 -1 -0.834421\n",
      "pattern4 1 1 1 0.886392\n",
      " modified Weights  [-2.47525808  2.60735088] 1.2727404548379588\n",
      "+++++++++++Epoch  225  cost=  0.06148295645837198\n",
      " Training with pattern  1  weights  [-2.47525808  2.60735088] 1.2727404548379588   weights  [-2.47525808  2.60735088]  bias  1.2766644733623231\n",
      "pattern1 0 0 1 0.855594\n",
      "pattern2 0 1 1 0.999154\n",
      "pattern3 1 0 -1 -0.833225\n",
      "pattern4 1 1 1 0.88723\n",
      " modified Weights  [-2.47525808  2.60735088] 1.2766644733623231\n",
      " Training with pattern  2  weights  [-2.47525808  2.60735088] 1.2727404548379588   weights  [-2.47525808  2.60735103]  bias  1.2766646163547957\n",
      "pattern1 0 0 1 0.855594\n",
      "pattern2 0 1 1 0.999154\n",
      "pattern3 1 0 -1 -0.833225\n",
      "pattern4 1 1 1 0.88723\n",
      " modified Weights  [-2.47525808  2.60735103] 1.2766646163547957\n",
      " Training with pattern  3  weights  [-2.47525808  2.60735088] 1.2727404548379588   weights  [-2.48035699  2.60735103]  bias  1.2715657073421067\n",
      "pattern1 0 0 1 0.854221\n",
      "pattern2 0 1 1 0.999146\n",
      "pattern3 1 0 -1 -0.836317\n",
      "pattern4 1 1 1 0.88504\n",
      " modified Weights  [-2.48035699  2.60735103] 1.2715657073421067\n",
      " Training with pattern  4  weights  [-2.47525808  2.60735088] 1.2727404548379588   weights  [-2.47786576  2.60984226]  bias  1.2740569414850733\n",
      "pattern1 0 0 1 0.854893\n",
      "pattern2 0 1 1 0.999154\n",
      "pattern3 1 0 -1 -0.834813\n",
      "pattern4 1 1 1 0.886649\n",
      " modified Weights  [-2.47786576  2.60984226] 1.2740569414850733\n",
      "+++++++++++Epoch  226  cost=  0.0611919717674876\n",
      " Training with pattern  1  weights  [-2.47786576  2.60984226] 1.2740569414850733   weights  [-2.47786576  2.60984226]  bias  1.2779625910403467\n",
      "pattern1 0 0 1 0.855941\n",
      "pattern2 0 1 1 0.999161\n",
      "pattern3 1 0 -1 -0.833625\n",
      "pattern4 1 1 1 0.887481\n",
      " modified Weights  [-2.47786576  2.60984226] 1.2779625910403467\n",
      " Training with pattern  2  weights  [-2.47786576  2.60984226] 1.2740569414850733   weights  [-2.47786576  2.6098424 ]  bias  1.277962731883036\n",
      "pattern1 0 0 1 0.855941\n",
      "pattern2 0 1 1 0.999161\n",
      "pattern3 1 0 -1 -0.833625\n",
      "pattern4 1 1 1 0.887481\n",
      " modified Weights  [-2.47786576  2.6098424 ] 1.277962731883036\n",
      " Training with pattern  3  weights  [-2.47786576  2.60984226] 1.2740569414850733   weights  [-2.48294135  2.6098424 ]  bias  1.272887141857059\n",
      "pattern1 0 0 1 0.854578\n",
      "pattern2 0 1 1 0.999152\n",
      "pattern3 1 0 -1 -0.836696\n",
      "pattern4 1 1 1 0.885306\n",
      " modified Weights  [-2.48294135  2.6098424 ] 1.272887141857059\n",
      " Training with pattern  4  weights  [-2.47786576  2.60984226] 1.2740569414850733   weights  [-2.48046127  2.61232247]  bias  1.2753672138572605\n",
      "pattern1 0 0 1 0.855246\n",
      "pattern2 0 1 1 0.99916\n",
      "pattern3 1 0 -1 -0.835202\n",
      "pattern4 1 1 1 0.886904\n",
      " modified Weights  [-2.48046127  2.61232247] 1.2753672138572605\n",
      "+++++++++++Epoch  227  cost=  0.060903638055313576\n",
      " Training with pattern  1  weights  [-2.48046127  2.61232247] 1.2753672138572605   weights  [-2.48046127  2.61232247]  bias  1.279254661130357\n",
      "pattern1 0 0 1 0.856286\n",
      "pattern2 0 1 1 0.999167\n",
      "pattern3 1 0 -1 -0.834022\n",
      "pattern4 1 1 1 0.887731\n",
      " modified Weights  [-2.48046127  2.61232247] 1.279254661130357\n",
      " Training with pattern  2  weights  [-2.48046127  2.61232247] 1.2753672138572605   weights  [-2.48046127  2.61232261]  bias  1.2792547998651185\n",
      "pattern1 0 0 1 0.856286\n",
      "pattern2 0 1 1 0.999167\n",
      "pattern3 1 0 -1 -0.834022\n",
      "pattern4 1 1 1 0.887731\n",
      " modified Weights  [-2.48046127  2.61232261] 1.2792547998651185\n",
      " Training with pattern  3  weights  [-2.48046127  2.61232247] 1.2753672138572605   weights  [-2.48551375  2.61232261]  bias  1.2742023220127834\n",
      "pattern1 0 0 1 0.854933\n",
      "pattern2 0 1 1 0.999158\n",
      "pattern3 1 0 -1 -0.837072\n",
      "pattern4 1 1 1 0.88557\n",
      " modified Weights  [-2.48551375  2.61232261] 1.2742023220127834\n",
      " Training with pattern  4  weights  [-2.48046127  2.61232247] 1.2753672138572605   weights  [-2.48304474  2.61479162]  bias  1.2766713288382383\n",
      "pattern1 0 0 1 0.855596\n",
      "pattern2 0 1 1 0.999167\n",
      "pattern3 1 0 -1 -0.835588\n",
      "pattern4 1 1 1 0.887158\n",
      " modified Weights  [-2.48304474  2.61479162] 1.2766713288382383\n",
      "+++++++++++Epoch  228  cost=  0.06061791986356225\n",
      " Training with pattern  1  weights  [-2.48304474  2.61479162] 1.2766713288382383   weights  [-2.48304474  2.61479162]  bias  1.2805407382884273\n",
      "pattern1 0 0 1 0.856629\n",
      "pattern2 0 1 1 0.999173\n",
      "pattern3 1 0 -1 -0.834417\n",
      "pattern4 1 1 1 0.887979\n",
      " modified Weights  [-2.48304474  2.61479162] 1.2805407382884273\n",
      " Training with pattern  2  weights  [-2.48304474  2.61479162] 1.2766713288382383   weights  [-2.48304474  2.61479176]  bias  1.28054087495612\n",
      "pattern1 0 0 1 0.856629\n",
      "pattern2 0 1 1 0.999173\n",
      "pattern3 1 0 -1 -0.834417\n",
      "pattern4 1 1 1 0.887979\n",
      " modified Weights  [-2.48304474  2.61479176] 1.28054087495612\n",
      " Training with pattern  3  weights  [-2.48304474  2.61479162] 1.2766713288382383   weights  [-2.48807431  2.61479176]  bias  1.2755113051660603\n",
      "pattern1 0 0 1 0.855284\n",
      "pattern2 0 1 1 0.999165\n",
      "pattern3 1 0 -1 -0.837447\n",
      "pattern4 1 1 1 0.885832\n",
      " modified Weights  [-2.48807431  2.61479176] 1.2755113051660603\n",
      " Training with pattern  4  weights  [-2.48304474  2.61479162] 1.2766713288382383   weights  [-2.48561628  2.61724979]  bias  1.2779693425447867\n",
      "pattern1 0 0 1 0.855943\n",
      "pattern2 0 1 1 0.999173\n",
      "pattern3 1 0 -1 -0.835972\n",
      "pattern4 1 1 1 0.88741\n",
      " modified Weights  [-2.48561628  2.61724979] 1.2779693425447867\n",
      "+++++++++++Epoch  229  cost=  0.06033478235680445\n",
      " Training with pattern  1  weights  [-2.48561628  2.61724979] 1.2779693425447867   weights  [-2.48561628  2.61724979]  bias  1.2818208764428547\n",
      "pattern1 0 0 1 0.856969\n",
      "pattern2 0 1 1 0.999179\n",
      "pattern3 1 0 -1 -0.834809\n",
      "pattern4 1 1 1 0.888225\n",
      " modified Weights  [-2.48561628  2.61724979] 1.2818208764428547\n",
      " Training with pattern  2  weights  [-2.48561628  2.61724979] 1.2779693425447867   weights  [-2.48561628  2.61724993]  bias  1.2818210110833688\n",
      "pattern1 0 0 1 0.856969\n",
      "pattern2 0 1 1 0.999179\n",
      "pattern3 1 0 -1 -0.834809\n",
      "pattern4 1 1 1 0.888225\n",
      " modified Weights  [-2.48561628  2.61724993] 1.2818210110833688\n",
      " Training with pattern  3  weights  [-2.48561628  2.61724979] 1.2779693425447867   weights  [-2.49062314  2.61724993]  bias  1.2768141478994899\n",
      "pattern1 0 0 1 0.855634\n",
      "pattern2 0 1 1 0.999171\n",
      "pattern3 1 0 -1 -0.837818\n",
      "pattern4 1 1 1 0.886093\n",
      " modified Weights  [-2.49062314  2.61724993] 1.2768141478994899\n",
      " Training with pattern  4  weights  [-2.48561628  2.61724979] 1.2779693425447867   weights  [-2.48817598  2.61969709]  bias  1.2792613103403483\n",
      "pattern1 0 0 1 0.856288\n",
      "pattern2 0 1 1 0.999179\n",
      "pattern3 1 0 -1 -0.836354\n",
      "pattern4 1 1 1 0.88766\n",
      " modified Weights  [-2.48817598  2.61969709] 1.2792613103403483\n",
      "+++++++++++Epoch  230  cost=  0.060054191308957325\n",
      " Training with pattern  1  weights  [-2.48817598  2.61969709] 1.2792613103403483   weights  [-2.48817598  2.61969709]  bias  1.2830951288069115\n",
      "pattern1 0 0 1 0.857307\n",
      "pattern2 0 1 1 0.999185\n",
      "pattern3 1 0 -1 -0.835198\n",
      "pattern4 1 1 1 0.88847\n",
      " modified Weights  [-2.48817598  2.61969709] 1.2830951288069115\n",
      " Training with pattern  2  weights  [-2.48817598  2.61969709] 1.2792613103403483   weights  [-2.48817598  2.61969722]  bias  1.2830952614591953\n",
      "pattern1 0 0 1 0.857307\n",
      "pattern2 0 1 1 0.999185\n",
      "pattern3 1 0 -1 -0.835198\n",
      "pattern4 1 1 1 0.88847\n",
      " modified Weights  [-2.48817598  2.61969722] 1.2830952614591953\n",
      " Training with pattern  3  weights  [-2.48817598  2.61969709] 1.2792613103403483   weights  [-2.49316033  2.61969722]  bias  1.2781109060352296\n",
      "pattern1 0 0 1 0.855981\n",
      "pattern2 0 1 1 0.999177\n",
      "pattern3 1 0 -1 -0.838188\n",
      "pattern4 1 1 1 0.886352\n",
      " modified Weights  [-2.49316033  2.61969722] 1.2781109060352296\n",
      " Training with pattern  4  weights  [-2.48817598  2.61969709] 1.2792613103403483   weights  [-2.49072395  2.6221336 ]  bias  1.280547286848334\n",
      "pattern1 0 0 1 0.856631\n",
      "pattern2 0 1 1 0.999185\n",
      "pattern3 1 0 -1 -0.836732\n",
      "pattern4 1 1 1 0.887909\n",
      " modified Weights  [-2.49072395  2.6221336 ] 1.280547286848334\n",
      "+++++++++++Epoch  231  cost=  0.05977611309011746\n",
      " *********Epoch  230 Error  0.05977611309011746\n",
      " Training with pattern  1  weights  [-2.49072395  2.6221336 ] 1.280547286848334   weights  [-2.49072395  2.6221336 ]  bias  1.284363547891319\n",
      "pattern1 0 0 1 0.857643\n",
      "pattern2 0 1 1 0.999191\n",
      "pattern3 1 0 -1 -0.835584\n",
      "pattern4 1 1 1 0.888714\n",
      " modified Weights  [-2.49072395  2.6221336 ] 1.284363547891319\n",
      " Training with pattern  2  weights  [-2.49072395  2.6221336 ] 1.280547286848334   weights  [-2.49072395  2.62213373]  bias  1.2843636785934058\n",
      "pattern1 0 0 1 0.857643\n",
      "pattern2 0 1 1 0.999191\n",
      "pattern3 1 0 -1 -0.835584\n",
      "pattern4 1 1 1 0.888714\n",
      " modified Weights  [-2.49072395  2.62213373] 1.2843636785934058\n",
      " Training with pattern  3  weights  [-2.49072395  2.6221336 ] 1.280547286848334   weights  [-2.495686    2.62213373]  bias  1.2794016346484296\n",
      "pattern1 0 0 1 0.856325\n",
      "pattern2 0 1 1 0.999183\n",
      "pattern3 1 0 -1 -0.838555\n",
      "pattern4 1 1 1 0.886609\n",
      " modified Weights  [-2.495686    2.62213373] 1.2794016346484296\n",
      " Training with pattern  4  weights  [-2.49072395  2.6221336 ] 1.280547286848334   weights  [-2.4932603   2.62455943]  bias  1.2818273259651363\n",
      "pattern1 0 0 1 0.856971\n",
      "pattern2 0 1 1 0.999191\n",
      "pattern3 1 0 -1 -0.837109\n",
      "pattern4 1 1 1 0.888156\n",
      " modified Weights  [-2.4932603   2.62455943] 1.2818273259651363\n",
      "+++++++++++Epoch  232  cost=  0.05950051465373449\n",
      " Training with pattern  1  weights  [-2.4932603   2.62455943] 1.2818273259651363   weights  [-2.4932603   2.62455943]  bias  1.2856261855164552\n",
      "pattern1 0 0 1 0.857977\n",
      "pattern2 0 1 1 0.999197\n",
      "pattern3 1 0 -1 -0.835968\n",
      "pattern4 1 1 1 0.888956\n",
      " modified Weights  [-2.4932603   2.62455943] 1.2856261855164552\n",
      " Training with pattern  2  weights  [-2.4932603   2.62455943] 1.2818273259651363   weights  [-2.4932603   2.62455955]  bias  1.2856263143054885\n",
      "pattern1 0 0 1 0.857977\n",
      "pattern2 0 1 1 0.999197\n",
      "pattern3 1 0 -1 -0.835968\n",
      "pattern4 1 1 1 0.888956\n",
      " modified Weights  [-2.4932603   2.62455955] 1.2856263143054885\n",
      " Training with pattern  3  weights  [-2.4932603   2.62455943] 1.2818273259651363   weights  [-2.49820023  2.62455955]  bias  1.2806863880803754\n",
      "pattern1 0 0 1 0.856668\n",
      "pattern2 0 1 1 0.999189\n",
      "pattern3 1 0 -1 -0.838919\n",
      "pattern4 1 1 1 0.886865\n",
      " modified Weights  [-2.49820023  2.62455955] 1.2806863880803754\n",
      " Training with pattern  4  weights  [-2.4932603   2.62455943] 1.2818273259651363   weights  [-2.49578514  2.62697465]  bias  1.2831014808728596\n",
      "pattern1 0 0 1 0.857309\n",
      "pattern2 0 1 1 0.999197\n",
      "pattern3 1 0 -1 -0.837483\n",
      "pattern4 1 1 1 0.888402\n",
      " modified Weights  [-2.49578514  2.62697465] 1.2831014808728596\n",
      "+++++++++++Epoch  233  cost=  0.059227363524110704\n",
      " Training with pattern  1  weights  [-2.49578514  2.62697465] 1.2831014808728596   weights  [-2.49578514  2.62697465]  bias  1.2868830928242974\n",
      "pattern1 0 0 1 0.858308\n",
      "pattern2 0 1 1 0.999203\n",
      "pattern3 1 0 -1 -0.83635\n",
      "pattern4 1 1 1 0.889196\n",
      " modified Weights  [-2.49578514  2.62697465] 1.2868830928242974\n",
      " Training with pattern  2  weights  [-2.49578514  2.62697465] 1.2831014808728596   weights  [-2.49578514  2.62697477]  bias  1.2868832197365543\n",
      "pattern1 0 0 1 0.858308\n",
      "pattern2 0 1 1 0.999203\n",
      "pattern3 1 0 -1 -0.83635\n",
      "pattern4 1 1 1 0.889196\n",
      " modified Weights  [-2.49578514  2.62697477] 1.2868832197365543\n",
      " Training with pattern  3  weights  [-2.49578514  2.62697465] 1.2831014808728596   weights  [-2.50070314  2.62697477]  bias  1.2819652199513443\n",
      "pattern1 0 0 1 0.857008\n",
      "pattern2 0 1 1 0.999195\n",
      "pattern3 1 0 -1 -0.839281\n",
      "pattern4 1 1 1 0.887119\n",
      " modified Weights  [-2.50070314  2.62697477] 1.2819652199513443\n",
      " Training with pattern  4  weights  [-2.49578514  2.62697465] 1.2831014808728596   weights  [-2.49829855  2.62937936]  bias  1.2843698040517755\n",
      "pattern1 0 0 1 0.857645\n",
      "pattern2 0 1 1 0.999203\n",
      "pattern3 1 0 -1 -0.837854\n",
      "pattern4 1 1 1 0.888646\n",
      " modified Weights  [-2.49829855  2.62937936] 1.2843698040517755\n",
      "+++++++++++Epoch  234  cost=  0.058956627784220214\n",
      " Training with pattern  1  weights  [-2.49829855  2.62937936] 1.2843698040517755   weights  [-2.49829855  2.62937936]  bias  1.2881343202901097\n",
      "pattern1 0 0 1 0.858637\n",
      "pattern2 0 1 1 0.999209\n",
      "pattern3 1 0 -1 -0.836729\n",
      "pattern4 1 1 1 0.889435\n",
      " modified Weights  [-2.49829855  2.62937936] 1.2881343202901097\n",
      " Training with pattern  2  weights  [-2.49829855  2.62937936] 1.2843698040517755   weights  [-2.49829855  2.62937948]  bias  1.2881344453610264\n",
      "pattern1 0 0 1 0.858637\n",
      "pattern2 0 1 1 0.999209\n",
      "pattern3 1 0 -1 -0.836729\n",
      "pattern4 1 1 1 0.889435\n",
      " modified Weights  [-2.49829855  2.62937948] 1.2881344453610264\n",
      " Training with pattern  3  weights  [-2.49829855  2.62937936] 1.2843698040517755   weights  [-2.50319482  2.62937948]  bias  1.283238183173184\n",
      "pattern1 0 0 1 0.857345\n",
      "pattern2 0 1 1 0.999201\n",
      "pattern3 1 0 -1 -0.839641\n",
      "pattern4 1 1 1 0.887372\n",
      " modified Weights  [-2.50319482  2.62937948] 1.283238183173184\n",
      " Training with pattern  4  weights  [-2.49829855  2.62937936] 1.2843698040517755   weights  [-2.50080065  2.63177365]  bias  1.2856323472925093\n",
      "pattern1 0 0 1 0.857978\n",
      "pattern2 0 1 1 0.999209\n",
      "pattern3 1 0 -1 -0.838223\n",
      "pattern4 1 1 1 0.888889\n",
      " modified Weights  [-2.50080065  2.63177365] 1.2856323472925093\n",
      "+++++++++++Epoch  235  cost=  0.05868827606383653\n",
      " Training with pattern  1  weights  [-2.50080065  2.63177365] 1.2856323472925093   weights  [-2.50080065  2.63177365]  bias  1.2893799177338827\n",
      "pattern1 0 0 1 0.858964\n",
      "pattern2 0 1 1 0.999215\n",
      "pattern3 1 0 -1 -0.837105\n",
      "pattern4 1 1 1 0.889673\n",
      " modified Weights  [-2.50080065  2.63177365] 1.2893799177338827\n",
      " Training with pattern  2  weights  [-2.50080065  2.63177365] 1.2856323472925093   weights  [-2.50080065  2.63177377]  bias  1.2893800409980767\n",
      "pattern1 0 0 1 0.858964\n",
      "pattern2 0 1 1 0.999215\n",
      "pattern3 1 0 -1 -0.837105\n",
      "pattern4 1 1 1 0.889673\n",
      " modified Weights  [-2.50080065  2.63177377] 1.2893800409980767\n",
      " Training with pattern  3  weights  [-2.50080065  2.63177365] 1.2856323472925093   weights  [-2.50567536  2.63177377]  bias  1.2845053299616203\n",
      "pattern1 0 0 1 0.857681\n",
      "pattern2 0 1 1 0.999207\n",
      "pattern3 1 0 -1 -0.839999\n",
      "pattern4 1 1 1 0.887622\n",
      " modified Weights  [-2.50567536  2.63177377] 1.2845053299616203\n",
      " Training with pattern  4  weights  [-2.50080065  2.63177365] 1.2856323472925093   weights  [-2.50329153  2.6341576 ]  bias  1.2868891617079656\n",
      "pattern1 0 0 1 0.85831\n",
      "pattern2 0 1 1 0.999215\n",
      "pattern3 1 0 -1 -0.83859\n",
      "pattern4 1 1 1 0.88913\n",
      " modified Weights  [-2.50329153  2.6341576 ] 1.2868891617079656\n",
      "+++++++++++Epoch  236  cost=  0.05842227752795911\n",
      " Training with pattern  1  weights  [-2.50329153  2.6341576 ] 1.2868891617079656   weights  [-2.50329153  2.6341576 ]  bias  1.2906199343315299\n",
      "pattern1 0 0 1 0.859289\n",
      "pattern2 0 1 1 0.99922\n",
      "pattern3 1 0 -1 -0.837479\n",
      "pattern4 1 1 1 0.889909\n",
      " modified Weights  [-2.50329153  2.6341576 ] 1.2906199343315299\n",
      " Training with pattern  2  weights  [-2.50329153  2.6341576 ] 1.2868891617079656   weights  [-2.50329153  2.63415772]  bias  1.2906200558228218\n",
      "pattern1 0 0 1 0.859289\n",
      "pattern2 0 1 1 0.99922\n",
      "pattern3 1 0 -1 -0.837479\n",
      "pattern4 1 1 1 0.889909\n",
      " modified Weights  [-2.50329153  2.63415772] 1.2906200558228218\n",
      " Training with pattern  3  weights  [-2.50329153  2.6341576 ] 1.2868891617079656   weights  [-2.50814487  2.63415772]  bias  1.2857667118482987\n",
      "pattern1 0 0 1 0.858014\n",
      "pattern2 0 1 1 0.999213\n",
      "pattern3 1 0 -1 -0.840354\n",
      "pattern4 1 1 1 0.887871\n",
      " modified Weights  [-2.50814487  2.63415772] 1.2857667118482987\n",
      " Training with pattern  4  weights  [-2.50329153  2.6341576 ] 1.2868891617079656   weights  [-2.50577129  2.63653131]  bias  1.2881402977449967\n",
      "pattern1 0 0 1 0.858639\n",
      "pattern2 0 1 1 0.99922\n",
      "pattern3 1 0 -1 -0.838954\n",
      "pattern4 1 1 1 0.889369\n",
      " modified Weights  [-2.50577129  2.63653131] 1.2881402977449967\n",
      "+++++++++++Epoch  237  cost=  0.05815860186553226\n",
      " Training with pattern  1  weights  [-2.50577129  2.63653131] 1.2881402977449967   weights  [-2.50577129  2.63653131]  bias  1.2918544186258467\n",
      "pattern1 0 0 1 0.859611\n",
      "pattern2 0 1 1 0.999226\n",
      "pattern3 1 0 -1 -0.837851\n",
      "pattern4 1 1 1 0.890143\n",
      " modified Weights  [-2.50577129  2.63653131] 1.2918544186258467\n",
      " Training with pattern  2  weights  [-2.50577129  2.63653131] 1.2881402977449967   weights  [-2.50577129  2.63653143]  bias  1.291854538377283\n",
      "pattern1 0 0 1 0.859611\n",
      "pattern2 0 1 1 0.999226\n",
      "pattern3 1 0 -1 -0.837851\n",
      "pattern4 1 1 1 0.890143\n",
      " modified Weights  [-2.50577129  2.63653143] 1.291854538377283\n",
      " Training with pattern  3  weights  [-2.50577129  2.63653131] 1.2881402977449967   weights  [-2.51060345  2.63653143]  bias  1.2870223796925726\n",
      "pattern1 0 0 1 0.858345\n",
      "pattern2 0 1 1 0.999219\n",
      "pattern3 1 0 -1 -0.840707\n",
      "pattern4 1 1 1 0.888119\n",
      " modified Weights  [-2.51060345  2.63653143] 1.2870223796925726\n",
      " Training with pattern  4  weights  [-2.50577129  2.63653131] 1.2881402977449967   weights  [-2.50824002  2.63889486]  bias  1.289385805195826\n",
      "pattern1 0 0 1 0.858966\n",
      "pattern2 0 1 1 0.999226\n",
      "pattern3 1 0 -1 -0.839316\n",
      "pattern4 1 1 1 0.889607\n",
      " modified Weights  [-2.50824002  2.63889486] 1.289385805195826\n",
      "+++++++++++Epoch  238  cost=  0.05789721927844563\n",
      " Training with pattern  1  weights  [-2.50824002  2.63889486] 1.289385805195826   weights  [-2.50824002  2.63889486]  bias  1.2930834185372402\n",
      "pattern1 0 0 1 0.859932\n",
      "pattern2 0 1 1 0.999232\n",
      "pattern3 1 0 -1 -0.83822\n",
      "pattern4 1 1 1 0.890376\n",
      " modified Weights  [-2.50824002  2.63889486] 1.2930834185372402\n",
      " Training with pattern  2  weights  [-2.50824002  2.63889486] 1.289385805195826   weights  [-2.50824002  2.63889497]  bias  1.2930835365811133\n",
      "pattern1 0 0 1 0.859932\n",
      "pattern2 0 1 1 0.999232\n",
      "pattern3 1 0 -1 -0.83822\n",
      "pattern4 1 1 1 0.890376\n",
      " modified Weights  [-2.50824002  2.63889497] 1.2930835365811133\n",
      " Training with pattern  3  weights  [-2.50824002  2.63889486] 1.289385805195826   weights  [-2.51305118  2.63889497]  bias  1.2882723836930352\n",
      "pattern1 0 0 1 0.858673\n",
      "pattern2 0 1 1 0.999224\n",
      "pattern3 1 0 -1 -0.841058\n",
      "pattern4 1 1 1 0.888365\n",
      " modified Weights  [-2.51305118  2.63889497] 1.2882723836930352\n",
      " Training with pattern  4  weights  [-2.50824002  2.63889486] 1.289385805195826   weights  [-2.51069783  2.64124832]  bias  1.2906257332092257\n",
      "pattern1 0 0 1 0.85929\n",
      "pattern2 0 1 1 0.999231\n",
      "pattern3 1 0 -1 -0.839675\n",
      "pattern4 1 1 1 0.889844\n",
      " modified Weights  [-2.51069783  2.64124832] 1.2906257332092257\n",
      "+++++++++++Epoch  239  cost=  0.057638100470809514\n",
      " Training with pattern  1  weights  [-2.51069783  2.64124832] 1.2906257332092257   weights  [-2.51069783  2.64124832]  bias  1.2943069813742325\n",
      "pattern1 0 0 1 0.86025\n",
      "pattern2 0 1 1 0.999237\n",
      "pattern3 1 0 -1 -0.838586\n",
      "pattern4 1 1 1 0.890608\n",
      " modified Weights  [-2.51069783  2.64124832] 1.2943069813742325\n",
      " Training with pattern  2  weights  [-2.51069783  2.64124832] 1.2906257332092257   weights  [-2.51069783  2.64124844]  bias  1.2943070977421014\n",
      "pattern1 0 0 1 0.86025\n",
      "pattern2 0 1 1 0.999237\n",
      "pattern3 1 0 -1 -0.838586\n",
      "pattern4 1 1 1 0.890608\n",
      " modified Weights  [-2.51069783  2.64124844] 1.2943070977421014\n",
      " Training with pattern  3  weights  [-2.51069783  2.64124832] 1.2906257332092257   weights  [-2.51548815  2.64124844]  bias  1.2895167733988113\n",
      "pattern1 0 0 1 0.859\n",
      "pattern2 0 1 1 0.99923\n",
      "pattern3 1 0 -1 -0.841407\n",
      "pattern4 1 1 1 0.88861\n",
      " modified Weights  [-2.51548815  2.64124844] 1.2895167733988113\n",
      " Training with pattern  4  weights  [-2.51069783  2.64124832] 1.2906257332092257   weights  [-2.51314479  2.6435918 ]  bias  1.2918601303014612\n",
      "pattern1 0 0 1 0.859613\n",
      "pattern2 0 1 1 0.999237\n",
      "pattern3 1 0 -1 -0.840033\n",
      "pattern4 1 1 1 0.890079\n",
      " modified Weights  [-2.51314479  2.6435918 ] 1.2918601303014612\n",
      "+++++++++++Epoch  240  cost=  0.05738121663849648\n",
      " Training with pattern  1  weights  [-2.51314479  2.6435918 ] 1.2918601303014612   weights  [-2.51314479  2.6435918 ]  bias  1.2955251538437471\n",
      "pattern1 0 0 1 0.860567\n",
      "pattern2 0 1 1 0.999242\n",
      "pattern3 1 0 -1 -0.838951\n",
      "pattern4 1 1 1 0.890838\n",
      " modified Weights  [-2.51314479  2.6435918 ] 1.2955251538437471\n",
      " Training with pattern  2  weights  [-2.51314479  2.6435918 ] 1.2918601303014612   weights  [-2.51314479  2.64359191]  bias  1.2955252685664567\n",
      "pattern1 0 0 1 0.860567\n",
      "pattern2 0 1 1 0.999242\n",
      "pattern3 1 0 -1 -0.838951\n",
      "pattern4 1 1 1 0.890838\n",
      " modified Weights  [-2.51314479  2.64359191] 1.2955252685664567\n",
      " Training with pattern  3  weights  [-2.51314479  2.6435918 ] 1.2918601303014612   weights  [-2.51791446  2.64359191]  bias  1.290755597720609\n",
      "pattern1 0 0 1 0.859324\n",
      "pattern2 0 1 1 0.999235\n",
      "pattern3 1 0 -1 -0.841753\n",
      "pattern4 1 1 1 0.888852\n",
      " modified Weights  [-2.51791446  2.64359191] 1.290755597720609\n",
      " Training with pattern  4  weights  [-2.51314479  2.6435918 ] 1.2918601303014612   weights  [-2.51558102  2.64592536]  bias  1.2930890443670036\n",
      "pattern1 0 0 1 0.859933\n",
      "pattern2 0 1 1 0.999242\n",
      "pattern3 1 0 -1 -0.840388\n",
      "pattern4 1 1 1 0.890313\n",
      " modified Weights  [-2.51558102  2.64592536] 1.2930890443670036\n",
      "+++++++++++Epoch  241  cost=  0.05712653945894156\n",
      " *********Epoch  240 Error  0.05712653945894156\n",
      " Training with pattern  1  weights  [-2.51558102  2.64592536] 1.2930890443670036   weights  [-2.51558102  2.64592536]  bias  1.296737982061178\n",
      "pattern1 0 0 1 0.860881\n",
      "pattern2 0 1 1 0.999248\n",
      "pattern3 1 0 -1 -0.839313\n",
      "pattern4 1 1 1 0.891067\n",
      " modified Weights  [-2.51558102  2.64592536] 1.296737982061178\n",
      " Training with pattern  2  weights  [-2.51558102  2.64592536] 1.2930890443670036   weights  [-2.51558102  2.64592547]  bias  1.2967380951688787\n",
      "pattern1 0 0 1 0.860881\n",
      "pattern2 0 1 1 0.999248\n",
      "pattern3 1 0 -1 -0.839313\n",
      "pattern4 1 1 1 0.891067\n",
      " modified Weights  [-2.51558102  2.64592547] 1.2967380951688787\n",
      " Training with pattern  3  weights  [-2.51558102  2.64592536] 1.2930890443670036   weights  [-2.52033021  2.64592547]  bias  1.2919889049415383\n",
      "pattern1 0 0 1 0.859647\n",
      "pattern2 0 1 1 0.999241\n",
      "pattern3 1 0 -1 -0.842098\n",
      "pattern4 1 1 1 0.889094\n",
      " modified Weights  [-2.52033021  2.64592547] 1.2919889049415383\n",
      " Training with pattern  4  weights  [-2.51558102  2.64592536] 1.2930890443670036   weights  [-2.51800659  2.64824909]  bias  1.294312522689018\n",
      "pattern1 0 0 1 0.860252\n",
      "pattern2 0 1 1 0.999248\n",
      "pattern3 1 0 -1 -0.84074\n",
      "pattern4 1 1 1 0.890545\n",
      " modified Weights  [-2.51800659  2.64824909] 1.294312522689018\n",
      "+++++++++++Epoch  242  cost=  0.05687404108119459\n",
      " Training with pattern  1  weights  [-2.51800659  2.64824909] 1.294312522689018   weights  [-2.51800659  2.64824909]  bias  1.297945511560253\n",
      "pattern1 0 0 1 0.861193\n",
      "pattern2 0 1 1 0.999253\n",
      "pattern3 1 0 -1 -0.839672\n",
      "pattern4 1 1 1 0.891295\n",
      " modified Weights  [-2.51800659  2.64824909] 1.297945511560253\n",
      " Training with pattern  2  weights  [-2.51800659  2.64824909] 1.294312522689018   weights  [-2.51800659  2.6482492 ]  bias  1.2979456230824187\n",
      "pattern1 0 0 1 0.861193\n",
      "pattern2 0 1 1 0.999253\n",
      "pattern3 1 0 -1 -0.839672\n",
      "pattern4 1 1 1 0.891295\n",
      " modified Weights  [-2.51800659  2.6482492 ] 1.2979456230824187\n",
      " Training with pattern  3  weights  [-2.51800659  2.64824909] 1.294312522689018   weights  [-2.52273547  2.6482492 ]  bias  1.2932167427277033\n",
      "pattern1 0 0 1 0.859967\n",
      "pattern2 0 1 1 0.999246\n",
      "pattern3 1 0 -1 -0.84244\n",
      "pattern4 1 1 1 0.889334\n",
      " modified Weights  [-2.52273547  2.6482492 ] 1.2932167427277033\n",
      " Training with pattern  4  weights  [-2.51800659  2.64824909] 1.294312522689018   weights  [-2.5204216   2.65056307]  bias  1.2955306119496337\n",
      "pattern1 0 0 1 0.860568\n",
      "pattern2 0 1 1 0.999253\n",
      "pattern3 1 0 -1 -0.841091\n",
      "pattern4 1 1 1 0.890776\n",
      " modified Weights  [-2.5204216   2.65056307] 1.2955306119496337\n",
      "+++++++++++Epoch  243  cost=  0.056623694116215796\n",
      " Training with pattern  1  weights  [-2.5204216   2.65056307] 1.2955306119496337   weights  [-2.5204216   2.65056307]  bias  1.299147787302693\n",
      "pattern1 0 0 1 0.861504\n",
      "pattern2 0 1 1 0.999258\n",
      "pattern3 1 0 -1 -0.84003\n",
      "pattern4 1 1 1 0.891521\n",
      " modified Weights  [-2.5204216   2.65056307] 1.299147787302693\n",
      " Training with pattern  2  weights  [-2.5204216   2.65056307] 1.2955306119496337   weights  [-2.5204216   2.65056318]  bias  1.2991478972681394\n",
      "pattern1 0 0 1 0.861504\n",
      "pattern2 0 1 1 0.999258\n",
      "pattern3 1 0 -1 -0.840029\n",
      "pattern4 1 1 1 0.891521\n",
      " modified Weights  [-2.5204216   2.65056318] 1.2991478972681394\n",
      " Training with pattern  3  weights  [-2.5204216   2.65056307] 1.2955306119496337   weights  [-2.52513034  2.65056318]  bias  1.2944391581385752\n",
      "pattern1 0 0 1 0.860285\n",
      "pattern2 0 1 1 0.999251\n",
      "pattern3 1 0 -1 -0.84278\n",
      "pattern4 1 1 1 0.889572\n",
      " modified Weights  [-2.52513034  2.65056318] 1.2944391581385752\n",
      " Training with pattern  4  weights  [-2.5204216   2.65056307] 1.2955306119496337   weights  [-2.52282614  2.65286738]  bias  1.2967433582400012\n",
      "pattern1 0 0 1 0.860882\n",
      "pattern2 0 1 1 0.999258\n",
      "pattern3 1 0 -1 -0.841439\n",
      "pattern4 1 1 1 0.891006\n",
      " modified Weights  [-2.52282614  2.65286738] 1.2967433582400012\n",
      "+++++++++++Epoch  244  cost=  0.05637547162740931\n",
      " Training with pattern  1  weights  [-2.52282614  2.65286738] 1.2967433582400012   weights  [-2.52282614  2.65286738]  bias  1.3003448536876734\n",
      "pattern1 0 0 1 0.861812\n",
      "pattern2 0 1 1 0.999264\n",
      "pattern3 1 0 -1 -0.840385\n",
      "pattern4 1 1 1 0.891746\n",
      " modified Weights  [-2.52282614  2.65286738] 1.3003448536876734\n",
      " Training with pattern  2  weights  [-2.52282614  2.65286738] 1.2967433582400012   weights  [-2.52282614  2.65286749]  bias  1.3003449621245748\n",
      "pattern1 0 0 1 0.861812\n",
      "pattern2 0 1 1 0.999264\n",
      "pattern3 1 0 -1 -0.840385\n",
      "pattern4 1 1 1 0.891746\n",
      " modified Weights  [-2.52282614  2.65286749] 1.3003449621245748\n",
      " Training with pattern  3  weights  [-2.52282614  2.65286738] 1.2967433582400012   weights  [-2.5275149   2.65286749]  bias  1.2956561976371481\n",
      "pattern1 0 0 1 0.860601\n",
      "pattern2 0 1 1 0.999257\n",
      "pattern3 1 0 -1 -0.843118\n",
      "pattern4 1 1 1 0.889809\n",
      " modified Weights  [-2.5275149   2.65286749] 1.2956561976371481\n",
      " Training with pattern  4  weights  [-2.52282614  2.65286738] 1.2967433582400012   weights  [-2.52522029  2.6551621 ]  bias  1.29795080707014\n",
      "pattern1 0 0 1 0.861195\n",
      "pattern2 0 1 1 0.999263\n",
      "pattern3 1 0 -1 -0.841785\n",
      "pattern4 1 1 1 0.891234\n",
      " modified Weights  [-2.52522029  2.6551621 ] 1.29795080707014\n",
      "+++++++++++Epoch  245  cost=  0.056129347121387195\n",
      " Training with pattern  1  weights  [-2.52522029  2.6551621 ] 1.29795080707014   weights  [-2.52522029  2.6551621 ]  bias  1.3015367545610894\n",
      "pattern1 0 0 1 0.862118\n",
      "pattern2 0 1 1 0.999269\n",
      "pattern3 1 0 -1 -0.840737\n",
      "pattern4 1 1 1 0.891969\n",
      " modified Weights  [-2.52522029  2.6551621 ] 1.3015367545610894\n",
      " Training with pattern  2  weights  [-2.52522029  2.6551621 ] 1.29795080707014   weights  [-2.52522029  2.6551622 ]  bias  1.301536861496996\n",
      "pattern1 0 0 1 0.862118\n",
      "pattern2 0 1 1 0.999269\n",
      "pattern3 1 0 -1 -0.840737\n",
      "pattern4 1 1 1 0.891969\n",
      " modified Weights  [-2.52522029  2.6551622 ] 1.301536861496996\n",
      " Training with pattern  3  weights  [-2.52522029  2.6551621 ] 1.29795080707014   weights  [-2.52988925  2.6551622 ]  bias  1.2968679070998836\n",
      "pattern1 0 0 1 0.860915\n",
      "pattern2 0 1 1 0.999262\n",
      "pattern3 1 0 -1 -0.843453\n",
      "pattern4 1 1 1 0.890045\n",
      " modified Weights  [-2.52988925  2.6551622 ] 1.2968679070998836\n",
      " Training with pattern  4  weights  [-2.52522029  2.6551621 ] 1.29795080707014   weights  [-2.52760415  2.6574473 ]  bias  1.299153003378583\n",
      "pattern1 0 0 1 0.861505\n",
      "pattern2 0 1 1 0.999269\n",
      "pattern3 1 0 -1 -0.842129\n",
      "pattern4 1 1 1 0.891461\n",
      " modified Weights  [-2.52760415  2.6574473 ] 1.299153003378583\n",
      "+++++++++++Epoch  246  cost=  0.05588529453895736\n",
      " Training with pattern  1  weights  [-2.52760415  2.6574473 ] 1.299153003378583   weights  [-2.52760415  2.6574473 ]  bias  1.302723533224635\n",
      "pattern1 0 0 1 0.862423\n",
      "pattern2 0 1 1 0.999274\n",
      "pattern3 1 0 -1 -0.841088\n",
      "pattern4 1 1 1 0.892191\n",
      " modified Weights  [-2.52760415  2.6574473 ] 1.302723533224635\n",
      " Training with pattern  2  weights  [-2.52760415  2.6574473 ] 1.299153003378583   weights  [-2.52760415  2.65744741]  bias  1.302723638686489\n",
      "pattern1 0 0 1 0.862423\n",
      "pattern2 0 1 1 0.999274\n",
      "pattern3 1 0 -1 -0.841088\n",
      "pattern4 1 1 1 0.892191\n",
      " modified Weights  [-2.52760415  2.65744741] 1.302723638686489\n",
      " Training with pattern  3  weights  [-2.52760415  2.6574473 ] 1.299153003378583   weights  [-2.53225346  2.65744741]  bias  1.2980743318264538\n",
      "pattern1 0 0 1 0.861227\n",
      "pattern2 0 1 1 0.999267\n",
      "pattern3 1 0 -1 -0.843787\n",
      "pattern4 1 1 1 0.890279\n",
      " modified Weights  [-2.53225346  2.65744741] 1.2980743318264538\n",
      " Training with pattern  4  weights  [-2.52760415  2.6574473 ] 1.299153003378583   weights  [-2.5299778   2.65972307]  bias  1.300349991541826\n",
      "pattern1 0 0 1 0.861813\n",
      "pattern2 0 1 1 0.999274\n",
      "pattern3 1 0 -1 -0.842471\n",
      "pattern4 1 1 1 0.891686\n",
      " modified Weights  [-2.5299778   2.65972307] 1.300349991541826\n",
      "+++++++++++Epoch  247  cost=  0.055643288246328984\n",
      " Training with pattern  1  weights  [-2.5299778   2.65972307] 1.300349991541826   weights  [-2.5299778   2.65972307]  bias  1.3039052324446974\n",
      "pattern1 0 0 1 0.862725\n",
      "pattern2 0 1 1 0.999279\n",
      "pattern3 1 0 -1 -0.841436\n",
      "pattern4 1 1 1 0.892412\n",
      " modified Weights  [-2.5299778   2.65972307] 1.3039052324446974\n",
      " Training with pattern  2  weights  [-2.5299778   2.65972307] 1.300349991541826   weights  [-2.5299778   2.65972317]  bias  1.303905336458849\n",
      "pattern1 0 0 1 0.862725\n",
      "pattern2 0 1 1 0.999279\n",
      "pattern3 1 0 -1 -0.841436\n",
      "pattern4 1 1 1 0.892412\n",
      " modified Weights  [-2.5299778   2.65972317] 1.303905336458849\n",
      " Training with pattern  3  weights  [-2.5299778   2.65972307] 1.300349991541826   weights  [-2.53460762  2.65972317]  bias  1.2992755165492802\n",
      "pattern1 0 0 1 0.861537\n",
      "pattern2 0 1 1 0.999272\n",
      "pattern3 1 0 -1 -0.844119\n",
      "pattern4 1 1 1 0.890511\n",
      " modified Weights  [-2.53460762  2.65972317] 1.2992755165492802\n",
      " Training with pattern  4  weights  [-2.5299778   2.65972307] 1.300349991541826   weights  [-2.53234132  2.66198947]  bias  1.3015418153835796\n",
      "pattern1 0 0 1 0.86212\n",
      "pattern2 0 1 1 0.999279\n",
      "pattern3 1 0 -1 -0.842811\n",
      "pattern4 1 1 1 0.89191\n",
      " modified Weights  [-2.53234132  2.66198947] 1.3015418153835796\n",
      "+++++++++++Epoch  248  cost=  0.05540330302653089\n",
      " Training with pattern  1  weights  [-2.53234132  2.66198947] 1.3015418153835796   weights  [-2.53234132  2.66198947]  bias  1.3050818944610707\n",
      "pattern1 0 0 1 0.863026\n",
      "pattern2 0 1 1 0.999284\n",
      "pattern3 1 0 -1 -0.841783\n",
      "pattern4 1 1 1 0.892632\n",
      " modified Weights  [-2.53234132  2.66198947] 1.3050818944610707\n",
      " Training with pattern  2  weights  [-2.53234132  2.66198947] 1.3015418153835796   weights  [-2.53234132  2.66198957]  bias  1.3050819970532936\n",
      "pattern1 0 0 1 0.863026\n",
      "pattern2 0 1 1 0.999284\n",
      "pattern3 1 0 -1 -0.841783\n",
      "pattern4 1 1 1 0.892632\n",
      " modified Weights  [-2.53234132  2.66198957] 1.3050819970532936\n",
      " Training with pattern  3  weights  [-2.53234132  2.66198947] 1.3015418153835796   weights  [-2.53695181  2.66198957]  bias  1.3004715054428813\n",
      "pattern1 0 0 1 0.861844\n",
      "pattern2 0 1 1 0.999277\n",
      "pattern3 1 0 -1 -0.844449\n",
      "pattern4 1 1 1 0.890743\n",
      " modified Weights  [-2.53695181  2.66198957] 1.3004715054428813\n",
      " Training with pattern  4  weights  [-2.53234132  2.66198947] 1.3015418153835796   weights  [-2.5346948   2.66424658]  bias  1.3027285181838362\n",
      "pattern1 0 0 1 0.862424\n",
      "pattern2 0 1 1 0.999284\n",
      "pattern3 1 0 -1 -0.843149\n",
      "pattern4 1 1 1 0.892133\n",
      " modified Weights  [-2.5346948   2.66424658] 1.3027285181838362\n",
      "+++++++++++Epoch  249  cost=  0.05516531407103388\n",
      " Training with pattern  1  weights  [-2.5346948   2.66424658] 1.3027285181838362   weights  [-2.5346948   2.66424658]  bias  1.306253560995494\n",
      "pattern1 0 0 1 0.863324\n",
      "pattern2 0 1 1 0.999289\n",
      "pattern3 1 0 -1 -0.842127\n",
      "pattern4 1 1 1 0.89285\n",
      " modified Weights  [-2.5346948   2.66424658] 1.306253560995494\n",
      " Training with pattern  2  weights  [-2.5346948   2.66424658] 1.3027285181838362   weights  [-2.5346948   2.66424668]  bias  1.3062536621909997\n",
      "pattern1 0 0 1 0.863324\n",
      "pattern2 0 1 1 0.999289\n",
      "pattern3 1 0 -1 -0.842127\n",
      "pattern4 1 1 1 0.89285\n",
      " modified Weights  [-2.5346948   2.66424668] 1.3062536621909997\n",
      " Training with pattern  3  weights  [-2.5346948   2.66424658] 1.3027285181838362   weights  [-2.53928612  2.66424668]  bias  1.301662342133026\n",
      "pattern1 0 0 1 0.86215\n",
      "pattern2 0 1 1 0.999282\n",
      "pattern3 1 0 -1 -0.844777\n",
      "pattern4 1 1 1 0.890972\n",
      " modified Weights  [-2.53928612  2.66424668] 1.301662342133026\n",
      " Training with pattern  4  weights  [-2.5346948   2.66424658] 1.3027285181838362   weights  [-2.53703832  2.66649449]  bias  1.3039101426877509\n",
      "pattern1 0 0 1 0.862726\n",
      "pattern2 0 1 1 0.999288\n",
      "pattern3 1 0 -1 -0.843484\n",
      "pattern4 1 1 1 0.892354\n",
      " modified Weights  [-2.53703832  2.66649449] 1.3039101426877509\n",
      "+++++++++++Epoch  250  cost=  0.054929296971574816\n",
      " Training with pattern  1  weights  [-2.53703832  2.66649449] 1.3039101426877509   weights  [-2.53703832  2.66649449]  bias  1.3074202732600195\n",
      "pattern1 0 0 1 0.863621\n",
      "pattern2 0 1 1 0.999293\n",
      "pattern3 1 0 -1 -0.842469\n",
      "pattern4 1 1 1 0.893067\n",
      " modified Weights  [-2.53703832  2.66649449] 1.3074202732600195\n",
      " Training with pattern  2  weights  [-2.53703832  2.66649449] 1.3039101426877509   weights  [-2.53703832  2.66649459]  bias  1.3074203730834724\n",
      "pattern1 0 0 1 0.863621\n",
      "pattern2 0 1 1 0.999293\n",
      "pattern3 1 0 -1 -0.842468\n",
      "pattern4 1 1 1 0.893067\n",
      " modified Weights  [-2.53703832  2.66649459] 1.3074203730834724\n",
      " Training with pattern  3  weights  [-2.53703832  2.66649449] 1.3039101426877509   weights  [-2.54161062  2.66649459]  bias  1.3028480697057063\n",
      "pattern1 0 0 1 0.862455\n",
      "pattern2 0 1 1 0.999287\n",
      "pattern3 1 0 -1 -0.845102\n",
      "pattern4 1 1 1 0.891201\n",
      " modified Weights  [-2.54161062  2.66649459] 1.3028480697057063\n",
      " Training with pattern  4  weights  [-2.53703832  2.66649449] 1.3039101426877509   weights  [-2.53937196  2.66873325]  bias  1.3050867311143446\n",
      "pattern1 0 0 1 0.863027\n",
      "pattern2 0 1 1 0.999293\n",
      "pattern3 1 0 -1 -0.843818\n",
      "pattern4 1 1 1 0.892575\n",
      " modified Weights  [-2.53937196  2.66873325] 1.3050867311143446\n",
      "+++++++++++Epoch  251  cost=  0.054695227712174055\n",
      " *********Epoch  250 Error  0.054695227712174055\n",
      " Training with pattern  1  weights  [-2.53937196  2.66873325] 1.3050867311143446   weights  [-2.53937196  2.66873325]  bias  1.3085820719652121\n",
      "pattern1 0 0 1 0.863916\n",
      "pattern2 0 1 1 0.999298\n",
      "pattern3 1 0 -1 -0.842808\n",
      "pattern4 1 1 1 0.893283\n",
      " modified Weights  [-2.53937196  2.66873325] 1.3085820719652121\n",
      " Training with pattern  2  weights  [-2.53937196  2.66873325] 1.3050867311143446   weights  [-2.53937196  2.66873335]  bias  1.3085821704407428\n",
      "pattern1 0 0 1 0.863916\n",
      "pattern2 0 1 1 0.999298\n",
      "pattern3 1 0 -1 -0.842808\n",
      "pattern4 1 1 1 0.893283\n",
      " modified Weights  [-2.53937196  2.66873335] 1.3085821704407428\n",
      " Training with pattern  3  weights  [-2.53937196  2.66873325] 1.3050867311143446   weights  [-2.5439254   2.66873335]  bias  1.3040287307159222\n",
      "pattern1 0 0 1 0.862757\n",
      "pattern2 0 1 1 0.999292\n",
      "pattern3 1 0 -1 -0.845426\n",
      "pattern4 1 1 1 0.891428\n",
      " modified Weights  [-2.5439254   2.66873335] 1.3040287307159222\n",
      " Training with pattern  4  weights  [-2.53937196  2.66873325] 1.3050867311143446   weights  [-2.54169581  2.67096294]  bias  1.3062583251650302\n",
      "pattern1 0 0 1 0.863326\n",
      "pattern2 0 1 1 0.999298\n",
      "pattern3 1 0 -1 -0.844149\n",
      "pattern4 1 1 1 0.892793\n",
      " modified Weights  [-2.54169581  2.67096294] 1.3062583251650302\n",
      "+++++++++++Epoch  252  cost=  0.05446308266134322\n",
      " Training with pattern  1  weights  [-2.54169581  2.67096294] 1.3062583251650302   weights  [-2.54169581  2.67096294]  bias  1.309738997328186\n",
      "pattern1 0 0 1 0.864209\n",
      "pattern2 0 1 1 0.999303\n",
      "pattern3 1 0 -1 -0.843146\n",
      "pattern4 1 1 1 0.893497\n",
      " modified Weights  [-2.54169581  2.67096294] 1.309738997328186\n",
      " Training with pattern  2  weights  [-2.54169581  2.67096294] 1.3062583251650302   weights  [-2.54169581  2.67096304]  bias  1.3097390944794058\n",
      "pattern1 0 0 1 0.864209\n",
      "pattern2 0 1 1 0.999303\n",
      "pattern3 1 0 -1 -0.843146\n",
      "pattern4 1 1 1 0.893498\n",
      " modified Weights  [-2.54169581  2.67096304] 1.3097390944794058\n",
      " Training with pattern  3  weights  [-2.54169581  2.67096294] 1.3062583251650302   weights  [-2.54623053  2.67096304]  bias  1.305204367196296\n",
      "pattern1 0 0 1 0.863057\n",
      "pattern2 0 1 1 0.999297\n",
      "pattern3 1 0 -1 -0.845748\n",
      "pattern4 1 1 1 0.891654\n",
      " modified Weights  [-2.54623053  2.67096304] 1.305204367196296\n",
      " Training with pattern  4  weights  [-2.54169581  2.67096294] 1.3062583251650302   weights  [-2.54400994  2.67318364]  bias  1.3074249660319692\n",
      "pattern1 0 0 1 0.863622\n",
      "pattern2 0 1 1 0.999303\n",
      "pattern3 1 0 -1 -0.844479\n",
      "pattern4 1 1 1 0.893011\n",
      " modified Weights  [-2.54400994  2.67318364] 1.3074249660319692\n",
      "+++++++++++Epoch  253  cost=  0.054232838564475846\n",
      " Training with pattern  1  weights  [-2.54400994  2.67318364] 1.3074249660319692   weights  [-2.54400994  2.67318364]  bias  1.3108910890804826\n",
      "pattern1 0 0 1 0.864501\n",
      "pattern2 0 1 1 0.999308\n",
      "pattern3 1 0 -1 -0.843482\n",
      "pattern4 1 1 1 0.893711\n",
      " modified Weights  [-2.54400994  2.67318364] 1.3108910890804826\n",
      " Training with pattern  2  weights  [-2.54400994  2.67318364] 1.3074249660319692   weights  [-2.54400994  2.67318373]  bias  1.310891184930496\n",
      "pattern1 0 0 1 0.864501\n",
      "pattern2 0 1 1 0.999308\n",
      "pattern3 1 0 -1 -0.843482\n",
      "pattern4 1 1 1 0.893711\n",
      " modified Weights  [-2.54400994  2.67318373] 1.310891184930496\n",
      " Training with pattern  3  weights  [-2.54400994  2.67318364] 1.3074249660319692   weights  [-2.5485261   2.67318373]  bias  1.3063750206655094\n",
      "pattern1 0 0 1 0.863355\n",
      "pattern2 0 1 1 0.999301\n",
      "pattern3 1 0 -1 -0.846068\n",
      "pattern4 1 1 1 0.891878\n",
      " modified Weights  [-2.5485261   2.67318373] 1.3063750206655094\n",
      " Training with pattern  4  weights  [-2.54400994  2.67318364] 1.3074249660319692   weights  [-2.54631443  2.67539541]  bias  1.3085866944062603\n",
      "pattern1 0 0 1 0.863917\n",
      "pattern2 0 1 1 0.999307\n",
      "pattern3 1 0 -1 -0.844806\n",
      "pattern4 1 1 1 0.893227\n",
      " modified Weights  [-2.54631443  2.67539541] 1.3085866944062603\n",
      "+++++++++++Epoch  254  cost=  0.05400447253641796\n",
      " Training with pattern  1  weights  [-2.54631443  2.67539541] 1.3085866944062603   weights  [-2.54631443  2.67539541]  bias  1.3120383864757912\n",
      "pattern1 0 0 1 0.86479\n",
      "pattern2 0 1 1 0.999312\n",
      "pattern3 1 0 -1 -0.843815\n",
      "pattern4 1 1 1 0.893923\n",
      " modified Weights  [-2.54631443  2.67539541] 1.3120383864757912\n",
      " Training with pattern  2  weights  [-2.54631443  2.67539541] 1.3085866944062603   weights  [-2.54631443  2.6753955 ]  bias  1.3120384810472092\n",
      "pattern1 0 0 1 0.86479\n",
      "pattern2 0 1 1 0.999312\n",
      "pattern3 1 0 -1 -0.843815\n",
      "pattern4 1 1 1 0.893923\n",
      " modified Weights  [-2.54631443  2.6753955 ] 1.3120384810472092\n",
      " Training with pattern  3  weights  [-2.54631443  2.67539541] 1.3085866944062603   weights  [-2.55081217  2.6753955 ]  bias  1.307540732136574\n",
      "pattern1 0 0 1 0.863652\n",
      "pattern2 0 1 1 0.999306\n",
      "pattern3 1 0 -1 -0.846386\n",
      "pattern4 1 1 1 0.892101\n",
      " modified Weights  [-2.55081217  2.6753955 ] 1.307540732136574\n",
      " Training with pattern  4  weights  [-2.54631443  2.67539541] 1.3085866944062603   weights  [-2.54860936  2.67759832]  bias  1.3097435504859662\n",
      "pattern1 0 0 1 0.864211\n",
      "pattern2 0 1 1 0.999312\n",
      "pattern3 1 0 -1 -0.845132\n",
      "pattern4 1 1 1 0.893442\n",
      " modified Weights  [-2.54860936  2.67759832] 1.3097435504859662\n",
      "+++++++++++Epoch  255  cost=  0.05377796205421193\n",
      " Training with pattern  1  weights  [-2.54860936  2.67759832] 1.3097435504859662   weights  [-2.54860936  2.67759832]  bias  1.3131809282975202\n",
      "pattern1 0 0 1 0.865078\n",
      "pattern2 0 1 1 0.999317\n",
      "pattern3 1 0 -1 -0.844147\n",
      "pattern4 1 1 1 0.894134\n",
      " modified Weights  [-2.54860936  2.67759832] 1.3131809282975202\n",
      " Training with pattern  2  weights  [-2.54860936  2.67759832] 1.3097435504859662   weights  [-2.54860936  2.67759841]  bias  1.3131810216124726\n",
      "pattern1 0 0 1 0.865078\n",
      "pattern2 0 1 1 0.999317\n",
      "pattern3 1 0 -1 -0.844147\n",
      "pattern4 1 1 1 0.894134\n",
      " modified Weights  [-2.54860936  2.67759841] 1.3131810216124726\n",
      " Training with pattern  3  weights  [-2.54860936  2.67759832] 1.3097435504859662   weights  [-2.55308884  2.67759841]  bias  1.3087015421249377\n",
      "pattern1 0 0 1 0.863946\n",
      "pattern2 0 1 1 0.999311\n",
      "pattern3 1 0 -1 -0.846702\n",
      "pattern4 1 1 1 0.892323\n",
      " modified Weights  [-2.55308884  2.67759841] 1.3087015421249377\n",
      " Training with pattern  4  weights  [-2.54860936  2.67759832] 1.3097435504859662   weights  [-2.5508948   2.67979244]  bias  1.3108955739839807\n",
      "pattern1 0 0 1 0.864502\n",
      "pattern2 0 1 1 0.999317\n",
      "pattern3 1 0 -1 -0.845455\n",
      "pattern4 1 1 1 0.893656\n",
      " modified Weights  [-2.5508948   2.67979244] 1.3108955739839807\n",
      "+++++++++++Epoch  256  cost=  0.05355328495001082\n",
      " Training with pattern  1  weights  [-2.5508948   2.67979244] 1.3108955739839807   weights  [-2.5508948   2.67979244]  bias  1.314318752866218\n",
      "pattern1 0 0 1 0.865364\n",
      "pattern2 0 1 1 0.999321\n",
      "pattern3 1 0 -1 -0.844476\n",
      "pattern4 1 1 1 0.894343\n",
      " modified Weights  [-2.5508948   2.67979244] 1.314318752866218\n",
      " Training with pattern  2  weights  [-2.5508948   2.67979244] 1.3108955739839807   weights  [-2.5508948   2.67979254]  bias  1.3143188449463652\n",
      "pattern1 0 0 1 0.865364\n",
      "pattern2 0 1 1 0.999321\n",
      "pattern3 1 0 -1 -0.844476\n",
      "pattern4 1 1 1 0.894343\n",
      " modified Weights  [-2.5508948   2.67979254] 1.3143188449463652\n",
      " Training with pattern  3  weights  [-2.5508948   2.67979244] 1.3108955739839807   weights  [-2.55535616  2.67979254]  bias  1.3098574906564284\n",
      "pattern1 0 0 1 0.864239\n",
      "pattern2 0 1 1 0.999315\n",
      "pattern3 1 0 -1 -0.847017\n",
      "pattern4 1 1 1 0.892543\n",
      " modified Weights  [-2.55535616  2.67979254] 1.3098574906564284\n",
      " Training with pattern  4  weights  [-2.5508948   2.67979244] 1.3108955739839807   weights  [-2.55317084  2.68197785]  bias  1.3120428041357395\n",
      "pattern1 0 0 1 0.864791\n",
      "pattern2 0 1 1 0.999321\n",
      "pattern3 1 0 -1 -0.845777\n",
      "pattern4 1 1 1 0.893869\n",
      " modified Weights  [-2.55317084  2.68197785] 1.3120428041357395\n",
      "+++++++++++Epoch  257  cost=  0.05333041940415639\n",
      " Training with pattern  1  weights  [-2.55317084  2.68197785] 1.3120428041357395   weights  [-2.55317084  2.68197785]  bias  1.3154518980468481\n",
      "pattern1 0 0 1 0.865648\n",
      "pattern2 0 1 1 0.999326\n",
      "pattern3 1 0 -1 -0.844804\n",
      "pattern4 1 1 1 0.894552\n",
      " modified Weights  [-2.55317084  2.68197785] 1.3154518980468481\n",
      " Training with pattern  2  weights  [-2.55317084  2.68197785] 1.3120428041357395   weights  [-2.55317084  2.68197794]  bias  1.3154519889133933\n",
      "pattern1 0 0 1 0.865648\n",
      "pattern2 0 1 1 0.999326\n",
      "pattern3 1 0 -1 -0.844804\n",
      "pattern4 1 1 1 0.894552\n",
      " modified Weights  [-2.55317084  2.68197794] 1.3154519889133933\n",
      " Training with pattern  3  weights  [-2.55317084  2.68197785] 1.3120428041357395   weights  [-2.55761422  2.68197794]  bias  1.3110086172750428\n",
      "pattern1 0 0 1 0.86453\n",
      "pattern2 0 1 1 0.99932\n",
      "pattern3 1 0 -1 -0.847329\n",
      "pattern4 1 1 1 0.892762\n",
      " modified Weights  [-2.55761422  2.68197794] 1.3110086172750428\n",
      " Training with pattern  4  weights  [-2.55317084  2.68197785] 1.3120428041357395   weights  [-2.55543755  2.6841546 ]  bias  1.3131852797067818\n",
      "pattern1 0 0 1 0.865079\n",
      "pattern2 0 1 1 0.999326\n",
      "pattern3 1 0 -1 -0.846097\n",
      "pattern4 1 1 1 0.89408\n",
      " modified Weights  [-2.55543755  2.6841546 ] 1.3131852797067818\n",
      "+++++++++++Epoch  258  cost=  0.05310934393841815\n",
      " Training with pattern  1  weights  [-2.55543755  2.6841546 ] 1.3131852797067818   weights  [-2.55543755  2.6841546 ]  bias  1.316580401255927\n",
      "pattern1 0 0 1 0.865931\n",
      "pattern2 0 1 1 0.99933\n",
      "pattern3 1 0 -1 -0.845129\n",
      "pattern4 1 1 1 0.894759\n",
      " modified Weights  [-2.55543755  2.6841546 ] 1.316580401255927\n",
      " Training with pattern  2  weights  [-2.55543755  2.6841546 ] 1.3131852797067818   weights  [-2.55543755  2.68415469]  bias  1.3165804909296275\n",
      "pattern1 0 0 1 0.865931\n",
      "pattern2 0 1 1 0.99933\n",
      "pattern3 1 0 -1 -0.845129\n",
      "pattern4 1 1 1 0.894759\n",
      " modified Weights  [-2.55543755  2.68415469] 1.3165804909296275\n",
      " Training with pattern  3  weights  [-2.55543755  2.6841546 ] 1.3131852797067818   weights  [-2.55986308  2.68415469]  bias  1.3121549610505823\n",
      "pattern1 0 0 1 0.86482\n",
      "pattern2 0 1 1 0.999324\n",
      "pattern3 1 0 -1 -0.84764\n",
      "pattern4 1 1 1 0.89298\n",
      " modified Weights  [-2.55986308  2.68415469] 1.3121549610505823\n",
      " Training with pattern  4  weights  [-2.55543755  2.6841546 ] 1.3131852797067818   weights  [-2.55769501  2.68632277]  bias  1.3143230390001621\n",
      "pattern1 0 0 1 0.865365\n",
      "pattern2 0 1 1 0.99933\n",
      "pattern3 1 0 -1 -0.846415\n",
      "pattern4 1 1 1 0.89429\n",
      " modified Weights  [-2.55769501  2.68632277] 1.3143230390001621\n",
      "+++++++++++Epoch  259  cost=  0.05289003740938829\n",
      " Training with pattern  1  weights  [-2.55769501  2.68632277] 1.3143230390001621   weights  [-2.55769501  2.68632277]  bias  1.3177042994685182\n",
      "pattern1 0 0 1 0.866212\n",
      "pattern2 0 1 1 0.999335\n",
      "pattern3 1 0 -1 -0.845453\n",
      "pattern4 1 1 1 0.894965\n",
      " modified Weights  [-2.55769501  2.68632277] 1.3177042994685182\n",
      " Training with pattern  2  weights  [-2.55769501  2.68632277] 1.3143230390001621   weights  [-2.55769501  2.68632286]  bias  1.317704387969696\n",
      "pattern1 0 0 1 0.866212\n",
      "pattern2 0 1 1 0.999335\n",
      "pattern3 1 0 -1 -0.845453\n",
      "pattern4 1 1 1 0.894965\n",
      " modified Weights  [-2.55769501  2.68632286] 1.317704387969696\n",
      " Training with pattern  3  weights  [-2.55769501  2.68632277] 1.3143230390001621   weights  [-2.56210283  2.68632286]  bias  1.3132965605861353\n",
      "pattern1 0 0 1 0.865107\n",
      "pattern2 0 1 1 0.999329\n",
      "pattern3 1 0 -1 -0.847949\n",
      "pattern4 1 1 1 0.893197\n",
      " modified Weights  [-2.56210283  2.68632286] 1.3132965605861353\n",
      " Training with pattern  4  weights  [-2.55769501  2.68632277] 1.3143230390001621   weights  [-2.55994327  2.68848242]  bias  1.315456119863716\n",
      "pattern1 0 0 1 0.865649\n",
      "pattern2 0 1 1 0.999335\n",
      "pattern3 1 0 -1 -0.846731\n",
      "pattern4 1 1 1 0.894499\n",
      " modified Weights  [-2.55994327  2.68848242] 1.315456119863716\n",
      "+++++++++++Epoch  260  cost=  0.05267247900202911\n",
      " Training with pattern  1  weights  [-2.55994327  2.68848242] 1.315456119863716   weights  [-2.55994327  2.68848242]  bias  1.3188236292250937\n",
      "pattern1 0 0 1 0.866491\n",
      "pattern2 0 1 1 0.999339\n",
      "pattern3 1 0 -1 -0.845775\n",
      "pattern4 1 1 1 0.89517\n",
      " modified Weights  [-2.55994327  2.68848242] 1.3188236292250937\n",
      " Training with pattern  2  weights  [-2.55994327  2.68848242] 1.315456119863716   weights  [-2.55994327  2.6884825 ]  bias  1.318823716573647\n",
      "pattern1 0 0 1 0.866491\n",
      "pattern2 0 1 1 0.999339\n",
      "pattern3 1 0 -1 -0.845775\n",
      "pattern4 1 1 1 0.89517\n",
      " modified Weights  [-2.55994327  2.6884825 ] 1.318823716573647\n",
      " Training with pattern  3  weights  [-2.55994327  2.68848242] 1.315456119863716   weights  [-2.56433354  2.6884825 ]  bias  1.3144334540254188\n",
      "pattern1 0 0 1 0.865393\n",
      "pattern2 0 1 1 0.999333\n",
      "pattern3 1 0 -1 -0.848256\n",
      "pattern4 1 1 1 0.893412\n",
      " modified Weights  [-2.56433354  2.6884825 ] 1.3144334540254188\n",
      " Training with pattern  4  weights  [-2.55994327  2.68848242] 1.315456119863716   weights  [-2.56218243  2.69063361]  bias  1.3165845596971877\n",
      "pattern1 0 0 1 0.865932\n",
      "pattern2 0 1 1 0.999339\n",
      "pattern3 1 0 -1 -0.847045\n",
      "pattern4 1 1 1 0.894707\n",
      " modified Weights  [-2.56218243  2.69063361] 1.3165845596971877\n",
      "+++++++++++Epoch  261  cost=  0.05245664822336688\n",
      " *********Epoch  260 Error  0.05245664822336688\n",
      " Training with pattern  1  weights  [-2.56218243  2.69063361] 1.3165845596971877   weights  [-2.56218243  2.69063361]  bias  1.3199384266382652\n",
      "pattern1 0 0 1 0.866769\n",
      "pattern2 0 1 1 0.999343\n",
      "pattern3 1 0 -1 -0.846094\n",
      "pattern4 1 1 1 0.895374\n",
      " modified Weights  [-2.56218243  2.69063361] 1.3199384266382652\n",
      " Training with pattern  2  weights  [-2.56218243  2.69063361] 1.3165845596971877   weights  [-2.56218243  2.6906337 ]  bias  1.3199385128536782\n",
      "pattern1 0 0 1 0.866769\n",
      "pattern2 0 1 1 0.999343\n",
      "pattern3 1 0 -1 -0.846094\n",
      "pattern4 1 1 1 0.895374\n",
      " modified Weights  [-2.56218243  2.6906337 ] 1.3199385128536782\n",
      " Training with pattern  3  weights  [-2.56218243  2.69063361] 1.3165845596971877   weights  [-2.56655526  2.6906337 ]  bias  1.315565679059974\n",
      "pattern1 0 0 1 0.865677\n",
      "pattern2 0 1 1 0.999338\n",
      "pattern3 1 0 -1 -0.848561\n",
      "pattern4 1 1 1 0.893626\n",
      " modified Weights  [-2.56655526  2.6906337 ] 1.315565679059974\n",
      " Training with pattern  4  weights  [-2.56218243  2.69063361] 1.3165845596971877   weights  [-2.56441255  2.69277641]  bias  1.3177083954592175\n",
      "pattern1 0 0 1 0.866213\n",
      "pattern2 0 1 1 0.999343\n",
      "pattern3 1 0 -1 -0.847357\n",
      "pattern4 1 1 1 0.894913\n",
      " modified Weights  [-2.56441255  2.69277641] 1.3177083954592175\n",
      "+++++++++++Epoch  262  cost=  0.05224252489633158\n",
      " Training with pattern  1  weights  [-2.56441255  2.69277641] 1.3177083954592175   weights  [-2.56441255  2.69277641]  bias  1.3210487273993834\n",
      "pattern1 0 0 1 0.867044\n",
      "pattern2 0 1 1 0.999348\n",
      "pattern3 1 0 -1 -0.846412\n",
      "pattern4 1 1 1 0.895577\n",
      " modified Weights  [-2.56441255  2.69277641] 1.3210487273993834\n",
      " Training with pattern  2  weights  [-2.56441255  2.69277641] 1.3177083954592175   weights  [-2.56441255  2.6927765 ]  bias  1.321048812500737\n",
      "pattern1 0 0 1 0.867045\n",
      "pattern2 0 1 1 0.999348\n",
      "pattern3 1 0 -1 -0.846412\n",
      "pattern4 1 1 1 0.895577\n",
      " modified Weights  [-2.56441255  2.6927765 ] 1.321048812500737\n",
      " Training with pattern  3  weights  [-2.56441255  2.69277641] 1.3177083954592175   weights  [-2.56876809  2.6927765 ]  bias  1.3166932729362224\n",
      "pattern1 0 0 1 0.865959\n",
      "pattern2 0 1 1 0.999342\n",
      "pattern3 1 0 -1 -0.848864\n",
      "pattern4 1 1 1 0.893839\n",
      " modified Weights  [-2.56876809  2.6927765 ] 1.3166932729362224\n",
      " Training with pattern  4  weights  [-2.56441255  2.69277641] 1.3177083954592175   weights  [-2.5666337   2.69491089]  bias  1.3188276636741942\n",
      "pattern1 0 0 1 0.866492\n",
      "pattern2 0 1 1 0.999347\n",
      "pattern3 1 0 -1 -0.847667\n",
      "pattern4 1 1 1 0.895119\n",
      " modified Weights  [-2.5666337   2.69491089] 1.3188276636741942\n",
      "+++++++++++Epoch  263  cost=  0.05203008915373514\n",
      " Training with pattern  1  weights  [-2.5666337   2.69491089] 1.3188276636741942   weights  [-2.5666337   2.69491089]  bias  1.3221545667850119\n",
      "pattern1 0 0 1 0.867319\n",
      "pattern2 0 1 1 0.999352\n",
      "pattern3 1 0 -1 -0.846728\n",
      "pattern4 1 1 1 0.895778\n",
      " modified Weights  [-2.5666337   2.69491089] 1.3221545667850119\n",
      " Training with pattern  2  weights  [-2.5666337   2.69491089] 1.3188276636741942   weights  [-2.5666337   2.69491097]  bias  1.3221546507909931\n",
      "pattern1 0 0 1 0.867319\n",
      "pattern2 0 1 1 0.999352\n",
      "pattern3 1 0 -1 -0.846728\n",
      "pattern4 1 1 1 0.895778\n",
      " modified Weights  [-2.5666337   2.69491097] 1.3221546507909931\n",
      " Training with pattern  3  weights  [-2.5666337   2.69491089] 1.3188276636741942   weights  [-2.57097208  2.69491097]  bias  1.3178162724623879\n",
      "pattern1 0 0 1 0.86624\n",
      "pattern2 0 1 1 0.999346\n",
      "pattern3 1 0 -1 -0.849166\n",
      "pattern4 1 1 1 0.89405\n",
      " modified Weights  [-2.57097208  2.69491097] 1.3178162724623879\n",
      " Training with pattern  4  weights  [-2.5666337   2.69491089] 1.3188276636741942   weights  [-2.56884595  2.6970371 ]  bias  1.319942400438978\n",
      "pattern1 0 0 1 0.86677\n",
      "pattern2 0 1 1 0.999352\n",
      "pattern3 1 0 -1 -0.847976\n",
      "pattern4 1 1 1 0.895323\n",
      " modified Weights  [-2.56884595  2.6970371 ] 1.319942400438978\n",
      "+++++++++++Epoch  264  cost=  0.051819321432386836\n",
      " Training with pattern  1  weights  [-2.56884595  2.6970371 ] 1.319942400438978   weights  [-2.56884595  2.6970371 ]  bias  1.3232559796632801\n",
      "pattern1 0 0 1 0.867591\n",
      "pattern2 0 1 1 0.999356\n",
      "pattern3 1 0 -1 -0.847042\n",
      "pattern4 1 1 1 0.895979\n",
      " modified Weights  [-2.56884595  2.6970371 ] 1.3232559796632801\n",
      " Training with pattern  2  weights  [-2.56884595  2.6970371 ] 1.319942400438978   weights  [-2.56884595  2.69703718]  bias  1.323256062592192\n",
      "pattern1 0 0 1 0.867591\n",
      "pattern2 0 1 1 0.999356\n",
      "pattern3 1 0 -1 -0.847042\n",
      "pattern4 1 1 1 0.895979\n",
      " modified Weights  [-2.56884595  2.69703718] 1.323256062592192\n",
      " Training with pattern  3  weights  [-2.56884595  2.6970371 ] 1.319942400438978   weights  [-2.5731673   2.69703718]  bias  1.3189347140152827\n",
      "pattern1 0 0 1 0.866519\n",
      "pattern2 0 1 1 0.99935\n",
      "pattern3 1 0 -1 -0.849466\n",
      "pattern4 1 1 1 0.894261\n",
      " modified Weights  [-2.5731673   2.69703718] 1.3189347140152827\n",
      " Training with pattern  4  weights  [-2.56884595  2.6970371 ] 1.319942400438978   weights  [-2.57104937  2.69915511]  bias  1.321052641429491\n",
      "pattern1 0 0 1 0.867045\n",
      "pattern2 0 1 1 0.999356\n",
      "pattern3 1 0 -1 -0.848283\n",
      "pattern4 1 1 1 0.895526\n",
      " modified Weights  [-2.57104937  2.69915511] 1.321052641429491\n",
      "+++++++++++Epoch  265  cost=  0.05161020246734179\n",
      " Training with pattern  1  weights  [-2.57104937  2.69915511] 1.321052641429491   weights  [-2.57104937  2.69915511]  bias  1.3243530005001127\n",
      "pattern1 0 0 1 0.867862\n",
      "pattern2 0 1 1 0.99936\n",
      "pattern3 1 0 -1 -0.847355\n",
      "pattern4 1 1 1 0.896178\n",
      " modified Weights  [-2.57104937  2.69915511] 1.3243530005001127\n",
      " Training with pattern  2  weights  [-2.57104937  2.69915511] 1.321052641429491   weights  [-2.57104937  2.69915519]  bias  1.3243530823698837\n",
      "pattern1 0 0 1 0.867862\n",
      "pattern2 0 1 1 0.99936\n",
      "pattern3 1 0 -1 -0.847355\n",
      "pattern4 1 1 1 0.896178\n",
      " modified Weights  [-2.57104937  2.69915519] 1.3243530823698837\n",
      " Training with pattern  3  weights  [-2.57104937  2.69915511] 1.321052641429491   weights  [-2.57535382  2.69915519]  bias  1.3200486335469663\n",
      "pattern1 0 0 1 0.866796\n",
      "pattern2 0 1 1 0.999355\n",
      "pattern3 1 0 -1 -0.849765\n",
      "pattern4 1 1 1 0.89447\n",
      " modified Weights  [-2.57535382  2.69915519] 1.3200486335469663\n",
      " Training with pattern  4  weights  [-2.57104937  2.69915511] 1.321052641429491   weights  [-2.57324403  2.70126498]  bias  1.3221584219071856\n",
      "pattern1 0 0 1 0.86732\n",
      "pattern2 0 1 1 0.99936\n",
      "pattern3 1 0 -1 -0.848588\n",
      "pattern4 1 1 1 0.895728\n",
      " modified Weights  [-2.57324403  2.70126498] 1.3221584219071856\n",
      "+++++++++++Epoch  266  cost=  0.051402713286278504\n",
      " Training with pattern  1  weights  [-2.57324403  2.70126498] 1.3221584219071856   weights  [-2.57324403  2.70126498]  bias  1.3254456633653435\n",
      "pattern1 0 0 1 0.868132\n",
      "pattern2 0 1 1 0.999364\n",
      "pattern3 1 0 -1 -0.847665\n",
      "pattern4 1 1 1 0.896376\n",
      " modified Weights  [-2.57324403  2.70126498] 1.3254456633653435\n",
      " Training with pattern  2  weights  [-2.57324403  2.70126498] 1.3221584219071856   weights  [-2.57324403  2.70126506]  bias  1.3254457441935361\n",
      "pattern1 0 0 1 0.868132\n",
      "pattern2 0 1 1 0.999364\n",
      "pattern3 1 0 -1 -0.847665\n",
      "pattern4 1 1 1 0.896376\n",
      " modified Weights  [-2.57324403  2.70126506] 1.3254457441935361\n",
      " Training with pattern  3  weights  [-2.57324403  2.70126498] 1.3221584219071856   weights  [-2.57753171  2.70126506]  bias  1.3211580665912743\n",
      "pattern1 0 0 1 0.867072\n",
      "pattern2 0 1 1 0.999359\n",
      "pattern3 1 0 -1 -0.850061\n",
      "pattern4 1 1 1 0.894678\n",
      " modified Weights  [-2.57753171  2.70126506] 1.3211580665912743\n",
      " Training with pattern  4  weights  [-2.57324403  2.70126498] 1.3221584219071856   weights  [-2.57543     2.70336677]  bias  1.3232597767253873\n",
      "pattern1 0 0 1 0.867592\n",
      "pattern2 0 1 1 0.999364\n",
      "pattern3 1 0 -1 -0.848891\n",
      "pattern4 1 1 1 0.895929\n",
      " modified Weights  [-2.57543     2.70336677] 1.3232597767253873\n",
      "+++++++++++Epoch  267  cost=  0.051196835204002464\n",
      " Training with pattern  1  weights  [-2.57543     2.70336677] 1.3232597767253873   weights  [-2.57543     2.70336677]  bias  1.326534001938713\n",
      "pattern1 0 0 1 0.8684\n",
      "pattern2 0 1 1 0.999368\n",
      "pattern3 1 0 -1 -0.847974\n",
      "pattern4 1 1 1 0.896573\n",
      " modified Weights  [-2.57543     2.70336677] 1.326534001938713\n",
      " Training with pattern  2  weights  [-2.57543     2.70336677] 1.3232597767253873   weights  [-2.57543     2.70336685]  bias  1.3265340817425328\n",
      "pattern1 0 0 1 0.8684\n",
      "pattern2 0 1 1 0.999368\n",
      "pattern3 1 0 -1 -0.847974\n",
      "pattern4 1 1 1 0.896573\n",
      " modified Weights  [-2.57543     2.70336685] 1.3265340817425328\n",
      " Training with pattern  3  weights  [-2.57543     2.70336677] 1.3232597767253873   weights  [-2.57970103  2.70336685]  bias  1.3222630482702256\n",
      "pattern1 0 0 1 0.867346\n",
      "pattern2 0 1 1 0.999363\n",
      "pattern3 1 0 -1 -0.850356\n",
      "pattern4 1 1 1 0.894885\n",
      " modified Weights  [-2.57970103  2.70336685] 1.3222630482702256\n",
      " Training with pattern  4  weights  [-2.57543     2.70336677] 1.3232597767253873   weights  [-2.57760734  2.70546054]  bias  1.324356740335518\n",
      "pattern1 0 0 1 0.867863\n",
      "pattern2 0 1 1 0.999368\n",
      "pattern3 1 0 -1 -0.849193\n",
      "pattern4 1 1 1 0.896129\n",
      " modified Weights  [-2.57760734  2.70546054] 1.324356740335518\n",
      "+++++++++++Epoch  268  cost=  0.05099254981707259\n",
      " Training with pattern  1  weights  [-2.57760734  2.70546054] 1.324356740335518   weights  [-2.57760734  2.70546054]  bias  1.3276180495157548\n",
      "pattern1 0 0 1 0.868666\n",
      "pattern2 0 1 1 0.999372\n",
      "pattern3 1 0 -1 -0.848281\n",
      "pattern4 1 1 1 0.896769\n",
      " modified Weights  [-2.57760734  2.70546054] 1.3276180495157548\n",
      " Training with pattern  2  weights  [-2.57760734  2.70546054] 1.324356740335518   weights  [-2.57760734  2.70546062]  bias  1.327618128312059\n",
      "pattern1 0 0 1 0.868666\n",
      "pattern2 0 1 1 0.999372\n",
      "pattern3 1 0 -1 -0.848281\n",
      "pattern4 1 1 1 0.896769\n",
      " modified Weights  [-2.57760734  2.70546062] 1.327618128312059\n",
      " Training with pattern  3  weights  [-2.57760734  2.70546054] 1.324356740335518   weights  [-2.58186185  2.70546062]  bias  1.3233636133003066\n",
      "pattern1 0 0 1 0.867618\n",
      "pattern2 0 1 1 0.999367\n",
      "pattern3 1 0 -1 -0.85065\n",
      "pattern4 1 1 1 0.895091\n",
      " modified Weights  [-2.58186185  2.70546062] 1.3233636133003066\n",
      " Training with pattern  4  weights  [-2.57760734  2.70546054] 1.324356740335518   weights  [-2.57977612  2.70754636]  bias  1.3254493467932031\n",
      "pattern1 0 0 1 0.868133\n",
      "pattern2 0 1 1 0.999372\n",
      "pattern3 1 0 -1 -0.849492\n",
      "pattern4 1 1 1 0.896328\n",
      " modified Weights  [-2.57977612  2.70754636] 1.3254493467932031\n",
      "+++++++++++Epoch  269  cost=  0.05078983899854731\n",
      " Training with pattern  1  weights  [-2.57977612  2.70754636] 1.3254493467932031   weights  [-2.57977612  2.70754636]  bias  1.3286978390135706\n",
      "pattern1 0 0 1 0.868931\n",
      "pattern2 0 1 1 0.999376\n",
      "pattern3 1 0 -1 -0.848586\n",
      "pattern4 1 1 1 0.896964\n",
      " modified Weights  [-2.57977612  2.70754636] 1.3286978390135706\n",
      " Training with pattern  2  weights  [-2.57977612  2.70754636] 1.3254493467932031   weights  [-2.57977612  2.70754643]  bias  1.3286979168188768\n",
      "pattern1 0 0 1 0.868931\n",
      "pattern2 0 1 1 0.999376\n",
      "pattern3 1 0 -1 -0.848586\n",
      "pattern4 1 1 1 0.896964\n",
      " modified Weights  [-2.57977612  2.70754643] 1.3286979168188768\n",
      " Training with pattern  3  weights  [-2.57977612  2.70754636] 1.3254493467932031   weights  [-2.58401424  2.70754643]  bias  1.3244597959986384\n",
      "pattern1 0 0 1 0.867889\n",
      "pattern2 0 1 1 0.999371\n",
      "pattern3 1 0 -1 -0.850941\n",
      "pattern4 1 1 1 0.895295\n",
      " modified Weights  [-2.58401424  2.70754643] 1.3244597959986384\n",
      " Training with pattern  4  weights  [-2.57977612  2.70754636] 1.3254493467932031   weights  [-2.58193641  2.70962427]  bias  1.3265376297642624\n",
      "pattern1 0 0 1 0.868401\n",
      "pattern2 0 1 1 0.999376\n",
      "pattern3 1 0 -1 -0.849791\n",
      "pattern4 1 1 1 0.896525\n",
      " modified Weights  [-2.58193641  2.70962427] 1.3265376297642624\n",
      "+++++++++++Epoch  270  cost=  0.05058868489284702\n",
      " Training with pattern  1  weights  [-2.58193641  2.70962427] 1.3265376297642624   weights  [-2.58193641  2.70962427]  bias  1.3297734029765\n",
      "pattern1 0 0 1 0.869194\n",
      "pattern2 0 1 1 0.99938\n",
      "pattern3 1 0 -1 -0.848889\n",
      "pattern4 1 1 1 0.897158\n",
      " modified Weights  [-2.58193641  2.70962427] 1.3297734029765\n",
      " Training with pattern  2  weights  [-2.58193641  2.70962427] 1.3265376297642624   weights  [-2.58193641  2.70962435]  bias  1.3297734798069936\n",
      "pattern1 0 0 1 0.869194\n",
      "pattern2 0 1 1 0.99938\n",
      "pattern3 1 0 -1 -0.848889\n",
      "pattern4 1 1 1 0.897158\n",
      " modified Weights  [-2.58193641  2.70962435] 1.3297734798069936\n",
      " Training with pattern  3  weights  [-2.58193641  2.70962427] 1.3265376297642624   weights  [-2.58615826  2.70962435]  bias  1.3255516302890253\n",
      "pattern1 0 0 1 0.868158\n",
      "pattern2 0 1 1 0.999375\n",
      "pattern3 1 0 -1 -0.851231\n",
      "pattern4 1 1 1 0.895498\n",
      " modified Weights  [-2.58615826  2.70962435] 1.3255516302890253\n",
      " Training with pattern  4  weights  [-2.58193641  2.70962427] 1.3265376297642624   weights  [-2.58408826  2.71169434]  bias  1.327621622530588\n",
      "pattern1 0 0 1 0.868667\n",
      "pattern2 0 1 1 0.99938\n",
      "pattern3 1 0 -1 -0.850087\n",
      "pattern4 1 1 1 0.896722\n",
      " modified Weights  [-2.58408826  2.71169434] 1.327621622530588\n",
      "+++++++++++Epoch  271  cost=  0.05038906991073043\n",
      " *********Epoch  270 Error  0.05038906991073043\n",
      " Training with pattern  1  weights  [-2.58408826  2.71169434] 1.327621622530588   weights  [-2.58408826  2.71169434]  bias  1.3308447735816813\n",
      "pattern1 0 0 1 0.869456\n",
      "pattern2 0 1 1 0.999384\n",
      "pattern3 1 0 -1 -0.849191\n",
      "pattern4 1 1 1 0.897351\n",
      " modified Weights  [-2.58408826  2.71169434] 1.3308447735816813\n",
      " Training with pattern  2  weights  [-2.58408826  2.71169434] 1.327621622530588   weights  [-2.58408826  2.71169441]  bias  1.3308448494532237\n",
      "pattern1 0 0 1 0.869456\n",
      "pattern2 0 1 1 0.999384\n",
      "pattern3 1 0 -1 -0.849191\n",
      "pattern4 1 1 1 0.897351\n",
      " modified Weights  [-2.58408826  2.71169441] 1.3308448494532237\n",
      " Training with pattern  3  weights  [-2.58408826  2.71169434] 1.327621622530588   weights  [-2.58829396  2.71169441]  bias  1.3266391497078922\n",
      "pattern1 0 0 1 0.868426\n",
      "pattern2 0 1 1 0.999379\n",
      "pattern3 1 0 -1 -0.85152\n",
      "pattern4 1 1 1 0.895701\n",
      " modified Weights  [-2.58829396  2.71169441] 1.3266391497078922\n",
      " Training with pattern  4  weights  [-2.58408826  2.71169434] 1.327621622530588   weights  [-2.58623176  2.71375662]  bias  1.3287013579959148\n",
      "pattern1 0 0 1 0.868932\n",
      "pattern2 0 1 1 0.999384\n",
      "pattern3 1 0 -1 -0.850382\n",
      "pattern4 1 1 1 0.896917\n",
      " modified Weights  [-2.58623176  2.71375662] 1.3287013579959148\n",
      "+++++++++++Epoch  272  cost=  0.05019097672438093\n",
      " Training with pattern  1  weights  [-2.58623176  2.71375662] 1.3287013579959148   weights  [-2.58623176  2.71375662]  bias  1.3319119826445136\n",
      "pattern1 0 0 1 0.869716\n",
      "pattern2 0 1 1 0.999388\n",
      "pattern3 1 0 -1 -0.849491\n",
      "pattern4 1 1 1 0.897543\n",
      " modified Weights  [-2.58623176  2.71375662] 1.3319119826445136\n",
      " Training with pattern  2  weights  [-2.58623176  2.71375662] 1.3287013579959148   weights  [-2.58623176  2.7137567 ]  bias  1.3319120575726497\n",
      "pattern1 0 0 1 0.869716\n",
      "pattern2 0 1 1 0.999388\n",
      "pattern3 1 0 -1 -0.849491\n",
      "pattern4 1 1 1 0.897543\n",
      " modified Weights  [-2.58623176  2.7137567 ] 1.3319120575726497\n",
      " Training with pattern  3  weights  [-2.58623176  2.71375662] 1.3287013579959148   weights  [-2.59042143  2.7137567 ]  bias  1.3277223874101103\n",
      "pattern1 0 0 1 0.868692\n",
      "pattern2 0 1 1 0.999383\n",
      "pattern3 1 0 -1 -0.851807\n",
      "pattern4 1 1 1 0.895902\n",
      " modified Weights  [-2.59042143  2.7137567 ] 1.3277223874101103\n",
      " Training with pattern  4  weights  [-2.58623176  2.71375662] 1.3287013579959148   weights  [-2.58836694  2.71581118]  bias  1.329776868691482\n",
      "pattern1 0 0 1 0.869195\n",
      "pattern2 0 1 1 0.999388\n",
      "pattern3 1 0 -1 -0.850675\n",
      "pattern4 1 1 1 0.897112\n",
      " modified Weights  [-2.58836694  2.71581118] 1.329776868691482\n",
      "+++++++++++Epoch  273  cost=  0.04999438826260094\n",
      " Training with pattern  1  weights  [-2.58836694  2.71581118] 1.329776868691482   weights  [-2.58836694  2.71581118]  bias  1.3329750616240161\n",
      "pattern1 0 0 1 0.869975\n",
      "pattern2 0 1 1 0.999392\n",
      "pattern3 1 0 -1 -0.849789\n",
      "pattern4 1 1 1 0.897734\n",
      " modified Weights  [-2.58836694  2.71581118] 1.3329750616240161\n",
      " Training with pattern  2  weights  [-2.58836694  2.71581118] 1.329776868691482   weights  [-2.58836694  2.71581125]  bias  1.3329751356239823\n",
      "pattern1 0 0 1 0.869975\n",
      "pattern2 0 1 1 0.999392\n",
      "pattern3 1 0 -1 -0.849789\n",
      "pattern4 1 1 1 0.897734\n",
      " modified Weights  [-2.58836694  2.71581125] 1.3329751356239823\n",
      " Training with pattern  3  weights  [-2.58836694  2.71581118] 1.329776868691482   weights  [-2.5925407   2.71581125]  bias  1.3288013761747146\n",
      "pattern1 0 0 1 0.868956\n",
      "pattern2 0 1 1 0.999387\n",
      "pattern3 1 0 -1 -0.852092\n",
      "pattern4 1 1 1 0.896102\n",
      " modified Weights  [-2.5925407   2.71581125] 1.3288013761747146\n",
      " Training with pattern  4  weights  [-2.58836694  2.71581118] 1.329776868691482   weights  [-2.59049389  2.71785806]  bias  1.3308481867815891\n",
      "pattern1 0 0 1 0.869456\n",
      "pattern2 0 1 1 0.999392\n",
      "pattern3 1 0 -1 -0.850966\n",
      "pattern4 1 1 1 0.897305\n",
      " modified Weights  [-2.59049389  2.71785806] 1.3308481867815891\n",
      "+++++++++++Epoch  274  cost=  0.04979928770611211\n",
      " Training with pattern  1  weights  [-2.59049389  2.71785806] 1.3308481867815891   weights  [-2.59049389  2.71785806]  bias  1.334034041628089\n",
      "pattern1 0 0 1 0.870232\n",
      "pattern2 0 1 1 0.999395\n",
      "pattern3 1 0 -1 -0.850085\n",
      "pattern4 1 1 1 0.897924\n",
      " modified Weights  [-2.59049389  2.71785806] 1.334034041628089\n",
      " Training with pattern  2  weights  [-2.59049389  2.71785806] 1.3308481867815891   weights  [-2.59049389  2.71785814]  bias  1.3340341147148198\n",
      "pattern1 0 0 1 0.870232\n",
      "pattern2 0 1 1 0.999395\n",
      "pattern3 1 0 -1 -0.850085\n",
      "pattern4 1 1 1 0.897924\n",
      " modified Weights  [-2.59049389  2.71785814] 1.3340341147148198\n",
      " Training with pattern  3  weights  [-2.59049389  2.71785806] 1.3308481867815891   weights  [-2.59465186  2.71785814]  bias  1.329876148410515\n",
      "pattern1 0 0 1 0.869219\n",
      "pattern2 0 1 1 0.99939\n",
      "pattern3 1 0 -1 -0.852375\n",
      "pattern4 1 1 1 0.896301\n",
      " modified Weights  [-2.59465186  2.71785814] 1.329876148410515\n",
      " Training with pattern  4  weights  [-2.59049389  2.71785806] 1.3308481867815891   weights  [-2.59261266  2.71989733]  bias  1.331915344069052\n",
      "pattern1 0 0 1 0.869717\n",
      "pattern2 0 1 1 0.999395\n",
      "pattern3 1 0 -1 -0.851256\n",
      "pattern4 1 1 1 0.897497\n",
      " modified Weights  [-2.59261266  2.71989733] 1.331915344069052\n",
      "+++++++++++Epoch  275  cost=  0.049605658482956526\n",
      " Training with pattern  1  weights  [-2.59261266  2.71989733] 1.331915344069052   weights  [-2.59261266  2.71989733]  bias  1.33508895341868\n",
      "pattern1 0 0 1 0.870488\n",
      "pattern2 0 1 1 0.999399\n",
      "pattern3 1 0 -1 -0.85038\n",
      "pattern4 1 1 1 0.898113\n",
      " modified Weights  [-2.59261266  2.71989733] 1.33508895341868\n",
      " Training with pattern  2  weights  [-2.59261266  2.71989733] 1.331915344069052   weights  [-2.59261266  2.7198974 ]  bias  1.3350890256068153\n",
      "pattern1 0 0 1 0.870488\n",
      "pattern2 0 1 1 0.999399\n",
      "pattern3 1 0 -1 -0.85038\n",
      "pattern4 1 1 1 0.898113\n",
      " modified Weights  [-2.59261266  2.7198974 ] 1.3350890256068153\n",
      " Training with pattern  3  weights  [-2.59261266  2.71989733] 1.331915344069052   weights  [-2.59675495  2.7198974 ]  bias  1.3309467361616047\n",
      "pattern1 0 0 1 0.869481\n",
      "pattern2 0 1 1 0.999394\n",
      "pattern3 1 0 -1 -0.852657\n",
      "pattern4 1 1 1 0.896498\n",
      " modified Weights  [-2.59675495  2.7198974 ] 1.3309467361616047\n",
      " Training with pattern  4  weights  [-2.59261266  2.71989733] 1.331915344069052   weights  [-2.59472332  2.72192904]  bias  1.3329783720005557\n",
      "pattern1 0 0 1 0.869975\n",
      "pattern2 0 1 1 0.999399\n",
      "pattern3 1 0 -1 -0.851544\n",
      "pattern4 1 1 1 0.897688\n",
      " modified Weights  [-2.59472332  2.72192904] 1.3329783720005557\n",
      "+++++++++++Epoch  276  cost=  0.049413484263999\n",
      " Training with pattern  1  weights  [-2.59472332  2.72192904] 1.3329783720005557   weights  [-2.59472332  2.72192904]  bias  1.3361398274168546\n",
      "pattern1 0 0 1 0.870742\n",
      "pattern2 0 1 1 0.999403\n",
      "pattern3 1 0 -1 -0.850673\n",
      "pattern4 1 1 1 0.8983\n",
      " modified Weights  [-2.59472332  2.72192904] 1.3361398274168546\n",
      " Training with pattern  2  weights  [-2.59472332  2.72192904] 1.3329783720005557   weights  [-2.59472332  2.72192911]  bias  1.3361398987207467\n",
      "pattern1 0 0 1 0.870742\n",
      "pattern2 0 1 1 0.999403\n",
      "pattern3 1 0 -1 -0.850673\n",
      "pattern4 1 1 1 0.8983\n",
      " modified Weights  [-2.59472332  2.72192911] 1.3361398987207467\n",
      " Training with pattern  3  weights  [-2.59472332  2.72192904] 1.3329783720005557   weights  [-2.59885004  2.72192911]  bias  1.3320131711127654\n",
      "pattern1 0 0 1 0.869741\n",
      "pattern2 0 1 1 0.999398\n",
      "pattern3 1 0 -1 -0.852938\n",
      "pattern4 1 1 1 0.896695\n",
      " modified Weights  [-2.59885004  2.72192911] 1.3320131711127654\n",
      " Training with pattern  4  weights  [-2.59472332  2.72192904] 1.3329783720005557   weights  [-2.59682591  2.72395324]  bias  1.3340373016719096\n",
      "pattern1 0 0 1 0.870233\n",
      "pattern2 0 1 1 0.999403\n",
      "pattern3 1 0 -1 -0.851831\n",
      "pattern4 1 1 1 0.897879\n",
      " modified Weights  [-2.59682591  2.72395324] 1.3340373016719096\n",
      "+++++++++++Epoch  277  cost=  0.049222748958525804\n",
      " Training with pattern  1  weights  [-2.59682591  2.72395324] 1.3340373016719096   weights  [-2.59682591  2.72395324]  bias  1.3371866937077748\n",
      "pattern1 0 0 1 0.870995\n",
      "pattern2 0 1 1 0.999406\n",
      "pattern3 1 0 -1 -0.850965\n",
      "pattern4 1 1 1 0.898487\n",
      " modified Weights  [-2.59682591  2.72395324] 1.3371866937077748\n",
      " Training with pattern  2  weights  [-2.59682591  2.72395324] 1.3340373016719096   weights  [-2.59682591  2.72395331]  bias  1.3371867641414947\n",
      "pattern1 0 0 1 0.870995\n",
      "pattern2 0 1 1 0.999406\n",
      "pattern3 1 0 -1 -0.850965\n",
      "pattern4 1 1 1 0.898487\n",
      " modified Weights  [-2.59682591  2.72395331] 1.3371867641414947\n",
      " Training with pattern  3  weights  [-2.59682591  2.72395324] 1.3340373016719096   weights  [-2.60093719  2.72395331]  bias  1.3330754845947745\n",
      "pattern1 0 0 1 0.869999\n",
      "pattern2 0 1 1 0.999402\n",
      "pattern3 1 0 -1 -0.853217\n",
      "pattern4 1 1 1 0.896891\n",
      " modified Weights  [-2.60093719  2.72395331] 1.3330754845947745\n",
      " Training with pattern  4  weights  [-2.59682591  2.72395324] 1.3340373016719096   weights  [-2.59892051  2.72596999]  bias  1.3350921638332078\n",
      "pattern1 0 0 1 0.870488\n",
      "pattern2 0 1 1 0.999406\n",
      "pattern3 1 0 -1 -0.852116\n",
      "pattern4 1 1 1 0.898068\n",
      " modified Weights  [-2.59892051  2.72596999] 1.3350921638332078\n",
      "+++++++++++Epoch  278  cost=  0.049033436709938934\n",
      " Training with pattern  1  weights  [-2.59892051  2.72596999] 1.3350921638332078   weights  [-2.59892051  2.72596999]  bias  1.3382295820455892\n",
      "pattern1 0 0 1 0.871246\n",
      "pattern2 0 1 1 0.99941\n",
      "pattern3 1 0 -1 -0.851254\n",
      "pattern4 1 1 1 0.898673\n",
      " modified Weights  [-2.59892051  2.72596999] 1.3382295820455892\n",
      " Training with pattern  2  weights  [-2.59892051  2.72596999] 1.3350921638332078   weights  [-2.59892051  2.72597006]  bias  1.3382296516229337\n",
      "pattern1 0 0 1 0.871246\n",
      "pattern2 0 1 1 0.99941\n",
      "pattern3 1 0 -1 -0.851254\n",
      "pattern4 1 1 1 0.898673\n",
      " modified Weights  [-2.59892051  2.72597006] 1.3382296516229337\n",
      " Training with pattern  3  weights  [-2.59892051  2.72596999] 1.3350921638332078   weights  [-2.60301646  2.72597006]  bias  1.3341337075896165\n",
      "pattern1 0 0 1 0.870256\n",
      "pattern2 0 1 1 0.999405\n",
      "pattern3 1 0 -1 -0.853495\n",
      "pattern4 1 1 1 0.897085\n",
      " modified Weights  [-2.60301646  2.72597006] 1.3341337075896165\n",
      " Training with pattern  4  weights  [-2.59892051  2.72596999] 1.3350921638332078   weights  [-2.60100718  2.72797934]  bias  1.3361429888938956\n",
      "pattern1 0 0 1 0.870743\n",
      "pattern2 0 1 1 0.99941\n",
      "pattern3 1 0 -1 -0.8524\n",
      "pattern4 1 1 1 0.898256\n",
      " modified Weights  [-2.60100718  2.72797934] 1.3361429888938956\n",
      "+++++++++++Epoch  279  cost=  0.04884553189154214\n",
      " Training with pattern  1  weights  [-2.60100718  2.72797934] 1.3361429888938956   weights  [-2.60100718  2.72797934]  bias  1.3392685218582332\n",
      "pattern1 0 0 1 0.871496\n",
      "pattern2 0 1 1 0.999414\n",
      "pattern3 1 0 -1 -0.851543\n",
      "pattern4 1 1 1 0.898858\n",
      " modified Weights  [-2.60100718  2.72797934] 1.3392685218582332\n",
      " Training with pattern  2  weights  [-2.60100718  2.72797934] 1.3361429888938956   weights  [-2.60100718  2.72797941]  bias  1.3392685905927308\n",
      "pattern1 0 0 1 0.871496\n",
      "pattern2 0 1 1 0.999414\n",
      "pattern3 1 0 -1 -0.851543\n",
      "pattern4 1 1 1 0.898858\n",
      " modified Weights  [-2.60100718  2.72797941] 1.3392685905927308\n",
      " Training with pattern  3  weights  [-2.60100718  2.72797934] 1.3361429888938956   weights  [-2.6050879   2.72797941]  bias  1.3351878707355964\n",
      "pattern1 0 0 1 0.870512\n",
      "pattern2 0 1 1 0.999409\n",
      "pattern3 1 0 -1 -0.853771\n",
      "pattern4 1 1 1 0.897279\n",
      " modified Weights  [-2.6050879   2.72797941] 1.3351878707355964\n",
      " Training with pattern  4  weights  [-2.60100718  2.72797934] 1.3361429888938956   weights  [-2.60308596  2.72998135]  bias  1.3371898069277417\n",
      "pattern1 0 0 1 0.870996\n",
      "pattern2 0 1 1 0.999414\n",
      "pattern3 1 0 -1 -0.852681\n",
      "pattern4 1 1 1 0.898443\n",
      " modified Weights  [-2.60308596  2.72998135] 1.3371898069277417\n",
      "+++++++++++Epoch  280  cost=  0.04865901910241818\n",
      " Training with pattern  1  weights  [-2.60308596  2.72998135] 1.3371898069277417   weights  [-2.60308596  2.72998135]  bias  1.3403035422521443\n",
      "pattern1 0 0 1 0.871745\n",
      "pattern2 0 1 1 0.999417\n",
      "pattern3 1 0 -1 -0.851829\n",
      "pattern4 1 1 1 0.899042\n",
      " modified Weights  [-2.60308596  2.72998135] 1.3403035422521443\n",
      " Training with pattern  2  weights  [-2.60308596  2.72998135] 1.3371898069277417   weights  [-2.60308596  2.72998141]  bias  1.3403036101570611\n",
      "pattern1 0 0 1 0.871745\n",
      "pattern2 0 1 1 0.999417\n",
      "pattern3 1 0 -1 -0.851829\n",
      "pattern4 1 1 1 0.899042\n",
      " modified Weights  [-2.60308596  2.72998141] 1.3403036101570611\n",
      " Training with pattern  3  weights  [-2.60308596  2.72998135] 1.3371898069277417   weights  [-2.60715157  2.72998141]  bias  1.3362380043323634\n",
      "pattern1 0 0 1 0.870766\n",
      "pattern2 0 1 1 0.999412\n",
      "pattern3 1 0 -1 -0.854045\n",
      "pattern4 1 1 1 0.897471\n",
      " modified Weights  [-2.60715157  2.72998141] 1.3362380043323634\n",
      " Training with pattern  4  weights  [-2.60308596  2.72998135] 1.3371898069277417   weights  [-2.60515692  2.73197606]  bias  1.3382326476777233\n",
      "pattern1 0 0 1 0.871247\n",
      "pattern2 0 1 1 0.999417\n",
      "pattern3 1 0 -1 -0.852962\n",
      "pattern4 1 1 1 0.898629\n",
      " modified Weights  [-2.60515692  2.73197606] 1.3382326476777233\n",
      "+++++++++++Epoch  281  cost=  0.04847388316339275\n",
      " *********Epoch  280 Error  0.04847388316339275\n",
      " Training with pattern  1  weights  [-2.60515692  2.73197606] 1.3382326476777233   weights  [-2.60515692  2.73197606]  bias  1.341334672016892\n",
      "pattern1 0 0 1 0.871992\n",
      "pattern2 0 1 1 0.999421\n",
      "pattern3 1 0 -1 -0.852114\n",
      "pattern4 1 1 1 0.899225\n",
      " modified Weights  [-2.60515692  2.73197606] 1.341334672016892\n",
      " Training with pattern  2  weights  [-2.60515692  2.73197606] 1.3382326476777233   weights  [-2.60515692  2.73197612]  bias  1.3413347391052384\n",
      "pattern1 0 0 1 0.871992\n",
      "pattern2 0 1 1 0.999421\n",
      "pattern3 1 0 -1 -0.852114\n",
      "pattern4 1 1 1 0.899225\n",
      " modified Weights  [-2.60515692  2.73197612] 1.3413347391052384\n",
      " Training with pattern  3  weights  [-2.60515692  2.73197606] 1.3382326476777233   weights  [-2.60920752  2.73197612]  bias  1.3372841383458423\n",
      "pattern1 0 0 1 0.871018\n",
      "pattern2 0 1 1 0.999416\n",
      "pattern3 1 0 -1 -0.854318\n",
      "pattern4 1 1 1 0.897663\n",
      " modified Weights  [-2.60920752  2.73197612] 1.3372841383458423\n",
      " Training with pattern  4  weights  [-2.60515692  2.73197606] 1.3382326476777233   weights  [-2.60722012  2.73396353]  bias  1.3392715405608222\n",
      "pattern1 0 0 1 0.871497\n",
      "pattern2 0 1 1 0.999421\n",
      "pattern3 1 0 -1 -0.853241\n",
      "pattern4 1 1 1 0.898815\n",
      " modified Weights  [-2.60722012  2.73396353] 1.3392715405608222\n",
      "+++++++++++Epoch  282  cost=  0.048290109113085636\n",
      " Training with pattern  1  weights  [-2.60722012  2.73396353] 1.3392715405608222   weights  [-2.60722012  2.73396353]  bias  1.3423619396297253\n",
      "pattern1 0 0 1 0.872238\n",
      "pattern2 0 1 1 0.999424\n",
      "pattern3 1 0 -1 -0.852398\n",
      "pattern4 1 1 1 0.899407\n",
      " modified Weights  [-2.60722012  2.73396353] 1.3423619396297253\n",
      " Training with pattern  2  weights  [-2.60722012  2.73396353] 1.3392715405608222   weights  [-2.60722012  2.73396359]  bias  1.3423620059142616\n",
      "pattern1 0 0 1 0.872238\n",
      "pattern2 0 1 1 0.999424\n",
      "pattern3 1 0 -1 -0.852398\n",
      "pattern4 1 1 1 0.899407\n",
      " modified Weights  [-2.60722012  2.73396359] 1.3423620059142616\n",
      " Training with pattern  3  weights  [-2.60722012  2.73396353] 1.3392715405608222   weights  [-2.61125583  2.73396359]  bias  1.338326302413075\n",
      "pattern1 0 0 1 0.87127\n",
      "pattern2 0 1 1 0.99942\n",
      "pattern3 1 0 -1 -0.85459\n",
      "pattern4 1 1 1 0.897853\n",
      " modified Weights  [-2.61125583  2.73396359] 1.338326302413075\n",
      " Training with pattern  4  weights  [-2.60722012  2.73396353] 1.3392715405608222   weights  [-2.60927561  2.73594381]  bias  1.340306514672733\n",
      "pattern1 0 0 1 0.871746\n",
      "pattern2 0 1 1 0.999424\n",
      "pattern3 1 0 -1 -0.853518\n",
      "pattern4 1 1 1 0.898999\n",
      " modified Weights  [-2.60927561  2.73594381] 1.340306514672733\n",
      "+++++++++++Epoch  283  cost=  0.04810768220404408\n",
      " Training with pattern  1  weights  [-2.60927561  2.73594381] 1.340306514672733   weights  [-2.60927561  2.73594381]  bias  1.34338537326004\n",
      "pattern1 0 0 1 0.872483\n",
      "pattern2 0 1 1 0.999428\n",
      "pattern3 1 0 -1 -0.85268\n",
      "pattern4 1 1 1 0.899588\n",
      " modified Weights  [-2.60927561  2.73594381] 1.34338537326004\n",
      " Training with pattern  2  weights  [-2.60927561  2.73594381] 1.340306514672733   weights  [-2.60927561  2.73594387]  bias  1.3433854387532815\n",
      "pattern1 0 0 1 0.872483\n",
      "pattern2 0 1 1 0.999428\n",
      "pattern3 1 0 -1 -0.85268\n",
      "pattern4 1 1 1 0.899588\n",
      " modified Weights  [-2.60927561  2.73594387] 1.3433854387532815\n",
      " Training with pattern  3  weights  [-2.60927561  2.73594381] 1.340306514672733   weights  [-2.61329653  2.73594387]  bias  1.3393645258469768\n",
      "pattern1 0 0 1 0.87152\n",
      "pattern2 0 1 1 0.999423\n",
      "pattern3 1 0 -1 -0.85486\n",
      "pattern4 1 1 1 0.898043\n",
      " modified Weights  [-2.61329653  2.73594387] 1.3393645258469768\n",
      " Training with pattern  4  weights  [-2.60927561  2.73594381] 1.340306514672733   weights  [-2.61132345  2.73791694]  bias  1.3413375987924905\n",
      "pattern1 0 0 1 0.871993\n",
      "pattern2 0 1 1 0.999428\n",
      "pattern3 1 0 -1 -0.853794\n",
      "pattern4 1 1 1 0.899182\n",
      " modified Weights  [-2.61132345  2.73791694] 1.3413375987924905\n",
      "+++++++++++Epoch  284  cost=  0.047926587898959164\n",
      " Training with pattern  1  weights  [-2.61132345  2.73791694] 1.3413375987924905   weights  [-2.61132345  2.73791694]  bias  1.3444050007737662\n",
      "pattern1 0 0 1 0.872726\n",
      "pattern2 0 1 1 0.999431\n",
      "pattern3 1 0 -1 -0.85296\n",
      "pattern4 1 1 1 0.899768\n",
      " modified Weights  [-2.61132345  2.73791694] 1.3444050007737662\n",
      " Training with pattern  2  weights  [-2.61132345  2.73791694] 1.3413375987924905   weights  [-2.61132345  2.73791701]  bias  1.3444050654879898\n",
      "pattern1 0 0 1 0.872726\n",
      "pattern2 0 1 1 0.999431\n",
      "pattern3 1 0 -1 -0.85296\n",
      "pattern4 1 1 1 0.899768\n",
      " modified Weights  [-2.61132345  2.73791701] 1.3444050654879898\n",
      " Training with pattern  3  weights  [-2.61132345  2.73791694] 1.3413375987924905   weights  [-2.61532968  2.73791701]  bias  1.3403988376410079\n",
      "pattern1 0 0 1 0.871768\n",
      "pattern2 0 1 1 0.999427\n",
      "pattern3 1 0 -1 -0.855128\n",
      "pattern4 1 1 1 0.898231\n",
      " modified Weights  [-2.61532968  2.73791701] 1.3403988376410079\n",
      " Training with pattern  4  weights  [-2.61132345  2.73791694] 1.3413375987924905   weights  [-2.6133637   2.73988299]  bias  1.3423648213870112\n",
      "pattern1 0 0 1 0.872239\n",
      "pattern2 0 1 1 0.999431\n",
      "pattern3 1 0 -1 -0.854068\n",
      "pattern4 1 1 1 0.899364\n",
      " modified Weights  [-2.6133637   2.73988299] 1.3423648213870112\n",
      "+++++++++++Epoch  285  cost=  0.04774681186696102\n",
      " Training with pattern  1  weights  [-2.6133637   2.73988299] 1.3423648213870112   weights  [-2.6133637   2.73988299]  bias  1.3454208497376785\n",
      "pattern1 0 0 1 0.872968\n",
      "pattern2 0 1 1 0.999434\n",
      "pattern3 1 0 -1 -0.853239\n",
      "pattern4 1 1 1 0.899947\n",
      " modified Weights  [-2.6133637   2.73988299] 1.3454208497376785\n",
      " Training with pattern  2  weights  [-2.6133637   2.73988299] 1.3423648213870112   weights  [-2.6133637   2.73988306]  bias  1.345420913684927\n",
      "pattern1 0 0 1 0.872968\n",
      "pattern2 0 1 1 0.999434\n",
      "pattern3 1 0 -1 -0.853239\n",
      "pattern4 1 1 1 0.899947\n",
      " modified Weights  [-2.6133637   2.73988306] 1.345420913684927\n",
      " Training with pattern  3  weights  [-2.6133637   2.73988299] 1.3423648213870112   weights  [-2.61735534  2.73988306]  bias  1.341429266473758\n",
      "pattern1 0 0 1 0.872015\n",
      "pattern2 0 1 1 0.99943\n",
      "pattern3 1 0 -1 -0.855396\n",
      "pattern4 1 1 1 0.898418\n",
      " modified Weights  [-2.61735534  2.73988306] 1.341429266473758\n",
      " Training with pattern  4  weights  [-2.6133637   2.73988299] 1.3423648213870112   weights  [-2.6153964  2.741842 ]  bias  1.3433882106155566\n",
      "pattern1 0 0 1 0.872484\n",
      "pattern2 0 1 1 0.999434\n",
      "pattern3 1 0 -1 -0.854341\n",
      "pattern4 1 1 1 0.899546\n",
      " modified Weights  [-2.6153964  2.741842 ] 1.3433882106155566\n",
      "+++++++++++Epoch  286  cost=  0.04756833997999151\n",
      " Training with pattern  1  weights  [-2.6153964  2.741842 ] 1.3433882106155566   weights  [-2.6153964  2.741842 ]  bias  1.3464329474236305\n",
      "pattern1 0 0 1 0.873209\n",
      "pattern2 0 1 1 0.999438\n",
      "pattern3 1 0 -1 -0.853516\n",
      "pattern4 1 1 1 0.900125\n",
      " modified Weights  [-2.6153964  2.741842 ] 1.3464329474236305\n",
      " Training with pattern  2  weights  [-2.6153964  2.741842 ] 1.3433882106155566   weights  [-2.6153964   2.74184206]  bias  1.3464330106157183\n",
      "pattern1 0 0 1 0.873209\n",
      "pattern2 0 1 1 0.999438\n",
      "pattern3 1 0 -1 -0.853516\n",
      "pattern4 1 1 1 0.900125\n",
      " modified Weights  [-2.6153964   2.74184206] 1.3464330106157183\n",
      " Training with pattern  3  weights  [-2.6153964  2.741842 ] 1.3433882106155566   weights  [-2.61937357  2.74184206]  bias  1.3424558407134546\n",
      "pattern1 0 0 1 0.872261\n",
      "pattern2 0 1 1 0.999433\n",
      "pattern3 1 0 -1 -0.855662\n",
      "pattern4 1 1 1 0.898605\n",
      " modified Weights  [-2.61937357  2.74184206] 1.3424558407134546\n",
      " Training with pattern  4  weights  [-2.6153964  2.741842 ] 1.3433882106155566   weights  [-2.61742162  2.74379402]  bias  1.3444077943341164\n",
      "pattern1 0 0 1 0.872727\n",
      "pattern2 0 1 1 0.999438\n",
      "pattern3 1 0 -1 -0.854612\n",
      "pattern4 1 1 1 0.899726\n",
      " modified Weights  [-2.61742162  2.74379402] 1.3444077943341164\n",
      "+++++++++++Epoch  287  cost=  0.04739115830925368\n",
      " Training with pattern  1  weights  [-2.61742162  2.74379402] 1.3444077943341164   weights  [-2.61742162  2.74379402]  bias  1.3474413208127154\n",
      "pattern1 0 0 1 0.873448\n",
      "pattern2 0 1 1 0.999441\n",
      "pattern3 1 0 -1 -0.853792\n",
      "pattern4 1 1 1 0.900302\n",
      " modified Weights  [-2.61742162  2.74379402] 1.3474413208127154\n",
      " Training with pattern  2  weights  [-2.61742162  2.74379402] 1.3444077943341164   weights  [-2.61742162  2.74379408]  bias  1.3474413832612342\n",
      "pattern1 0 0 1 0.873448\n",
      "pattern2 0 1 1 0.999441\n",
      "pattern3 1 0 -1 -0.853792\n",
      "pattern4 1 1 1 0.900302\n",
      " modified Weights  [-2.61742162  2.74379408] 1.3474413832612342\n",
      " Training with pattern  3  weights  [-2.61742162  2.74379402] 1.3444077943341164   weights  [-2.62138441  2.74379408]  bias  1.343478588422388\n",
      "pattern1 0 0 1 0.872505\n",
      "pattern2 0 1 1 0.999437\n",
      "pattern3 1 0 -1 -0.855926\n",
      "pattern4 1 1 1 0.89879\n",
      " modified Weights  [-2.62138441  2.74379408] 1.343478588422388\n",
      " Training with pattern  4  weights  [-2.61742162  2.74379402] 1.3444077943341164   weights  [-2.6194394   2.74573909]  bias  1.3454236000997144\n",
      "pattern1 0 0 1 0.872969\n",
      "pattern2 0 1 1 0.999441\n",
      "pattern3 1 0 -1 -0.854882\n",
      "pattern4 1 1 1 0.899906\n",
      " modified Weights  [-2.6194394   2.74573909] 1.3454236000997144\n",
      "+++++++++++Epoch  288  cost=  0.047215253121734274\n",
      " Training with pattern  1  weights  [-2.6194394   2.74573909] 1.3454236000997144   weights  [-2.6194394   2.74573909]  bias  1.3484459965993532\n",
      "pattern1 0 0 1 0.873686\n",
      "pattern2 0 1 1 0.999444\n",
      "pattern3 1 0 -1 -0.854067\n",
      "pattern4 1 1 1 0.900479\n",
      " modified Weights  [-2.6194394   2.74573909] 1.3484459965993532\n",
      " Training with pattern  2  weights  [-2.6194394   2.74573909] 1.3454236000997144   weights  [-2.6194394   2.74573915]  bias  1.348446058315676\n",
      "pattern1 0 0 1 0.873686\n",
      "pattern2 0 1 1 0.999444\n",
      "pattern3 1 0 -1 -0.854067\n",
      "pattern4 1 1 1 0.900479\n",
      " modified Weights  [-2.6194394   2.74573915] 1.348446058315676\n",
      " Training with pattern  3  weights  [-2.6194394   2.74573909] 1.3454236000997144   weights  [-2.62338792  2.74573915]  bias  1.3444975373612589\n",
      "pattern1 0 0 1 0.872748\n",
      "pattern2 0 1 1 0.99944\n",
      "pattern3 1 0 -1 -0.856189\n",
      "pattern4 1 1 1 0.898975\n",
      " modified Weights  [-2.62338792  2.74573915] 1.3444975373612589\n",
      " Training with pattern  4  weights  [-2.6194394   2.74573909] 1.3454236000997144   weights  [-2.6214498   2.74767727]  bias  1.3464356551746388\n",
      "pattern1 0 0 1 0.873209\n",
      "pattern2 0 1 1 0.999444\n",
      "pattern3 1 0 -1 -0.855151\n",
      "pattern4 1 1 1 0.900084\n",
      " modified Weights  [-2.6214498   2.74767727] 1.3464356551746388\n",
      "+++++++++++Epoch  289  cost=  0.04704061087679882\n",
      " Training with pattern  1  weights  [-2.6214498   2.74767727] 1.3464356551746388   weights  [-2.6214498   2.74767727]  bias  1.3494470011953064\n",
      "pattern1 0 0 1 0.873923\n",
      "pattern2 0 1 1 0.999448\n",
      "pattern3 1 0 -1 -0.85434\n",
      "pattern4 1 1 1 0.900654\n",
      " modified Weights  [-2.6214498   2.74767727] 1.3494470011953064\n",
      " Training with pattern  2  weights  [-2.6214498   2.74767727] 1.3464356551746388   weights  [-2.6214498   2.74767733]  bias  1.3494470621905934\n",
      "pattern1 0 0 1 0.873923\n",
      "pattern2 0 1 1 0.999448\n",
      "pattern3 1 0 -1 -0.85434\n",
      "pattern4 1 1 1 0.900654\n",
      " modified Weights  [-2.6214498   2.74767733] 1.3494470621905934\n",
      " Training with pattern  3  weights  [-2.6214498   2.74767727] 1.3464356551746388   weights  [-2.62538415  2.74767733]  bias  1.3455127149934487\n",
      "pattern1 0 0 1 0.87299\n",
      "pattern2 0 1 1 0.999443\n",
      "pattern3 1 0 -1 -0.856451\n",
      "pattern4 1 1 1 0.899158\n",
      " modified Weights  [-2.62538415  2.74767733] 1.3455127149934487\n",
      " Training with pattern  4  weights  [-2.6214498   2.74767727] 1.3464356551746388   weights  [-2.62345288  2.7496086 ]  bias  1.347443986530598\n",
      "pattern1 0 0 1 0.873449\n",
      "pattern2 0 1 1 0.999448\n",
      "pattern3 1 0 -1 -0.855418\n",
      "pattern4 1 1 1 0.900262\n",
      " modified Weights  [-2.62345288  2.7496086 ] 1.347443986530598\n",
      "+++++++++++Epoch  290  cost=  0.046867218222857235\n",
      " Training with pattern  1  weights  [-2.62345288  2.7496086 ] 1.347443986530598   weights  [-2.62345288  2.7496086 ]  bias  1.3504443607336283\n",
      "pattern1 0 0 1 0.874158\n",
      "pattern2 0 1 1 0.999451\n",
      "pattern3 1 0 -1 -0.854611\n",
      "pattern4 1 1 1 0.900829\n",
      " modified Weights  [-2.62345288  2.7496086 ] 1.3504443607336283\n",
      " Training with pattern  2  weights  [-2.62345288  2.7496086 ] 1.347443986530598   weights  [-2.62345288  2.74960866]  bias  1.3504444210188304\n",
      "pattern1 0 0 1 0.874158\n",
      "pattern2 0 1 1 0.999451\n",
      "pattern3 1 0 -1 -0.854611\n",
      "pattern4 1 1 1 0.900829\n",
      " modified Weights  [-2.62345288  2.74960866] 1.3504444210188304\n",
      " Training with pattern  3  weights  [-2.62345288  2.7496086 ] 1.347443986530598   weights  [-2.62737315  2.74960866]  bias  1.3465241484892172\n",
      "pattern1 0 0 1 0.87323\n",
      "pattern2 0 1 1 0.999447\n",
      "pattern3 1 0 -1 -0.856711\n",
      "pattern4 1 1 1 0.899341\n",
      " modified Weights  [-2.62737315  2.74960866] 1.3465241484892172\n",
      " Training with pattern  4  weights  [-2.62345288  2.7496086 ] 1.347443986530598   weights  [-2.62544868  2.75153314]  bias  1.3484486208528041\n",
      "pattern1 0 0 1 0.873687\n",
      "pattern2 0 1 1 0.999451\n",
      "pattern3 1 0 -1 -0.855684\n",
      "pattern4 1 1 1 0.900439\n",
      " modified Weights  [-2.62544868  2.75153314] 1.3484486208528041\n",
      "+++++++++++Epoch  291  cost=  0.0466950619940981\n",
      " *********Epoch  290 Error  0.0466950619940981\n",
      " Training with pattern  1  weights  [-2.62544868  2.75153314] 1.3484486208528041   weights  [-2.62544868  2.75153314]  bias  1.351438101072539\n",
      "pattern1 0 0 1 0.874392\n",
      "pattern2 0 1 1 0.999454\n",
      "pattern3 1 0 -1 -0.854881\n",
      "pattern4 1 1 1 0.901003\n",
      " modified Weights  [-2.62544868  2.75153314] 1.351438101072539\n",
      " Training with pattern  2  weights  [-2.62544868  2.75153314] 1.3484486208528041   weights  [-2.62544868  2.7515332 ]  bias  1.3514381606584032\n",
      "pattern1 0 0 1 0.874392\n",
      "pattern2 0 1 1 0.999454\n",
      "pattern3 1 0 -1 -0.854881\n",
      "pattern4 1 1 1 0.901003\n",
      " modified Weights  [-2.62544868  2.7515332 ] 1.3514381606584032\n",
      " Training with pattern  3  weights  [-2.62544868  2.75153314] 1.3484486208528041   weights  [-2.62935497  2.7515332 ]  bias  1.3475318647298247\n",
      "pattern1 0 0 1 0.873469\n",
      "pattern2 0 1 1 0.99945\n",
      "pattern3 1 0 -1 -0.85697\n",
      "pattern4 1 1 1 0.899522\n",
      " modified Weights  [-2.62935497  2.7515332 ] 1.3475318647298247\n",
      " Training with pattern  4  weights  [-2.62544868  2.75153314] 1.3484486208528041   weights  [-2.62743725  2.75345092]  bias  1.3494495845439858\n",
      "pattern1 0 0 1 0.873923\n",
      "pattern2 0 1 1 0.999454\n",
      "pattern3 1 0 -1 -0.855948\n",
      "pattern4 1 1 1 0.900615\n",
      " modified Weights  [-2.62743725  2.75345092] 1.3494495845439858\n",
      "+++++++++++Epoch  292  cost=  0.0465241292072899\n",
      " Training with pattern  1  weights  [-2.62743725  2.75345092] 1.3494495845439858   weights  [-2.62743725  2.75345092]  bias  1.3524282477992386\n",
      "pattern1 0 0 1 0.874625\n",
      "pattern2 0 1 1 0.999457\n",
      "pattern3 1 0 -1 -0.855149\n",
      "pattern4 1 1 1 0.901176\n",
      " modified Weights  [-2.62743725  2.75345092] 1.3524282477992386\n",
      " Training with pattern  2  weights  [-2.62743725  2.75345092] 1.3494495845439858   weights  [-2.62743725  2.75345097]  bias  1.3524283066963128\n",
      "pattern1 0 0 1 0.874625\n",
      "pattern2 0 1 1 0.999457\n",
      "pattern3 1 0 -1 -0.855149\n",
      "pattern4 1 1 1 0.901176\n",
      " modified Weights  [-2.62743725  2.75345097] 1.3524283066963128\n",
      " Training with pattern  3  weights  [-2.62743725  2.75345092] 1.3494495845439858   weights  [-2.63132967  2.75345097]  bias  1.3485358903115838\n",
      "pattern1 0 0 1 0.873707\n",
      "pattern2 0 1 1 0.999453\n",
      "pattern3 1 0 -1 -0.857227\n",
      "pattern4 1 1 1 0.899703\n",
      " modified Weights  [-2.63132967  2.75345097] 1.3485358903115838\n",
      " Training with pattern  4  weights  [-2.62743725  2.75345092] 1.3494495845439858   weights  [-2.62941866  2.75536199]  bias  1.350446903728331\n",
      "pattern1 0 0 1 0.874159\n",
      "pattern2 0 1 1 0.999457\n",
      "pattern3 1 0 -1 -0.856211\n",
      "pattern4 1 1 1 0.900789\n",
      " modified Weights  [-2.62941866  2.75536199] 1.350446903728331\n",
      "+++++++++++Epoch  293  cost=  0.046354407058648066\n",
      " Training with pattern  1  weights  [-2.62941866  2.75536199] 1.350446903728331   weights  [-2.62941866  2.75536199]  bias  1.3534148262336536\n",
      "pattern1 0 0 1 0.874857\n",
      "pattern2 0 1 1 0.99946\n",
      "pattern3 1 0 -1 -0.855417\n",
      "pattern4 1 1 1 0.901348\n",
      " modified Weights  [-2.62941866  2.75536199] 1.3534148262336536\n",
      " Training with pattern  2  weights  [-2.62941866  2.75536199] 1.350446903728331   weights  [-2.62941866  2.75536205]  bias  1.35341488445229\n",
      "pattern1 0 0 1 0.874857\n",
      "pattern2 0 1 1 0.99946\n",
      "pattern3 1 0 -1 -0.855417\n",
      "pattern4 1 1 1 0.901348\n",
      " modified Weights  [-2.62941866  2.75536205] 1.35341488445229\n",
      " Training with pattern  3  weights  [-2.62941866  2.75536199] 1.350446903728331   weights  [-2.63329729  2.75536205]  bias  1.3495362515498404\n",
      "pattern1 0 0 1 0.873944\n",
      "pattern2 0 1 1 0.999456\n",
      "pattern3 1 0 -1 -0.857484\n",
      "pattern4 1 1 1 0.899882\n",
      " modified Weights  [-2.63329729  2.75536205] 1.3495362515498404\n",
      " Training with pattern  4  weights  [-2.62941866  2.75536199] 1.350446903728331   weights  [-2.63139294  2.7572664 ]  bias  1.3514406042553617\n",
      "pattern1 0 0 1 0.874393\n",
      "pattern2 0 1 1 0.99946\n",
      "pattern3 1 0 -1 -0.856472\n",
      "pattern4 1 1 1 0.900964\n",
      " modified Weights  [-2.63139294  2.7572664 ] 1.3514406042553617\n",
      "+++++++++++Epoch  294  cost=  0.04618588292076591\n",
      " Training with pattern  1  weights  [-2.63139294  2.7572664 ] 1.3514406042553617   weights  [-2.63139294  2.7572664 ]  bias  1.3543978614321168\n",
      "pattern1 0 0 1 0.875087\n",
      "pattern2 0 1 1 0.999464\n",
      "pattern3 1 0 -1 -0.855682\n",
      "pattern4 1 1 1 0.901519\n",
      " modified Weights  [-2.63139294  2.7572664 ] 1.3543978614321168\n",
      " Training with pattern  2  weights  [-2.63139294  2.7572664 ] 1.3514406042553617   weights  [-2.63139294  2.75726646]  bias  1.3543979189824769\n",
      "pattern1 0 0 1 0.875087\n",
      "pattern2 0 1 1 0.999464\n",
      "pattern3 1 0 -1 -0.855682\n",
      "pattern4 1 1 1 0.901519\n",
      " modified Weights  [-2.63139294  2.75726646] 1.3543979189824769\n",
      " Training with pattern  3  weights  [-2.63139294  2.7572664 ] 1.3514406042553617   weights  [-2.63525788  2.75726646]  bias  1.3505329744828842\n",
      "pattern1 0 0 1 0.874179\n",
      "pattern2 0 1 1 0.999459\n",
      "pattern3 1 0 -1 -0.857739\n",
      "pattern4 1 1 1 0.900061\n",
      " modified Weights  [-2.63525788  2.75726646] 1.3505329744828842\n",
      " Training with pattern  4  weights  [-2.63139294  2.7572664 ] 1.3514406042553617   weights  [-2.63336015  2.75916419]  bias  1.3524307117037413\n",
      "pattern1 0 0 1 0.874626\n",
      "pattern2 0 1 1 0.999463\n",
      "pattern3 1 0 -1 -0.856732\n",
      "pattern4 1 1 1 0.901137\n",
      " modified Weights  [-2.63336015  2.75916419] 1.3524307117037413\n",
      "+++++++++++Epoch  295  cost=  0.04601854433960775\n",
      " Training with pattern  1  weights  [-2.63336015  2.75916419] 1.3524307117037413   weights  [-2.63336015  2.75916419]  bias  1.355377378190988\n",
      "pattern1 0 0 1 0.875317\n",
      "pattern2 0 1 1 0.999467\n",
      "pattern3 1 0 -1 -0.855947\n",
      "pattern4 1 1 1 0.901689\n",
      " modified Weights  [-2.63336015  2.75916419] 1.355377378190988\n",
      " Training with pattern  2  weights  [-2.63336015  2.75916419] 1.3524307117037413   weights  [-2.63336015  2.75916425]  bias  1.3553774350830465\n",
      "pattern1 0 0 1 0.875317\n",
      "pattern2 0 1 1 0.999467\n",
      "pattern3 1 0 -1 -0.855947\n",
      "pattern4 1 1 1 0.901689\n",
      " modified Weights  [-2.63336015  2.75916425] 1.3553774350830465\n",
      " Training with pattern  3  weights  [-2.63336015  2.75916419] 1.3524307117037413   weights  [-2.6372115   2.75916425]  bias  1.3515260848757955\n",
      "pattern1 0 0 1 0.874413\n",
      "pattern2 0 1 1 0.999462\n",
      "pattern3 1 0 -1 -0.857992\n",
      "pattern4 1 1 1 0.900239\n",
      " modified Weights  [-2.6372115   2.75916425] 1.3515260848757955\n",
      " Training with pattern  4  weights  [-2.63336015  2.75916419] 1.3524307117037413   weights  [-2.63532033  2.76105542]  bias  1.3534172513850178\n",
      "pattern1 0 0 1 0.874857\n",
      "pattern2 0 1 1 0.999467\n",
      "pattern3 1 0 -1 -0.856991\n",
      "pattern4 1 1 1 0.901309\n",
      " modified Weights  [-2.63532033  2.76105542] 1.3534172513850178\n",
      "+++++++++++Epoch  296  cost=  0.04585237903156336\n",
      " Training with pattern  1  weights  [-2.63532033  2.76105542] 1.3534172513850178   weights  [-2.63532033  2.76105542]  bias  1.356353401050211\n",
      "pattern1 0 0 1 0.875545\n",
      "pattern2 0 1 1 0.99947\n",
      "pattern3 1 0 -1 -0.856209\n",
      "pattern4 1 1 1 0.901859\n",
      " modified Weights  [-2.63532033  2.76105542] 1.356353401050211\n",
      " Training with pattern  2  weights  [-2.63532033  2.76105542] 1.3534172513850178   weights  [-2.63532033  2.76105547]  bias  1.3563534572937601\n",
      "pattern1 0 0 1 0.875545\n",
      "pattern2 0 1 1 0.99947\n",
      "pattern3 1 0 -1 -0.856209\n",
      "pattern4 1 1 1 0.901859\n",
      " modified Weights  [-2.63532033  2.76105547] 1.3563534572937601\n",
      " Training with pattern  3  weights  [-2.63532033  2.76105542] 1.3534172513850178   weights  [-2.63915818  2.76105547]  bias  1.3525156082242222\n",
      "pattern1 0 0 1 0.874646\n",
      "pattern2 0 1 1 0.999466\n",
      "pattern3 1 0 -1 -0.858245\n",
      "pattern4 1 1 1 0.900416\n",
      " modified Weights  [-2.63915818  2.76105547] 1.3525156082242222\n",
      " Training with pattern  4  weights  [-2.63532033  2.76105542] 1.3534172513850178   weights  [-2.63727354  2.76294011]  bias  1.3544002483473014\n",
      "pattern1 0 0 1 0.875088\n",
      "pattern2 0 1 1 0.99947\n",
      "pattern3 1 0 -1 -0.857249\n",
      "pattern4 1 1 1 0.901481\n",
      " modified Weights  [-2.63727354  2.76294011] 1.3544002483473014\n",
      "+++++++++++Epoch  297  cost=  0.04568737488056232\n",
      " Training with pattern  1  weights  [-2.63727354  2.76294011] 1.3544002483473014   weights  [-2.63727354  2.76294011]  bias  1.3573259542968104\n",
      "pattern1 0 0 1 0.875771\n",
      "pattern2 0 1 1 0.999473\n",
      "pattern3 1 0 -1 -0.856471\n",
      "pattern4 1 1 1 0.902027\n",
      " modified Weights  [-2.63727354  2.76294011] 1.3573259542968104\n",
      " Training with pattern  2  weights  [-2.63727354  2.76294011] 1.3544002483473014   weights  [-2.63727354  2.76294017]  bias  1.3573260099014635\n",
      "pattern1 0 0 1 0.875771\n",
      "pattern2 0 1 1 0.999473\n",
      "pattern3 1 0 -1 -0.856471\n",
      "pattern4 1 1 1 0.902027\n",
      " modified Weights  [-2.63727354  2.76294017] 1.3573260099014635\n",
      " Training with pattern  3  weights  [-2.63727354  2.76294011] 1.3544002483473014   weights  [-2.64109798  2.76294017]  bias  1.3535015697580937\n",
      "pattern1 0 0 1 0.874877\n",
      "pattern2 0 1 1 0.999469\n",
      "pattern3 1 0 -1 -0.858496\n",
      "pattern4 1 1 1 0.900592\n",
      " modified Weights  [-2.64109798  2.76294017] 1.3535015697580937\n",
      " Training with pattern  4  weights  [-2.63727354  2.76294011] 1.3544002483473014   weights  [-2.63921982  2.76481833]  bias  1.3553797273788812\n",
      "pattern1 0 0 1 0.875317\n",
      "pattern2 0 1 1 0.999473\n",
      "pattern3 1 0 -1 -0.857505\n",
      "pattern4 1 1 1 0.901651\n",
      " modified Weights  [-2.63921982  2.76481833] 1.3553797273788812\n",
      "+++++++++++Epoch  298  cost=  0.04552351993524527\n",
      " Training with pattern  1  weights  [-2.63921982  2.76481833] 1.3553797273788812   weights  [-2.63921982  2.76481833]  bias  1.3582950619683298\n",
      "pattern1 0 0 1 0.875997\n",
      "pattern2 0 1 1 0.999476\n",
      "pattern3 1 0 -1 -0.856731\n",
      "pattern4 1 1 1 0.902195\n",
      " modified Weights  [-2.63921982  2.76481833] 1.3582950619683298\n",
      " Training with pattern  2  weights  [-2.63921982  2.76481833] 1.3553797273788812   weights  [-2.63921982  2.76481838]  bias  1.3582951169435256\n",
      "pattern1 0 0 1 0.875997\n",
      "pattern2 0 1 1 0.999476\n",
      "pattern3 1 0 -1 -0.856731\n",
      "pattern4 1 1 1 0.902195\n",
      " modified Weights  [-2.63921982  2.76481838] 1.3582951169435256\n",
      " Training with pattern  3  weights  [-2.63921982  2.76481833] 1.3553797273788812   weights  [-2.64303094  2.76481838]  bias  1.354483994445272\n",
      "pattern1 0 0 1 0.875108\n",
      "pattern2 0 1 1 0.999472\n",
      "pattern3 1 0 -1 -0.858746\n",
      "pattern4 1 1 1 0.900767\n",
      " modified Weights  [-2.64303094  2.76481838] 1.354483994445272\n",
      " Training with pattern  4  weights  [-2.63921982  2.76481833] 1.3553797273788812   weights  [-2.64115922  2.7666901 ]  bias  1.356355713011779\n",
      "pattern1 0 0 1 0.875545\n",
      "pattern2 0 1 1 0.999476\n",
      "pattern3 1 0 -1 -0.857759\n",
      "pattern4 1 1 1 0.901821\n",
      " modified Weights  [-2.64115922  2.7666901 ] 1.356355713011779\n",
      "+++++++++++Epoch  299  cost=  0.04536080240619306\n",
      " Training with pattern  1  weights  [-2.64115922  2.7666901 ] 1.356355713011779   weights  [-2.64115922  2.7666901 ]  bias  1.3592607478562129\n",
      "pattern1 0 0 1 0.876221\n",
      "pattern2 0 1 1 0.999479\n",
      "pattern3 1 0 -1 -0.85699\n",
      "pattern4 1 1 1 0.902362\n",
      " modified Weights  [-2.64115922  2.7666901 ] 1.3592607478562129\n",
      " Training with pattern  2  weights  [-2.64115922  2.7666901 ] 1.356355713011779   weights  [-2.64115922  2.76669015]  bias  1.3592608022112185\n",
      "pattern1 0 0 1 0.876222\n",
      "pattern2 0 1 1 0.999479\n",
      "pattern3 1 0 -1 -0.85699\n",
      "pattern4 1 1 1 0.902362\n",
      " modified Weights  [-2.64115922  2.76669015] 1.3592608022112185\n",
      " Training with pattern  3  weights  [-2.64115922  2.7666901 ] 1.356355713011779   weights  [-2.64495712  2.76669015]  bias  1.3554629069951392\n",
      "pattern1 0 0 1 0.875337\n",
      "pattern2 0 1 1 0.999475\n",
      "pattern3 1 0 -1 -0.858994\n",
      "pattern4 1 1 1 0.900941\n",
      " modified Weights  [-2.64495712  2.76669015] 1.3554629069951392\n",
      " Training with pattern  4  weights  [-2.64115922  2.7666901 ] 1.356355713011779   weights  [-2.6430918   2.76855548]  bias  1.3573282295252422\n",
      "pattern1 0 0 1 0.875772\n",
      "pattern2 0 1 1 0.999479\n",
      "pattern3 1 0 -1 -0.858013\n",
      "pattern4 1 1 1 0.90199\n",
      " modified Weights  [-2.6430918   2.76855548] 1.3573282295252422\n",
      "+++++++++++Epoch  300  cost=  0.045199210663211496\n",
      " Training with pattern  1  weights  [-2.6430918   2.76855548] 1.3573282295252422   weights  [-2.6430918   2.76855548]  bias  1.3602230355091252\n",
      "pattern1 0 0 1 0.876445\n",
      "pattern2 0 1 1 0.999482\n",
      "pattern3 1 0 -1 -0.857247\n",
      "pattern4 1 1 1 0.902528\n",
      " modified Weights  [-2.6430918   2.76855548] 1.3602230355091252\n",
      " Training with pattern  2  weights  [-2.6430918   2.76855548] 1.3573282295252422   weights  [-2.6430918   2.76855553]  bias  1.3602230892530407\n",
      "pattern1 0 0 1 0.876445\n",
      "pattern2 0 1 1 0.999482\n",
      "pattern3 1 0 -1 -0.857247\n",
      "pattern4 1 1 1 0.902528\n",
      " modified Weights  [-2.6430918   2.76855553] 1.3602230892530407\n",
      " Training with pattern  3  weights  [-2.6430918   2.76855548] 1.3573282295252422   weights  [-2.64687655  2.76855553]  bias  1.3564383318621258\n",
      "pattern1 0 0 1 0.875564\n",
      "pattern2 0 1 1 0.999478\n",
      "pattern3 1 0 -1 -0.859241\n",
      "pattern4 1 1 1 0.901115\n",
      " modified Weights  [-2.64687655  2.76855553] 1.3564383318621258\n",
      " Training with pattern  4  weights  [-2.6430918   2.76855548] 1.3573282295252422   weights  [-2.64501759  2.7704145 ]  bias  1.3582973009491808\n",
      "pattern1 0 0 1 0.875998\n",
      "pattern2 0 1 1 0.999481\n",
      "pattern3 1 0 -1 -0.858265\n",
      "pattern4 1 1 1 0.902158\n",
      " modified Weights  [-2.64501759  2.7704145 ] 1.3582973009491808\n",
      "+++++++++++Epoch  301  cost=  0.0450387332326695\n",
      " *********Epoch  300 Error  0.0450387332326695\n",
      " Training with pattern  1  weights  [-2.64501759  2.7704145 ] 1.3582973009491808   weights  [-2.64501759  2.7704145 ]  bias  1.3611819482362224\n",
      "pattern1 0 0 1 0.876667\n",
      "pattern2 0 1 1 0.999484\n",
      "pattern3 1 0 -1 -0.857504\n",
      "pattern4 1 1 1 0.902693\n",
      " modified Weights  [-2.64501759  2.7704145 ] 1.3611819482362224\n",
      " Training with pattern  2  weights  [-2.64501759  2.7704145 ] 1.3582973009491808   weights  [-2.64501759  2.77041455]  bias  1.361182001377984\n",
      "pattern1 0 0 1 0.876667\n",
      "pattern2 0 1 1 0.999484\n",
      "pattern3 1 0 -1 -0.857503\n",
      "pattern4 1 1 1 0.902693\n",
      " modified Weights  [-2.64501759  2.77041455] 1.361182001377984\n",
      " Training with pattern  3  weights  [-2.64501759  2.7704145 ] 1.3582973009491808   weights  [-2.64878929  2.77041455]  bias  1.3574102932491776\n",
      "pattern1 0 0 1 0.875791\n",
      "pattern2 0 1 1 0.999481\n",
      "pattern3 1 0 -1 -0.859487\n",
      "pattern4 1 1 1 0.901287\n",
      " modified Weights  [-2.64878929  2.77041455] 1.3574102932491776\n",
      " Training with pattern  4  weights  [-2.64501759  2.7704145 ] 1.3582973009491808   weights  [-2.64693664  2.77226721]  bias  1.3592629510675427\n",
      "pattern1 0 0 1 0.876222\n",
      "pattern2 0 1 1 0.999484\n",
      "pattern3 1 0 -1 -0.858516\n",
      "pattern4 1 1 1 0.902325\n",
      " modified Weights  [-2.64693664  2.77226721] 1.3592629510675427\n",
      "+++++++++++Epoch  302  cost=  0.04487935879489048\n",
      " Training with pattern  1  weights  [-2.64693664  2.77226721] 1.3592629510675427   weights  [-2.64693664  2.77226721]  bias  1.3621375091103651\n",
      "pattern1 0 0 1 0.876888\n",
      "pattern2 0 1 1 0.999487\n",
      "pattern3 1 0 -1 -0.857758\n",
      "pattern4 1 1 1 0.902858\n",
      " modified Weights  [-2.64693664  2.77226721] 1.3621375091103651\n",
      " Training with pattern  2  weights  [-2.64693664  2.77226721] 1.3592629510675427   weights  [-2.64693664  2.77226726]  bias  1.3621375616587486\n",
      "pattern1 0 0 1 0.876888\n",
      "pattern2 0 1 1 0.999487\n",
      "pattern3 1 0 -1 -0.857758\n",
      "pattern4 1 1 1 0.902858\n",
      " modified Weights  [-2.64693664  2.77226726] 1.3621375616587486\n",
      " Training with pattern  3  weights  [-2.64693664  2.77226721] 1.3592629510675427   weights  [-2.65069538  2.77226726]  bias  1.3583788151111662\n",
      "pattern1 0 0 1 0.876017\n",
      "pattern2 0 1 1 0.999483\n",
      "pattern3 1 0 -1 -0.859732\n",
      "pattern4 1 1 1 0.901459\n",
      " modified Weights  [-2.65069538  2.77226726] 1.3583788151111662\n",
      " Training with pattern  4  weights  [-2.64693664  2.77226721] 1.3592629510675427   weights  [-2.64884899  2.77411365]  bias  1.3602252034216353\n",
      "pattern1 0 0 1 0.876445\n",
      "pattern2 0 1 1 0.999487\n",
      "pattern3 1 0 -1 -0.858766\n",
      "pattern4 1 1 1 0.902491\n",
      " modified Weights  [-2.64884899  2.77411365] 1.3602252034216353\n",
      "+++++++++++Epoch  303  cost=  0.044721076181595716\n",
      " Training with pattern  1  weights  [-2.64884899  2.77411365] 1.3602252034216353   weights  [-2.64884899  2.77411365]  bias  1.3630897409712766\n",
      "pattern1 0 0 1 0.877108\n",
      "pattern2 0 1 1 0.99949\n",
      "pattern3 1 0 -1 -0.858012\n",
      "pattern4 1 1 1 0.903021\n",
      " modified Weights  [-2.64884899  2.77411365] 1.3630897409712766\n",
      " Training with pattern  2  weights  [-2.64884899  2.77411365] 1.3602252034216353   weights  [-2.64884899  2.7741137 ]  bias  1.3630897929349006\n",
      "pattern1 0 0 1 0.877108\n",
      "pattern2 0 1 1 0.99949\n",
      "pattern3 1 0 -1 -0.858012\n",
      "pattern4 1 1 1 0.903022\n",
      " modified Weights  [-2.64884899  2.7741137 ] 1.3630897929349006\n",
      " Training with pattern  3  weights  [-2.64884899  2.77411365] 1.3602252034216353   weights  [-2.65259487  2.7741137 ]  bias  1.35934392115824\n",
      "pattern1 0 0 1 0.876241\n",
      "pattern2 0 1 1 0.999486\n",
      "pattern3 1 0 -1 -0.859976\n",
      "pattern4 1 1 1 0.90163\n",
      " modified Weights  [-2.65259487  2.7741137 ] 1.35934392115824\n",
      " Training with pattern  4  weights  [-2.64884899  2.77411365] 1.3602252034216353   weights  [-2.65075471  2.77595386]  bias  1.36118408131339\n",
      "pattern1 0 0 1 0.876667\n",
      "pattern2 0 1 1 0.99949\n",
      "pattern3 1 0 -1 -0.859014\n",
      "pattern4 1 1 1 0.902657\n",
      " modified Weights  [-2.65075471  2.77595386] 1.36118408131339\n",
      "+++++++++++Epoch  304  cost=  0.04456387437339804\n",
      " Training with pattern  1  weights  [-2.65075471  2.77595386] 1.36118408131339   weights  [-2.65075471  2.77595386]  bias  1.3640386664286512\n",
      "pattern1 0 0 1 0.877326\n",
      "pattern2 0 1 1 0.999493\n",
      "pattern3 1 0 -1 -0.858264\n",
      "pattern4 1 1 1 0.903184\n",
      " modified Weights  [-2.65075471  2.77595386] 1.3640386664286512\n",
      " Training with pattern  2  weights  [-2.65075471  2.77595386] 1.36118408131339   weights  [-2.65075471  2.77595392]  bias  1.364038717815981\n",
      "pattern1 0 0 1 0.877326\n",
      "pattern2 0 1 1 0.999493\n",
      "pattern3 1 0 -1 -0.858264\n",
      "pattern4 1 1 1 0.903184\n",
      " modified Weights  [-2.65075471  2.77595392] 1.364038717815981\n",
      " Training with pattern  3  weights  [-2.65075471  2.77595386] 1.36118408131339   weights  [-2.65448779  2.77595392]  bias  1.3603056348591211\n",
      "pattern1 0 0 1 0.876464\n",
      "pattern2 0 1 1 0.999489\n",
      "pattern3 1 0 -1 -0.860218\n",
      "pattern4 1 1 1 0.901799\n",
      " modified Weights  [-2.65448779  2.77595392] 1.3603056348591211\n",
      " Training with pattern  4  weights  [-2.65075471  2.77595386] 1.36118408131339   weights  [-2.65265382  2.77778789]  bias  1.3621396078085717\n",
      "pattern1 0 0 1 0.876888\n",
      "pattern2 0 1 1 0.999493\n",
      "pattern3 1 0 -1 -0.859261\n",
      "pattern4 1 1 1 0.902822\n",
      " modified Weights  [-2.65265382  2.77778789] 1.3621396078085717\n",
      "+++++++++++Epoch  305  cost=  0.04440774249734502\n",
      " Training with pattern  1  weights  [-2.65265382  2.77778789] 1.3621396078085717   weights  [-2.65265382  2.77778789]  bias  1.3649843078652109\n",
      "pattern1 0 0 1 0.877544\n",
      "pattern2 0 1 1 0.999496\n",
      "pattern3 1 0 -1 -0.858515\n",
      "pattern4 1 1 1 0.903347\n",
      " modified Weights  [-2.65265382  2.77778789] 1.3649843078652109\n",
      " Training with pattern  2  weights  [-2.65265382  2.77778789] 1.3621396078085717   weights  [-2.65265382  2.77778794]  bias  1.3649843586845611\n",
      "pattern1 0 0 1 0.877544\n",
      "pattern2 0 1 1 0.999496\n",
      "pattern3 1 0 -1 -0.858515\n",
      "pattern4 1 1 1 0.903347\n",
      " modified Weights  [-2.65265382  2.77778794] 1.3649843586845611\n",
      " Training with pattern  3  weights  [-2.65265382  2.77778789] 1.3621396078085717   weights  [-2.65637419  2.77778794]  bias  1.3612639794443462\n",
      "pattern1 0 0 1 0.876686\n",
      "pattern2 0 1 1 0.999492\n",
      "pattern3 1 0 -1 -0.860459\n",
      "pattern4 1 1 1 0.901968\n",
      " modified Weights  [-2.65637419  2.77778794] 1.3612639794443462\n",
      " Training with pattern  4  weights  [-2.65265382  2.77778789] 1.3621396078085717   weights  [-2.65454637  2.77961577]  bias  1.363091805739938\n",
      "pattern1 0 0 1 0.877108\n",
      "pattern2 0 1 1 0.999496\n",
      "pattern3 1 0 -1 -0.859507\n",
      "pattern4 1 1 1 0.902986\n",
      " modified Weights  [-2.65454637  2.77961577] 1.363091805739938\n",
      "+++++++++++Epoch  306  cost=  0.04425266982451043\n",
      " Training with pattern  1  weights  [-2.65454637  2.77961577] 1.363091805739938   weights  [-2.65454637  2.77961577]  bias  1.3659266874397105\n",
      "pattern1 0 0 1 0.877761\n",
      "pattern2 0 1 1 0.999499\n",
      "pattern3 1 0 -1 -0.858765\n",
      "pattern4 1 1 1 0.903508\n",
      " modified Weights  [-2.65454637  2.77961577] 1.3659266874397105\n",
      " Training with pattern  2  weights  [-2.65454637  2.77961577] 1.363091805739938   weights  [-2.65454637  2.77961582]  bias  1.3659267376992485\n",
      "pattern1 0 0 1 0.877761\n",
      "pattern2 0 1 1 0.999499\n",
      "pattern3 1 0 -1 -0.858765\n",
      "pattern4 1 1 1 0.903508\n",
      " modified Weights  [-2.65454637  2.77961582] 1.3659267376992485\n",
      " Training with pattern  3  weights  [-2.65454637  2.77961577] 1.363091805739938   weights  [-2.65825413  2.77961582]  bias  1.3622189779094536\n",
      "pattern1 0 0 1 0.876907\n",
      "pattern2 0 1 1 0.999495\n",
      "pattern3 1 0 -1 -0.860699\n",
      "pattern4 1 1 1 0.902137\n",
      " modified Weights  [-2.65825413  2.77961582] 1.3622189779094536\n",
      " Training with pattern  4  weights  [-2.65454637  2.77961577] 1.363091805739938   weights  [-2.65643241  2.78143754]  bias  1.3640406977103423\n",
      "pattern1 0 0 1 0.877327\n",
      "pattern2 0 1 1 0.999499\n",
      "pattern3 1 0 -1 -0.859752\n",
      "pattern4 1 1 1 0.903149\n",
      " modified Weights  [-2.65643241  2.78143754] 1.3640406977103423\n",
      "+++++++++++Epoch  307  cost=  0.04409864576763211\n",
      " Training with pattern  1  weights  [-2.65643241  2.78143754] 1.3640406977103423   weights  [-2.65643241  2.78143754]  bias  1.3668658270898946\n",
      "pattern1 0 0 1 0.877976\n",
      "pattern2 0 1 1 0.999501\n",
      "pattern3 1 0 -1 -0.859013\n",
      "pattern4 1 1 1 0.903668\n",
      " modified Weights  [-2.65643241  2.78143754] 1.3668658270898946\n",
      " Training with pattern  2  weights  [-2.65643241  2.78143754] 1.3640406977103423   weights  [-2.65643241  2.78143758]  bias  1.366865876797644\n",
      "pattern1 0 0 1 0.877976\n",
      "pattern2 0 1 1 0.999501\n",
      "pattern3 1 0 -1 -0.859013\n",
      "pattern4 1 1 1 0.903668\n",
      " modified Weights  [-2.65643241  2.78143758] 1.366865876797644\n",
      " Training with pattern  3  weights  [-2.65643241  2.78143754] 1.3640406977103423   weights  [-2.66012763  2.78143758]  bias  1.363170653018118\n",
      "pattern1 0 0 1 0.877126\n",
      "pattern2 0 1 1 0.999498\n",
      "pattern3 1 0 -1 -0.860938\n",
      "pattern4 1 1 1 0.902304\n",
      " modified Weights  [-2.66012763  2.78143758] 1.363170653018118\n",
      " Training with pattern  4  weights  [-2.65643241  2.78143754] 1.3640406977103423   weights  [-2.65831198  2.78325324]  bias  1.3649863060957885\n",
      "pattern1 0 0 1 0.877545\n",
      "pattern2 0 1 1 0.999501\n",
      "pattern3 1 0 -1 -0.859995\n",
      "pattern4 1 1 1 0.903311\n",
      " modified Weights  [-2.65831198  2.78325324] 1.3649863060957885\n",
      "+++++++++++Epoch  308  cost=  0.04394565987879755\n",
      " Training with pattern  1  weights  [-2.65831198  2.78325324] 1.3649863060957885   weights  [-2.65831198  2.78325324]  bias  1.3678017485354057\n",
      "pattern1 0 0 1 0.87819\n",
      "pattern2 0 1 1 0.999504\n",
      "pattern3 1 0 -1 -0.85926\n",
      "pattern4 1 1 1 0.903828\n",
      " modified Weights  [-2.65831198  2.78325324] 1.3678017485354057\n",
      " Training with pattern  2  weights  [-2.65831198  2.78325324] 1.3649863060957885   weights  [-2.65831198  2.78325329]  bias  1.3678017976992487\n",
      "pattern1 0 0 1 0.87819\n",
      "pattern2 0 1 1 0.999504\n",
      "pattern3 1 0 -1 -0.85926\n",
      "pattern4 1 1 1 0.903828\n",
      " modified Weights  [-2.65831198  2.78325329] 1.3678017976992487\n",
      " Training with pattern  3  weights  [-2.65831198  2.78325324] 1.3649863060957885   weights  [-2.66199475  2.78325329]  bias  1.3641190273052326\n",
      "pattern1 0 0 1 0.877345\n",
      "pattern2 0 1 1 0.9995\n",
      "pattern3 1 0 -1 -0.861175\n",
      "pattern4 1 1 1 0.902471\n",
      " modified Weights  [-2.66199475  2.78325329] 1.3641190273052326\n",
      " Training with pattern  4  weights  [-2.65831198  2.78325324] 1.3649863060957885   weights  [-2.66018512  2.78506291]  bias  1.365928653048433\n",
      "pattern1 0 0 1 0.877761\n",
      "pattern2 0 1 1 0.999504\n",
      "pattern3 1 0 -1 -0.860237\n",
      "pattern4 1 1 1 0.903473\n",
      " modified Weights  [-2.66018512  2.78506291] 1.365928653048433\n",
      "+++++++++++Epoch  309  cost=  0.04379370184717266\n",
      " Training with pattern  1  weights  [-2.66018512  2.78506291] 1.365928653048433   weights  [-2.66018512  2.78506291]  bias  1.3687344732806446\n",
      "pattern1 0 0 1 0.878403\n",
      "pattern2 0 1 1 0.999507\n",
      "pattern3 1 0 -1 -0.859506\n",
      "pattern4 1 1 1 0.903987\n",
      " modified Weights  [-2.66018512  2.78506291] 1.3687344732806446\n",
      " Training with pattern  2  weights  [-2.66018512  2.78506291] 1.365928653048433   weights  [-2.66018512  2.78506296]  bias  1.368734521908325\n",
      "pattern1 0 0 1 0.878403\n",
      "pattern2 0 1 1 0.999507\n",
      "pattern3 1 0 -1 -0.859506\n",
      "pattern4 1 1 1 0.903987\n",
      " modified Weights  [-2.66018512  2.78506296] 1.368734521908325\n",
      " Training with pattern  3  weights  [-2.66018512  2.78506291] 1.365928653048433   weights  [-2.66385552  2.78506296]  bias  1.3650641230799412\n",
      "pattern1 0 0 1 0.877562\n",
      "pattern2 0 1 1 0.999503\n",
      "pattern3 1 0 -1 -0.861412\n",
      "pattern4 1 1 1 0.902636\n",
      " modified Weights  [-2.66385552  2.78506296] 1.3650641230799412\n",
      " Training with pattern  4  weights  [-2.66018512  2.78506291] 1.365928653048433   weights  [-2.66205189  2.7868666 ]  bias  1.3668677604995396\n",
      "pattern1 0 0 1 0.877976\n",
      "pattern2 0 1 1 0.999507\n",
      "pattern3 1 0 -1 -0.860478\n",
      "pattern4 1 1 1 0.903634\n",
      " modified Weights  [-2.66205189  2.7868666 ] 1.3668677604995396\n",
      "+++++++++++Epoch  310  cost=  0.043642761496776\n",
      " Training with pattern  1  weights  [-2.66205189  2.7868666 ] 1.3668677604995396   weights  [-2.66205189  2.7868666 ]  bias  1.3696640226175845\n",
      "pattern1 0 0 1 0.878616\n",
      "pattern2 0 1 1 0.99951\n",
      "pattern3 1 0 -1 -0.859751\n",
      "pattern4 1 1 1 0.904146\n",
      " modified Weights  [-2.66205189  2.7868666 ] 1.3696640226175845\n",
      " Training with pattern  2  weights  [-2.66205189  2.7868666 ] 1.3668677604995396   weights  [-2.66205189  2.78686665]  bias  1.3696640707167107\n",
      "pattern1 0 0 1 0.878616\n",
      "pattern2 0 1 1 0.99951\n",
      "pattern3 1 0 -1 -0.859751\n",
      "pattern4 1 1 1 0.904146\n",
      " modified Weights  [-2.66205189  2.78686665] 1.3696640707167107\n",
      " Training with pattern  3  weights  [-2.66205189  2.7868666 ] 1.3668677604995396   weights  [-2.66570999  2.78686665]  bias  1.3660059624286198\n",
      "pattern1 0 0 1 0.877779\n",
      "pattern2 0 1 1 0.999506\n",
      "pattern3 1 0 -1 -0.861647\n",
      "pattern4 1 1 1 0.902801\n",
      " modified Weights  [-2.66570999  2.78686665] 1.3660059624286198\n",
      " Training with pattern  4  weights  [-2.66205189  2.7868666 ] 1.3668677604995396   weights  [-2.66391231  2.78866433]  bias  1.3678036501623854\n",
      "pattern1 0 0 1 0.878191\n",
      "pattern2 0 1 1 0.999509\n",
      "pattern3 1 0 -1 -0.860718\n",
      "pattern4 1 1 1 0.903794\n",
      " modified Weights  [-2.66391231  2.78866433] 1.3678036501623854\n",
      "+++++++++++Epoch  311  cost=  0.04349282878429525\n",
      " *********Epoch  310 Error  0.04349282878429525\n",
      " Training with pattern  1  weights  [-2.66391231  2.78866433] 1.3678036501623854   weights  [-2.66391231  2.78866433]  bias  1.3705904176285402\n",
      "pattern1 0 0 1 0.878827\n",
      "pattern2 0 1 1 0.999512\n",
      "pattern3 1 0 -1 -0.859994\n",
      "pattern4 1 1 1 0.904303\n",
      " modified Weights  [-2.66391231  2.78866433] 1.3705904176285402\n",
      " Training with pattern  2  weights  [-2.66391231  2.78866433] 1.3678036501623854   weights  [-2.66391231  2.78866438]  bias  1.3705904652065886\n",
      "pattern1 0 0 1 0.878827\n",
      "pattern2 0 1 1 0.999512\n",
      "pattern3 1 0 -1 -0.859994\n",
      "pattern4 1 1 1 0.904303\n",
      " modified Weights  [-2.66391231  2.78866438] 1.3705904652065886\n",
      " Training with pattern  3  weights  [-2.66391231  2.78866433] 1.3678036501623854   weights  [-2.6675582   2.78866438]  bias  1.366944567217811\n",
      "pattern1 0 0 1 0.877994\n",
      "pattern2 0 1 1 0.999509\n",
      "pattern3 1 0 -1 -0.861881\n",
      "pattern4 1 1 1 0.902965\n",
      " modified Weights  [-2.6675582   2.78866438] 1.366944567217811\n",
      " Training with pattern  4  weights  [-2.66391231  2.78866433] 1.3678036501623854   weights  [-2.66576643  2.79045616]  bias  1.3687363435351187\n",
      "pattern1 0 0 1 0.878404\n",
      "pattern2 0 1 1 0.999512\n",
      "pattern3 1 0 -1 -0.860957\n",
      "pattern4 1 1 1 0.903953\n",
      " modified Weights  [-2.66576643  2.79045616] 1.3687363435351187\n",
      "+++++++++++Epoch  312  cost=  0.04334389379694589\n",
      " Training with pattern  1  weights  [-2.66576643  2.79045616] 1.3687363435351187   weights  [-2.66576643  2.79045616]  bias  1.3715136791888922\n",
      "pattern1 0 0 1 0.879037\n",
      "pattern2 0 1 1 0.999515\n",
      "pattern3 1 0 -1 -0.860236\n",
      "pattern4 1 1 1 0.90446\n",
      " modified Weights  [-2.66576643  2.79045616] 1.3715136791888922\n",
      " Training with pattern  2  weights  [-2.66576643  2.79045616] 1.3687363435351187   weights  [-2.66576643  2.79045621]  bias  1.371513726253209\n",
      "pattern1 0 0 1 0.879037\n",
      "pattern2 0 1 1 0.999515\n",
      "pattern3 1 0 -1 -0.860236\n",
      "pattern4 1 1 1 0.90446\n",
      " modified Weights  [-2.66576643  2.79045621] 1.371513726253209\n",
      " Training with pattern  3  weights  [-2.66576643  2.79045616] 1.3687363435351187   weights  [-2.66940019  2.79045621]  bias  1.3678799590971087\n",
      "pattern1 0 0 1 0.878208\n",
      "pattern2 0 1 1 0.999511\n",
      "pattern3 1 0 -1 -0.862114\n",
      "pattern4 1 1 1 0.903129\n",
      " modified Weights  [-2.66940019  2.79045621] 1.3678799590971087\n",
      " Training with pattern  4  weights  [-2.66576643  2.79045616] 1.3687363435351187   weights  [-2.66761429  2.79224211]  bias  1.369665861903571\n",
      "pattern1 0 0 1 0.878616\n",
      "pattern2 0 1 1 0.999515\n",
      "pattern3 1 0 -1 -0.861194\n",
      "pattern4 1 1 1 0.904112\n",
      " modified Weights  [-2.66761429  2.79224211] 1.369665861903571\n",
      "+++++++++++Epoch  313  cost=  0.04319594675037138\n",
      " Training with pattern  1  weights  [-2.66761429  2.79224211] 1.369665861903571   weights  [-2.66761429  2.79224211]  bias  1.3724338279697659\n",
      "pattern1 0 0 1 0.879246\n",
      "pattern2 0 1 1 0.999517\n",
      "pattern3 1 0 -1 -0.860477\n",
      "pattern4 1 1 1 0.904616\n",
      " modified Weights  [-2.66761429  2.79224211] 1.3724338279697659\n",
      " Training with pattern  2  weights  [-2.66761429  2.79224211] 1.369665861903571   weights  [-2.66761429  2.79224216]  bias  1.3724338745275702\n",
      "pattern1 0 0 1 0.879246\n",
      "pattern2 0 1 1 0.999517\n",
      "pattern3 1 0 -1 -0.860477\n",
      "pattern4 1 1 1 0.904616\n",
      " modified Weights  [-2.66761429  2.79224216] 1.3724338745275702\n",
      " Training with pattern  3  weights  [-2.66761429  2.79224211] 1.369665861903571   weights  [-2.67123601  2.79224216]  bias  1.3688121595019953\n",
      "pattern1 0 0 1 0.878421\n",
      "pattern2 0 1 1 0.999514\n",
      "pattern3 1 0 -1 -0.862346\n",
      "pattern4 1 1 1 0.903291\n",
      " modified Weights  [-2.67123601  2.79224216] 1.3688121595019953\n",
      " Training with pattern  4  weights  [-2.66761429  2.79224211] 1.369665861903571   weights  [-2.66945594  2.79402222]  bias  1.3705922263440236\n",
      "pattern1 0 0 1 0.878827\n",
      "pattern2 0 1 1 0.999517\n",
      "pattern3 1 0 -1 -0.86143\n",
      "pattern4 1 1 1 0.90427\n",
      " modified Weights  [-2.66945594  2.79402222] 1.3705922263440236\n",
      "+++++++++++Epoch  314  cost=  0.043048977986583185\n",
      " Training with pattern  1  weights  [-2.66945594  2.79402222] 1.3705922263440236   weights  [-2.66945594  2.79402222]  bias  1.3733508844406686\n",
      "pattern1 0 0 1 0.879454\n",
      "pattern2 0 1 1 0.99952\n",
      "pattern3 1 0 -1 -0.860717\n",
      "pattern4 1 1 1 0.904771\n",
      " modified Weights  [-2.66945594  2.79402222] 1.3733508844406686\n",
      " Training with pattern  2  weights  [-2.66945594  2.79402222] 1.3705922263440236   weights  [-2.66945594  2.79402227]  bias  1.3733509304990548\n",
      "pattern1 0 0 1 0.879454\n",
      "pattern2 0 1 1 0.99952\n",
      "pattern3 1 0 -1 -0.860717\n",
      "pattern4 1 1 1 0.904771\n",
      " modified Weights  [-2.66945594  2.79402227] 1.3733509304990548\n",
      " Training with pattern  3  weights  [-2.66945594  2.79402222] 1.3705922263440236   weights  [-2.67306568  2.79402227]  bias  1.3697411896566367\n",
      "pattern1 0 0 1 0.878633\n",
      "pattern2 0 1 1 0.999517\n",
      "pattern3 1 0 -1 -0.862577\n",
      "pattern4 1 1 1 0.903453\n",
      " modified Weights  [-2.67306568  2.79402227] 1.3697411896566367\n",
      " Training with pattern  4  weights  [-2.66945594  2.79402222] 1.3705922263440236   weights  [-2.67129141  2.79579654]  bias  1.3715154577259283\n",
      "pattern1 0 0 1 0.879037\n",
      "pattern2 0 1 1 0.99952\n",
      "pattern3 1 0 -1 -0.861665\n",
      "pattern4 1 1 1 0.904427\n",
      " modified Weights  [-2.67129141  2.79579654] 1.3715154577259283\n",
      "+++++++++++Epoch  315  cost=  0.042902977971940114\n",
      " Training with pattern  1  weights  [-2.67129141  2.79579654] 1.3715154577259283   weights  [-2.67129141  2.79579654]  bias  1.3742648688720847\n",
      "pattern1 0 0 1 0.879661\n",
      "pattern2 0 1 1 0.999523\n",
      "pattern3 1 0 -1 -0.860956\n",
      "pattern4 1 1 1 0.904926\n",
      " modified Weights  [-2.67129141  2.79579654] 1.3742648688720847\n",
      " Training with pattern  2  weights  [-2.67129141  2.79579654] 1.3715154577259283   weights  [-2.67129141  2.79579658]  bias  1.3742649144380252\n",
      "pattern1 0 0 1 0.879661\n",
      "pattern2 0 1 1 0.999523\n",
      "pattern3 1 0 -1 -0.860956\n",
      "pattern4 1 1 1 0.904926\n",
      " modified Weights  [-2.67129141  2.79579658] 1.3742649144380252\n",
      " Training with pattern  3  weights  [-2.67129141  2.79579654] 1.3715154577259283   weights  [-2.67488926  2.79579658]  bias  1.3706670705766273\n",
      "pattern1 0 0 1 0.878844\n",
      "pattern2 0 1 1 0.999519\n",
      "pattern3 1 0 -1 -0.862806\n",
      "pattern4 1 1 1 0.903614\n",
      " modified Weights  [-2.67488926  2.79579658] 1.3706670705766273\n",
      " Training with pattern  4  weights  [-2.67129141  2.79579654] 1.3715154577259283   weights  [-2.67312075  2.79756509]  bias  1.3724355767145864\n",
      "pattern1 0 0 1 0.879246\n",
      "pattern2 0 1 1 0.999523\n",
      "pattern3 1 0 -1 -0.861899\n",
      "pattern4 1 1 1 0.904583\n",
      " modified Weights  [-2.67312075  2.79756509] 1.3724355767145864\n",
      "+++++++++++Epoch  316  cost=  0.0427579372951663\n",
      " Training with pattern  1  weights  [-2.67312075  2.79756509] 1.3724355767145864   weights  [-2.67312075  2.79756509]  bias  1.3751758013380295\n",
      "pattern1 0 0 1 0.879866\n",
      "pattern2 0 1 1 0.999525\n",
      "pattern3 1 0 -1 -0.861193\n",
      "pattern4 1 1 1 0.90508\n",
      " modified Weights  [-2.67312075  2.79756509] 1.3751758013380295\n",
      " Training with pattern  2  weights  [-2.67312075  2.79756509] 1.3724355767145864   weights  [-2.67312075  2.79756513]  bias  1.3751758464183776\n",
      "pattern1 0 0 1 0.879866\n",
      "pattern2 0 1 1 0.999525\n",
      "pattern3 1 0 -1 -0.861193\n",
      "pattern4 1 1 1 0.90508\n",
      " modified Weights  [-2.67312075  2.79756513] 1.3751758464183776\n",
      " Training with pattern  3  weights  [-2.67312075  2.79756509] 1.3724355767145864   weights  [-2.67670677  2.79756513]  bias  1.3715898230716956\n",
      "pattern1 0 0 1 0.879054\n",
      "pattern2 0 1 1 0.999522\n",
      "pattern3 1 0 -1 -0.863035\n",
      "pattern4 1 1 1 0.903774\n",
      " modified Weights  [-2.67670677  2.79756513] 1.3715898230716956\n",
      " Training with pattern  4  weights  [-2.67312075  2.79756509] 1.3724355767145864   weights  [-2.67494399  2.79932791]  bias  1.3733526037737838\n",
      "pattern1 0 0 1 0.879454\n",
      "pattern2 0 1 1 0.999525\n",
      "pattern3 1 0 -1 -0.862132\n",
      "pattern4 1 1 1 0.904738\n",
      " modified Weights  [-2.67494399  2.79932791] 1.3733526037737838\n",
      "+++++++++++Epoch  317  cost=  0.04261384666540687\n",
      " Training with pattern  1  weights  [-2.67494399  2.79932791] 1.3733526037737838   weights  [-2.67494399  2.79932791]  bias  1.3760837017185616\n",
      "pattern1 0 0 1 0.880071\n",
      "pattern2 0 1 1 0.999528\n",
      "pattern3 1 0 -1 -0.861429\n",
      "pattern4 1 1 1 0.905233\n",
      " modified Weights  [-2.67494399  2.79932791] 1.3760837017185616\n",
      " Training with pattern  2  weights  [-2.67494399  2.79932791] 1.3733526037737838   weights  [-2.67494399  2.79932796]  bias  1.3760837463200533\n",
      "pattern1 0 0 1 0.880071\n",
      "pattern2 0 1 1 0.999528\n",
      "pattern3 1 0 -1 -0.861429\n",
      "pattern4 1 1 1 0.905233\n",
      " modified Weights  [-2.67494399  2.79932796] 1.3760837463200533\n",
      " Training with pattern  3  weights  [-2.67494399  2.79932791] 1.3733526037737838   weights  [-2.67851827  2.79932796]  bias  1.3725094677483618\n",
      "pattern1 0 0 1 0.879263\n",
      "pattern2 0 1 1 0.999524\n",
      "pattern3 1 0 -1 -0.863262\n",
      "pattern4 1 1 1 0.903934\n",
      " modified Weights  [-2.67851827  2.79932796] 1.3725094677483618\n",
      " Training with pattern  4  weights  [-2.67494399  2.79932791] 1.3733526037737838   weights  [-2.67676118  2.80108505]  bias  1.3742665591683825\n",
      "pattern1 0 0 1 0.879661\n",
      "pattern2 0 1 1 0.999528\n",
      "pattern3 1 0 -1 -0.862364\n",
      "pattern4 1 1 1 0.904893\n",
      " modified Weights  [-2.67676118  2.80108505] 1.3742665591683825\n",
      "+++++++++++Epoch  318  cost=  0.04247069691032014\n",
      " Training with pattern  1  weights  [-2.67676118  2.80108505] 1.3742665591683825   weights  [-2.67676118  2.80108505]  bias  1.3769885897022556\n",
      "pattern1 0 0 1 0.880275\n",
      "pattern2 0 1 1 0.99953\n",
      "pattern3 1 0 -1 -0.861665\n",
      "pattern4 1 1 1 0.905385\n",
      " modified Weights  [-2.67676118  2.80108505] 1.3769885897022556\n",
      " Training with pattern  2  weights  [-2.67676118  2.80108505] 1.3742665591683825   weights  [-2.67676118  2.80108509]  bias  1.3769886338315118\n",
      "pattern1 0 0 1 0.880275\n",
      "pattern2 0 1 1 0.99953\n",
      "pattern3 1 0 -1 -0.861665\n",
      "pattern4 1 1 1 0.905385\n",
      " modified Weights  [-2.67676118  2.80108509] 1.3769886338315118\n",
      " Training with pattern  3  weights  [-2.67676118  2.80108505] 1.3742665591683825   weights  [-2.68032379  2.80108509]  bias  1.3734260250125554\n",
      "pattern1 0 0 1 0.879471\n",
      "pattern2 0 1 1 0.999527\n",
      "pattern3 1 0 -1 -0.863488\n",
      "pattern4 1 1 1 0.904092\n",
      " modified Weights  [-2.68032379  2.80108509] 1.3734260250125554\n",
      " Training with pattern  4  weights  [-2.67676118  2.80108505] 1.3742665591683825   weights  [-2.67857235  2.80283653]  bias  1.3751774629668732\n",
      "pattern1 0 0 1 0.879867\n",
      "pattern2 0 1 1 0.99953\n",
      "pattern3 1 0 -1 -0.862595\n",
      "pattern4 1 1 1 0.905047\n",
      " modified Weights  [-2.67857235  2.80283653] 1.3751774629668732\n",
      "+++++++++++Epoch  319  cost=  0.042328478974205774\n",
      " Training with pattern  1  weights  [-2.67857235  2.80283653] 1.3751774629668732   weights  [-2.67857235  2.80283653]  bias  1.3778904847886366\n",
      "pattern1 0 0 1 0.880478\n",
      "pattern2 0 1 1 0.999533\n",
      "pattern3 1 0 -1 -0.861899\n",
      "pattern4 1 1 1 0.905537\n",
      " modified Weights  [-2.67857235  2.80283653] 1.3778904847886366\n",
      " Training with pattern  2  weights  [-2.67857235  2.80283653] 1.3751774629668732   weights  [-2.67857235  2.80283658]  bias  1.377890528452166\n",
      "pattern1 0 0 1 0.880478\n",
      "pattern2 0 1 1 0.999533\n",
      "pattern3 1 0 -1 -0.861899\n",
      "pattern4 1 1 1 0.905537\n",
      " modified Weights  [-2.67857235  2.80283658] 1.377890528452166\n",
      " Training with pattern  3  weights  [-2.67857235  2.80283653] 1.3751774629668732   weights  [-2.68212336  2.80283658]  bias  1.3743395150721913\n",
      "pattern1 0 0 1 0.879677\n",
      "pattern2 0 1 1 0.999529\n",
      "pattern3 1 0 -1 -0.863714\n",
      "pattern4 1 1 1 0.90425\n",
      " modified Weights  [-2.68212336  2.80283658] 1.3743395150721913\n",
      " Training with pattern  4  weights  [-2.67857235  2.80283653] 1.3751774629668732   weights  [-2.68037754  2.8045824 ]  bias  1.3760853350438849\n",
      "pattern1 0 0 1 0.880072\n",
      "pattern2 0 1 1 0.999533\n",
      "pattern3 1 0 -1 -0.862824\n",
      "pattern4 1 1 1 0.905201\n",
      " modified Weights  [-2.68037754  2.8045824 ] 1.3760853350438849\n",
      "+++++++++++Epoch  320  cost=  0.042187183916168554\n",
      " Training with pattern  1  weights  [-2.68037754  2.8045824 ] 1.3760853350438849   weights  [-2.68037754  2.8045824 ]  bias  1.3787894062905748\n",
      "pattern1 0 0 1 0.88068\n",
      "pattern2 0 1 1 0.999535\n",
      "pattern3 1 0 -1 -0.862131\n",
      "pattern4 1 1 1 0.905688\n",
      " modified Weights  [-2.68037754  2.8045824 ] 1.3787894062905748\n",
      " Training with pattern  2  weights  [-2.68037754  2.8045824 ] 1.3760853350438849   weights  [-2.68037754  2.80458244]  bias  1.3787894494947763\n",
      "pattern1 0 0 1 0.88068\n",
      "pattern2 0 1 1 0.999535\n",
      "pattern3 1 0 -1 -0.862131\n",
      "pattern4 1 1 1 0.905688\n",
      " modified Weights  [-2.68037754  2.80458244] 1.3787894494947763\n",
      " Training with pattern  3  weights  [-2.68037754  2.8045824 ] 1.3760853350438849   weights  [-2.68391704  2.80458244]  bias  1.3752499579397035\n",
      "pattern1 0 0 1 0.879883\n",
      "pattern2 0 1 1 0.999532\n",
      "pattern3 1 0 -1 -0.863938\n",
      "pattern4 1 1 1 0.904407\n",
      " modified Weights  [-2.68391704  2.80458244] 1.3752499579397035\n",
      " Training with pattern  4  weights  [-2.68037754  2.8045824 ] 1.3760853350438849   weights  [-2.6821768   2.80632268]  bias  1.3769901950826573\n",
      "pattern1 0 0 1 0.880276\n",
      "pattern2 0 1 1 0.999535\n",
      "pattern3 1 0 -1 -0.863052\n",
      "pattern4 1 1 1 0.905353\n",
      " modified Weights  [-2.6821768   2.80632268] 1.3769901950826573\n",
      "+++++++++++Epoch  321  cost=  0.042046802908316146\n",
      " *********Epoch  320 Error  0.042046802908316146\n",
      " Training with pattern  1  weights  [-2.6821768   2.80632268] 1.3769901950826573   weights  [-2.6821768   2.80632268]  bias  1.3796853733366445\n",
      "pattern1 0 0 1 0.880881\n",
      "pattern2 0 1 1 0.999538\n",
      "pattern3 1 0 -1 -0.862363\n",
      "pattern4 1 1 1 0.905838\n",
      " modified Weights  [-2.6821768   2.80632268] 1.3796853733366445\n",
      " Training with pattern  2  weights  [-2.6821768   2.80632268] 1.3769901950826573   weights  [-2.6821768   2.80632272]  bias  1.3796854160878085\n",
      "pattern1 0 0 1 0.880881\n",
      "pattern2 0 1 1 0.999538\n",
      "pattern3 1 0 -1 -0.862363\n",
      "pattern4 1 1 1 0.905838\n",
      " modified Weights  [-2.6821768   2.80632272] 1.3796854160878085\n",
      " Training with pattern  3  weights  [-2.6821768   2.80632268] 1.3769901950826573   weights  [-2.68570484  2.80632272]  bias  1.3761573734345396\n",
      "pattern1 0 0 1 0.880088\n",
      "pattern2 0 1 1 0.999534\n",
      "pattern3 1 0 -1 -0.864161\n",
      "pattern4 1 1 1 0.904564\n",
      " modified Weights  [-2.68570484  2.80632272] 1.3761573734345396\n",
      " Training with pattern  4  weights  [-2.6821768   2.80632268] 1.3769901950826573   weights  [-2.68397015  2.80805741]  bias  1.3778920625774718\n",
      "pattern1 0 0 1 0.880478\n",
      "pattern2 0 1 1 0.999538\n",
      "pattern3 1 0 -1 -0.86328\n",
      "pattern4 1 1 1 0.905505\n",
      " modified Weights  [-2.68397015  2.80805741] 1.3778920625774718\n",
      "+++++++++++Epoch  322  cost=  0.04190732723399053\n",
      " Training with pattern  1  weights  [-2.68397015  2.80805741] 1.3778920625774718   weights  [-2.68397015  2.80805741]  bias  1.3805784048734444\n",
      "pattern1 0 0 1 0.881081\n",
      "pattern2 0 1 1 0.99954\n",
      "pattern3 1 0 -1 -0.862594\n",
      "pattern4 1 1 1 0.905988\n",
      " modified Weights  [-2.68397015  2.80805741] 1.3805784048734444\n",
      " Training with pattern  2  weights  [-2.68397015  2.80805741] 1.3778920625774718   weights  [-2.68397015  2.80805745]  bias  1.3805784471777558\n",
      "pattern1 0 0 1 0.881081\n",
      "pattern2 0 1 1 0.99954\n",
      "pattern3 1 0 -1 -0.862594\n",
      "pattern4 1 1 1 0.905988\n",
      " modified Weights  [-2.68397015  2.80805745] 1.3805784471777558\n",
      " Training with pattern  3  weights  [-2.68397015  2.80805741] 1.3778920625774718   weights  [-2.68748682  2.80805745]  bias  1.377061781185616\n",
      "pattern1 0 0 1 0.880292\n",
      "pattern2 0 1 1 0.999537\n",
      "pattern3 1 0 -1 -0.864383\n",
      "pattern4 1 1 1 0.904719\n",
      " modified Weights  [-2.68748682  2.80805745] 1.377061781185616\n",
      " Training with pattern  4  weights  [-2.68397015  2.80805741] 1.3778920625774718   weights  [-2.68575764  2.80978663]  bias  1.3787909568360461\n",
      "pattern1 0 0 1 0.88068\n",
      "pattern2 0 1 1 0.99954\n",
      "pattern3 1 0 -1 -0.863506\n",
      "pattern4 1 1 1 0.905657\n",
      " modified Weights  [-2.68575764  2.80978663] 1.3787909568360461\n",
      "+++++++++++Epoch  323  cost=  0.04176874828603269\n",
      " Training with pattern  1  weights  [-2.68575764  2.80978663] 1.3787909568360461   weights  [-2.68575764  2.80978663]  bias  1.3814685196678829\n",
      "pattern1 0 0 1 0.88128\n",
      "pattern2 0 1 1 0.999542\n",
      "pattern3 1 0 -1 -0.862823\n",
      "pattern4 1 1 1 0.906137\n",
      " modified Weights  [-2.68575764  2.80978663] 1.3814685196678829\n",
      " Training with pattern  2  weights  [-2.68575764  2.80978663] 1.3787909568360461   weights  [-2.68575764  2.80978667]  bias  1.3814685615314228\n",
      "pattern1 0 0 1 0.88128\n",
      "pattern2 0 1 1 0.999542\n",
      "pattern3 1 0 -1 -0.862823\n",
      "pattern4 1 1 1 0.906137\n",
      " modified Weights  [-2.68575764  2.80978667] 1.3814685615314228\n",
      " Training with pattern  3  weights  [-2.68575764  2.80978663] 1.3787909568360461   weights  [-2.689263    2.80978667]  bias  1.3779632006337332\n",
      "pattern1 0 0 1 0.880494\n",
      "pattern2 0 1 1 0.999539\n",
      "pattern3 1 0 -1 -0.864604\n",
      "pattern4 1 1 1 0.904874\n",
      " modified Weights  [-2.689263    2.80978667] 1.3779632006337332\n",
      " Training with pattern  4  weights  [-2.68575764  2.80978663] 1.3787909568360461   weights  [-2.68753931  2.81151036]  bias  1.3796868969818894\n",
      "pattern1 0 0 1 0.880881\n",
      "pattern2 0 1 1 0.999542\n",
      "pattern3 1 0 -1 -0.863731\n",
      "pattern4 1 1 1 0.905807\n",
      " modified Weights  [-2.68753931  2.81151036] 1.3796868969818894\n",
      "+++++++++++Epoch  324  cost=  0.04163105756507936\n",
      " Training with pattern  1  weights  [-2.68753931  2.81151036] 1.3796868969818894   weights  [-2.68753931  2.81151036]  bias  1.3823557363094263\n",
      "pattern1 0 0 1 0.881478\n",
      "pattern2 0 1 1 0.999545\n",
      "pattern3 1 0 -1 -0.863052\n",
      "pattern4 1 1 1 0.906285\n",
      " modified Weights  [-2.68753931  2.81151036] 1.3823557363094263\n",
      " Training with pattern  2  weights  [-2.68753931  2.81151036] 1.3796868969818894   weights  [-2.68753931  2.81151041]  bias  1.3823557777381743\n",
      "pattern1 0 0 1 0.881478\n",
      "pattern2 0 1 1 0.999545\n",
      "pattern3 1 0 -1 -0.863052\n",
      "pattern4 1 1 1 0.906285\n",
      " modified Weights  [-2.68753931  2.81151041] 1.3823557777381743\n",
      " Training with pattern  3  weights  [-2.68753931  2.81151036] 1.3796868969818894   weights  [-2.69103343  2.81151041]  bias  1.378861651033954\n",
      "pattern1 0 0 1 0.880696\n",
      "pattern2 0 1 1 0.999542\n",
      "pattern3 1 0 -1 -0.864824\n",
      "pattern4 1 1 1 0.905029\n",
      " modified Weights  [-2.69103343  2.81151041] 1.378861651033954\n",
      " Training with pattern  4  weights  [-2.68753931  2.81151036] 1.3796868969818894   weights  [-2.68931518  2.81322866]  bias  1.3805799019566216\n",
      "pattern1 0 0 1 0.881081\n",
      "pattern2 0 1 1 0.999545\n",
      "pattern3 1 0 -1 -0.863955\n",
      "pattern4 1 1 1 0.905957\n",
      " modified Weights  [-2.68931518  2.81322866] 1.3805799019566216\n",
      "+++++++++++Epoch  325  cost=  0.041494246677891415\n",
      " Training with pattern  1  weights  [-2.68931518  2.81322866] 1.3805799019566216   weights  [-2.68931518  2.81322866]  bias  1.3832400732123138\n",
      "pattern1 0 0 1 0.881675\n",
      "pattern2 0 1 1 0.999547\n",
      "pattern3 1 0 -1 -0.863279\n",
      "pattern4 1 1 1 0.906433\n",
      " modified Weights  [-2.68931518  2.81322866] 1.3832400732123138\n",
      " Training with pattern  2  weights  [-2.68931518  2.81322866] 1.3805799019566216   weights  [-2.68931518  2.8132287 ]  bias  1.3832401142121495\n",
      "pattern1 0 0 1 0.881675\n",
      "pattern2 0 1 1 0.999547\n",
      "pattern3 1 0 -1 -0.863279\n",
      "pattern4 1 1 1 0.906433\n",
      " modified Weights  [-2.68931518  2.8132287 ] 1.3832401142121495\n",
      " Training with pattern  3  weights  [-2.68931518  2.81322866] 1.3805799019566216   weights  [-2.69279815  2.8132287 ]  bias  1.3797571514579448\n",
      "pattern1 0 0 1 0.880897\n",
      "pattern2 0 1 1 0.999544\n",
      "pattern3 1 0 -1 -0.865043\n",
      "pattern4 1 1 1 0.905182\n",
      " modified Weights  [-2.69279815  2.8132287 ] 1.3797571514579448\n",
      " Training with pattern  4  weights  [-2.68931518  2.81322866] 1.3805799019566216   weights  [-2.69108531  2.81494154]  bias  1.3814699905222572\n",
      "pattern1 0 0 1 0.88128\n",
      "pattern2 0 1 1 0.999547\n",
      "pattern3 1 0 -1 -0.864178\n",
      "pattern4 1 1 1 0.906106\n",
      " modified Weights  [-2.69108531  2.81494154] 1.3814699905222572\n",
      "+++++++++++Epoch  326  cost=  0.041358307335712684\n",
      " Training with pattern  1  weights  [-2.69108531  2.81494154] 1.3814699905222572   weights  [-2.69108531  2.81494154]  bias  1.3841215486177374\n",
      "pattern1 0 0 1 0.881871\n",
      "pattern2 0 1 1 0.99955\n",
      "pattern3 1 0 -1 -0.863505\n",
      "pattern4 1 1 1 0.90658\n",
      " modified Weights  [-2.69108531  2.81494154] 1.3841215486177374\n",
      " Training with pattern  2  weights  [-2.69108531  2.81494154] 1.3814699905222572   weights  [-2.69108531  2.81494158]  bias  1.3841215891944434\n",
      "pattern1 0 0 1 0.881871\n",
      "pattern2 0 1 1 0.99955\n",
      "pattern3 1 0 -1 -0.863505\n",
      "pattern4 1 1 1 0.90658\n",
      " modified Weights  [-2.69108531  2.81494158] 1.3841215891944434\n",
      " Training with pattern  3  weights  [-2.69108531  2.81494154] 1.3814699905222572   weights  [-2.69455718  2.81494158]  bias  1.3806497207962802\n",
      "pattern1 0 0 1 0.881097\n",
      "pattern2 0 1 1 0.999546\n",
      "pattern3 1 0 -1 -0.865261\n",
      "pattern4 1 1 1 0.905335\n",
      " modified Weights  [-2.69455718  2.81494158] 1.3806497207962802\n",
      " Training with pattern  4  weights  [-2.69108531  2.81494154] 1.3814699905222572   weights  [-2.69284971  2.81664904]  bias  1.382357181263453\n",
      "pattern1 0 0 1 0.881478\n",
      "pattern2 0 1 1 0.999549\n",
      "pattern3 1 0 -1 -0.8644\n",
      "pattern4 1 1 1 0.906255\n",
      " modified Weights  [-2.69284971  2.81664904] 1.382357181263453\n",
      "+++++++++++Epoch  327  cost=  0.041223231352660025\n",
      " Training with pattern  1  weights  [-2.69284971  2.81664904] 1.382357181263453   weights  [-2.69284971  2.81664904]  bias  1.385000180595989\n",
      "pattern1 0 0 1 0.882066\n",
      "pattern2 0 1 1 0.999552\n",
      "pattern3 1 0 -1 -0.86373\n",
      "pattern4 1 1 1 0.906726\n",
      " modified Weights  [-2.69284971  2.81664904] 1.385000180595989\n",
      " Training with pattern  2  weights  [-2.69284971  2.81664904] 1.382357181263453   weights  [-2.69284971  2.81664908]  bias  1.3850002207552514\n",
      "pattern1 0 0 1 0.882066\n",
      "pattern2 0 1 1 0.999552\n",
      "pattern3 1 0 -1 -0.86373\n",
      "pattern4 1 1 1 0.906726\n",
      " modified Weights  [-2.69284971  2.81664908] 1.3850002207552514\n",
      " Training with pattern  3  weights  [-2.69284971  2.81664904] 1.382357181263453   weights  [-2.69631056  2.81664908]  bias  1.3815393777607103\n",
      "pattern1 0 0 1 0.881296\n",
      "pattern2 0 1 1 0.999549\n",
      "pattern3 1 0 -1 -0.865478\n",
      "pattern4 1 1 1 0.905487\n",
      " modified Weights  [-2.69631056  2.81664908] 1.3815393777607103\n",
      " Training with pattern  4  weights  [-2.69284971  2.81664904] 1.382357181263453   weights  [-2.69460844  2.81835119]  bias  1.3832414925897185\n",
      "pattern1 0 0 1 0.881675\n",
      "pattern2 0 1 1 0.999552\n",
      "pattern3 1 0 -1 -0.864621\n",
      "pattern4 1 1 1 0.906402\n",
      " modified Weights  [-2.69460844  2.81835119] 1.3832414925897185\n",
      "+++++++++++Epoch  328  cost=  0.04108901064414129\n",
      " Training with pattern  1  weights  [-2.69460844  2.81835119] 1.3832414925897185   weights  [-2.69460844  2.81835119]  bias  1.385875987048572\n",
      "pattern1 0 0 1 0.88226\n",
      "pattern2 0 1 1 0.999554\n",
      "pattern3 1 0 -1 -0.863954\n",
      "pattern4 1 1 1 0.906871\n",
      " modified Weights  [-2.69460844  2.81835119] 1.385875987048572\n",
      " Training with pattern  2  weights  [-2.69460844  2.81835119] 1.3832414925897185   weights  [-2.69460844  2.81835123]  bias  1.3858760267959835\n",
      "pattern1 0 0 1 0.88226\n",
      "pattern2 0 1 1 0.999554\n",
      "pattern3 1 0 -1 -0.863954\n",
      "pattern4 1 1 1 0.906871\n",
      " modified Weights  [-2.69460844  2.81835123] 1.3858760267959835\n",
      " Training with pattern  3  weights  [-2.69460844  2.81835119] 1.3832414925897185   weights  [-2.69805833  2.81835123]  bias  1.3824261408863954\n",
      "pattern1 0 0 1 0.881493\n",
      "pattern2 0 1 1 0.999551\n",
      "pattern3 1 0 -1 -0.865694\n",
      "pattern4 1 1 1 0.905638\n",
      " modified Weights  [-2.69805833  2.81835123] 1.3824261408863954\n",
      " Training with pattern  4  weights  [-2.69460844  2.81835119] 1.3832414925897185   weights  [-2.69636153  2.82004803]  bias  1.3841229427375974\n",
      "pattern1 0 0 1 0.881871\n",
      "pattern2 0 1 1 0.999554\n",
      "pattern3 1 0 -1 -0.864841\n",
      "pattern4 1 1 1 0.90655\n",
      " modified Weights  [-2.69636153  2.82004803] 1.3841229427375974\n",
      "+++++++++++Epoch  329  cost=  0.04095563722530408\n",
      " Training with pattern  1  weights  [-2.69636153  2.82004803] 1.3841229427375974   weights  [-2.69636153  2.82004803]  bias  1.3867489857102842\n",
      "pattern1 0 0 1 0.882454\n",
      "pattern2 0 1 1 0.999556\n",
      "pattern3 1 0 -1 -0.864177\n",
      "pattern4 1 1 1 0.907016\n",
      " modified Weights  [-2.69636153  2.82004803] 1.3867489857102842\n",
      " Training with pattern  2  weights  [-2.69636153  2.82004803] 1.3841229427375974   weights  [-2.69636153  2.82004807]  bias  1.3867490250513455\n",
      "pattern1 0 0 1 0.882454\n",
      "pattern2 0 1 1 0.999556\n",
      "pattern3 1 0 -1 -0.864177\n",
      "pattern4 1 1 1 0.907016\n",
      " modified Weights  [-2.69636153  2.82004807] 1.3867490250513455\n",
      " Training with pattern  3  weights  [-2.69636153  2.82004803] 1.3841229427375974   weights  [-2.69980052  2.82004807]  bias  1.3833100285341033\n",
      "pattern1 0 0 1 0.88169\n",
      "pattern2 0 1 1 0.999553\n",
      "pattern3 1 0 -1 -0.865909\n",
      "pattern4 1 1 1 0.905789\n",
      " modified Weights  [-2.69980052  2.82004807] 1.3833100285341033\n",
      " Training with pattern  4  weights  [-2.69636153  2.82004803] 1.3841229427375974   weights  [-2.698109    2.82173959]  bias  1.3850015497728105\n",
      "pattern1 0 0 1 0.882066\n",
      "pattern2 0 1 1 0.999556\n",
      "pattern3 1 0 -1 -0.86506\n",
      "pattern4 1 1 1 0.906696\n",
      " modified Weights  [-2.698109    2.82173959] 1.3850015497728105\n",
      "+++++++++++Epoch  330  cost=  0.04082310320951159\n",
      " Training with pattern  1  weights  [-2.698109    2.82173959] 1.3850015497728105   weights  [-2.698109    2.82173959]  bias  1.3876191941512657\n",
      "pattern1 0 0 1 0.882646\n",
      "pattern2 0 1 1 0.999559\n",
      "pattern3 1 0 -1 -0.864399\n",
      "pattern4 1 1 1 0.907161\n",
      " modified Weights  [-2.698109    2.82173959] 1.3876191941512657\n",
      " Training with pattern  2  weights  [-2.698109    2.82173959] 1.3850015497728105   weights  [-2.698109    2.82173963]  bias  1.3876192330913868\n",
      "pattern1 0 0 1 0.882646\n",
      "pattern2 0 1 1 0.999559\n",
      "pattern3 1 0 -1 -0.864399\n",
      "pattern4 1 1 1 0.907161\n",
      " modified Weights  [-2.698109    2.82173963] 1.3876192330913868\n",
      " Training with pattern  3  weights  [-2.698109    2.82173959] 1.3850015497728105   weights  [-2.70153718  2.82173963]  bias  1.3841910588923745\n",
      "pattern1 0 0 1 0.881886\n",
      "pattern2 0 1 1 0.999556\n",
      "pattern3 1 0 -1 -0.866122\n",
      "pattern4 1 1 1 0.905939\n",
      " modified Weights  [-2.70153718  2.82173963] 1.3841910588923745\n",
      " Training with pattern  4  weights  [-2.698109    2.82173959] 1.3850015497728105   weights  [-2.6998509   2.82342591]  bias  1.3858773315923674\n",
      "pattern1 0 0 1 0.882261\n",
      "pattern2 0 1 1 0.999559\n",
      "pattern3 1 0 -1 -0.865277\n",
      "pattern4 1 1 1 0.906842\n",
      " modified Weights  [-2.6998509   2.82342591] 1.3858773315923674\n",
      "+++++++++++Epoch  331  cost=  0.040691400806846134\n",
      " *********Epoch  330 Error  0.040691400806846134\n",
      " Training with pattern  1  weights  [-2.6998509   2.82342591] 1.3858773315923674   weights  [-2.6998509   2.82342591]  bias  1.3884866297790173\n",
      "pattern1 0 0 1 0.882837\n",
      "pattern2 0 1 1 0.999561\n",
      "pattern3 1 0 -1 -0.86462\n",
      "pattern4 1 1 1 0.907304\n",
      " modified Weights  [-2.6998509   2.82342591] 1.3884866297790173\n",
      " Training with pattern  2  weights  [-2.6998509   2.82342591] 1.3858773315923674   weights  [-2.6998509   2.82342594]  bias  1.3884866683235202\n",
      "pattern1 0 0 1 0.882837\n",
      "pattern2 0 1 1 0.999561\n",
      "pattern3 1 0 -1 -0.86462\n",
      "pattern4 1 1 1 0.907304\n",
      " modified Weights  [-2.6998509   2.82342594] 1.3884866683235202\n",
      " Training with pattern  3  weights  [-2.6998509   2.82342591] 1.3858773315923674   weights  [-2.70326832  2.82342594]  bias  1.3850692499796542\n",
      "pattern1 0 0 1 0.882081\n",
      "pattern2 0 1 1 0.999558\n",
      "pattern3 1 0 -1 -0.866335\n",
      "pattern4 1 1 1 0.906088\n",
      " modified Weights  [-2.70326832  2.82342594] 1.3850692499796542\n",
      " Training with pattern  4  weights  [-2.6998509   2.82342591] 1.3858773315923674   weights  [-2.70158727  2.825107  ]  bias  1.386750305926647\n",
      "pattern1 0 0 1 0.882454\n",
      "pattern2 0 1 1 0.999561\n",
      "pattern3 1 0 -1 -0.865494\n",
      "pattern4 1 1 1 0.906987\n",
      " modified Weights  [-2.70158727  2.825107  ] 1.386750305926647\n",
      "+++++++++++Epoch  332  cost=  0.04056052232264105\n",
      " Training with pattern  1  weights  [-2.70158727  2.825107  ] 1.386750305926647   weights  [-2.70158727  2.825107  ]  bias  1.389351309840388\n",
      "pattern1 0 0 1 0.883028\n",
      "pattern2 0 1 1 0.999563\n",
      "pattern3 1 0 -1 -0.86484\n",
      "pattern4 1 1 1 0.907447\n",
      " modified Weights  [-2.70158727  2.825107  ] 1.389351309840388\n",
      " Training with pattern  2  weights  [-2.70158727  2.825107  ] 1.386750305926647   weights  [-2.70158727  2.82510704]  bias  1.3893513479945079\n",
      "pattern1 0 0 1 0.883028\n",
      "pattern2 0 1 1 0.999563\n",
      "pattern3 1 0 -1 -0.86484\n",
      "pattern4 1 1 1 0.907447\n",
      " modified Weights  [-2.70158727  2.82510704] 1.3893513479945079\n",
      " Training with pattern  3  weights  [-2.70158727  2.825107  ] 1.386750305926647   weights  [-2.70499399  2.82510704]  bias  1.3859446196463905\n",
      "pattern1 0 0 1 0.882275\n",
      "pattern2 0 1 1 0.99956\n",
      "pattern3 1 0 -1 -0.866547\n",
      "pattern4 1 1 1 0.906237\n",
      " modified Weights  [-2.70499399  2.82510704] 1.3859446196463905\n",
      " Training with pattern  4  weights  [-2.70158727  2.825107  ] 1.386750305926647   weights  [-2.70331812  2.82678291]  bias  1.3876204903414457\n",
      "pattern1 0 0 1 0.882646\n",
      "pattern2 0 1 1 0.999563\n",
      "pattern3 1 0 -1 -0.86571\n",
      "pattern4 1 1 1 0.907131\n",
      " modified Weights  [-2.70331812  2.82678291] 1.3876204903414457\n",
      "+++++++++++Epoch  333  cost=  0.04043046015603752\n",
      " Training with pattern  1  weights  [-2.70331812  2.82678291] 1.3876204903414457   weights  [-2.70331812  2.82678291]  bias  1.3902132514235321\n",
      "pattern1 0 0 1 0.883218\n",
      "pattern2 0 1 1 0.999565\n",
      "pattern3 1 0 -1 -0.865059\n",
      "pattern4 1 1 1 0.90759\n",
      " modified Weights  [-2.70331812  2.82678291] 1.3902132514235321\n",
      " Training with pattern  2  weights  [-2.70331812  2.82678291] 1.3876204903414457   weights  [-2.70331812  2.82678295]  bias  1.3902132891924188\n",
      "pattern1 0 0 1 0.883218\n",
      "pattern2 0 1 1 0.999565\n",
      "pattern3 1 0 -1 -0.865059\n",
      "pattern4 1 1 1 0.90759\n",
      " modified Weights  [-2.70331812  2.82678295] 1.3902132891924188\n",
      " Training with pattern  3  weights  [-2.70331812  2.82678291] 1.3876204903414457   weights  [-2.70671423  2.82678295]  bias  1.3868171855771012\n",
      "pattern1 0 0 1 0.882469\n",
      "pattern2 0 1 1 0.999562\n",
      "pattern3 1 0 -1 -0.866758\n",
      "pattern4 1 1 1 0.906385\n",
      " modified Weights  [-2.70671423  2.82678295] 1.3868171855771012\n",
      " Training with pattern  4  weights  [-2.70331812  2.82678291] 1.3876204903414457   weights  [-2.70504351  2.82845366]  bias  1.3884879022399919\n",
      "pattern1 0 0 1 0.882838\n",
      "pattern2 0 1 1 0.999565\n",
      "pattern3 1 0 -1 -0.865925\n",
      "pattern4 1 1 1 0.907275\n",
      " modified Weights  [-2.70504351  2.82845366] 1.3884879022399919\n",
      "+++++++++++Epoch  334  cost=  0.040301206798568606\n",
      " Training with pattern  1  weights  [-2.70504351  2.82845366] 1.3884879022399919   weights  [-2.70504351  2.82845366]  bias  1.3910724714598364\n",
      "pattern1 0 0 1 0.883407\n",
      "pattern2 0 1 1 0.999568\n",
      "pattern3 1 0 -1 -0.865277\n",
      "pattern4 1 1 1 0.907731\n",
      " modified Weights  [-2.70504351  2.82845366] 1.3910724714598364\n",
      " Training with pattern  2  weights  [-2.70504351  2.82845366] 1.3884879022399919   weights  [-2.70504351  2.8284537 ]  bias  1.3910725088485563\n",
      "pattern1 0 0 1 0.883407\n",
      "pattern2 0 1 1 0.999568\n",
      "pattern3 1 0 -1 -0.865277\n",
      "pattern4 1 1 1 0.907731\n",
      " modified Weights  [-2.70504351  2.8284537 ] 1.3910725088485563\n",
      " Training with pattern  3  weights  [-2.70504351  2.82845366] 1.3884879022399919   weights  [-2.70842905  2.8284537 ]  bias  1.3876869652924084\n",
      "pattern1 0 0 1 0.882661\n",
      "pattern2 0 1 1 0.999565\n",
      "pattern3 1 0 -1 -0.866968\n",
      "pattern4 1 1 1 0.906532\n",
      " modified Weights  [-2.70842905  2.8284537 ] 1.3876869652924084\n",
      " Training with pattern  4  weights  [-2.70504351  2.82845366] 1.3884879022399919   weights  [-2.70676346  2.83011929]  bias  1.389352558864933\n",
      "pattern1 0 0 1 0.883028\n",
      "pattern2 0 1 1 0.999568\n",
      "pattern3 1 0 -1 -0.866139\n",
      "pattern4 1 1 1 0.907419\n",
      " modified Weights  [-2.70676346  2.83011929] 1.389352558864933\n",
      "+++++++++++Epoch  335  cost=  0.040172754832768054\n",
      " Training with pattern  1  weights  [-2.70676346  2.83011929] 1.389352558864933   weights  [-2.70676346  2.83011929]  bias  1.3919289867258184\n",
      "pattern1 0 0 1 0.883595\n",
      "pattern2 0 1 1 0.99957\n",
      "pattern3 1 0 -1 -0.865494\n",
      "pattern4 1 1 1 0.907872\n",
      " modified Weights  [-2.70676346  2.83011929] 1.3919289867258184\n",
      " Training with pattern  2  weights  [-2.70676346  2.83011929] 1.389352558864933   weights  [-2.70676346  2.83011933]  bias  1.391929023739356\n",
      "pattern1 0 0 1 0.883595\n",
      "pattern2 0 1 1 0.99957\n",
      "pattern3 1 0 -1 -0.865494\n",
      "pattern4 1 1 1 0.907872\n",
      " modified Weights  [-2.70676346  2.83011933] 1.391929023739356\n",
      " Training with pattern  3  weights  [-2.70676346  2.83011929] 1.389352558864933   weights  [-2.71013851  2.83011933]  bias  1.3885539761510435\n",
      "pattern1 0 0 1 0.882852\n",
      "pattern2 0 1 1 0.999567\n",
      "pattern3 1 0 -1 -0.867177\n",
      "pattern4 1 1 1 0.906679\n",
      " modified Weights  [-2.71013851  2.83011933] 1.3885539761510435\n",
      " Training with pattern  4  weights  [-2.70676346  2.83011929] 1.389352558864933   weights  [-2.70847801  2.83177983]  bias  1.3902144773002916\n",
      "pattern1 0 0 1 0.883218\n",
      "pattern2 0 1 1 0.99957\n",
      "pattern3 1 0 -1 -0.866351\n",
      "pattern4 1 1 1 0.907561\n",
      " modified Weights  [-2.70847801  2.83177983] 1.3902144773002916\n",
      "+++++++++++Epoch  336  cost=  0.04004509693080471\n",
      " Training with pattern  1  weights  [-2.70847801  2.83177983] 1.3902144773002916   weights  [-2.70847801  2.83177983]  bias  1.392782813844998\n",
      "pattern1 0 0 1 0.883782\n",
      "pattern2 0 1 1 0.999572\n",
      "pattern3 1 0 -1 -0.865709\n",
      "pattern4 1 1 1 0.908013\n",
      " modified Weights  [-2.70847801  2.83177983] 1.392782813844998\n",
      " Training with pattern  2  weights  [-2.70847801  2.83177983] 1.3902144773002916   weights  [-2.70847801  2.83177987]  bias  1.3927828504882578\n",
      "pattern1 0 0 1 0.883782\n",
      "pattern2 0 1 1 0.999572\n",
      "pattern3 1 0 -1 -0.865709\n",
      "pattern4 1 1 1 0.908013\n",
      " modified Weights  [-2.70847801  2.83177987] 1.3927828504882578\n",
      " Training with pattern  3  weights  [-2.70847801  2.83177983] 1.3902144773002916   weights  [-2.71184262  2.83177987]  bias  1.3894182353518205\n",
      "pattern1 0 0 1 0.883043\n",
      "pattern2 0 1 1 0.999569\n",
      "pattern3 1 0 -1 -0.867386\n",
      "pattern4 1 1 1 0.906825\n",
      " modified Weights  [-2.71184262  2.83177987] 1.3894182353518205\n",
      " Training with pattern  4  weights  [-2.70847801  2.83177983] 1.3902144773002916   weights  [-2.71018718  2.83343531]  bias  1.3910736744733914\n",
      "pattern1 0 0 1 0.883407\n",
      "pattern2 0 1 1 0.999572\n",
      "pattern3 1 0 -1 -0.866563\n",
      "pattern4 1 1 1 0.907703\n",
      " modified Weights  [-2.71018718  2.83343531] 1.3910736744733914\n",
      "+++++++++++Epoch  337  cost=  0.039918225853140456\n",
      " Training with pattern  1  weights  [-2.71018718  2.83343531] 1.3910736744733914   weights  [-2.71018718  2.83343531]  bias  1.393633969289738\n",
      "pattern1 0 0 1 0.883968\n",
      "pattern2 0 1 1 0.999574\n",
      "pattern3 1 0 -1 -0.865924\n",
      "pattern4 1 1 1 0.908153\n",
      " modified Weights  [-2.71018718  2.83343531] 1.393633969289738\n",
      " Training with pattern  2  weights  [-2.71018718  2.83343531] 1.3910736744733914   weights  [-2.71018718  2.83343534]  bias  1.3936340055675454\n",
      "pattern1 0 0 1 0.883968\n",
      "pattern2 0 1 1 0.999574\n",
      "pattern3 1 0 -1 -0.865924\n",
      "pattern4 1 1 1 0.908153\n",
      " modified Weights  [-2.71018718  2.83343534] 1.3936340055675454\n",
      " Training with pattern  3  weights  [-2.71018718  2.83343531] 1.3910736744733914   weights  [-2.71354143  2.83343534]  bias  1.3902797599355807\n",
      "pattern1 0 0 1 0.883232\n",
      "pattern2 0 1 1 0.999571\n",
      "pattern3 1 0 -1 -0.867593\n",
      "pattern4 1 1 1 0.90697\n",
      " modified Weights  [-2.71354143  2.83343534] 1.3902797599355807\n",
      " Training with pattern  4  weights  [-2.71018718  2.83343531] 1.3910736744733914   weights  [-2.71189102  2.83508575]  bias  1.3919301671567543\n",
      "pattern1 0 0 1 0.883595\n",
      "pattern2 0 1 1 0.999574\n",
      "pattern3 1 0 -1 -0.866774\n",
      "pattern4 1 1 1 0.907844\n",
      " modified Weights  [-2.71189102  2.83508575] 1.3919301671567543\n",
      "+++++++++++Epoch  338  cost=  0.03979213444721303\n",
      " Training with pattern  1  weights  [-2.71189102  2.83508575] 1.3919301671567543   weights  [-2.71189102  2.83508575]  bias  1.3944824693830593\n",
      "pattern1 0 0 1 0.884153\n",
      "pattern2 0 1 1 0.999576\n",
      "pattern3 1 0 -1 -0.866138\n",
      "pattern4 1 1 1 0.908292\n",
      " modified Weights  [-2.71189102  2.83508575] 1.3944824693830593\n",
      " Training with pattern  2  weights  [-2.71189102  2.83508575] 1.3919301671567543   weights  [-2.71189102  2.83508579]  bias  1.3944825053001628\n",
      "pattern1 0 0 1 0.884153\n",
      "pattern2 0 1 1 0.999576\n",
      "pattern3 1 0 -1 -0.866138\n",
      "pattern4 1 1 1 0.908292\n",
      " modified Weights  [-2.71189102  2.83508579] 1.3944825053001628\n",
      " Training with pattern  3  weights  [-2.71189102  2.83508575] 1.3919301671567543   weights  [-2.71523496  2.83508579]  bias  1.3911385667871066\n",
      "pattern1 0 0 1 0.883421\n",
      "pattern2 0 1 1 0.999573\n",
      "pattern3 1 0 -1 -0.867799\n",
      "pattern4 1 1 1 0.907114\n",
      " modified Weights  [-2.71523496  2.83508579] 1.3911385667871066\n",
      " Training with pattern  4  weights  [-2.71189102  2.83508575] 1.3919301671567543   weights  [-2.71358956  2.83673119]  bias  1.3927839719699695\n",
      "pattern1 0 0 1 0.883782\n",
      "pattern2 0 1 1 0.999576\n",
      "pattern3 1 0 -1 -0.866984\n",
      "pattern4 1 1 1 0.907985\n",
      " modified Weights  [-2.71358956  2.83673119] 1.3927839719699695\n",
      "+++++++++++Epoch  339  cost=  0.03966681564614148\n",
      " Training with pattern  1  weights  [-2.71358956  2.83673119] 1.3927839719699695   weights  [-2.71358956  2.83673119]  bias  1.3953283303004282\n",
      "pattern1 0 0 1 0.884338\n",
      "pattern2 0 1 1 0.999578\n",
      "pattern3 1 0 -1 -0.866351\n",
      "pattern4 1 1 1 0.908431\n",
      " modified Weights  [-2.71358956  2.83673119] 1.3953283303004282\n",
      " Training with pattern  2  weights  [-2.71358956  2.83673119] 1.3927839719699695   weights  [-2.71358956  2.83673123]  bias  1.3953283658615\n",
      "pattern1 0 0 1 0.884338\n",
      "pattern2 0 1 1 0.999578\n",
      "pattern3 1 0 -1 -0.866351\n",
      "pattern4 1 1 1 0.908431\n",
      " modified Weights  [-2.71358956  2.83673123] 1.3953283658615\n",
      " Training with pattern  3  weights  [-2.71358956  2.83673119] 1.3927839719699695   weights  [-2.71692325  2.83673123]  bias  1.3919946726370074\n",
      "pattern1 0 0 1 0.883609\n",
      "pattern2 0 1 1 0.999575\n",
      "pattern3 1 0 -1 -0.868004\n",
      "pattern4 1 1 1 0.907258\n",
      " modified Weights  [-2.71692325  2.83673123] 1.3919946726370074\n",
      " Training with pattern  4  weights  [-2.71358956  2.83673119] 1.3927839719699695   weights  [-2.71528282  2.83837166]  bias  1.3936351053815337\n",
      "pattern1 0 0 1 0.883968\n",
      "pattern2 0 1 1 0.999578\n",
      "pattern3 1 0 -1 -0.867193\n",
      "pattern4 1 1 1 0.908125\n",
      " modified Weights  [-2.71528282  2.83837166] 1.3936351053815337\n",
      "+++++++++++Epoch  340  cost=  0.03954226246745503\n",
      " Training with pattern  1  weights  [-2.71528282  2.83837166] 1.3936351053815337   weights  [-2.71528282  2.83837166]  bias  1.3961715680715179\n",
      "pattern1 0 0 1 0.884521\n",
      "pattern2 0 1 1 0.99958\n",
      "pattern3 1 0 -1 -0.866563\n",
      "pattern4 1 1 1 0.908569\n",
      " modified Weights  [-2.71528282  2.83837166] 1.3961715680715179\n",
      " Training with pattern  2  weights  [-2.71528282  2.83837166] 1.3936351053815337   weights  [-2.71528282  2.8383717 ]  bias  1.3961716032811562\n",
      "pattern1 0 0 1 0.884521\n",
      "pattern2 0 1 1 0.99958\n",
      "pattern3 1 0 -1 -0.866563\n",
      "pattern4 1 1 1 0.908569\n",
      " modified Weights  [-2.71528282  2.8383717 ] 1.3961716032811562\n",
      " Training with pattern  3  weights  [-2.71528282  2.83837166] 1.3936351053815337   weights  [-2.71860632  2.8383717 ]  bias  1.3928480940635783\n",
      "pattern1 0 0 1 0.883796\n",
      "pattern2 0 1 1 0.999578\n",
      "pattern3 1 0 -1 -0.868209\n",
      "pattern4 1 1 1 0.907402\n",
      " modified Weights  [-2.71860632  2.8383717 ] 1.3928480940635783\n",
      " Training with pattern  4  weights  [-2.71528282  2.83837166] 1.3936351053815337   weights  [-2.71697084  2.84000719]  bias  1.394483583710665\n",
      "pattern1 0 0 1 0.884153\n",
      "pattern2 0 1 1 0.99958\n",
      "pattern3 1 0 -1 -0.867401\n",
      "pattern4 1 1 1 0.908264\n",
      " modified Weights  [-2.71697084  2.84000719] 1.394483583710665\n",
      "+++++++++++Epoch  341  cost=  0.03941846801184398\n",
      " *********Epoch  340 Error  0.03941846801184398\n",
      " Training with pattern  1  weights  [-2.71697084  2.84000719] 1.394483583710665   weights  [-2.71697084  2.84000719]  bias  1.3970121985819424\n",
      "pattern1 0 0 1 0.884704\n",
      "pattern2 0 1 1 0.999582\n",
      "pattern3 1 0 -1 -0.866774\n",
      "pattern4 1 1 1 0.908706\n",
      " modified Weights  [-2.71697084  2.84000719] 1.3970121985819424\n",
      " Training with pattern  2  weights  [-2.71697084  2.84000719] 1.394483583710665   weights  [-2.71697084  2.84000722]  bias  1.3970122334446724\n",
      "pattern1 0 0 1 0.884704\n",
      "pattern2 0 1 1 0.999582\n",
      "pattern3 1 0 -1 -0.866774\n",
      "pattern4 1 1 1 0.908706\n",
      " modified Weights  [-2.71697084  2.84000722] 1.3970122334446724\n",
      " Training with pattern  3  weights  [-2.71697084  2.84000719] 1.394483583710665   weights  [-2.72028422  2.84000722]  bias  1.3936988474946297\n",
      "pattern1 0 0 1 0.883982\n",
      "pattern2 0 1 1 0.99958\n",
      "pattern3 1 0 -1 -0.868412\n",
      "pattern4 1 1 1 0.907544\n",
      " modified Weights  [-2.72028422  2.84000722] 1.3936988474946297\n",
      " Training with pattern  4  weights  [-2.71697084  2.84000719] 1.394483583710665   weights  [-2.71865365  2.8416378 ]  bias  1.3953294231290896\n",
      "pattern1 0 0 1 0.884338\n",
      "pattern2 0 1 1 0.999582\n",
      "pattern3 1 0 -1 -0.867608\n",
      "pattern4 1 1 1 0.908403\n",
      " modified Weights  [-2.71865365  2.8416378 ] 1.3953294231290896\n",
      "+++++++++++Epoch  342  cost=  0.03929542546193329\n",
      " Training with pattern  1  weights  [-2.71865365  2.8416378 ] 1.3953294231290896   weights  [-2.71865365  2.8416378 ]  bias  1.397850237574967\n",
      "pattern1 0 0 1 0.884886\n",
      "pattern2 0 1 1 0.999585\n",
      "pattern3 1 0 -1 -0.866984\n",
      "pattern4 1 1 1 0.908843\n",
      " modified Weights  [-2.71865365  2.8416378 ] 1.397850237574967\n",
      " Training with pattern  2  weights  [-2.71865365  2.8416378 ] 1.3953294231290896   weights  [-2.71865365  2.84163783]  bias  1.3978502720952424\n",
      "pattern1 0 0 1 0.884886\n",
      "pattern2 0 1 1 0.999585\n",
      "pattern3 1 0 -1 -0.866984\n",
      "pattern4 1 1 1 0.908843\n",
      " modified Weights  [-2.71865365  2.84163783] 1.3978502720952424\n",
      " Training with pattern  3  weights  [-2.71865365  2.8416378 ] 1.3953294231290896   weights  [-2.72195697  2.84163783]  bias  1.3945469492092888\n",
      "pattern1 0 0 1 0.884167\n",
      "pattern2 0 1 1 0.999582\n",
      "pattern3 1 0 -1 -0.868615\n",
      "pattern4 1 1 1 0.907686\n",
      " modified Weights  [-2.72195697  2.84163783] 1.3945469492092888\n",
      " Training with pattern  4  weights  [-2.71865365  2.8416378 ] 1.3953294231290896   weights  [-2.72033128  2.84326352]  bias  1.3961726396628005\n",
      "pattern1 0 0 1 0.884522\n",
      "pattern2 0 1 1 0.999584\n",
      "pattern3 1 0 -1 -0.867814\n",
      "pattern4 1 1 1 0.908542\n",
      " modified Weights  [-2.72033128  2.84326352] 1.3961726396628005\n",
      "+++++++++++Epoch  343  cost=  0.039173128081076806\n",
      " Training with pattern  1  weights  [-2.72033128  2.84326352] 1.3961726396628005   weights  [-2.72033128  2.84326352]  bias  1.3986857006531923\n",
      "pattern1 0 0 1 0.885067\n",
      "pattern2 0 1 1 0.999587\n",
      "pattern3 1 0 -1 -0.867193\n",
      "pattern4 1 1 1 0.908979\n",
      " modified Weights  [-2.72033128  2.84326352] 1.3986857006531923\n",
      " Training with pattern  2  weights  [-2.72033128  2.84326352] 1.3961726396628005   weights  [-2.72033128  2.84326356]  bias  1.3986857348353958\n",
      "pattern1 0 0 1 0.885067\n",
      "pattern2 0 1 1 0.999587\n",
      "pattern3 1 0 -1 -0.867193\n",
      "pattern4 1 1 1 0.908979\n",
      " modified Weights  [-2.72033128  2.84326356] 1.3986857348353958\n",
      " Training with pattern  3  weights  [-2.72033128  2.84326352] 1.3961726396628005   weights  [-2.7236246   2.84326356]  bias  1.395392415339777\n",
      "pattern1 0 0 1 0.884352\n",
      "pattern2 0 1 1 0.999584\n",
      "pattern3 1 0 -1 -0.868817\n",
      "pattern4 1 1 1 0.907828\n",
      " modified Weights  [-2.7236246   2.84326356] 1.395392415339777\n",
      " Training with pattern  4  weights  [-2.72033128  2.84326352] 1.3961726396628005   weights  [-2.72200376  2.84488439]  bias  1.3970132491937919\n",
      "pattern1 0 0 1 0.884704\n",
      "pattern2 0 1 1 0.999587\n",
      "pattern3 1 0 -1 -0.86802\n",
      "pattern4 1 1 1 0.908679\n",
      " modified Weights  [-2.72200376  2.84488439] 1.3970132491937919\n",
      "+++++++++++Epoch  344  cost=  0.03905156921217383\n",
      " Training with pattern  1  weights  [-2.72200376  2.84488439] 1.3970132491937919   weights  [-2.72200376  2.84488439]  bias  1.3995186032802127\n",
      "pattern1 0 0 1 0.885248\n",
      "pattern2 0 1 1 0.999589\n",
      "pattern3 1 0 -1 -0.867401\n",
      "pattern4 1 1 1 0.909115\n",
      " modified Weights  [-2.72200376  2.84488439] 1.3995186032802127\n",
      " Training with pattern  2  weights  [-2.72200376  2.84488439] 1.3970132491937919   weights  [-2.72200376  2.84488442]  bias  1.399518637128659\n",
      "pattern1 0 0 1 0.885248\n",
      "pattern2 0 1 1 0.999589\n",
      "pattern3 1 0 -1 -0.867401\n",
      "pattern4 1 1 1 0.909115\n",
      " modified Weights  [-2.72200376  2.84488442] 1.399518637128659\n",
      " Training with pattern  3  weights  [-2.72200376  2.84488439] 1.3970132491937919   weights  [-2.72528714  2.84488442]  bias  1.396235261873159\n",
      "pattern1 0 0 1 0.884535\n",
      "pattern2 0 1 1 0.999586\n",
      "pattern3 1 0 -1 -0.869017\n",
      "pattern4 1 1 1 0.907969\n",
      " modified Weights  [-2.72528714  2.84488442] 1.396235261873159\n",
      " Training with pattern  4  weights  [-2.72200376  2.84488439] 1.3970132491937919   weights  [-2.72367113  2.84650043]  bias  1.397851267461768\n",
      "pattern1 0 0 1 0.884886\n",
      "pattern2 0 1 1 0.999589\n",
      "pattern3 1 0 -1 -0.868224\n",
      "pattern4 1 1 1 0.908816\n",
      " modified Weights  [-2.72367113  2.84650043] 1.397851267461768\n",
      "+++++++++++Epoch  345  cost=  0.038930742276504525\n",
      " Training with pattern  1  weights  [-2.72367113  2.84650043] 1.397851267461768   weights  [-2.72367113  2.84650043]  bias  1.4003489607822528\n",
      "pattern1 0 0 1 0.885427\n",
      "pattern2 0 1 1 0.999591\n",
      "pattern3 1 0 -1 -0.867608\n",
      "pattern4 1 1 1 0.90925\n",
      " modified Weights  [-2.72367113  2.84650043] 1.4003489607822528\n",
      " Training with pattern  2  weights  [-2.72367113  2.84650043] 1.397851267461768   weights  [-2.72367113  2.84650046]  bias  1.4003489943011884\n",
      "pattern1 0 0 1 0.885427\n",
      "pattern2 0 1 1 0.999591\n",
      "pattern3 1 0 -1 -0.867608\n",
      "pattern4 1 1 1 0.90925\n",
      " modified Weights  [-2.72367113  2.84650046] 1.4003489943011884\n",
      " Training with pattern  3  weights  [-2.72367113  2.84650043] 1.397851267461768   weights  [-2.72694462  2.84650046]  bias  1.3970755046530665\n",
      "pattern1 0 0 1 0.884718\n",
      "pattern2 0 1 1 0.999588\n",
      "pattern3 1 0 -1 -0.869217\n",
      "pattern4 1 1 1 0.908109\n",
      " modified Weights  [-2.72694462  2.84650046] 1.3970755046530665\n",
      " Training with pattern  4  weights  [-2.72367113  2.84650043] 1.397851267461768   weights  [-2.72533342  2.84811167]  bias  1.3986867100658253\n",
      "pattern1 0 0 1 0.885067\n",
      "pattern2 0 1 1 0.999591\n",
      "pattern3 1 0 -1 -0.868427\n",
      "pattern4 1 1 1 0.908953\n",
      " modified Weights  [-2.72533342  2.84811167] 1.3986867100658253\n",
      "+++++++++++Epoch  346  cost=  0.0388106407725878\n",
      " Training with pattern  1  weights  [-2.72533342  2.84811167] 1.3986867100658253   weights  [-2.72533342  2.84811167]  bias  1.4011767883497779\n",
      "pattern1 0 0 1 0.885606\n",
      "pattern2 0 1 1 0.999593\n",
      "pattern3 1 0 -1 -0.867814\n",
      "pattern4 1 1 1 0.909384\n",
      " modified Weights  [-2.72533342  2.84811167] 1.4011767883497779\n",
      " Training with pattern  2  weights  [-2.72533342  2.84811167] 1.3986867100658253   weights  [-2.72533342  2.8481117 ]  bias  1.4011768215433833\n",
      "pattern1 0 0 1 0.885606\n",
      "pattern2 0 1 1 0.999593\n",
      "pattern3 1 0 -1 -0.867814\n",
      "pattern4 1 1 1 0.909384\n",
      " modified Weights  [-2.72533342  2.8481117 ] 1.4011768215433833\n",
      " Training with pattern  3  weights  [-2.72533342  2.84811167] 1.3986867100658253   weights  [-2.72859708  2.8481117 ]  bias  1.3979131593813967\n",
      "pattern1 0 0 1 0.8849\n",
      "pattern2 0 1 1 0.99959\n",
      "pattern3 1 0 -1 -0.869416\n",
      "pattern4 1 1 1 0.908248\n",
      " modified Weights  [-2.72859708  2.8481117 ] 1.3979131593813967\n",
      " Training with pattern  4  weights  [-2.72533342  2.84811167] 1.3986867100658253   weights  [-2.72699065  2.84971813]  bias  1.3995195924661112\n",
      "pattern1 0 0 1 0.885248\n",
      "pattern2 0 1 1 0.999593\n",
      "pattern3 1 0 -1 -0.86863\n",
      "pattern4 1 1 1 0.909088\n",
      " modified Weights  [-2.72699065  2.84971813] 1.3995195924661112\n",
      "+++++++++++Epoch  347  cost=  0.038691258275057344\n",
      " Training with pattern  1  weights  [-2.72699065  2.84971813] 1.3995195924661112   weights  [-2.72699065  2.84971813]  bias  1.4020021010390826\n",
      "pattern1 0 0 1 0.885784\n",
      "pattern2 0 1 1 0.999595\n",
      "pattern3 1 0 -1 -0.868019\n",
      "pattern4 1 1 1 0.909518\n",
      " modified Weights  [-2.72699065  2.84971813] 1.4020021010390826\n",
      " Training with pattern  2  weights  [-2.72699065  2.84971813] 1.3995195924661112   weights  [-2.72699065  2.84971817]  bias  1.4020021339114725\n",
      "pattern1 0 0 1 0.885784\n",
      "pattern2 0 1 1 0.999595\n",
      "pattern3 1 0 -1 -0.868019\n",
      "pattern4 1 1 1 0.909518\n",
      " modified Weights  [-2.72699065  2.84971817] 1.4020021339114725\n",
      " Training with pattern  3  weights  [-2.72699065  2.84971813] 1.3995195924661112   weights  [-2.73024454  2.84971817]  bias  1.3987482416199855\n",
      "pattern1 0 0 1 0.885081\n",
      "pattern2 0 1 1 0.999592\n",
      "pattern3 1 0 -1 -0.869615\n",
      "pattern4 1 1 1 0.908387\n",
      " modified Weights  [-2.73024454  2.84971817] 1.3987482416199855\n",
      " Training with pattern  4  weights  [-2.72699065  2.84971813] 1.3995195924661112   weights  [-2.72864285  2.85131986]  bias  1.4003499299854578\n",
      "pattern1 0 0 1 0.885427\n",
      "pattern2 0 1 1 0.999595\n",
      "pattern3 1 0 -1 -0.868831\n",
      "pattern4 1 1 1 0.909224\n",
      " modified Weights  [-2.72864285  2.85131986] 1.4003499299854578\n",
      "+++++++++++Epoch  348  cost=  0.03857258843355797\n",
      " Training with pattern  1  weights  [-2.72864285  2.85131986] 1.4003499299854578   weights  [-2.72864285  2.85131986]  bias  1.4028249137738547\n",
      "pattern1 0 0 1 0.885961\n",
      "pattern2 0 1 1 0.999597\n",
      "pattern3 1 0 -1 -0.868223\n",
      "pattern4 1 1 1 0.909652\n",
      " modified Weights  [-2.72864285  2.85131986] 1.4028249137738547\n",
      " Training with pattern  2  weights  [-2.72864285  2.85131986] 1.4003499299854578   weights  [-2.72864285  2.85131989]  bias  1.4028249463290805\n",
      "pattern1 0 0 1 0.885961\n",
      "pattern2 0 1 1 0.999597\n",
      "pattern3 1 0 -1 -0.868223\n",
      "pattern4 1 1 1 0.909652\n",
      " modified Weights  [-2.72864285  2.85131989] 1.4028249463290805\n",
      " Training with pattern  3  weights  [-2.72864285  2.85131986] 1.4003499299854578   weights  [-2.73188703  2.85131989]  bias  1.3995807667922566\n",
      "pattern1 0 0 1 0.885261\n",
      "pattern2 0 1 1 0.999594\n",
      "pattern3 1 0 -1 -0.869812\n",
      "pattern4 1 1 1 0.908526\n",
      " modified Weights  [-2.73188703  2.85131989] 1.3995807667922566\n",
      " Training with pattern  4  weights  [-2.72864285  2.85131986] 1.4003499299854578   weights  [-2.73029006  2.85291686]  bias  1.401177737810993\n",
      "pattern1 0 0 1 0.885606\n",
      "pattern2 0 1 1 0.999596\n",
      "pattern3 1 0 -1 -0.869032\n",
      "pattern4 1 1 1 0.909358\n",
      " modified Weights  [-2.73029006  2.85291686] 1.401177737810993\n",
      "+++++++++++Epoch  349  cost=  0.03845462497166055\n",
      " Training with pattern  1  weights  [-2.73029006  2.85291686] 1.401177737810993   weights  [-2.73029006  2.85291686]  bias  1.4036452413467182\n",
      "pattern1 0 0 1 0.886137\n",
      "pattern2 0 1 1 0.999598\n",
      "pattern3 1 0 -1 -0.868427\n",
      "pattern4 1 1 1 0.909784\n",
      " modified Weights  [-2.73029006  2.85291686] 1.4036452413467182\n",
      " Training with pattern  2  weights  [-2.73029006  2.85291686] 1.401177737810993   weights  [-2.73029006  2.85291689]  bias  1.4036452735887681\n",
      "pattern1 0 0 1 0.886137\n",
      "pattern2 0 1 1 0.999598\n",
      "pattern3 1 0 -1 -0.868427\n",
      "pattern4 1 1 1 0.909784\n",
      " modified Weights  [-2.73029006  2.85291689] 1.4036452735887681\n",
      " Training with pattern  3  weights  [-2.73029006  2.85291686] 1.401177737810993   weights  [-2.73352458  2.85291689]  bias  1.400410750184847\n",
      "pattern1 0 0 1 0.88544\n",
      "pattern2 0 1 1 0.999596\n",
      "pattern3 1 0 -1 -0.870008\n",
      "pattern4 1 1 1 0.908663\n",
      " modified Weights  [-2.73352458  2.85291689] 1.400410750184847\n",
      " Training with pattern  4  weights  [-2.73029006  2.85291686] 1.401177737810993   weights  [-2.7319323   2.85450917]  bias  1.4020030309957272\n",
      "pattern1 0 0 1 0.885784\n",
      "pattern2 0 1 1 0.999598\n",
      "pattern3 1 0 -1 -0.869232\n",
      "pattern4 1 1 1 0.909492\n",
      " modified Weights  [-2.7319323   2.85450917] 1.4020030309957272\n",
      "+++++++++++Epoch  350  cost=  0.038337361685796274\n",
      " Training with pattern  1  weights  [-2.7319323   2.85450917] 1.4020030309957272   weights  [-2.7319323   2.85450917]  bias  1.4044630984207536\n",
      "pattern1 0 0 1 0.886313\n",
      "pattern2 0 1 1 0.9996\n",
      "pattern3 1 0 -1 -0.868629\n",
      "pattern4 1 1 1 0.909917\n",
      " modified Weights  [-2.7319323   2.85450917] 1.4044630984207536\n",
      " Training with pattern  2  weights  [-2.7319323   2.85450917] 1.4020030309957272   weights  [-2.7319323  2.8545092]  bias  1.4044631303535542\n",
      "pattern1 0 0 1 0.886313\n",
      "pattern2 0 1 1 0.9996\n",
      "pattern3 1 0 -1 -0.868629\n",
      "pattern4 1 1 1 0.909917\n",
      " modified Weights  [-2.7319323  2.8545092] 1.4044631303535542\n",
      " Training with pattern  3  weights  [-2.7319323   2.85450917] 1.4020030309957272   weights  [-2.73515722  2.8545092 ]  bias  1.4012382069492075\n",
      "pattern1 0 0 1 0.885619\n",
      "pattern2 0 1 1 0.999598\n",
      "pattern3 1 0 -1 -0.870204\n",
      "pattern4 1 1 1 0.9088\n",
      " modified Weights  [-2.73515722  2.8545092 ] 1.4012382069492075\n",
      " Training with pattern  4  weights  [-2.7319323   2.85450917] 1.4020030309957272   weights  [-2.73356961  2.85609682]  bias  1.4028258244601164\n",
      "pattern1 0 0 1 0.885961\n",
      "pattern2 0 1 1 0.9996\n",
      "pattern3 1 0 -1 -0.869431\n",
      "pattern4 1 1 1 0.909626\n",
      " modified Weights  [-2.73356961  2.85609682] 1.4028258244601164\n",
      "+++++++++++Epoch  351  cost=  0.03822079244420833\n",
      " *********Epoch  350 Error  0.03822079244420833\n",
      " Training with pattern  1  weights  [-2.73356961  2.85609682] 1.4028258244601164   weights  [-2.73356961  2.85609682]  bias  1.4052784995309948\n",
      "pattern1 0 0 1 0.886487\n",
      "pattern2 0 1 1 0.999602\n",
      "pattern3 1 0 -1 -0.868831\n",
      "pattern4 1 1 1 0.910048\n",
      " modified Weights  [-2.73356961  2.85609682] 1.4052784995309948\n",
      " Training with pattern  2  weights  [-2.73356961  2.85609682] 1.4028258244601164   weights  [-2.73356961  2.85609685]  bias  1.4052785311584122\n",
      "pattern1 0 0 1 0.886487\n",
      "pattern2 0 1 1 0.999602\n",
      "pattern3 1 0 -1 -0.868831\n",
      "pattern4 1 1 1 0.910048\n",
      " modified Weights  [-2.73356961  2.85609685] 1.4052785311584122\n",
      " Training with pattern  3  weights  [-2.73356961  2.85609682] 1.4028258244601164   weights  [-2.73678499  2.85609685]  bias  1.4020631521031812\n",
      "pattern1 0 0 1 0.885797\n",
      "pattern2 0 1 1 0.9996\n",
      "pattern3 1 0 -1 -0.870399\n",
      "pattern4 1 1 1 0.908937\n",
      " modified Weights  [-2.73678499  2.85609685] 1.4020631521031812\n",
      " Training with pattern  4  weights  [-2.73356961  2.85609682] 1.4028258244601164   weights  [-2.73520201  2.85767983]  bias  1.4036461329936043\n",
      "pattern1 0 0 1 0.886137\n",
      "pattern2 0 1 1 0.999602\n",
      "pattern3 1 0 -1 -0.869629\n",
      "pattern4 1 1 1 0.909759\n",
      " modified Weights  [-2.73520201  2.85767983] 1.4036461329936043\n",
      "+++++++++++Epoch  352  cost=  0.038104911185922394\n",
      " Training with pattern  1  weights  [-2.73520201  2.85767983] 1.4036461329936043   weights  [-2.73520201  2.85767983]  bias  1.4060914590859068\n",
      "pattern1 0 0 1 0.886661\n",
      "pattern2 0 1 1 0.999604\n",
      "pattern3 1 0 -1 -0.869032\n",
      "pattern4 1 1 1 0.910179\n",
      " modified Weights  [-2.73520201  2.85767983] 1.4060914590859068\n",
      " Training with pattern  2  weights  [-2.73520201  2.85767983] 1.4036461329936043   weights  [-2.73520201  2.85767987]  bias  1.4060914904117479\n",
      "pattern1 0 0 1 0.886661\n",
      "pattern2 0 1 1 0.999604\n",
      "pattern3 1 0 -1 -0.869032\n",
      "pattern4 1 1 1 0.910179\n",
      " modified Weights  [-2.73520201  2.85767987] 1.4060914904117479\n",
      " Training with pattern  3  weights  [-2.73520201  2.85767983] 1.4036461329936043   weights  [-2.7384079   2.85767987]  bias  1.4028856005325583\n",
      "pattern1 0 0 1 0.885974\n",
      "pattern2 0 1 1 0.999602\n",
      "pattern3 1 0 -1 -0.870593\n",
      "pattern4 1 1 1 0.909073\n",
      " modified Weights  [-2.7384079   2.85767987] 1.4028856005325583\n",
      " Training with pattern  4  weights  [-2.73520201  2.85767983] 1.4036461329936043   weights  [-2.73682952  2.85925824]  bias  1.4044639712561413\n",
      "pattern1 0 0 1 0.886313\n",
      "pattern2 0 1 1 0.999604\n",
      "pattern3 1 0 -1 -0.869826\n",
      "pattern4 1 1 1 0.909891\n",
      " modified Weights  [-2.73682952  2.85925824] 1.4044639712561413\n",
      "+++++++++++Epoch  353  cost=  0.03798971191973434\n",
      " Training with pattern  1  weights  [-2.73682952  2.85925824] 1.4044639712561413   weights  [-2.73682952  2.85925824]  bias  1.406901991368841\n",
      "pattern1 0 0 1 0.886834\n",
      "pattern2 0 1 1 0.999606\n",
      "pattern3 1 0 -1 -0.869232\n",
      "pattern4 1 1 1 0.91031\n",
      " modified Weights  [-2.73682952  2.85925824] 1.406901991368841\n",
      " Training with pattern  2  weights  [-2.73682952  2.85925824] 1.4044639712561413   weights  [-2.73682952  2.85925827]  bias  1.406902022396854\n",
      "pattern1 0 0 1 0.886834\n",
      "pattern2 0 1 1 0.999606\n",
      "pattern3 1 0 -1 -0.869232\n",
      "pattern4 1 1 1 0.91031\n",
      " modified Weights  [-2.73682952  2.85925827] 1.406902022396854\n",
      " Training with pattern  3  weights  [-2.73682952  2.85925824] 1.4044639712561413   weights  [-2.74002598  2.85925827]  bias  1.4037055669926093\n",
      "pattern1 0 0 1 0.88615\n",
      "pattern2 0 1 1 0.999604\n",
      "pattern3 1 0 -1 -0.870786\n",
      "pattern4 1 1 1 0.909208\n",
      " modified Weights  [-2.74002598  2.85925827] 1.4037055669926093\n",
      " Training with pattern  4  weights  [-2.73682952  2.85925824] 1.4044639712561413   weights  [-2.73845219  2.86083205]  bias  1.4052793537796808\n",
      "pattern1 0 0 1 0.886487\n",
      "pattern2 0 1 1 0.999606\n",
      "pattern3 1 0 -1 -0.870023\n",
      "pattern4 1 1 1 0.910023\n",
      " modified Weights  [-2.73845219  2.86083205] 1.4052793537796808\n",
      "+++++++++++Epoch  354  cost=  0.03787518872321504\n",
      " Training with pattern  1  weights  [-2.73845219  2.86083205] 1.4052793537796808   weights  [-2.73845219  2.86083205]  bias  1.407710110539469\n",
      "pattern1 0 0 1 0.887007\n",
      "pattern2 0 1 1 0.999608\n",
      "pattern3 1 0 -1 -0.869431\n",
      "pattern4 1 1 1 0.91044\n",
      " modified Weights  [-2.73845219  2.86083205] 1.407710110539469\n",
      " Training with pattern  2  weights  [-2.73845219  2.86083205] 1.4052793537796808   weights  [-2.73845219  2.86083208]  bias  1.407710141273345\n",
      "pattern1 0 0 1 0.887007\n",
      "pattern2 0 1 1 0.999608\n",
      "pattern3 1 0 -1 -0.869431\n",
      "pattern4 1 1 1 0.91044\n",
      " modified Weights  [-2.73845219  2.86083208] 1.407710141273345\n",
      " Training with pattern  3  weights  [-2.73845219  2.86083205] 1.4052793537796808   weights  [-2.74163927  2.86083208]  bias  1.4045230661095949\n",
      "pattern1 0 0 1 0.886325\n",
      "pattern2 0 1 1 0.999605\n",
      "pattern3 1 0 -1 -0.870978\n",
      "pattern4 1 1 1 0.909343\n",
      " modified Weights  [-2.74163927  2.86083208] 1.4045230661095949\n",
      " Training with pattern  4  weights  [-2.73845219  2.86083205] 1.4052793537796808   weights  [-2.74007004  2.86240131]  bias  1.4060922949696562\n",
      "pattern1 0 0 1 0.886661\n",
      "pattern2 0 1 1 0.999608\n",
      "pattern3 1 0 -1 -0.870218\n",
      "pattern4 1 1 1 0.910154\n",
      " modified Weights  [-2.74007004  2.86240131] 1.4060922949696562\n",
      "+++++++++++Epoch  355  cost=  0.037761335741732134\n",
      " Training with pattern  1  weights  [-2.74007004  2.86240131] 1.4060922949696562   weights  [-2.74007004  2.86240131]  bias  1.4085158306351984\n",
      "pattern1 0 0 1 0.887179\n",
      "pattern2 0 1 1 0.99961\n",
      "pattern3 1 0 -1 -0.869629\n",
      "pattern4 1 1 1 0.910569\n",
      " modified Weights  [-2.74007004  2.86240131] 1.4085158306351984\n",
      " Training with pattern  2  weights  [-2.74007004  2.86240131] 1.4060922949696562   weights  [-2.74007004  2.86240134]  bias  1.4085158610785724\n",
      "pattern1 0 0 1 0.887179\n",
      "pattern2 0 1 1 0.99961\n",
      "pattern3 1 0 -1 -0.869629\n",
      "pattern4 1 1 1 0.910569\n",
      " modified Weights  [-2.74007004  2.86240134] 1.4085158610785724\n",
      " Training with pattern  3  weights  [-2.74007004  2.86240131] 1.4060922949696562   weights  [-2.74324779  2.86240134]  bias  1.405338112382256\n",
      "pattern1 0 0 1 0.8865\n",
      "pattern2 0 1 1 0.999607\n",
      "pattern3 1 0 -1 -0.871169\n",
      "pattern4 1 1 1 0.909477\n",
      " modified Weights  [-2.74324779  2.86240134] 1.405338112382256\n",
      " Training with pattern  4  weights  [-2.74007004  2.86240131] 1.4060922949696562   weights  [-2.74168309  2.86396604]  bias  1.4069028091064342\n",
      "pattern1 0 0 1 0.886835\n",
      "pattern2 0 1 1 0.99961\n",
      "pattern3 1 0 -1 -0.870413\n",
      "pattern4 1 1 1 0.910285\n",
      " modified Weights  [-2.74168309  2.86396604] 1.4069028091064342\n",
      "+++++++++++Epoch  356  cost=  0.037648147187488726\n",
      " Training with pattern  1  weights  [-2.74168309  2.86396604] 1.4069028091064342   weights  [-2.74168309  2.86396604]  bias  1.4093191655725659\n",
      "pattern1 0 0 1 0.887349\n",
      "pattern2 0 1 1 0.999612\n",
      "pattern3 1 0 -1 -0.869826\n",
      "pattern4 1 1 1 0.910698\n",
      " modified Weights  [-2.74168309  2.86396604] 1.4093191655725659\n",
      " Training with pattern  2  weights  [-2.74168309  2.86396604] 1.4069028091064342   weights  [-2.74168309  2.86396607]  bias  1.4093191957290174\n",
      "pattern1 0 0 1 0.887349\n",
      "pattern2 0 1 1 0.999612\n",
      "pattern3 1 0 -1 -0.869826\n",
      "pattern4 1 1 1 0.910698\n",
      " modified Weights  [-2.74168309  2.86396607] 1.4093191957290174\n",
      " Training with pattern  3  weights  [-2.74168309  2.86396604] 1.4069028091064342   weights  [-2.74485157  2.86396607]  bias  1.4061507201832804\n",
      "pattern1 0 0 1 0.886674\n",
      "pattern2 0 1 1 0.999609\n",
      "pattern3 1 0 -1 -0.87136\n",
      "pattern4 1 1 1 0.909611\n",
      " modified Weights  [-2.74485157  2.86396607] 1.4061507201832804\n",
      " Training with pattern  4  weights  [-2.74168309  2.86396604] 1.4069028091064342   weights  [-2.74329138  2.86552626]  bias  1.4077109103467498\n",
      "pattern1 0 0 1 0.887007\n",
      "pattern2 0 1 1 0.999612\n",
      "pattern3 1 0 -1 -0.870607\n",
      "pattern4 1 1 1 0.910415\n",
      " modified Weights  [-2.74329138  2.86552626] 1.4077109103467498\n",
      "+++++++++++Epoch  357  cost=  0.03753561733857791\n",
      " Training with pattern  1  weights  [-2.74329138  2.86552626] 1.4077109103467498   weights  [-2.74329138  2.86552626]  bias  1.4101201291486125\n",
      "pattern1 0 0 1 0.88752\n",
      "pattern2 0 1 1 0.999613\n",
      "pattern3 1 0 -1 -0.870022\n",
      "pattern4 1 1 1 0.910827\n",
      " modified Weights  [-2.74329138  2.86552626] 1.4101201291486125\n",
      " Training with pattern  2  weights  [-2.74329138  2.86552626] 1.4077109103467498   weights  [-2.74329138  2.86552629]  bias  1.4101201590216672\n",
      "pattern1 0 0 1 0.88752\n",
      "pattern2 0 1 1 0.999613\n",
      "pattern3 1 0 -1 -0.870022\n",
      "pattern4 1 1 1 0.910827\n",
      " modified Weights  [-2.74329138  2.86552629] 1.4101201590216672\n",
      " Training with pattern  3  weights  [-2.74329138  2.86552626] 1.4077109103467498   weights  [-2.74645063  2.86552629]  bias  1.4069609037607507\n",
      "pattern1 0 0 1 0.886847\n",
      "pattern2 0 1 1 0.999611\n",
      "pattern3 1 0 -1 -0.87155\n",
      "pattern4 1 1 1 0.909744\n",
      " modified Weights  [-2.74645063  2.86552629] 1.4069609037607507\n",
      " Training with pattern  4  weights  [-2.74329138  2.86552626] 1.4077109103467498   weights  [-2.74489492  2.867082  ]  bias  1.408516612725119\n",
      "pattern1 0 0 1 0.887179\n",
      "pattern2 0 1 1 0.999613\n",
      "pattern3 1 0 -1 -0.8708\n",
      "pattern4 1 1 1 0.910545\n",
      " modified Weights  [-2.74489492  2.867082  ] 1.408516612725119\n",
      "+++++++++++Epoch  358  cost=  0.03742374053805368\n",
      " Training with pattern  1  weights  [-2.74489492  2.867082  ] 1.408516612725119   weights  [-2.74489492  2.867082  ]  bias  1.4109187350422383\n",
      "pattern1 0 0 1 0.887689\n",
      "pattern2 0 1 1 0.999615\n",
      "pattern3 1 0 -1 -0.870218\n",
      "pattern4 1 1 1 0.910955\n",
      " modified Weights  [-2.74489492  2.867082  ] 1.4109187350422383\n",
      " Training with pattern  2  weights  [-2.74489492  2.867082  ] 1.408516612725119   weights  [-2.74489492  2.86708203]  bias  1.4109187646353682\n",
      "pattern1 0 0 1 0.887689\n",
      "pattern2 0 1 1 0.999615\n",
      "pattern3 1 0 -1 -0.870218\n",
      "pattern4 1 1 1 0.910955\n",
      " modified Weights  [-2.74489492  2.86708203] 1.4109187646353682\n",
      " Training with pattern  3  weights  [-2.74489492  2.867082  ] 1.408516612725119   weights  [-2.74804501  2.86708203]  bias  1.407768677239569\n",
      "pattern1 0 0 1 0.887019\n",
      "pattern2 0 1 1 0.999613\n",
      "pattern3 1 0 -1 -0.871739\n",
      "pattern4 1 1 1 0.909876\n",
      " modified Weights  [-2.74804501  2.86708203] 1.407768677239569\n",
      " Training with pattern  4  weights  [-2.74489492  2.867082  ] 1.408516612725119   weights  [-2.74649376  2.86863328]  bias  1.4093199301552326\n",
      "pattern1 0 0 1 0.88735\n",
      "pattern2 0 1 1 0.999615\n",
      "pattern3 1 0 -1 -0.870992\n",
      "pattern4 1 1 1 0.910674\n",
      " modified Weights  [-2.74649376  2.86863328] 1.4093199301552326\n",
      "+++++++++++Epoch  359  cost=  0.037312511193016346\n",
      " Training with pattern  1  weights  [-2.74649376  2.86863328] 1.4093199301552326   weights  [-2.74649376  2.86863328]  bias  1.4117149968155391\n",
      "pattern1 0 0 1 0.887858\n",
      "pattern2 0 1 1 0.999617\n",
      "pattern3 1 0 -1 -0.870412\n",
      "pattern4 1 1 1 0.911082\n",
      " modified Weights  [-2.74649376  2.86863328] 1.4117149968155391\n",
      " Training with pattern  2  weights  [-2.74649376  2.86863328] 1.4093199301552326   weights  [-2.74649376  2.86863331]  bias  1.4117150261321643\n",
      "pattern1 0 0 1 0.887858\n",
      "pattern2 0 1 1 0.999617\n",
      "pattern3 1 0 -1 -0.870412\n",
      "pattern4 1 1 1 0.911082\n",
      " modified Weights  [-2.74649376  2.86863331] 1.4117150261321643\n",
      " Training with pattern  3  weights  [-2.74649376  2.86863328] 1.4093199301552326   weights  [-2.74963473  2.86863331]  bias  1.4085740546228647\n",
      "pattern1 0 0 1 0.887191\n",
      "pattern2 0 1 1 0.999615\n",
      "pattern3 1 0 -1 -0.871927\n",
      "pattern4 1 1 1 0.910008\n",
      " modified Weights  [-2.74963473  2.86863331] 1.4085740546228647\n",
      " Training with pattern  4  weights  [-2.74649376  2.86863328] 1.4093199301552326   weights  [-2.74808791  2.87018013]  bias  1.4101208764313304\n",
      "pattern1 0 0 1 0.88752\n",
      "pattern2 0 1 1 0.999617\n",
      "pattern3 1 0 -1 -0.871183\n",
      "pattern4 1 1 1 0.910803\n",
      " modified Weights  [-2.74808791  2.87018013] 1.4101208764313304\n",
      "+++++++++++Epoch  360  cost=  0.03720192377371495\n",
      " Training with pattern  1  weights  [-2.74808791  2.87018013] 1.4101208764313304   weights  [-2.74808791  2.87018013]  bias  1.412508927915123\n",
      "pattern1 0 0 1 0.888026\n",
      "pattern2 0 1 1 0.999619\n",
      "pattern3 1 0 -1 -0.870606\n",
      "pattern4 1 1 1 0.911209\n",
      " modified Weights  [-2.74808791  2.87018013] 1.412508927915123\n",
      " Training with pattern  2  weights  [-2.74808791  2.87018013] 1.4101208764313304   weights  [-2.74808791  2.87018016]  bias  1.4125089569586118\n",
      "pattern1 0 0 1 0.888026\n",
      "pattern2 0 1 1 0.999619\n",
      "pattern3 1 0 -1 -0.870606\n",
      "pattern4 1 1 1 0.911209\n",
      " modified Weights  [-2.74808791  2.87018016] 1.4125089569586118\n",
      " Training with pattern  3  weights  [-2.74808791  2.87018013] 1.4101208764313304   weights  [-2.75121981  2.87018016]  bias  1.4093770497933782\n",
      "pattern1 0 0 1 0.887362\n",
      "pattern2 0 1 1 0.999616\n",
      "pattern3 1 0 -1 -0.872114\n",
      "pattern4 1 1 1 0.91014\n",
      " modified Weights  [-2.75121981  2.87018016] 1.4093770497933782\n",
      " Training with pattern  4  weights  [-2.74808791  2.87018013] 1.4101208764313304   weights  [-2.7496774   2.87172258]  bias  1.4109194652295542\n",
      "pattern1 0 0 1 0.887689\n",
      "pattern2 0 1 1 0.999619\n",
      "pattern3 1 0 -1 -0.871374\n",
      "pattern4 1 1 1 0.910931\n",
      " modified Weights  [-2.7496774   2.87172258] 1.4109194652295542\n",
      "+++++++++++Epoch  361  cost=  0.037091972812663465\n",
      " *********Epoch  360 Error  0.037091972812663465\n",
      " Training with pattern  1  weights  [-2.7496774   2.87172258] 1.4109194652295542   weights  [-2.7496774   2.87172258]  bias  1.41330054167341\n",
      "pattern1 0 0 1 0.888193\n",
      "pattern2 0 1 1 0.999621\n",
      "pattern3 1 0 -1 -0.870799\n",
      "pattern4 1 1 1 0.911335\n",
      " modified Weights  [-2.7496774   2.87172258] 1.41330054167341\n",
      " Training with pattern  2  weights  [-2.7496774   2.87172258] 1.4109194652295542   weights  [-2.7496774   2.87172261]  bias  1.4133005704470802\n",
      "pattern1 0 0 1 0.888193\n",
      "pattern2 0 1 1 0.999621\n",
      "pattern3 1 0 -1 -0.870799\n",
      "pattern4 1 1 1 0.911335\n",
      " modified Weights  [-2.7496774   2.87172261] 1.4133005704470802\n",
      " Training with pattern  3  weights  [-2.7496774   2.87172258] 1.4109194652295542   weights  [-2.75280029  2.87172261]  bias  1.4101776765148295\n",
      "pattern1 0 0 1 0.887532\n",
      "pattern2 0 1 1 0.999618\n",
      "pattern3 1 0 -1 -0.872301\n",
      "pattern4 1 1 1 0.91027\n",
      " modified Weights  [-2.75280029  2.87172261] 1.4101776765148295\n",
      " Training with pattern  4  weights  [-2.7496774   2.87172258] 1.4109194652295542   weights  [-2.75126226  2.87326064]  bias  1.4117157101092843\n",
      "pattern1 0 0 1 0.887858\n",
      "pattern2 0 1 1 0.999621\n",
      "pattern3 1 0 -1 -0.871563\n",
      "pattern4 1 1 1 0.911058\n",
      " modified Weights  [-2.75126226  2.87326064] 1.4117157101092843\n",
      "+++++++++++Epoch  362  cost=  0.036982652903772166\n",
      " Training with pattern  1  weights  [-2.75126226  2.87326064] 1.4117157101092843   weights  [-2.75126226  2.87326064]  bias  1.4140898513099118\n",
      "pattern1 0 0 1 0.888359\n",
      "pattern2 0 1 1 0.999622\n",
      "pattern3 1 0 -1 -0.870991\n",
      "pattern4 1 1 1 0.911461\n",
      " modified Weights  [-2.75126226  2.87326064] 1.4140898513099118\n",
      " Training with pattern  2  weights  [-2.75126226  2.87326064] 1.4117157101092843   weights  [-2.75126226  2.87326067]  bias  1.4140898798170325\n",
      "pattern1 0 0 1 0.888359\n",
      "pattern2 0 1 1 0.999622\n",
      "pattern3 1 0 -1 -0.870991\n",
      "pattern4 1 1 1 0.911461\n",
      " modified Weights  [-2.75126226  2.87326067] 1.4140898798170325\n",
      " Training with pattern  3  weights  [-2.75126226  2.87326064] 1.4117157101092843   weights  [-2.75437619  2.87326067]  bias  1.410975948433264\n",
      "pattern1 0 0 1 0.887701\n",
      "pattern2 0 1 1 0.99962\n",
      "pattern3 1 0 -1 -0.872487\n",
      "pattern4 1 1 1 0.910401\n",
      " modified Weights  [-2.75437619  2.87326067] 1.410975948433264\n",
      " Training with pattern  4  weights  [-2.75126226  2.87326064] 1.4117157101092843   weights  [-2.75284251  2.87479435]  bias  1.412509624514456\n",
      "pattern1 0 0 1 0.888026\n",
      "pattern2 0 1 1 0.999622\n",
      "pattern3 1 0 -1 -0.871752\n",
      "pattern4 1 1 1 0.911185\n",
      " modified Weights  [-2.75284251  2.87479435] 1.412509624514456\n",
      "+++++++++++Epoch  363  cost=  0.03687395870149289\n",
      " Training with pattern  1  weights  [-2.75284251  2.87479435] 1.412509624514456   weights  [-2.75284251  2.87479435]  bias  1.4148768699324965\n",
      "pattern1 0 0 1 0.888525\n",
      "pattern2 0 1 1 0.999624\n",
      "pattern3 1 0 -1 -0.871183\n",
      "pattern4 1 1 1 0.911586\n",
      " modified Weights  [-2.75284251  2.87479435] 1.4148768699324965\n",
      " Training with pattern  2  weights  [-2.75284251  2.87479435] 1.412509624514456   weights  [-2.75284251  2.87479437]  bias  1.4148768981762871\n",
      "pattern1 0 0 1 0.888525\n",
      "pattern2 0 1 1 0.999624\n",
      "pattern3 1 0 -1 -0.871183\n",
      "pattern4 1 1 1 0.911586\n",
      " modified Weights  [-2.75284251  2.87479437] 1.4148768981762871\n",
      " Training with pattern  3  weights  [-2.75284251  2.87479435] 1.412509624514456   weights  [-2.75594753  2.87479437]  bias  1.4117718790783815\n",
      "pattern1 0 0 1 0.88787\n",
      "pattern2 0 1 1 0.999622\n",
      "pattern3 1 0 -1 -0.872672\n",
      "pattern4 1 1 1 0.91053\n",
      " modified Weights  [-2.75594753  2.87479437] 1.4117718790783815\n",
      " Training with pattern  4  weights  [-2.75284251  2.87479435] 1.412509624514456   weights  [-2.75441819  2.87632372]  bias  1.4133012217748568\n",
      "pattern1 0 0 1 0.888193\n",
      "pattern2 0 1 1 0.999624\n",
      "pattern3 1 0 -1 -0.87194\n",
      "pattern4 1 1 1 0.911311\n",
      " modified Weights  [-2.75441819  2.87632372] 1.4133012217748568\n",
      "+++++++++++Epoch  364  cost=  0.036765884919979536\n",
      " Training with pattern  1  weights  [-2.75441819  2.87632372] 1.4133012217748568   weights  [-2.75441819  2.87632372]  bias  1.4156616105386324\n",
      "pattern1 0 0 1 0.88869\n",
      "pattern2 0 1 1 0.999626\n",
      "pattern3 1 0 -1 -0.871373\n",
      "pattern4 1 1 1 0.911711\n",
      " modified Weights  [-2.75441819  2.87632372] 1.4156616105386324\n",
      " Training with pattern  2  weights  [-2.75441819  2.87632372] 1.4133012217748568   weights  [-2.75441819  2.87632374]  bias  1.415661638522265\n",
      "pattern1 0 0 1 0.88869\n",
      "pattern2 0 1 1 0.999626\n",
      "pattern3 1 0 -1 -0.871373\n",
      "pattern4 1 1 1 0.911711\n",
      " modified Weights  [-2.75441819  2.87632374] 1.415661638522265\n",
      " Training with pattern  3  weights  [-2.75441819  2.87632372] 1.4133012217748568   weights  [-2.75751435  2.87632374]  bias  1.4125654818648459\n",
      "pattern1 0 0 1 0.888038\n",
      "pattern2 0 1 1 0.999624\n",
      "pattern3 1 0 -1 -0.872856\n",
      "pattern4 1 1 1 0.91066\n",
      " modified Weights  [-2.75751435  2.87632374] 1.4125654818648459\n",
      " Training with pattern  4  weights  [-2.75441819  2.87632372] 1.4133012217748568   weights  [-2.75598931  2.87784878]  bias  1.414090515107408\n",
      "pattern1 0 0 1 0.88836\n",
      "pattern2 0 1 1 0.999626\n",
      "pattern3 1 0 -1 -0.872128\n",
      "pattern4 1 1 1 0.911437\n",
      " modified Weights  [-2.75598931  2.87784878] 1.414090515107408\n",
      "+++++++++++Epoch  365  cost=  0.036658426332261504\n",
      " Training with pattern  1  weights  [-2.75598931  2.87784878] 1.414090515107408   weights  [-2.75598931  2.87784878]  bias  1.4164440860166168\n",
      "pattern1 0 0 1 0.888855\n",
      "pattern2 0 1 1 0.999628\n",
      "pattern3 1 0 -1 -0.871563\n",
      "pattern4 1 1 1 0.911835\n",
      " modified Weights  [-2.75598931  2.87784878] 1.4164440860166168\n",
      " Training with pattern  2  weights  [-2.75598931  2.87784878] 1.414090515107408   weights  [-2.75598931  2.87784881]  bias  1.4164441137432164\n",
      "pattern1 0 0 1 0.888855\n",
      "pattern2 0 1 1 0.999628\n",
      "pattern3 1 0 -1 -0.871563\n",
      "pattern4 1 1 1 0.911835\n",
      " modified Weights  [-2.75598931  2.87784881] 1.4164441137432164\n",
      " Training with pattern  3  weights  [-2.75598931  2.87784878] 1.414090515107408   weights  [-2.75907666  2.87784881]  bias  1.4133567700935763\n",
      "pattern1 0 0 1 0.888205\n",
      "pattern2 0 1 1 0.999625\n",
      "pattern3 1 0 -1 -0.873039\n",
      "pattern4 1 1 1 0.910788\n",
      " modified Weights  [-2.75907666  2.87784881] 1.4133567700935763\n",
      " Training with pattern  4  weights  [-2.75598931  2.87784878] 1.414090515107408   weights  [-2.75755591  2.87936955]  bias  1.4148775176174253\n",
      "pattern1 0 0 1 0.888525\n",
      "pattern2 0 1 1 0.999628\n",
      "pattern3 1 0 -1 -0.872314\n",
      "pattern4 1 1 1 0.911563\n",
      " modified Weights  [-2.75755591  2.87936955] 1.4148775176174253\n",
      "+++++++++++Epoch  366  cost=  0.036551577769431076\n",
      " Training with pattern  1  weights  [-2.75755591  2.87936955] 1.4148775176174253   weights  [-2.75755591  2.87936955]  bias  1.4172243091467873\n",
      "pattern1 0 0 1 0.889018\n",
      "pattern2 0 1 1 0.999629\n",
      "pattern3 1 0 -1 -0.871752\n",
      "pattern4 1 1 1 0.911959\n",
      " modified Weights  [-2.75755591  2.87936955] 1.4172243091467873\n",
      " Training with pattern  2  weights  [-2.75755591  2.87936955] 1.4148775176174253   weights  [-2.75755591  2.87936958]  bias  1.4172243366194328\n",
      "pattern1 0 0 1 0.889018\n",
      "pattern2 0 1 1 0.999629\n",
      "pattern3 1 0 -1 -0.871752\n",
      "pattern4 1 1 1 0.911959\n",
      " modified Weights  [-2.75755591  2.87936958] 1.4172243366194328\n",
      " Training with pattern  3  weights  [-2.75755591  2.87936955] 1.4148775176174253   weights  [-2.76063449  2.87936958]  bias  1.4141457569530205\n",
      "pattern1 0 0 1 0.888371\n",
      "pattern2 0 1 1 0.999627\n",
      "pattern3 1 0 -1 -0.873222\n",
      "pattern4 1 1 1 0.910916\n",
      " modified Weights  [-2.76063449  2.87936958] 1.4141457569530205\n",
      " Training with pattern  4  weights  [-2.75755591  2.87936955] 1.4148775176174253   weights  [-2.75911801  2.88088607]  bias  1.4156622422998646\n",
      "pattern1 0 0 1 0.888691\n",
      "pattern2 0 1 1 0.999629\n",
      "pattern3 1 0 -1 -0.8725\n",
      "pattern4 1 1 1 0.911688\n",
      " modified Weights  [-2.75911801  2.88088607] 1.4156622422998646\n",
      "+++++++++++Epoch  367  cost=  0.03644533411984424\n",
      " Training with pattern  1  weights  [-2.75911801  2.88088607] 1.4156622422998646   weights  [-2.75911801  2.88088607]  bias  1.4180022926027163\n",
      "pattern1 0 0 1 0.889181\n",
      "pattern2 0 1 1 0.999631\n",
      "pattern3 1 0 -1 -0.87194\n",
      "pattern4 1 1 1 0.912082\n",
      " modified Weights  [-2.75911801  2.88088607] 1.4180022926027163\n",
      " Training with pattern  2  weights  [-2.75911801  2.88088607] 1.4156622422998646   weights  [-2.75911801  2.88088609]  bias  1.418002319824441\n",
      "pattern1 0 0 1 0.889181\n",
      "pattern2 0 1 1 0.999631\n",
      "pattern3 1 0 -1 -0.87194\n",
      "pattern4 1 1 1 0.912082\n",
      " modified Weights  [-2.75911801  2.88088609] 1.418002319824441\n",
      " Training with pattern  3  weights  [-2.75911801  2.88088607] 1.4156622422998646   weights  [-2.76218787  2.88088609]  bias  1.4149324555204104\n",
      "pattern1 0 0 1 0.888537\n",
      "pattern2 0 1 1 0.999629\n",
      "pattern3 1 0 -1 -0.873404\n",
      "pattern4 1 1 1 0.911044\n",
      " modified Weights  [-2.76218787  2.88088609] 1.4149324555204104\n",
      " Training with pattern  4  weights  [-2.75911801  2.88088607] 1.4156622422998646   weights  [-2.76067562  2.88239834]  bias  1.4164447020405488\n",
      "pattern1 0 0 1 0.888855\n",
      "pattern2 0 1 1 0.999631\n",
      "pattern3 1 0 -1 -0.872685\n",
      "pattern4 1 1 1 0.911812\n",
      " modified Weights  [-2.76067562  2.88239834] 1.4164447020405488\n",
      "+++++++++++Epoch  368  cost=  0.03633969032833444\n",
      " Training with pattern  1  weights  [-2.76067562  2.88239834] 1.4164447020405488   weights  [-2.76067562  2.88239834]  bias  1.418778048952389\n",
      "pattern1 0 0 1 0.889344\n",
      "pattern2 0 1 1 0.999633\n",
      "pattern3 1 0 -1 -0.872127\n",
      "pattern4 1 1 1 0.912204\n",
      " modified Weights  [-2.76067562  2.88239834] 1.418778048952389\n",
      " Training with pattern  2  weights  [-2.76067562  2.88239834] 1.4164447020405488   weights  [-2.76067562  2.88239837]  bias  1.4187780759261819\n",
      "pattern1 0 0 1 0.889344\n",
      "pattern2 0 1 1 0.999633\n",
      "pattern3 1 0 -1 -0.872127\n",
      "pattern4 1 1 1 0.912204\n",
      " modified Weights  [-2.76067562  2.88239837] 1.4187780759261819\n",
      " Training with pattern  3  weights  [-2.76067562  2.88239834] 1.4164447020405488   weights  [-2.76373682  2.88239837]  bias  1.415716878763002\n",
      "pattern1 0 0 1 0.888702\n",
      "pattern2 0 1 1 0.99963\n",
      "pattern3 1 0 -1 -0.873585\n",
      "pattern4 1 1 1 0.911171\n",
      " modified Weights  [-2.76373682  2.88239837] 1.415716878763002\n",
      " Training with pattern  4  weights  [-2.76067562  2.88239834] 1.4164447020405488   weights  [-2.76222879  2.8839064 ]  bias  1.4172249096173797\n",
      "pattern1 0 0 1 0.889019\n",
      "pattern2 0 1 1 0.999633\n",
      "pattern3 1 0 -1 -0.872869\n",
      "pattern4 1 1 1 0.911936\n",
      " modified Weights  [-2.76222879  2.8839064 ] 1.4172249096173797\n",
      "+++++++++++Epoch  369  cost=  0.03623464139543945\n",
      " Training with pattern  1  weights  [-2.76222879  2.8839064 ] 1.4172249096173797   weights  [-2.76222879  2.8839064 ]  bias  1.419551590659366\n",
      "pattern1 0 0 1 0.889505\n",
      "pattern2 0 1 1 0.999634\n",
      "pattern3 1 0 -1 -0.872314\n",
      "pattern4 1 1 1 0.912327\n",
      " modified Weights  [-2.76222879  2.8839064 ] 1.419551590659366\n",
      " Training with pattern  2  weights  [-2.76222879  2.8839064 ] 1.4172249096173797   weights  [-2.76222879  2.88390642]  bias  1.4195516173881724\n",
      "pattern1 0 0 1 0.889505\n",
      "pattern2 0 1 1 0.999634\n",
      "pattern3 1 0 -1 -0.872314\n",
      "pattern4 1 1 1 0.912327\n",
      " modified Weights  [-2.76222879  2.88390642] 1.4195516173881724\n",
      " Training with pattern  3  weights  [-2.76222879  2.8839064 ] 1.4172249096173797   weights  [-2.76528137  2.88390642]  bias  1.4164990395392942\n",
      "pattern1 0 0 1 0.888866\n",
      "pattern2 0 1 1 0.999632\n",
      "pattern3 1 0 -1 -0.873766\n",
      "pattern4 1 1 1 0.911297\n",
      " modified Weights  [-2.76528137  2.88390642] 1.4164990395392942\n",
      " Training with pattern  4  weights  [-2.76222879  2.8839064 ] 1.4172249096173797   weights  [-2.76377753  2.88541026]  bias  1.41800287770153\n",
      "pattern1 0 0 1 0.889182\n",
      "pattern2 0 1 1 0.999634\n",
      "pattern3 1 0 -1 -0.873052\n",
      "pattern4 1 1 1 0.912059\n",
      " modified Weights  [-2.76377753  2.88541026] 1.41800287770153\n",
      "+++++++++++Epoch  370  cost=  0.036130182376640625\n",
      " Training with pattern  1  weights  [-2.76377753  2.88541026] 1.41800287770153   weights  [-2.76377753  2.88541026]  bias  1.4203229300839293\n",
      "pattern1 0 0 1 0.889666\n",
      "pattern2 0 1 1 0.999636\n",
      "pattern3 1 0 -1 -0.8725\n",
      "pattern4 1 1 1 0.912448\n",
      " modified Weights  [-2.76377753  2.88541026] 1.4203229300839293\n",
      " Training with pattern  2  weights  [-2.76377753  2.88541026] 1.41800287770153   weights  [-2.76377753  2.88541029]  bias  1.4203229565706512\n",
      "pattern1 0 0 1 0.889666\n",
      "pattern2 0 1 1 0.999636\n",
      "pattern3 1 0 -1 -0.872499\n",
      "pattern4 1 1 1 0.912448\n",
      " modified Weights  [-2.76377753  2.88541029] 1.4203229565706512\n",
      " Training with pattern  3  weights  [-2.76377753  2.88541026] 1.41800287770153   weights  [-2.76682153  2.88541029]  bias  1.4172789506002363\n",
      "pattern1 0 0 1 0.88903\n",
      "pattern2 0 1 1 0.999634\n",
      "pattern3 1 0 -1 -0.873945\n",
      "pattern4 1 1 1 0.911423\n",
      " modified Weights  [-2.76682153  2.88541029] 1.4172789506002363\n",
      " Training with pattern  4  weights  [-2.76377753  2.88541026] 1.41800287770153   weights  [-2.76532187  2.88690996]  bias  1.4187786188586229\n",
      "pattern1 0 0 1 0.889344\n",
      "pattern2 0 1 1 0.999636\n",
      "pattern3 1 0 -1 -0.873235\n",
      "pattern4 1 1 1 0.912182\n",
      " modified Weights  [-2.76532187  2.88690996] 1.4187786188586229\n",
      "+++++++++++Epoch  371  cost=  0.0360263083816144\n",
      " *********Epoch  370 Error  0.0360263083816144\n",
      " Training with pattern  1  weights  [-2.76532187  2.88690996] 1.4187786188586229   weights  [-2.76532187  2.88690996]  bias  1.4210920794842121\n",
      "pattern1 0 0 1 0.889827\n",
      "pattern2 0 1 1 0.999638\n",
      "pattern3 1 0 -1 -0.872684\n",
      "pattern4 1 1 1 0.91257\n",
      " modified Weights  [-2.76532187  2.88690996] 1.4210920794842121\n",
      " Training with pattern  2  weights  [-2.76532187  2.88690996] 1.4187786188586229   weights  [-2.76532187  2.88690998]  bias  1.4210921057317094\n",
      "pattern1 0 0 1 0.889827\n",
      "pattern2 0 1 1 0.999638\n",
      "pattern3 1 0 -1 -0.872684\n",
      "pattern4 1 1 1 0.91257\n",
      " modified Weights  [-2.76532187  2.88690998] 1.4210921057317094\n",
      " Training with pattern  3  weights  [-2.76532187  2.88690996] 1.4187786188586229   weights  [-2.76835735  2.88690998]  bias  1.4180566245904123\n",
      "pattern1 0 0 1 0.889193\n",
      "pattern2 0 1 1 0.999635\n",
      "pattern3 1 0 -1 -0.874124\n",
      "pattern4 1 1 1 0.911549\n",
      " modified Weights  [-2.76835735  2.88690998] 1.4180566245904123\n",
      " Training with pattern  4  weights  [-2.76532187  2.88690996] 1.4187786188586229   weights  [-2.76686183  2.8884055 ]  bias  1.4195521455498912\n",
      "pattern1 0 0 1 0.889505\n",
      "pattern2 0 1 1 0.999638\n",
      "pattern3 1 0 -1 -0.873417\n",
      "pattern4 1 1 1 0.912304\n",
      " modified Weights  [-2.76686183  2.8884055 ] 1.4195521455498912\n",
      "+++++++++++Epoch  372  cost=  0.035923014573496455\n",
      " Training with pattern  1  weights  [-2.76686183  2.8884055 ] 1.4195521455498912   weights  [-2.76686183  2.8884055 ]  bias  1.421859051017315\n",
      "pattern1 0 0 1 0.889986\n",
      "pattern2 0 1 1 0.999639\n",
      "pattern3 1 0 -1 -0.872869\n",
      "pattern4 1 1 1 0.91269\n",
      " modified Weights  [-2.76686183  2.8884055 ] 1.421859051017315\n",
      " Training with pattern  2  weights  [-2.76686183  2.8884055 ] 1.4195521455498912   weights  [-2.76686183  2.88840553]  bias  1.4218590770284059\n",
      "pattern1 0 0 1 0.889986\n",
      "pattern2 0 1 1 0.999639\n",
      "pattern3 1 0 -1 -0.872869\n",
      "pattern4 1 1 1 0.91269\n",
      " modified Weights  [-2.76686183  2.88840553] 1.4218590770284059\n",
      " Training with pattern  3  weights  [-2.76686183  2.8884055 ] 1.4195521455498912   weights  [-2.76988883  2.88840553]  bias  1.4188320740492155\n",
      "pattern1 0 0 1 0.889355\n",
      "pattern2 0 1 1 0.999637\n",
      "pattern3 1 0 -1 -0.874302\n",
      "pattern4 1 1 1 0.911674\n",
      " modified Weights  [-2.76988883  2.88840553] 1.4188320740492155\n",
      " Training with pattern  4  weights  [-2.76686183  2.8884055 ] 1.4195521455498912   weights  [-2.76839743  2.88989693]  bias  1.4203234701333247\n",
      "pattern1 0 0 1 0.889666\n",
      "pattern2 0 1 1 0.999639\n",
      "pattern3 1 0 -1 -0.873598\n",
      "pattern4 1 1 1 0.912426\n",
      " modified Weights  [-2.76839743  2.88989693] 1.4203234701333247\n",
      "+++++++++++Epoch  373  cost=  0.03582029616815738\n",
      " Training with pattern  1  weights  [-2.76839743  2.88989693] 1.4203234701333247   weights  [-2.76839743  2.88989693]  bias  1.4226238567404057\n",
      "pattern1 0 0 1 0.890145\n",
      "pattern2 0 1 1 0.999641\n",
      "pattern3 1 0 -1 -0.873052\n",
      "pattern4 1 1 1 0.912811\n",
      " modified Weights  [-2.76839743  2.88989693] 1.4226238567404057\n",
      " Training with pattern  2  weights  [-2.76839743  2.88989693] 1.4203234701333247   weights  [-2.76839743  2.88989695]  bias  1.4226238825178676\n",
      "pattern1 0 0 1 0.890145\n",
      "pattern2 0 1 1 0.999641\n",
      "pattern3 1 0 -1 -0.873052\n",
      "pattern4 1 1 1 0.912811\n",
      " modified Weights  [-2.76839743  2.88989695] 1.4226238825178676\n",
      " Training with pattern  3  weights  [-2.76839743  2.88989693] 1.4203234701333247   weights  [-2.771416    2.88989695]  bias  1.419605311412003\n",
      "pattern1 0 0 1 0.889517\n",
      "pattern2 0 1 1 0.999639\n",
      "pattern3 1 0 -1 -0.87448\n",
      "pattern4 1 1 1 0.911798\n",
      " modified Weights  [-2.771416    2.88989695] 1.419605311412003\n",
      " Training with pattern  4  weights  [-2.76839743  2.88989693] 1.4203234701333247   weights  [-2.76992871  2.89138425]  bias  1.4210926048647998\n",
      "pattern1 0 0 1 0.889827\n",
      "pattern2 0 1 1 0.999641\n",
      "pattern3 1 0 -1 -0.873778\n",
      "pattern4 1 1 1 0.912548\n",
      " modified Weights  [-2.76992871  2.89138425] 1.4210926048647998\n",
      "+++++++++++Epoch  374  cost=  0.03571814843348989\n",
      " Training with pattern  1  weights  [-2.76992871  2.89138425] 1.4210926048647998   weights  [-2.76992871  2.89138425]  bias  1.423386508611804\n",
      "pattern1 0 0 1 0.890303\n",
      "pattern2 0 1 1 0.999643\n",
      "pattern3 1 0 -1 -0.873235\n",
      "pattern4 1 1 1 0.91293\n",
      " modified Weights  [-2.76992871  2.89138425] 1.423386508611804\n",
      " Training with pattern  2  weights  [-2.76992871  2.89138425] 1.4210926048647998   weights  [-2.76992871  2.89138427]  bias  1.4233865341583745\n",
      "pattern1 0 0 1 0.890303\n",
      "pattern2 0 1 1 0.999643\n",
      "pattern3 1 0 -1 -0.873235\n",
      "pattern4 1 1 1 0.91293\n",
      " modified Weights  [-2.76992871  2.89138427] 1.4233865341583745\n",
      " Training with pattern  3  weights  [-2.76992871  2.89138425] 1.4210926048647998   weights  [-2.7729389   2.89138427]  bias  1.4203763490112356\n",
      "pattern1 0 0 1 0.889677\n",
      "pattern2 0 1 1 0.99964\n",
      "pattern3 1 0 -1 -0.874657\n",
      "pattern4 1 1 1 0.911922\n",
      " modified Weights  [-2.7729389   2.89138427] 1.4203763490112356\n",
      " Training with pattern  4  weights  [-2.76992871  2.89138425] 1.4210926048647998   weights  [-2.77145568  2.89286748]  bias  1.4218595618991936\n",
      "pattern1 0 0 1 0.889986\n",
      "pattern2 0 1 1 0.999643\n",
      "pattern3 1 0 -1 -0.873958\n",
      "pattern4 1 1 1 0.912668\n",
      " modified Weights  [-2.77145568  2.89286748] 1.4218595618991936\n",
      "+++++++++++Epoch  375  cost=  0.035616566688708086\n",
      " Training with pattern  1  weights  [-2.77145568  2.89286748] 1.4218595618991936   weights  [-2.77145568  2.89286748]  bias  1.424147018492053\n",
      "pattern1 0 0 1 0.890461\n",
      "pattern2 0 1 1 0.999644\n",
      "pattern3 1 0 -1 -0.873417\n",
      "pattern4 1 1 1 0.91305\n",
      " modified Weights  [-2.77145568  2.89286748] 1.424147018492053\n",
      " Training with pattern  2  weights  [-2.77145568  2.89286748] 1.4218595618991936   weights  [-2.77145568  2.89286751]  bias  1.4241470438104298\n",
      "pattern1 0 0 1 0.890461\n",
      "pattern2 0 1 1 0.999644\n",
      "pattern3 1 0 -1 -0.873417\n",
      "pattern4 1 1 1 0.91305\n",
      " modified Weights  [-2.77145568  2.89286751] 1.4241470438104298\n",
      " Training with pattern  3  weights  [-2.77145568  2.89286748] 1.4218595618991936   weights  [-2.77445753  2.89286751]  bias  1.4211451990776018\n",
      "pattern1 0 0 1 0.889838\n",
      "pattern2 0 1 1 0.999642\n",
      "pattern3 1 0 -1 -0.874833\n",
      "pattern4 1 1 1 0.912046\n",
      " modified Weights  [-2.77445753  2.89286751] 1.4211451990776018\n",
      " Training with pattern  4  weights  [-2.77145568  2.89286748] 1.4218595618991936   weights  [-2.77297837  2.89434666]  bias  1.4226243532914837\n",
      "pattern1 0 0 1 0.890145\n",
      "pattern2 0 1 1 0.999644\n",
      "pattern3 1 0 -1 -0.874137\n",
      "pattern4 1 1 1 0.912789\n",
      " modified Weights  [-2.77297837  2.89434666] 1.4226243532914837\n",
      "+++++++++++Epoch  376  cost=  0.03551554630365729\n",
      " Training with pattern  1  weights  [-2.77297837  2.89434666] 1.4226243532914837   weights  [-2.77297837  2.89434666]  bias  1.4249053981449753\n",
      "pattern1 0 0 1 0.890618\n",
      "pattern2 0 1 1 0.999646\n",
      "pattern3 1 0 -1 -0.873598\n",
      "pattern4 1 1 1 0.913169\n",
      " modified Weights  [-2.77297837  2.89434666] 1.4249053981449753\n",
      " Training with pattern  2  weights  [-2.77297837  2.89434666] 1.4226243532914837   weights  [-2.77297837  2.89434669]  bias  1.4249054232378175\n",
      "pattern1 0 0 1 0.890618\n",
      "pattern2 0 1 1 0.999646\n",
      "pattern3 1 0 -1 -0.873598\n",
      "pattern4 1 1 1 0.913169\n",
      " modified Weights  [-2.77297837  2.89434669] 1.4249054232378175\n",
      " Training with pattern  3  weights  [-2.77297837  2.89434666] 1.4226243532914837   weights  [-2.77597192  2.89434669]  bias  1.4219118737411285\n",
      "pattern1 0 0 1 0.889997\n",
      "pattern2 0 1 1 0.999644\n",
      "pattern3 1 0 -1 -0.875008\n",
      "pattern4 1 1 1 0.912169\n",
      " modified Weights  [-2.77597192  2.89434669] 1.4219118737411285\n",
      " Training with pattern  4  weights  [-2.77297837  2.89434666] 1.4226243532914837   weights  [-2.77449681  2.89582181]  bias  1.423386990997833\n",
      "pattern1 0 0 1 0.890303\n",
      "pattern2 0 1 1 0.999646\n",
      "pattern3 1 0 -1 -0.874315\n",
      "pattern4 1 1 1 0.912909\n",
      " modified Weights  [-2.77449681  2.89582181] 1.423386990997833\n",
      "+++++++++++Epoch  377  cost=  0.03541508269813562\n",
      " Training with pattern  1  weights  [-2.77449681  2.89582181] 1.423386990997833   weights  [-2.77449681  2.89582181]  bias  1.4256616592387141\n",
      "pattern1 0 0 1 0.890774\n",
      "pattern2 0 1 1 0.999647\n",
      "pattern3 1 0 -1 -0.873778\n",
      "pattern4 1 1 1 0.913287\n",
      " modified Weights  [-2.77449681  2.89582181] 1.4256616592387141\n",
      " Training with pattern  2  weights  [-2.77449681  2.89582181] 1.423386990997833   weights  [-2.77449681  2.89582183]  bias  1.4256616841086427\n",
      "pattern1 0 0 1 0.890774\n",
      "pattern2 0 1 1 0.999647\n",
      "pattern3 1 0 -1 -0.873778\n",
      "pattern4 1 1 1 0.913287\n",
      " modified Weights  [-2.77449681  2.89582183] 1.4256616841086427\n",
      " Training with pattern  3  weights  [-2.77449681  2.89582181] 1.423386990997833   weights  [-2.77748211  2.89582183]  bias  1.4226763850322726\n",
      "pattern1 0 0 1 0.890156\n",
      "pattern2 0 1 1 0.999645\n",
      "pattern3 1 0 -1 -0.875183\n",
      "pattern4 1 1 1 0.912291\n",
      " modified Weights  [-2.77748211  2.89582183] 1.4226763850322726\n",
      " Training with pattern  4  weights  [-2.77449681  2.89582181] 1.423386990997833   weights  [-2.776011    2.89729293]  bias  1.424147486876659\n",
      "pattern1 0 0 1 0.890461\n",
      "pattern2 0 1 1 0.999647\n",
      "pattern3 1 0 -1 -0.874492\n",
      "pattern4 1 1 1 0.913028\n",
      " modified Weights  [-2.776011    2.89729293] 1.424147486876659\n",
      "+++++++++++Epoch  378  cost=  0.035315171341225936\n",
      " Training with pattern  1  weights  [-2.776011    2.89729293] 1.424147486876659   weights  [-2.776011    2.89729293]  bias  1.4264158133467624\n",
      "pattern1 0 0 1 0.89093\n",
      "pattern2 0 1 1 0.999649\n",
      "pattern3 1 0 -1 -0.873958\n",
      "pattern4 1 1 1 0.913405\n",
      " modified Weights  [-2.776011    2.89729293] 1.4264158133467624\n",
      " Training with pattern  2  weights  [-2.776011    2.89729293] 1.424147486876659   weights  [-2.776011    2.89729296]  bias  1.4264158379963607\n",
      "pattern1 0 0 1 0.89093\n",
      "pattern2 0 1 1 0.999649\n",
      "pattern3 1 0 -1 -0.873958\n",
      "pattern4 1 1 1 0.913405\n",
      " modified Weights  [-2.776011    2.89729296] 1.4264158379963607\n",
      " Training with pattern  3  weights  [-2.776011    2.89729293] 1.424147486876659   weights  [-2.7789881   2.89729296]  bias  1.4234387448830026\n",
      "pattern1 0 0 1 0.890314\n",
      "pattern2 0 1 1 0.999647\n",
      "pattern3 1 0 -1 -0.875357\n",
      "pattern4 1 1 1 0.912413\n",
      " modified Weights  [-2.7789881   2.89729296] 1.4234387448830026\n",
      " Training with pattern  4  weights  [-2.776011    2.89729293] 1.424147486876659   weights  [-2.77752099  2.89876006]  bias  1.4249058526896907\n",
      "pattern1 0 0 1 0.890618\n",
      "pattern2 0 1 1 0.999649\n",
      "pattern3 1 0 -1 -0.874669\n",
      "pattern4 1 1 1 0.913147\n",
      " modified Weights  [-2.77752099  2.89876006] 1.4249058526896907\n",
      "+++++++++++Epoch  379  cost=  0.035215807750638047\n",
      " Training with pattern  1  weights  [-2.77752099  2.89876006] 1.4249058526896907   weights  [-2.77752099  2.89876006]  bias  1.4271678719489767\n",
      "pattern1 0 0 1 0.891085\n",
      "pattern2 0 1 1 0.99965\n",
      "pattern3 1 0 -1 -0.874137\n",
      "pattern4 1 1 1 0.913522\n",
      " modified Weights  [-2.77752099  2.89876006] 1.4271678719489767\n",
      " Training with pattern  2  weights  [-2.77752099  2.89876006] 1.4249058526896907   weights  [-2.77752099  2.89876009]  bias  1.4271678963807917\n",
      "pattern1 0 0 1 0.891085\n",
      "pattern2 0 1 1 0.99965\n",
      "pattern3 1 0 -1 -0.874137\n",
      "pattern4 1 1 1 0.913522\n",
      " modified Weights  [-2.77752099  2.89876009] 1.4271678963807917\n",
      " Training with pattern  3  weights  [-2.77752099  2.89876006] 1.4249058526896907   weights  [-2.78048992  2.89876009]  bias  1.4241989651278628\n",
      "pattern1 0 0 1 0.890472\n",
      "pattern2 0 1 1 0.999648\n",
      "pattern3 1 0 -1 -0.87553\n",
      "pattern4 1 1 1 0.912534\n",
      " modified Weights  [-2.78048992  2.89876009] 1.4241989651278628\n",
      " Training with pattern  4  weights  [-2.77752099  2.89876006] 1.4249058526896907   weights  [-2.77902679  2.90022322]  bias  1.4256621001030094\n",
      "pattern1 0 0 1 0.890774\n",
      "pattern2 0 1 1 0.99965\n",
      "pattern3 1 0 -1 -0.874845\n",
      "pattern4 1 1 1 0.913266\n",
      " modified Weights  [-2.77902679  2.90022322] 1.4256621001030094\n",
      "+++++++++++Epoch  380  cost=  0.03511698749206303\n",
      " Training with pattern  1  weights  [-2.77902679  2.90022322] 1.4256621001030094   weights  [-2.77902679  2.90022322]  bias  1.427917846432579\n",
      "pattern1 0 0 1 0.891239\n",
      "pattern2 0 1 1 0.999652\n",
      "pattern3 1 0 -1 -0.874315\n",
      "pattern4 1 1 1 0.913639\n",
      " modified Weights  [-2.77902679  2.90022322] 1.427917846432579\n",
      " Training with pattern  2  weights  [-2.77902679  2.90022322] 1.4256621001030094   weights  [-2.77902679  2.90022325]  bias  1.4279178706491211\n",
      "pattern1 0 0 1 0.891239\n",
      "pattern2 0 1 1 0.999652\n",
      "pattern3 1 0 -1 -0.874315\n",
      "pattern4 1 1 1 0.913639\n",
      " modified Weights  [-2.77902679  2.90022325] 1.4279178706491211\n",
      " Training with pattern  3  weights  [-2.77902679  2.90022322] 1.4256621001030094   weights  [-2.7819876   2.90022325]  bias  1.4249570575050239\n",
      "pattern1 0 0 1 0.890628\n",
      "pattern2 0 1 1 0.99965\n",
      "pattern3 1 0 -1 -0.875703\n",
      "pattern4 1 1 1 0.912655\n",
      " modified Weights  [-2.7819876   2.90022325] 1.4249570575050239\n",
      " Training with pattern  4  weights  [-2.77902679  2.90022322] 1.4256621001030094   weights  [-2.78052842  2.90168243]  bias  1.426416240688076\n",
      "pattern1 0 0 1 0.89093\n",
      "pattern2 0 1 1 0.999652\n",
      "pattern3 1 0 -1 -0.87502\n",
      "pattern4 1 1 1 0.913384\n",
      " modified Weights  [-2.78052842  2.90168243] 1.426416240688076\n",
      "+++++++++++Epoch  381  cost=  0.03501870617853524\n",
      " *********Epoch  380 Error  0.03501870617853524\n",
      " Training with pattern  1  weights  [-2.78052842  2.90168243] 1.426416240688076   weights  [-2.78052842  2.90168243]  bias  1.428665748093143\n",
      "pattern1 0 0 1 0.891393\n",
      "pattern2 0 1 1 0.999654\n",
      "pattern3 1 0 -1 -0.874492\n",
      "pattern4 1 1 1 0.913756\n",
      " modified Weights  [-2.78052842  2.90168243] 1.428665748093143\n",
      " Training with pattern  2  weights  [-2.78052842  2.90168243] 1.426416240688076   weights  [-2.78052842  2.90168246]  bias  1.4286657720968872\n",
      "pattern1 0 0 1 0.891393\n",
      "pattern2 0 1 1 0.999654\n",
      "pattern3 1 0 -1 -0.874492\n",
      "pattern4 1 1 1 0.913756\n",
      " modified Weights  [-2.78052842  2.90168246] 1.4286657720968872\n",
      " Training with pattern  3  weights  [-2.78052842  2.90168243] 1.426416240688076   weights  [-2.78348115  2.90168246]  bias  1.4257130336573192\n",
      "pattern1 0 0 1 0.890785\n",
      "pattern2 0 1 1 0.999651\n",
      "pattern3 1 0 -1 -0.875874\n",
      "pattern4 1 1 1 0.912776\n",
      " modified Weights  [-2.78348115  2.90168246] 1.4257130336573192\n",
      " Training with pattern  4  weights  [-2.78052842  2.90168243] 1.426416240688076   weights  [-2.7820259   2.90313771]  bias  1.427168285922746\n",
      "pattern1 0 0 1 0.891085\n",
      "pattern2 0 1 1 0.999654\n",
      "pattern3 1 0 -1 -0.875195\n",
      "pattern4 1 1 1 0.913501\n",
      " modified Weights  [-2.7820259   2.90313771] 1.427168285922746\n",
      "+++++++++++Epoch  382  cost=  0.03492095946980675\n",
      " Training with pattern  1  weights  [-2.7820259   2.90313771] 1.427168285922746   weights  [-2.7820259   2.90313771]  bias  1.4294115881355705\n",
      "pattern1 0 0 1 0.891546\n",
      "pattern2 0 1 1 0.999655\n",
      "pattern3 1 0 -1 -0.874669\n",
      "pattern4 1 1 1 0.913872\n",
      " modified Weights  [-2.7820259   2.90313771] 1.4294115881355705\n",
      " Training with pattern  2  weights  [-2.7820259   2.90313771] 1.427168285922746   weights  [-2.7820259   2.90313773]  bias  1.4294116119289564\n",
      "pattern1 0 0 1 0.891546\n",
      "pattern2 0 1 1 0.999655\n",
      "pattern3 1 0 -1 -0.874669\n",
      "pattern4 1 1 1 0.913872\n",
      " modified Weights  [-2.7820259   2.90313773] 1.4294116119289564\n",
      " Training with pattern  3  weights  [-2.7820259   2.90313771] 1.427168285922746   weights  [-2.78497061  2.90313773]  bias  1.4264669051332681\n",
      "pattern1 0 0 1 0.89094\n",
      "pattern2 0 1 1 0.999653\n",
      "pattern3 1 0 -1 -0.876046\n",
      "pattern4 1 1 1 0.912896\n",
      " modified Weights  [-2.78497061  2.90313773] 1.4264669051332681\n",
      " Training with pattern  4  weights  [-2.7820259   2.90313771] 1.427168285922746   weights  [-2.78351927  2.90458907]  bias  1.427918247192269\n",
      "pattern1 0 0 1 0.891239\n",
      "pattern2 0 1 1 0.999655\n",
      "pattern3 1 0 -1 -0.875369\n",
      "pattern4 1 1 1 0.913618\n",
      " modified Weights  [-2.78351927  2.90458907] 1.427918247192269\n",
      "+++++++++++Epoch  383  cost=  0.0348237430717305\n",
      " Training with pattern  1  weights  [-2.78351927  2.90458907] 1.427918247192269   weights  [-2.78351927  2.90458907]  bias  1.430155377675051\n",
      "pattern1 0 0 1 0.891698\n",
      "pattern2 0 1 1 0.999657\n",
      "pattern3 1 0 -1 -0.874845\n",
      "pattern4 1 1 1 0.913987\n",
      " modified Weights  [-2.78351927  2.90458907] 1.430155377675051\n",
      " Training with pattern  2  weights  [-2.78351927  2.90458907] 1.427918247192269   weights  [-2.78351927  2.9045891 ]  bias  1.4301554012604842\n",
      "pattern1 0 0 1 0.891698\n",
      "pattern2 0 1 1 0.999657\n",
      "pattern3 1 0 -1 -0.874845\n",
      "pattern4 1 1 1 0.913987\n",
      " modified Weights  [-2.78351927  2.9045891 ] 1.4301554012604842\n",
      " Training with pattern  3  weights  [-2.78351927  2.90458907] 1.427918247192269   weights  [-2.78645598  2.9045891 ]  bias  1.4272186833880842\n",
      "pattern1 0 0 1 0.891095\n",
      "pattern2 0 1 1 0.999655\n",
      "pattern3 1 0 -1 -0.876216\n",
      "pattern4 1 1 1 0.913015\n",
      " modified Weights  [-2.78645598  2.9045891 ] 1.4272186833880842\n",
      " Training with pattern  4  weights  [-2.78351927  2.90458907] 1.427918247192269   weights  [-2.78500853  2.90603655]  bias  1.4286661357902755\n",
      "pattern1 0 0 1 0.891393\n",
      "pattern2 0 1 1 0.999657\n",
      "pattern3 1 0 -1 -0.875542\n",
      "pattern4 1 1 1 0.913735\n",
      " modified Weights  [-2.78500853  2.90603655] 1.4286661357902755\n",
      "+++++++++++Epoch  384  cost=  0.034727052735653144\n",
      " Training with pattern  1  weights  [-2.78500853  2.90603655] 1.4286661357902755   weights  [-2.78500853  2.90603655]  bias  1.4308971277380123\n",
      "pattern1 0 0 1 0.89185\n",
      "pattern2 0 1 1 0.999658\n",
      "pattern3 1 0 -1 -0.87502\n",
      "pattern4 1 1 1 0.914103\n",
      " modified Weights  [-2.78500853  2.90603655] 1.4308971277380123\n",
      " Training with pattern  2  weights  [-2.78500853  2.90603655] 1.4286661357902755   weights  [-2.78500853  2.90603657]  bias  1.4308971511178643\n",
      "pattern1 0 0 1 0.89185\n",
      "pattern2 0 1 1 0.999658\n",
      "pattern3 1 0 -1 -0.87502\n",
      "pattern4 1 1 1 0.914103\n",
      " modified Weights  [-2.78500853  2.90603657] 1.4308971511178643\n",
      " Training with pattern  3  weights  [-2.78500853  2.90603655] 1.4286661357902755   weights  [-2.7879373   2.90603657]  bias  1.4279683797846716\n",
      "pattern1 0 0 1 0.89125\n",
      "pattern2 0 1 1 0.999656\n",
      "pattern3 1 0 -1 -0.876386\n",
      "pattern4 1 1 1 0.913134\n",
      " modified Weights  [-2.7879373   2.90603657] 1.4279683797846716\n",
      " Training with pattern  4  weights  [-2.78500853  2.90603655] 1.4286661357902755   weights  [-2.78649372  2.90748016]  bias  1.4294119629197521\n",
      "pattern1 0 0 1 0.891546\n",
      "pattern2 0 1 1 0.999658\n",
      "pattern3 1 0 -1 -0.875714\n",
      "pattern4 1 1 1 0.913851\n",
      " modified Weights  [-2.78649372  2.90748016] 1.4294119629197521\n",
      "+++++++++++Epoch  385  cost=  0.0346308842578178\n",
      " Training with pattern  1  weights  [-2.78649372  2.90748016] 1.4294119629197521   weights  [-2.78649372  2.90748016]  bias  1.4316368492630567\n",
      "pattern1 0 0 1 0.892002\n",
      "pattern2 0 1 1 0.99966\n",
      "pattern3 1 0 -1 -0.875195\n",
      "pattern4 1 1 1 0.914217\n",
      " modified Weights  [-2.78649372  2.90748016] 1.4316368492630567\n",
      " Training with pattern  2  weights  [-2.78649372  2.90748016] 1.4294119629197521   weights  [-2.78649372  2.90748018]  bias  1.431636872439666\n",
      "pattern1 0 0 1 0.892002\n",
      "pattern2 0 1 1 0.99966\n",
      "pattern3 1 0 -1 -0.875195\n",
      "pattern4 1 1 1 0.914217\n",
      " modified Weights  [-2.78649372  2.90748018] 1.431636872439666\n",
      " Training with pattern  3  weights  [-2.78649372  2.90748016] 1.4294119629197521   weights  [-2.78941459  2.90748018]  bias  1.428716005594608\n",
      "pattern1 0 0 1 0.891403\n",
      "pattern2 0 1 1 0.999658\n",
      "pattern3 1 0 -1 -0.876555\n",
      "pattern4 1 1 1 0.913253\n",
      " modified Weights  [-2.78941459  2.90748018] 1.428716005594608\n",
      " Training with pattern  4  weights  [-2.78649372  2.90748016] 1.4294119629197521   weights  [-2.78797485  2.90891991]  bias  1.4301557396940028\n",
      "pattern1 0 0 1 0.891699\n",
      "pattern2 0 1 1 0.99966\n",
      "pattern3 1 0 -1 -0.875886\n",
      "pattern4 1 1 1 0.913967\n",
      " modified Weights  [-2.78797485  2.90891991] 1.4301557396940028\n",
      "+++++++++++Epoch  386  cost=  0.03453523347877564\n",
      " Training with pattern  1  weights  [-2.78797485  2.90891991] 1.4301557396940028   weights  [-2.78797485  2.90891991]  bias  1.4323745531018854\n",
      "pattern1 0 0 1 0.892152\n",
      "pattern2 0 1 1 0.999661\n",
      "pattern3 1 0 -1 -0.875369\n",
      "pattern4 1 1 1 0.914332\n",
      " modified Weights  [-2.78797485  2.90891991] 1.4323745531018854\n",
      " Training with pattern  2  weights  [-2.78797485  2.90891991] 1.4301557396940028   weights  [-2.78797485  2.90891994]  bias  1.4323745760775577\n",
      "pattern1 0 0 1 0.892152\n",
      "pattern2 0 1 1 0.999661\n",
      "pattern3 1 0 -1 -0.875369\n",
      "pattern4 1 1 1 0.914332\n",
      " modified Weights  [-2.78797485  2.90891994] 1.4323745760775577\n",
      " Training with pattern  3  weights  [-2.78797485  2.90891991] 1.4301557396940028   weights  [-2.79088786  2.90891994]  bias  1.4294615719991133\n",
      "pattern1 0 0 1 0.891556\n",
      "pattern2 0 1 1 0.999659\n",
      "pattern3 1 0 -1 -0.876723\n",
      "pattern4 1 1 1 0.913371\n",
      " modified Weights  [-2.79088786  2.90891994] 1.4294615719991133\n",
      " Training with pattern  4  weights  [-2.78797485  2.90891991] 1.4301557396940028   weights  [-2.78945195  2.91035584]  bias  1.4308974771375964\n",
      "pattern1 0 0 1 0.89185\n",
      "pattern2 0 1 1 0.999661\n",
      "pattern3 1 0 -1 -0.876057\n",
      "pattern4 1 1 1 0.914082\n",
      " modified Weights  [-2.78945195  2.91035584] 1.4308974771375964\n",
      "+++++++++++Epoch  387  cost=  0.03444009628280759\n",
      " Training with pattern  1  weights  [-2.78945195  2.91035584] 1.4308974771375964   weights  [-2.78945195  2.91035584]  bias  1.433110250020211\n",
      "pattern1 0 0 1 0.892302\n",
      "pattern2 0 1 1 0.999663\n",
      "pattern3 1 0 -1 -0.875542\n",
      "pattern4 1 1 1 0.914445\n",
      " modified Weights  [-2.78945195  2.91035584] 1.433110250020211\n",
      " Training with pattern  2  weights  [-2.78945195  2.91035584] 1.4308974771375964   weights  [-2.78945195  2.91035586]  bias  1.4331102727972196\n",
      "pattern1 0 0 1 0.892302\n",
      "pattern2 0 1 1 0.999663\n",
      "pattern3 1 0 -1 -0.875542\n",
      "pattern4 1 1 1 0.914445\n",
      " modified Weights  [-2.78945195  2.91035586] 1.4331102727972196\n",
      " Training with pattern  3  weights  [-2.78945195  2.91035584] 1.4308974771375964   weights  [-2.79235713  2.91035586]  bias  1.4302050900900067\n",
      "pattern1 0 0 1 0.891709\n",
      "pattern2 0 1 1 0.999661\n",
      "pattern3 1 0 -1 -0.876891\n",
      "pattern4 1 1 1 0.913489\n",
      " modified Weights  [-2.79235713  2.91035586] 1.4302050900900067\n",
      " Training with pattern  4  weights  [-2.78945195  2.91035584] 1.4308974771375964   weights  [-2.79092504  2.91178796]  bias  1.4316371861873034\n",
      "pattern1 0 0 1 0.892002\n",
      "pattern2 0 1 1 0.999662\n",
      "pattern3 1 0 -1 -0.876228\n",
      "pattern4 1 1 1 0.914197\n",
      " modified Weights  [-2.79092504  2.91178796] 1.4316371861873034\n",
      "+++++++++++Epoch  388  cost=  0.03434546859735392\n",
      " Training with pattern  1  weights  [-2.79092504  2.91178796] 1.4316371861873034   weights  [-2.79092504  2.91178796]  bias  1.433843950698657\n",
      "pattern1 0 0 1 0.892452\n",
      "pattern2 0 1 1 0.999664\n",
      "pattern3 1 0 -1 -0.875714\n",
      "pattern4 1 1 1 0.914559\n",
      " modified Weights  [-2.79092504  2.91178796] 1.433843950698657\n",
      " Training with pattern  2  weights  [-2.79092504  2.91178796] 1.4316371861873034   weights  [-2.79092504  2.91178798]  bias  1.4338439732792438\n",
      "pattern1 0 0 1 0.892452\n",
      "pattern2 0 1 1 0.999664\n",
      "pattern3 1 0 -1 -0.875714\n",
      "pattern4 1 1 1 0.914559\n",
      " modified Weights  [-2.79092504  2.91178798] 1.4338439732792438\n",
      " Training with pattern  3  weights  [-2.79092504  2.91178796] 1.4316371861873034   weights  [-2.79382244  2.91178798]  bias  1.4309465708706512\n",
      "pattern1 0 0 1 0.89186\n",
      "pattern2 0 1 1 0.999662\n",
      "pattern3 1 0 -1 -0.877058\n",
      "pattern4 1 1 1 0.913606\n",
      " modified Weights  [-2.79382244  2.91178798] 1.4309465708706512\n",
      " Training with pattern  4  weights  [-2.79092504  2.91178796] 1.4316371861873034   weights  [-2.79239413  2.91321629]  bias  1.4323748776930199\n",
      "pattern1 0 0 1 0.892152\n",
      "pattern2 0 1 1 0.999664\n",
      "pattern3 1 0 -1 -0.876398\n",
      "pattern4 1 1 1 0.914311\n",
      " modified Weights  [-2.79239413  2.91321629] 1.4323748776930199\n",
      "+++++++++++Epoch  389  cost=  0.034251346392453474\n",
      " Training with pattern  1  weights  [-2.79239413  2.91321629] 1.4323748776930199   weights  [-2.79239413  2.91321629]  bias  1.4345756657336475\n",
      "pattern1 0 0 1 0.8926\n",
      "pattern2 0 1 1 0.999665\n",
      "pattern3 1 0 -1 -0.875886\n",
      "pattern4 1 1 1 0.914672\n",
      " modified Weights  [-2.79239413  2.91321629] 1.4345756657336475\n",
      " Training with pattern  2  weights  [-2.79239413  2.91321629] 1.4323748776930199   weights  [-2.79239413  2.91321631]  bias  1.434575688120023\n",
      "pattern1 0 0 1 0.8926\n",
      "pattern2 0 1 1 0.999665\n",
      "pattern3 1 0 -1 -0.875886\n",
      "pattern4 1 1 1 0.914672\n",
      " modified Weights  [-2.79239413  2.91321631] 1.434575688120023\n",
      " Training with pattern  3  weights  [-2.79239413  2.91321629] 1.4323748776930199   weights  [-2.7952838   2.91321631]  bias  1.4316860252568846\n",
      "pattern1 0 0 1 0.892012\n",
      "pattern2 0 1 1 0.999663\n",
      "pattern3 1 0 -1 -0.877225\n",
      "pattern4 1 1 1 0.913723\n",
      " modified Weights  [-2.7952838   2.91321631] 1.4316860252568846\n",
      " Training with pattern  4  weights  [-2.79239413  2.91321629] 1.4323748776930199   weights  [-2.79385926  2.91464085]  bias  1.4331105624186788\n",
      "pattern1 0 0 1 0.892302\n",
      "pattern2 0 1 1 0.999665\n",
      "pattern3 1 0 -1 -0.876567\n",
      "pattern4 1 1 1 0.914425\n",
      " modified Weights  [-2.79385926  2.91464085] 1.4331105624186788\n",
      "+++++++++++Epoch  390  cost=  0.034157725680191244\n",
      " Training with pattern  1  weights  [-2.79385926  2.91464085] 1.4331105624186788   weights  [-2.79385926  2.91464085]  bias  1.4353054056382832\n",
      "pattern1 0 0 1 0.892749\n",
      "pattern2 0 1 1 0.999667\n",
      "pattern3 1 0 -1 -0.876057\n",
      "pattern4 1 1 1 0.914784\n",
      " modified Weights  [-2.79385926  2.91464085] 1.4353054056382832\n",
      " Training with pattern  2  weights  [-2.79385926  2.91464085] 1.4331105624186788   weights  [-2.79385926  2.91464087]  bias  1.4353054278326276\n",
      "pattern1 0 0 1 0.892749\n",
      "pattern2 0 1 1 0.999667\n",
      "pattern3 1 0 -1 -0.876057\n",
      "pattern4 1 1 1 0.914784\n",
      " modified Weights  [-2.79385926  2.91464087] 1.4353054278326276\n",
      " Training with pattern  3  weights  [-2.79385926  2.91464085] 1.4331105624186788   weights  [-2.79674122  2.91464087]  bias  1.4324234640779405\n",
      "pattern1 0 0 1 0.892162\n",
      "pattern2 0 1 1 0.999665\n",
      "pattern3 1 0 -1 -0.877391\n",
      "pattern4 1 1 1 0.913839\n",
      " modified Weights  [-2.79674122  2.91464087] 1.4324234640779405\n",
      " Training with pattern  4  weights  [-2.79385926  2.91464085] 1.4331105624186788   weights  [-2.79532044  2.91606166]  bias  1.4338442510431513\n",
      "pattern1 0 0 1 0.892452\n",
      "pattern2 0 1 1 0.999667\n",
      "pattern3 1 0 -1 -0.876735\n",
      "pattern4 1 1 1 0.914539\n",
      " modified Weights  [-2.79532044  2.91606166] 1.4338442510431513\n",
      "+++++++++++Epoch  391  cost=  0.03406460251415448\n",
      " *********Epoch  390 Error  0.03406460251415448\n",
      " Training with pattern  1  weights  [-2.79532044  2.91606166] 1.4338442510431513   weights  [-2.79532044  2.91606166]  bias  1.4360331808432092\n",
      "pattern1 0 0 1 0.892896\n",
      "pattern2 0 1 1 0.999668\n",
      "pattern3 1 0 -1 -0.876228\n",
      "pattern4 1 1 1 0.914896\n",
      " modified Weights  [-2.79532044  2.91606166] 1.4360331808432092\n",
      " Training with pattern  2  weights  [-2.79532044  2.91606166] 1.4338442510431513   weights  [-2.79532044  2.91606168]  bias  1.4360332028476723\n",
      "pattern1 0 0 1 0.892896\n",
      "pattern2 0 1 1 0.999668\n",
      "pattern3 1 0 -1 -0.876228\n",
      "pattern4 1 1 1 0.914896\n",
      " modified Weights  [-2.79532044  2.91606168] 1.4360332028476723\n",
      " Training with pattern  3  weights  [-2.79532044  2.91606166] 1.4338442510431513   weights  [-2.79819474  2.91606168]  bias  1.4331588980773553\n",
      "pattern1 0 0 1 0.892312\n",
      "pattern2 0 1 1 0.999666\n",
      "pattern3 1 0 -1 -0.877556\n",
      "pattern4 1 1 1 0.913955\n",
      " modified Weights  [-2.79819474  2.91606168] 1.4331588980773553\n",
      " Training with pattern  4  weights  [-2.79532044  2.91606166] 1.4338442510431513   weights  [-2.79677768  2.91747874]  bias  1.4345759541611334\n",
      "pattern1 0 0 1 0.892601\n",
      "pattern2 0 1 1 0.999668\n",
      "pattern3 1 0 -1 -0.876903\n",
      "pattern4 1 1 1 0.914652\n",
      " modified Weights  [-2.79677768  2.91747874] 1.4345759541611334\n",
      "+++++++++++Epoch  392  cost=  0.033971972988897446\n",
      " Training with pattern  1  weights  [-2.79677768  2.91747874] 1.4345759541611334   weights  [-2.79677768  2.91747874]  bias  1.4367590016974676\n",
      "pattern1 0 0 1 0.893043\n",
      "pattern2 0 1 1 0.99967\n",
      "pattern3 1 0 -1 -0.876397\n",
      "pattern4 1 1 1 0.915008\n",
      " modified Weights  [-2.79677768  2.91747874] 1.4367590016974676\n",
      " Training with pattern  2  weights  [-2.79677768  2.91747874] 1.4345759541611334   weights  [-2.79677768  2.91747876]  bias  1.4367590235141698\n",
      "pattern1 0 0 1 0.893043\n",
      "pattern2 0 1 1 0.99967\n",
      "pattern3 1 0 -1 -0.876397\n",
      "pattern4 1 1 1 0.915008\n",
      " modified Weights  [-2.79677768  2.91747876] 1.4367590235141698\n",
      " Training with pattern  3  weights  [-2.79677768  2.91747874] 1.4345759541611334   weights  [-2.79964437  2.91747876]  bias  1.4338923379138635\n",
      "pattern1 0 0 1 0.892461\n",
      "pattern2 0 1 1 0.999668\n",
      "pattern3 1 0 -1 -0.87772\n",
      "pattern4 1 1 1 0.91407\n",
      " modified Weights  [-2.79964437  2.91747876] 1.4338923379138635\n",
      " Training with pattern  4  weights  [-2.79677768  2.91747874] 1.4345759541611334   weights  [-2.79823103  2.9188921 ]  bias  1.4353056822840236\n",
      "pattern1 0 0 1 0.892749\n",
      "pattern2 0 1 1 0.99967\n",
      "pattern3 1 0 -1 -0.87707\n",
      "pattern4 1 1 1 0.914765\n",
      " modified Weights  [-2.79823103  2.9188921 ] 1.4353056822840236\n",
      "+++++++++++Epoch  393  cost=  0.033879833239414105\n",
      " Training with pattern  1  weights  [-2.79823103  2.9188921 ] 1.4353056822840236   weights  [-2.79823103  2.9188921 ]  bias  1.4374828784693423\n",
      "pattern1 0 0 1 0.89319\n",
      "pattern2 0 1 1 0.999671\n",
      "pattern3 1 0 -1 -0.876566\n",
      "pattern4 1 1 1 0.915119\n",
      " modified Weights  [-2.79823103  2.9188921 ] 1.4374828784693423\n",
      " Training with pattern  2  weights  [-2.79823103  2.9188921 ] 1.4353056822840236   weights  [-2.79823103  2.91889212]  bias  1.4374829001003748\n",
      "pattern1 0 0 1 0.89319\n",
      "pattern2 0 1 1 0.999671\n",
      "pattern3 1 0 -1 -0.876566\n",
      "pattern4 1 1 1 0.915119\n",
      " modified Weights  [-2.79823103  2.91889212] 1.4374829001003748\n",
      " Training with pattern  3  weights  [-2.79823103  2.9188921 ] 1.4353056822840236   weights  [-2.80109013  2.91889212]  bias  1.4346237941622828\n",
      "pattern1 0 0 1 0.89261\n",
      "pattern2 0 1 1 0.999669\n",
      "pattern3 1 0 -1 -0.877884\n",
      "pattern4 1 1 1 0.914185\n",
      " modified Weights  [-2.80109013  2.91889212] 1.4346237941622828\n",
      " Training with pattern  4  weights  [-2.79823103  2.9188921 ] 1.4353056822840236   weights  [-2.79968048  2.92030178]  bias  1.4360334458407877\n",
      "pattern1 0 0 1 0.892896\n",
      "pattern2 0 1 1 0.999671\n",
      "pattern3 1 0 -1 -0.877236\n",
      "pattern4 1 1 1 0.914877\n",
      " modified Weights  [-2.79968048  2.92030178] 1.4360334458407877\n",
      "+++++++++++Epoch  394  cost=  0.033788179440618876\n",
      " Training with pattern  1  weights  [-2.79968048  2.92030178] 1.4360334458407877   weights  [-2.79968048  2.92030178]  bias  1.4382048213471912\n",
      "pattern1 0 0 1 0.893336\n",
      "pattern2 0 1 1 0.999673\n",
      "pattern3 1 0 -1 -0.876735\n",
      "pattern4 1 1 1 0.91523\n",
      " modified Weights  [-2.79968048  2.92030178] 1.4382048213471912\n",
      " Training with pattern  2  weights  [-2.79968048  2.92030178] 1.4360334458407877   weights  [-2.79968048  2.9203018 ]  bias  1.4382048427946166\n",
      "pattern1 0 0 1 0.893336\n",
      "pattern2 0 1 1 0.999673\n",
      "pattern3 1 0 -1 -0.876735\n",
      "pattern4 1 1 1 0.91523\n",
      " modified Weights  [-2.79968048  2.9203018 ] 1.4382048427946166\n",
      " Training with pattern  3  weights  [-2.79968048  2.92030178] 1.4360334458407877   weights  [-2.80253205  2.9203018 ]  bias  1.4353532773143869\n",
      "pattern1 0 0 1 0.892758\n",
      "pattern2 0 1 1 0.999671\n",
      "pattern3 1 0 -1 -0.878048\n",
      "pattern4 1 1 1 0.914299\n",
      " modified Weights  [-2.80253205  2.9203018 ] 1.4353532773143869\n",
      " Training with pattern  4  weights  [-2.79968048  2.92030178] 1.4360334458407877   weights  [-2.80112607  2.92170778]  bias  1.4367592551788142\n",
      "pattern1 0 0 1 0.893043\n",
      "pattern2 0 1 1 0.999672\n",
      "pattern3 1 0 -1 -0.877402\n",
      "pattern4 1 1 1 0.914989\n",
      " modified Weights  [-2.80112607  2.92170778] 1.4367592551788142\n",
      "+++++++++++Epoch  395  cost=  0.03369700780683586\n",
      " Training with pattern  1  weights  [-2.80112607  2.92170778] 1.4367592551788142   weights  [-2.80112607  2.92170778]  bias  1.4389248404402692\n",
      "pattern1 0 0 1 0.893481\n",
      "pattern2 0 1 1 0.999674\n",
      "pattern3 1 0 -1 -0.876903\n",
      "pattern4 1 1 1 0.91534\n",
      " modified Weights  [-2.80112607  2.92170778] 1.4389248404402692\n",
      " Training with pattern  2  weights  [-2.80112607  2.92170778] 1.4367592551788142   weights  [-2.80112607  2.9217078 ]  bias  1.4389248617061219\n",
      "pattern1 0 0 1 0.893481\n",
      "pattern2 0 1 1 0.999674\n",
      "pattern3 1 0 -1 -0.876903\n",
      "pattern4 1 1 1 0.91534\n",
      " modified Weights  [-2.80112607  2.9217078 ] 1.4389248617061219\n",
      " Training with pattern  3  weights  [-2.80112607  2.92170778] 1.4367592551788142   weights  [-2.80397013  2.9217078 ]  bias  1.4360807977797667\n",
      "pattern1 0 0 1 0.892906\n",
      "pattern2 0 1 1 0.999672\n",
      "pattern3 1 0 -1 -0.87821\n",
      "pattern4 1 1 1 0.914413\n",
      " modified Weights  [-2.80397013  2.9217078 ] 1.4360807977797667\n",
      " Training with pattern  4  weights  [-2.80112607  2.92170778] 1.4367592551788142   weights  [-2.80256781  2.92311012]  bias  1.4374831205647567\n",
      "pattern1 0 0 1 0.89319\n",
      "pattern2 0 1 1 0.999674\n",
      "pattern3 1 0 -1 -0.877567\n",
      "pattern4 1 1 1 0.9151\n",
      " modified Weights  [-2.80256781  2.92311012] 1.4374831205647567\n",
      "+++++++++++Epoch  396  cost=  0.033606314591295004\n",
      " Training with pattern  1  weights  [-2.80256781  2.92311012] 1.4374831205647567   weights  [-2.80256781  2.92311012]  bias  1.4396429457795397\n",
      "pattern1 0 0 1 0.893626\n",
      "pattern2 0 1 1 0.999675\n",
      "pattern3 1 0 -1 -0.87707\n",
      "pattern4 1 1 1 0.91545\n",
      " modified Weights  [-2.80256781  2.92311012] 1.4396429457795397\n",
      " Training with pattern  2  weights  [-2.80256781  2.92311012] 1.4374831205647567   weights  [-2.80256781  2.92311014]  bias  1.439642966865826\n",
      "pattern1 0 0 1 0.893626\n",
      "pattern2 0 1 1 0.999675\n",
      "pattern3 1 0 -1 -0.87707\n",
      "pattern4 1 1 1 0.91545\n",
      " modified Weights  [-2.80256781  2.92311014] 1.439642966865826\n",
      " Training with pattern  3  weights  [-2.80256781  2.92311012] 1.4374831205647567   weights  [-2.80540441  2.92311014]  bias  1.4368063658866805\n",
      "pattern1 0 0 1 0.893053\n",
      "pattern2 0 1 1 0.999673\n",
      "pattern3 1 0 -1 -0.878372\n",
      "pattern4 1 1 1 0.914527\n",
      " modified Weights  [-2.80540441  2.92311014] 1.4368063658866805\n",
      " Training with pattern  4  weights  [-2.80256781  2.92311012] 1.4374831205647567   weights  [-2.80400572  2.92450883]  bias  1.4382050521853658\n",
      "pattern1 0 0 1 0.893336\n",
      "pattern2 0 1 1 0.999675\n",
      "pattern3 1 0 -1 -0.877732\n",
      "pattern4 1 1 1 0.915211\n",
      " modified Weights  [-2.80400572  2.92450883] 1.4382050521853658\n",
      "+++++++++++Epoch  397  cost=  0.03351609608563683\n",
      " Training with pattern  1  weights  [-2.80400572  2.92450883] 1.4382050521853658   weights  [-2.80400572  2.92450883]  bias  1.4403591473184745\n",
      "pattern1 0 0 1 0.89377\n",
      "pattern2 0 1 1 0.999677\n",
      "pattern3 1 0 -1 -0.877236\n",
      "pattern4 1 1 1 0.91556\n",
      " modified Weights  [-2.80400572  2.92450883] 1.4403591473184745\n",
      " Training with pattern  2  weights  [-2.80400572  2.92450883] 1.4382050521853658   weights  [-2.80400572  2.92450885]  bias  1.440359168227174\n",
      "pattern1 0 0 1 0.89377\n",
      "pattern2 0 1 1 0.999677\n",
      "pattern3 1 0 -1 -0.877236\n",
      "pattern4 1 1 1 0.91556\n",
      " modified Weights  [-2.80400572  2.92450885] 1.440359168227174\n",
      " Training with pattern  3  weights  [-2.80400572  2.92450883] 1.4382050521853658   weights  [-2.8068349   2.92450885]  bias  1.4375299918828943\n",
      "pattern1 0 0 1 0.893199\n",
      "pattern2 0 1 1 0.999675\n",
      "pattern3 1 0 -1 -0.878534\n",
      "pattern4 1 1 1 0.91464\n",
      " modified Weights  [-2.8068349   2.92450885] 1.4375299918828943\n",
      " Training with pattern  4  weights  [-2.80400572  2.92450883] 1.4382050521853658   weights  [-2.80543983  2.92590392]  bias  1.438925060148312\n",
      "pattern1 0 0 1 0.893481\n",
      "pattern2 0 1 1 0.999677\n",
      "pattern3 1 0 -1 -0.877895\n",
      "pattern4 1 1 1 0.915321\n",
      " modified Weights  [-2.80543983  2.92590392] 1.438925060148312\n",
      "+++++++++++Epoch  398  cost=  0.03342634861942379\n",
      " Training with pattern  1  weights  [-2.80543983  2.92590392] 1.438925060148312   weights  [-2.80543983  2.92590392]  bias  1.441073454933847\n",
      "pattern1 0 0 1 0.893914\n",
      "pattern2 0 1 1 0.999678\n",
      "pattern3 1 0 -1 -0.877402\n",
      "pattern4 1 1 1 0.915669\n",
      " modified Weights  [-2.80543983  2.92590392] 1.441073454933847\n",
      " Training with pattern  2  weights  [-2.80543983  2.92590392] 1.438925060148312   weights  [-2.80543983  2.92590394]  bias  1.4410734756669121\n",
      "pattern1 0 0 1 0.893914\n",
      "pattern2 0 1 1 0.999678\n",
      "pattern3 1 0 -1 -0.877402\n",
      "pattern4 1 1 1 0.915669\n",
      " modified Weights  [-2.80543983  2.92590394] 1.4410734756669121\n",
      " Training with pattern  3  weights  [-2.80543983  2.92590392] 1.438925060148312   weights  [-2.80826162  2.92590394]  bias  1.4382516859365102\n",
      "pattern1 0 0 1 0.893345\n",
      "pattern2 0 1 1 0.999676\n",
      "pattern3 1 0 -1 -0.878694\n",
      "pattern4 1 1 1 0.914753\n",
      " modified Weights  [-2.80826162  2.92590394] 1.4382516859365102\n",
      " Training with pattern  4  weights  [-2.80543983  2.92590392] 1.438925060148312   weights  [-2.80687015  2.92729541]  bias  1.4396431544829964\n",
      "pattern1 0 0 1 0.893626\n",
      "pattern2 0 1 1 0.999678\n",
      "pattern3 1 0 -1 -0.878059\n",
      "pattern4 1 1 1 0.915432\n",
      " modified Weights  [-2.80687015  2.92729541] 1.4396431544829964\n",
      "+++++++++++Epoch  399  cost=  0.033337068559659955\n",
      " Training with pattern  1  weights  [-2.80687015  2.92729541] 1.4396431544829964   weights  [-2.80687015  2.92729541]  bias  1.4417858784265127\n",
      "pattern1 0 0 1 0.894057\n",
      "pattern2 0 1 1 0.999679\n",
      "pattern3 1 0 -1 -0.877567\n",
      "pattern4 1 1 1 0.915778\n",
      " modified Weights  [-2.80687015  2.92729541] 1.4417858784265127\n",
      " Training with pattern  2  weights  [-2.80687015  2.92729541] 1.4396431544829964   weights  [-2.80687015  2.92729543]  bias  1.4417858989858694\n",
      "pattern1 0 0 1 0.894057\n",
      "pattern2 0 1 1 0.999679\n",
      "pattern3 1 0 -1 -0.877567\n",
      "pattern4 1 1 1 0.915778\n",
      " modified Weights  [-2.80687015  2.92729543] 1.4417858989858694\n",
      " Training with pattern  3  weights  [-2.80687015  2.92729541] 1.4396431544829964   weights  [-2.80968459  2.92729543]  bias  1.4389714581367845\n",
      "pattern1 0 0 1 0.89349\n",
      "pattern2 0 1 1 0.999678\n",
      "pattern3 1 0 -1 -0.878855\n",
      "pattern4 1 1 1 0.914865\n",
      " modified Weights  [-2.80968459  2.92729543] 1.4389714581367845\n",
      " Training with pattern  4  weights  [-2.80687015  2.92729541] 1.4396431544829964   weights  [-2.80829671  2.92868331]  bias  1.4403593451413528\n",
      "pattern1 0 0 1 0.89377\n",
      "pattern2 0 1 1 0.999679\n",
      "pattern3 1 0 -1 -0.878221\n",
      "pattern4 1 1 1 0.915541\n",
      " modified Weights  [-2.80829671  2.92868331] 1.4403593451413528\n",
      "+++++++++++Epoch  400  cost=  0.033248252310317285\n",
      " Training with pattern  1  weights  [-2.80829671  2.92868331] 1.4403593451413528   weights  [-2.80829671  2.92868331]  bias  1.4424964275221799\n",
      "pattern1 0 0 1 0.894199\n",
      "pattern2 0 1 1 0.999681\n",
      "pattern3 1 0 -1 -0.877732\n",
      "pattern4 1 1 1 0.915886\n",
      " modified Weights  [-2.80829671  2.92868331] 1.4424964275221799\n",
      " Training with pattern  2  weights  [-2.80829671  2.92868331] 1.4403593451413528   weights  [-2.80829671  2.92868333]  bias  1.4424964479097282\n",
      "pattern1 0 0 1 0.894199\n",
      "pattern2 0 1 1 0.999681\n",
      "pattern3 1 0 -1 -0.877732\n",
      "pattern4 1 1 1 0.915886\n",
      " modified Weights  [-2.80829671  2.92868333] 1.4424964479097282\n",
      " Training with pattern  3  weights  [-2.80829671  2.92868331] 1.4403593451413528   weights  [-2.81110384  2.92868333]  bias  1.4396893184949358\n",
      "pattern1 0 0 1 0.893635\n",
      "pattern2 0 1 1 0.999679\n",
      "pattern3 1 0 -1 -0.879014\n",
      "pattern4 1 1 1 0.914977\n",
      " modified Weights  [-2.81110384  2.92868333] 1.4396893184949358\n",
      " Training with pattern  4  weights  [-2.80829671  2.92868331] 1.4403593451413528   weights  [-2.80971951  2.93006766]  bias  1.441073641998636\n",
      "pattern1 0 0 1 0.893914\n",
      "pattern2 0 1 1 0.999681\n",
      "pattern3 1 0 -1 -0.878383\n",
      "pattern4 1 1 1 0.91565\n",
      " modified Weights  [-2.80971951  2.93006766] 1.441073641998636\n",
      "+++++++++++Epoch  401  cost=  0.033159896311869025\n",
      " *********Epoch  400 Error  0.033159896311869025\n",
      " Training with pattern  1  weights  [-2.80971951  2.93006766] 1.441073641998636   weights  [-2.80971951  2.93006766]  bias  1.443205111872171\n",
      "pattern1 0 0 1 0.894341\n",
      "pattern2 0 1 1 0.999682\n",
      "pattern3 1 0 -1 -0.877895\n",
      "pattern4 1 1 1 0.915994\n",
      " modified Weights  [-2.80971951  2.93006766] 1.443205111872171\n",
      " Training with pattern  2  weights  [-2.80971951  2.93006766] 1.441073641998636   weights  [-2.80971951  2.93006768]  bias  1.4432051320897852\n",
      "pattern1 0 0 1 0.894341\n",
      "pattern2 0 1 1 0.999682\n",
      "pattern3 1 0 -1 -0.877895\n",
      "pattern4 1 1 1 0.915994\n",
      " modified Weights  [-2.80971951  2.93006768] 1.4432051320897852\n",
      " Training with pattern  3  weights  [-2.80971951  2.93006766] 1.441073641998636   weights  [-2.81251937  2.93006768]  bias  1.4404052769449411\n",
      "pattern1 0 0 1 0.893779\n",
      "pattern2 0 1 1 0.99968\n",
      "pattern3 1 0 -1 -0.879173\n",
      "pattern4 1 1 1 0.915088\n",
      " modified Weights  [-2.81251937  2.93006768] 1.4404052769449411\n",
      " Training with pattern  4  weights  [-2.80971951  2.93006766] 1.441073641998636   weights  [-2.81113859  2.93144845]  bias  1.441786054854205\n",
      "pattern1 0 0 1 0.894057\n",
      "pattern2 0 1 1 0.999682\n",
      "pattern3 1 0 -1 -0.878545\n",
      "pattern4 1 1 1 0.915759\n",
      " modified Weights  [-2.81113859  2.93144845] 1.441786054854205\n",
      "+++++++++++Epoch  402  cost=  0.03307199704083068\n",
      " Training with pattern  1  weights  [-2.81113859  2.93144845] 1.441786054854205   weights  [-2.81113859  2.93144845]  bias  1.4439119410541752\n",
      "pattern1 0 0 1 0.894482\n",
      "pattern2 0 1 1 0.999683\n",
      "pattern3 1 0 -1 -0.878059\n",
      "pattern4 1 1 1 0.916102\n",
      " modified Weights  [-2.81113859  2.93144845] 1.4439119410541752\n",
      " Training with pattern  2  weights  [-2.81113859  2.93144845] 1.441786054854205   weights  [-2.81113859  2.93144847]  bias  1.443911961103705\n",
      "pattern1 0 0 1 0.894482\n",
      "pattern2 0 1 1 0.999683\n",
      "pattern3 1 0 -1 -0.878059\n",
      "pattern4 1 1 1 0.916102\n",
      " modified Weights  [-2.81113859  2.93144847] 1.443911961103705\n",
      " Training with pattern  3  weights  [-2.81113859  2.93144845] 1.441786054854205   weights  [-2.81393121  2.93144847]  bias  1.4411193433443263\n",
      "pattern1 0 0 1 0.893923\n",
      "pattern2 0 1 1 0.999682\n",
      "pattern3 1 0 -1 -0.879331\n",
      "pattern4 1 1 1 0.915199\n",
      " modified Weights  [-2.81393121  2.93144847] 1.4411193433443263\n",
      " Training with pattern  4  weights  [-2.81113859  2.93144845] 1.441786054854205   weights  [-2.81255396  2.93282572]  bias  1.4424965934322929\n",
      "pattern1 0 0 1 0.894199\n",
      "pattern2 0 1 1 0.999683\n",
      "pattern3 1 0 -1 -0.878705\n",
      "pattern4 1 1 1 0.915868\n",
      " modified Weights  [-2.81255396  2.93282572] 1.4424965934322929\n",
      "+++++++++++Epoch  403  cost=  0.032984551009307514\n",
      " Training with pattern  1  weights  [-2.81255396  2.93282572] 1.4424965934322929   weights  [-2.81255396  2.93282572]  bias  1.4446169245729916\n",
      "pattern1 0 0 1 0.894623\n",
      "pattern2 0 1 1 0.999685\n",
      "pattern3 1 0 -1 -0.878221\n",
      "pattern4 1 1 1 0.916209\n",
      " modified Weights  [-2.81255396  2.93282572] 1.4446169245729916\n",
      " Training with pattern  2  weights  [-2.81255396  2.93282572] 1.4424965934322929   weights  [-2.81255396  2.93282574]  bias  1.4446169444562613\n",
      "pattern1 0 0 1 0.894623\n",
      "pattern2 0 1 1 0.999685\n",
      "pattern3 1 0 -1 -0.878221\n",
      "pattern4 1 1 1 0.916209\n",
      " modified Weights  [-2.81255396  2.93282574] 1.4446169444562613\n",
      " Training with pattern  3  weights  [-2.81255396  2.93282572] 1.4424965934322929   weights  [-2.81533937  2.93282574]  bias  1.4418315274749403\n",
      "pattern1 0 0 1 0.894066\n",
      "pattern2 0 1 1 0.999683\n",
      "pattern3 1 0 -1 -0.879489\n",
      "pattern4 1 1 1 0.91531\n",
      " modified Weights  [-2.81533937  2.93282574] 1.4418315274749403\n",
      " Training with pattern  4  weights  [-2.81255396  2.93282572] 1.4424965934322929   weights  [-2.81396563  2.93419948]  bias  1.4432052673827682\n",
      "pattern1 0 0 1 0.894341\n",
      "pattern2 0 1 1 0.999685\n",
      "pattern3 1 0 -1 -0.878865\n",
      "pattern4 1 1 1 0.915976\n",
      " modified Weights  [-2.81396563  2.93419948] 1.4432052673827682\n",
      "+++++++++++Epoch  404  cost=  0.032897554764548725\n",
      " Training with pattern  1  weights  [-2.81396563  2.93419948] 1.4432052673827682   weights  [-2.81396563  2.93419948]  bias  1.4453200718612613\n",
      "pattern1 0 0 1 0.894764\n",
      "pattern2 0 1 1 0.999686\n",
      "pattern3 1 0 -1 -0.878383\n",
      "pattern4 1 1 1 0.916316\n",
      " modified Weights  [-2.81396563  2.93419948] 1.4453200718612613\n",
      " Training with pattern  2  weights  [-2.81396563  2.93419948] 1.4432052673827682   weights  [-2.81396563  2.9341995 ]  bias  1.445320091580071\n",
      "pattern1 0 0 1 0.894764\n",
      "pattern2 0 1 1 0.999686\n",
      "pattern3 1 0 -1 -0.878383\n",
      "pattern4 1 1 1 0.916316\n",
      " modified Weights  [-2.81396563  2.9341995 ] 1.445320091580071\n",
      " Training with pattern  3  weights  [-2.81396563  2.93419948] 1.4432052673827682   weights  [-2.81674389  2.9341995 ]  bias  1.4425418390437246\n",
      "pattern1 0 0 1 0.894208\n",
      "pattern2 0 1 1 0.999684\n",
      "pattern3 1 0 -1 -0.879646\n",
      "pattern4 1 1 1 0.91542\n",
      " modified Weights  [-2.81674389  2.9341995 ] 1.4425418390437246\n",
      " Training with pattern  4  weights  [-2.81396563  2.93419948] 1.4432052673827682   weights  [-2.81537364  2.93556975]  bias  1.4439120862818866\n",
      "pattern1 0 0 1 0.894482\n",
      "pattern2 0 1 1 0.999686\n",
      "pattern3 1 0 -1 -0.879025\n",
      "pattern4 1 1 1 0.916084\n",
      " modified Weights  [-2.81537364  2.93556975] 1.4439120862818866\n",
      "+++++++++++Epoch  405  cost=  0.032811004888508175\n",
      " Training with pattern  1  weights  [-2.81537364  2.93556975] 1.4439120862818866   weights  [-2.81537364  2.93556975]  bias  1.4460213922801914\n",
      "pattern1 0 0 1 0.894903\n",
      "pattern2 0 1 1 0.999687\n",
      "pattern3 1 0 -1 -0.878544\n",
      "pattern4 1 1 1 0.916422\n",
      " modified Weights  [-2.81537364  2.93556975] 1.4460213922801914\n",
      " Training with pattern  2  weights  [-2.81537364  2.93556975] 1.4439120862818866   weights  [-2.81537364  2.93556977]  bias  1.4460214118363175\n",
      "pattern1 0 0 1 0.894903\n",
      "pattern2 0 1 1 0.999687\n",
      "pattern3 1 0 -1 -0.878544\n",
      "pattern4 1 1 1 0.916422\n",
      " modified Weights  [-2.81537364  2.93556977] 1.4460214118363175\n",
      " Training with pattern  3  weights  [-2.81537364  2.93556975] 1.4439120862818866   weights  [-2.81814476  2.93556977]  bias  1.4432502876834707\n",
      "pattern1 0 0 1 0.89435\n",
      "pattern2 0 1 1 0.999686\n",
      "pattern3 1 0 -1 -0.879803\n",
      "pattern4 1 1 1 0.91553\n",
      " modified Weights  [-2.81814476  2.93556977] 1.4432502876834707\n",
      " Training with pattern  4  weights  [-2.81537364  2.93556975] 1.4439120862818866   weights  [-2.81677799  2.93693654]  bias  1.4446170596330332\n",
      "pattern1 0 0 1 0.894623\n",
      "pattern2 0 1 1 0.999687\n",
      "pattern3 1 0 -1 -0.879184\n",
      "pattern4 1 1 1 0.916191\n",
      " modified Weights  [-2.81677799  2.93693654] 1.4446170596330332\n",
      "+++++++++++Epoch  406  cost=  0.03272489799741218\n",
      " Training with pattern  1  weights  [-2.81677799  2.93693654] 1.4446170596330332   weights  [-2.81677799  2.93693654]  bias  1.4467208951202712\n",
      "pattern1 0 0 1 0.895043\n",
      "pattern2 0 1 1 0.999689\n",
      "pattern3 1 0 -1 -0.878705\n",
      "pattern4 1 1 1 0.916528\n",
      " modified Weights  [-2.81677799  2.93693654] 1.4467208951202712\n",
      " Training with pattern  2  weights  [-2.81677799  2.93693654] 1.4446170596330332   weights  [-2.81677799  2.93693656]  bias  1.446720914515466\n",
      "pattern1 0 0 1 0.895043\n",
      "pattern2 0 1 1 0.999689\n",
      "pattern3 1 0 -1 -0.878705\n",
      "pattern4 1 1 1 0.916528\n",
      " modified Weights  [-2.81677799  2.93693656] 1.446720914515466\n",
      " Training with pattern  3  weights  [-2.81677799  2.93693654] 1.4446170596330332   weights  [-2.81954202  2.93693656]  bias  1.443956882953568\n",
      "pattern1 0 0 1 0.894491\n",
      "pattern2 0 1 1 0.999687\n",
      "pattern3 1 0 -1 -0.879959\n",
      "pattern4 1 1 1 0.915639\n",
      " modified Weights  [-2.81954202  2.93693656] 1.443956882953568\n",
      " Training with pattern  4  weights  [-2.81677799  2.93693654] 1.4446170596330332   weights  [-2.81817871  2.93829988]  bias  1.4453201968674545\n",
      "pattern1 0 0 1 0.894764\n",
      "pattern2 0 1 1 0.999689\n",
      "pattern3 1 0 -1 -0.879342\n",
      "pattern4 1 1 1 0.916298\n",
      " modified Weights  [-2.81817871  2.93829988] 1.4453201968674545\n",
      "+++++++++++Epoch  407  cost=  0.03263923074133376\n",
      " Training with pattern  1  weights  [-2.81817871  2.93829988] 1.4453201968674545   weights  [-2.81817871  2.93829988]  bias  1.4474185896019771\n",
      "pattern1 0 0 1 0.895181\n",
      "pattern2 0 1 1 0.99969\n",
      "pattern3 1 0 -1 -0.878865\n",
      "pattern4 1 1 1 0.916634\n",
      " modified Weights  [-2.81817871  2.93829988] 1.4474185896019771\n",
      " Training with pattern  2  weights  [-2.81817871  2.93829988] 1.4453201968674545   weights  [-2.81817871  2.9382999 ]  bias  1.4474186088379701\n",
      "pattern1 0 0 1 0.895181\n",
      "pattern2 0 1 1 0.99969\n",
      "pattern3 1 0 -1 -0.878865\n",
      "pattern4 1 1 1 0.916634\n",
      " modified Weights  [-2.81817871  2.9382999 ] 1.4474186088379701\n",
      " Training with pattern  3  weights  [-2.81817871  2.93829988] 1.4453201968674545   weights  [-2.82093568  2.9382999 ]  bias  1.4446616343407446\n",
      "pattern1 0 0 1 0.894632\n",
      "pattern2 0 1 1 0.999688\n",
      "pattern3 1 0 -1 -0.880114\n",
      "pattern4 1 1 1 0.915748\n",
      " modified Weights  [-2.82093568  2.9382999 ] 1.4446616343407446\n",
      " Training with pattern  4  weights  [-2.81817871  2.93829988] 1.4453201968674545   weights  [-2.81957581  2.93965977]  bias  1.446021507344984\n",
      "pattern1 0 0 1 0.894903\n",
      "pattern2 0 1 1 0.99969\n",
      "pattern3 1 0 -1 -0.8795\n",
      "pattern4 1 1 1 0.916404\n",
      " modified Weights  [-2.81957581  2.93965977] 1.446021507344984\n",
      "+++++++++++Epoch  408  cost=  0.03255399980377181\n",
      " Training with pattern  1  weights  [-2.81957581  2.93965977] 1.446021507344984   weights  [-2.81957581  2.93965977]  bias  1.448114484876471\n",
      "pattern1 0 0 1 0.895319\n",
      "pattern2 0 1 1 0.999691\n",
      "pattern3 1 0 -1 -0.879025\n",
      "pattern4 1 1 1 0.916739\n",
      " modified Weights  [-2.81957581  2.93965977] 1.448114484876471\n",
      " Training with pattern  2  weights  [-2.81957581  2.93965977] 1.446021507344984   weights  [-2.81957581  2.93965979]  bias  1.4481145039549685\n",
      "pattern1 0 0 1 0.895319\n",
      "pattern2 0 1 1 0.999691\n",
      "pattern3 1 0 -1 -0.879025\n",
      "pattern4 1 1 1 0.916739\n",
      " modified Weights  [-2.81957581  2.93965979] 1.4481145039549685\n",
      " Training with pattern  3  weights  [-2.81957581  2.93965977] 1.446021507344984   weights  [-2.82232576  2.93965979]  bias  1.4453645512597946\n",
      "pattern1 0 0 1 0.894772\n",
      "pattern2 0 1 1 0.999689\n",
      "pattern3 1 0 -1 -0.880269\n",
      "pattern4 1 1 1 0.915857\n",
      " modified Weights  [-2.82232576  2.93965979] 1.4453645512597946\n",
      " Training with pattern  4  weights  [-2.81957581  2.93965977] 1.446021507344984   weights  [-2.82096931  2.94101624]  bias  1.446721000354755\n",
      "pattern1 0 0 1 0.895043\n",
      "pattern2 0 1 1 0.999691\n",
      "pattern3 1 0 -1 -0.879657\n",
      "pattern4 1 1 1 0.91651\n",
      " modified Weights  [-2.82096931  2.94101624] 1.446721000354755\n",
      "+++++++++++Epoch  409  cost=  0.032469201901238726\n",
      " Training with pattern  1  weights  [-2.82096931  2.94101624] 1.446721000354755   weights  [-2.82096931  2.94101624]  bias  1.4488085900262884\n",
      "pattern1 0 0 1 0.895457\n",
      "pattern2 0 1 1 0.999692\n",
      "pattern3 1 0 -1 -0.879184\n",
      "pattern4 1 1 1 0.916844\n",
      " modified Weights  [-2.82096931  2.94101624] 1.4488085900262884\n",
      " Training with pattern  2  weights  [-2.82096931  2.94101624] 1.446721000354755   weights  [-2.82096931  2.94101626]  bias  1.4488086089489742\n",
      "pattern1 0 0 1 0.895457\n",
      "pattern2 0 1 1 0.999692\n",
      "pattern3 1 0 -1 -0.879184\n",
      "pattern4 1 1 1 0.916844\n",
      " modified Weights  [-2.82096931  2.94101626] 1.4488086089489742\n",
      " Training with pattern  3  weights  [-2.82096931  2.94101624] 1.446721000354755   weights  [-2.82371228  2.94101626]  bias  1.4460656430543006\n",
      "pattern1 0 0 1 0.894912\n",
      "pattern2 0 1 1 0.999691\n",
      "pattern3 1 0 -1 -0.880423\n",
      "pattern4 1 1 1 0.915965\n",
      " modified Weights  [-2.82371228  2.94101626] 1.4460656430543006\n",
      " Training with pattern  4  weights  [-2.82096931  2.94101624] 1.446721000354755   weights  [-2.82235924  2.9423693 ]  bias  1.4474186851159074\n",
      "pattern1 0 0 1 0.895181\n",
      "pattern2 0 1 1 0.999692\n",
      "pattern3 1 0 -1 -0.879813\n",
      "pattern4 1 1 1 0.916616\n",
      " modified Weights  [-2.82235924  2.9423693 ] 1.4474186851159074\n",
      "+++++++++++Epoch  410  cost=  0.03238483378285193\n",
      " Training with pattern  1  weights  [-2.82235924  2.9423693 ] 1.4474186851159074   weights  [-2.82235924  2.9423693 ]  bias  1.4495009140660184\n",
      "pattern1 0 0 1 0.895594\n",
      "pattern2 0 1 1 0.999694\n",
      "pattern3 1 0 -1 -0.879342\n",
      "pattern4 1 1 1 0.916948\n",
      " modified Weights  [-2.82235924  2.9423693 ] 1.4495009140660184\n",
      " Training with pattern  2  weights  [-2.82235924  2.9423693 ] 1.4474186851159074   weights  [-2.82235924  2.94236932]  bias  1.4495009328345547\n",
      "pattern1 0 0 1 0.895594\n",
      "pattern2 0 1 1 0.999694\n",
      "pattern3 1 0 -1 -0.879342\n",
      "pattern4 1 1 1 0.916948\n",
      " modified Weights  [-2.82235924  2.94236932] 1.4495009328345547\n",
      " Training with pattern  3  weights  [-2.82235924  2.9423693 ] 1.4474186851159074   weights  [-2.82509525  2.94236932]  bias  1.4467649189973457\n",
      "pattern1 0 0 1 0.895051\n",
      "pattern2 0 1 1 0.999692\n",
      "pattern3 1 0 -1 -0.880577\n",
      "pattern4 1 1 1 0.916072\n",
      " modified Weights  [-2.82509525  2.94236932] 1.4467649189973457\n",
      " Training with pattern  4  weights  [-2.82235924  2.9423693 ] 1.4474186851159074   weights  [-2.8237456   2.94371897]  bias  1.4481145707782852\n",
      "pattern1 0 0 1 0.895319\n",
      "pattern2 0 1 1 0.999694\n",
      "pattern3 1 0 -1 -0.879969\n",
      "pattern4 1 1 1 0.916721\n",
      " modified Weights  [-2.8237456   2.94371897] 1.4481145707782852\n",
      "+++++++++++Epoch  411  cost=  0.03230089222993319\n",
      " *********Epoch  410 Error  0.03230089222993319\n",
      " Training with pattern  1  weights  [-2.8237456   2.94371897] 1.4481145707782852   weights  [-2.8237456   2.94371897]  bias  1.4501914659429778\n",
      "pattern1 0 0 1 0.895731\n",
      "pattern2 0 1 1 0.999695\n",
      "pattern3 1 0 -1 -0.8795\n",
      "pattern4 1 1 1 0.917052\n",
      " modified Weights  [-2.8237456   2.94371897] 1.4501914659429778\n",
      " Training with pattern  2  weights  [-2.8237456   2.94371897] 1.4481145707782852   weights  [-2.8237456   2.94371899]  bias  1.450191484559004\n",
      "pattern1 0 0 1 0.895731\n",
      "pattern2 0 1 1 0.999695\n",
      "pattern3 1 0 -1 -0.8795\n",
      "pattern4 1 1 1 0.917052\n",
      " modified Weights  [-2.8237456   2.94371899] 1.450191484559004\n",
      " Training with pattern  3  weights  [-2.8237456   2.94371897] 1.4481145707782852   weights  [-2.8264747   2.94371899]  bias  1.4474623882922149\n",
      "pattern1 0 0 1 0.89519\n",
      "pattern2 0 1 1 0.999693\n",
      "pattern3 1 0 -1 -0.88073\n",
      "pattern4 1 1 1 0.91618\n",
      " modified Weights  [-2.8264747   2.94371899] 1.4474623882922149\n",
      " Training with pattern  4  weights  [-2.8237456   2.94371897] 1.4481145707782852   weights  [-2.82512842  2.94506527]  bias  1.448808666423124\n",
      "pattern1 0 0 1 0.895457\n",
      "pattern2 0 1 1 0.999695\n",
      "pattern3 1 0 -1 -0.880124\n",
      "pattern4 1 1 1 0.916826\n",
      " modified Weights  [-2.82512842  2.94506527] 1.448808666423124\n",
      "+++++++++++Epoch  412  cost=  0.03221737405561233\n",
      " Training with pattern  1  weights  [-2.82512842  2.94506527] 1.448808666423124   weights  [-2.82512842  2.94506527]  bias  1.450880254537871\n",
      "pattern1 0 0 1 0.895867\n",
      "pattern2 0 1 1 0.999696\n",
      "pattern3 1 0 -1 -0.879657\n",
      "pattern4 1 1 1 0.917156\n",
      " modified Weights  [-2.82512842  2.94506527] 1.450880254537871\n",
      " Training with pattern  2  weights  [-2.82512842  2.94506527] 1.448808666423124   weights  [-2.82512842  2.94506528]  bias  1.450880273003006\n",
      "pattern1 0 0 1 0.895867\n",
      "pattern2 0 1 1 0.999696\n",
      "pattern3 1 0 -1 -0.879657\n",
      "pattern4 1 1 1 0.917156\n",
      " modified Weights  [-2.82512842  2.94506528] 1.450880273003006\n",
      " Training with pattern  3  weights  [-2.82512842  2.94506527] 1.448808666423124   weights  [-2.82785063  2.94506528]  bias  1.4481580600730903\n",
      "pattern1 0 0 1 0.895328\n",
      "pattern2 0 1 1 0.999694\n",
      "pattern3 1 0 -1 -0.880882\n",
      "pattern4 1 1 1 0.916287\n",
      " modified Weights  [-2.82785063  2.94506528] 1.4481580600730903\n",
      " Training with pattern  4  weights  [-2.82512842  2.94506527] 1.448808666423124   weights  [-2.82650771  2.9464082 ]  bias  1.4495009810637314\n",
      "pattern1 0 0 1 0.895594\n",
      "pattern2 0 1 1 0.999696\n",
      "pattern3 1 0 -1 -0.880279\n",
      "pattern4 1 1 1 0.916931\n",
      " modified Weights  [-2.82650771  2.9464082 ] 1.4495009810637314\n",
      "+++++++++++Epoch  413  cost=  0.03213427610443819\n",
      " Training with pattern  1  weights  [-2.82650771  2.9464082 ] 1.4495009810637314   weights  [-2.82650771  2.9464082 ]  bias  1.4515672886654494\n",
      "pattern1 0 0 1 0.896002\n",
      "pattern2 0 1 1 0.999697\n",
      "pattern3 1 0 -1 -0.879813\n",
      "pattern4 1 1 1 0.917259\n",
      " modified Weights  [-2.82650771  2.9464082 ] 1.4515672886654494\n",
      " Training with pattern  2  weights  [-2.82650771  2.9464082 ] 1.4495009810637314   weights  [-2.82650771  2.94640822]  bias  1.4515673069812904\n",
      "pattern1 0 0 1 0.896002\n",
      "pattern2 0 1 1 0.999697\n",
      "pattern3 1 0 -1 -0.879813\n",
      "pattern4 1 1 1 0.917259\n",
      " modified Weights  [-2.82650771  2.94640822] 1.4515673069812904\n",
      " Training with pattern  3  weights  [-2.82650771  2.9464082 ] 1.4495009810637314   weights  [-2.82922307  2.94640822]  bias  1.4488519434057379\n",
      "pattern1 0 0 1 0.895466\n",
      "pattern2 0 1 1 0.999696\n",
      "pattern3 1 0 -1 -0.881034\n",
      "pattern4 1 1 1 0.916393\n",
      " modified Weights  [-2.82922307  2.94640822] 1.4488519434057379\n",
      " Training with pattern  4  weights  [-2.82650771  2.9464082 ] 1.4495009810637314   weights  [-2.82788349  2.9477478 ]  bias  1.4501915236461596\n",
      "pattern1 0 0 1 0.895731\n",
      "pattern2 0 1 1 0.999697\n",
      "pattern3 1 0 -1 -0.880433\n",
      "pattern4 1 1 1 0.917035\n",
      " modified Weights  [-2.82788349  2.9477478 ] 1.4501915236461596\n",
      "+++++++++++Epoch  414  cost=  0.032051595251993775\n",
      " Training with pattern  1  weights  [-2.82788349  2.9477478 ] 1.4501915236461596   weights  [-2.82788349  2.9477478 ]  bias  1.4522525770751566\n",
      "pattern1 0 0 1 0.896137\n",
      "pattern2 0 1 1 0.999699\n",
      "pattern3 1 0 -1 -0.879969\n",
      "pattern4 1 1 1 0.917362\n",
      " modified Weights  [-2.82788349  2.9477478 ] 1.4522525770751566\n",
      " Training with pattern  2  weights  [-2.82788349  2.9477478 ] 1.4501915236461596   weights  [-2.82788349  2.94774782]  bias  1.45225259524328\n",
      "pattern1 0 0 1 0.896137\n",
      "pattern2 0 1 1 0.999699\n",
      "pattern3 1 0 -1 -0.879969\n",
      "pattern4 1 1 1 0.917362\n",
      " modified Weights  [-2.82788349  2.94774782] 1.45225259524328\n",
      " Training with pattern  3  weights  [-2.82788349  2.9477478 ] 1.4501915236461596   weights  [-2.83059204  2.94774782]  bias  1.4495440472881818\n",
      "pattern1 0 0 1 0.895603\n",
      "pattern2 0 1 1 0.999697\n",
      "pattern3 1 0 -1 -0.881186\n",
      "pattern4 1 1 1 0.916499\n",
      " modified Weights  [-2.83059204  2.94774782] 1.4495440472881818\n",
      " Training with pattern  4  weights  [-2.82788349  2.9477478 ] 1.4501915236461596   weights  [-2.82925579  2.94908408]  bias  1.4508803030498667\n",
      "pattern1 0 0 1 0.895867\n",
      "pattern2 0 1 1 0.999699\n",
      "pattern3 1 0 -1 -0.880587\n",
      "pattern4 1 1 1 0.917138\n",
      " modified Weights  [-2.82925579  2.94908408] 1.4508803030498667\n",
      "+++++++++++Epoch  415  cost=  0.03196932840451849\n",
      " Training with pattern  1  weights  [-2.82925579  2.94908408] 1.4508803030498667   weights  [-2.82925579  2.94908408]  bias  1.4529361284517683\n",
      "pattern1 0 0 1 0.896272\n",
      "pattern2 0 1 1 0.9997\n",
      "pattern3 1 0 -1 -0.880124\n",
      "pattern4 1 1 1 0.917464\n",
      " modified Weights  [-2.82925579  2.94908408] 1.4529361284517683\n",
      " Training with pattern  2  weights  [-2.82925579  2.94908408] 1.4508803030498667   weights  [-2.82925579  2.9490841 ]  bias  1.4529361464737303\n",
      "pattern1 0 0 1 0.896272\n",
      "pattern2 0 1 1 0.9997\n",
      "pattern3 1 0 -1 -0.880124\n",
      "pattern4 1 1 1 0.917464\n",
      " modified Weights  [-2.82925579  2.9490841 ] 1.4529361464737303\n",
      " Training with pattern  3  weights  [-2.82925579  2.94908408] 1.4508803030498667   weights  [-2.83195755  2.9490841 ]  bias  1.4502343806513762\n",
      "pattern1 0 0 1 0.895739\n",
      "pattern2 0 1 1 0.999698\n",
      "pattern3 1 0 -1 -0.881337\n",
      "pattern4 1 1 1 0.916605\n",
      " modified Weights  [-2.83195755  2.9490841 ] 1.4502343806513762\n",
      " Training with pattern  4  weights  [-2.82925579  2.94908408] 1.4508803030498667   weights  [-2.8306246   2.95041704]  bias  1.4515673280883743\n",
      "pattern1 0 0 1 0.896002\n",
      "pattern2 0 1 1 0.9997\n",
      "pattern3 1 0 -1 -0.88074\n",
      "pattern4 1 1 1 0.917242\n",
      " modified Weights  [-2.8306246   2.95041704] 1.4515673280883743\n",
      "+++++++++++Epoch  416  cost=  0.03188747249853423\n",
      " Training with pattern  1  weights  [-2.8306246   2.95041704] 1.4515673280883743   weights  [-2.8306246   2.95041704]  bias  1.453617951416025\n",
      "pattern1 0 0 1 0.896406\n",
      "pattern2 0 1 1 0.999701\n",
      "pattern3 1 0 -1 -0.880279\n",
      "pattern4 1 1 1 0.917567\n",
      " modified Weights  [-2.8306246   2.95041704] 1.453617951416025\n",
      " Training with pattern  2  weights  [-2.8306246   2.95041704] 1.4515673280883743   weights  [-2.8306246   2.95041706]  bias  1.4536179692933613\n",
      "pattern1 0 0 1 0.896406\n",
      "pattern2 0 1 1 0.999701\n",
      "pattern3 1 0 -1 -0.880279\n",
      "pattern4 1 1 1 0.917567\n",
      " modified Weights  [-2.8306246   2.95041706] 1.4536179692933613\n",
      " Training with pattern  3  weights  [-2.8306246   2.95041704] 1.4515673280883743   weights  [-2.83331962  2.95041706]  bias  1.4509229523598646\n",
      "pattern1 0 0 1 0.895875\n",
      "pattern2 0 1 1 0.999699\n",
      "pattern3 1 0 -1 -0.881487\n",
      "pattern4 1 1 1 0.91671\n",
      " modified Weights  [-2.83331962  2.95041706] 1.4509229523598646\n",
      " Training with pattern  4  weights  [-2.8306246   2.95041704] 1.4515673280883743   weights  [-2.83198997  2.95174672]  bias  1.452252607509913\n",
      "pattern1 0 0 1 0.896137\n",
      "pattern2 0 1 1 0.999701\n",
      "pattern3 1 0 -1 -0.880892\n",
      "pattern4 1 1 1 0.917345\n",
      " modified Weights  [-2.83198997  2.95174672] 1.452252607509913\n",
      "+++++++++++Epoch  417  cost=  0.031806024500478876\n",
      " Training with pattern  1  weights  [-2.83198997  2.95174672] 1.452252607509913   weights  [-2.83198997  2.95174672]  bias  1.4542980545252557\n",
      "pattern1 0 0 1 0.896539\n",
      "pattern2 0 1 1 0.999702\n",
      "pattern3 1 0 -1 -0.880433\n",
      "pattern4 1 1 1 0.917668\n",
      " modified Weights  [-2.83198997  2.95174672] 1.4542980545252557\n",
      " Training with pattern  2  weights  [-2.83198997  2.95174672] 1.452252607509913   weights  [-2.83198997  2.95174673]  bias  1.4542980722594823\n",
      "pattern1 0 0 1 0.896539\n",
      "pattern2 0 1 1 0.999702\n",
      "pattern3 1 0 -1 -0.880433\n",
      "pattern4 1 1 1 0.917668\n",
      " modified Weights  [-2.83198997  2.95174673] 1.4542980722594823\n",
      " Training with pattern  3  weights  [-2.83198997  2.95174672] 1.452252607509913   weights  [-2.83467827  2.95174673]  bias  1.4516097712124325\n",
      "pattern1 0 0 1 0.896011\n",
      "pattern2 0 1 1 0.999701\n",
      "pattern3 1 0 -1 -0.881637\n",
      "pattern4 1 1 1 0.916815\n",
      " modified Weights  [-2.83467827  2.95174673] 1.4516097712124325\n",
      " Training with pattern  4  weights  [-2.83198997  2.95174672] 1.452252607509913   weights  [-2.83335189  2.95307311]  bias  1.4529361499980626\n",
      "pattern1 0 0 1 0.896272\n",
      "pattern2 0 1 1 0.999702\n",
      "pattern3 1 0 -1 -0.881044\n",
      "pattern4 1 1 1 0.917447\n",
      " modified Weights  [-2.83335189  2.95307311] 1.4529361499980626\n",
      "+++++++++++Epoch  418  cost=  0.03172498140634314\n",
      " Training with pattern  1  weights  [-2.83335189  2.95307311] 1.4529361499980626   weights  [-2.83335189  2.95307311]  bias  1.4549764462739943\n",
      "pattern1 0 0 1 0.896673\n",
      "pattern2 0 1 1 0.999703\n",
      "pattern3 1 0 -1 -0.880587\n",
      "pattern4 1 1 1 0.91777\n",
      " modified Weights  [-2.83335189  2.95307311] 1.4549764462739943\n",
      " Training with pattern  2  weights  [-2.83335189  2.95307311] 1.4529361499980626   weights  [-2.83335189  2.95307313]  bias  1.4549764638666074\n",
      "pattern1 0 0 1 0.896673\n",
      "pattern2 0 1 1 0.999703\n",
      "pattern3 1 0 -1 -0.880587\n",
      "pattern4 1 1 1 0.91777\n",
      " modified Weights  [-2.83335189  2.95307313] 1.4549764638666074\n",
      " Training with pattern  3  weights  [-2.83335189  2.95307311] 1.4529361499980626   weights  [-2.83603351  2.95307313]  bias  1.4522948459427525\n",
      "pattern1 0 0 1 0.896146\n",
      "pattern2 0 1 1 0.999702\n",
      "pattern3 1 0 -1 -0.881786\n",
      "pattern4 1 1 1 0.91692\n",
      " modified Weights  [-2.83603351  2.95307313] 1.4522948459427525\n",
      " Training with pattern  4  weights  [-2.83335189  2.95307311] 1.4529361499980626   weights  [-2.83471039  2.95439625]  bias  1.4536179641723839\n",
      "pattern1 0 0 1 0.896406\n",
      "pattern2 0 1 1 0.999703\n",
      "pattern3 1 0 -1 -0.881196\n",
      "pattern4 1 1 1 0.91755\n",
      " modified Weights  [-2.83471039  2.95439625] 1.4536179641723839\n",
      "+++++++++++Epoch  419  cost=  0.03164434024131411\n",
      " Training with pattern  1  weights  [-2.83471039  2.95439625] 1.4536179641723839   weights  [-2.83471039  2.95439625]  bias  1.4556531350945892\n",
      "pattern1 0 0 1 0.896805\n",
      "pattern2 0 1 1 0.999705\n",
      "pattern3 1 0 -1 -0.88074\n",
      "pattern4 1 1 1 0.917871\n",
      " modified Weights  [-2.83471039  2.95439625] 1.4556531350945892\n",
      " Training with pattern  2  weights  [-2.83471039  2.95439625] 1.4536179641723839   weights  [-2.83471039  2.95439627]  bias  1.4556531525470662\n",
      "pattern1 0 0 1 0.896805\n",
      "pattern2 0 1 1 0.999705\n",
      "pattern3 1 0 -1 -0.88074\n",
      "pattern4 1 1 1 0.917871\n",
      " modified Weights  [-2.83471039  2.95439627] 1.4556531525470662\n",
      " Training with pattern  3  weights  [-2.83471039  2.95439625] 1.4536179641723839   weights  [-2.83738536  2.95439627]  bias  1.4529781852200208\n",
      "pattern1 0 0 1 0.89628\n",
      "pattern2 0 1 1 0.999703\n",
      "pattern3 1 0 -1 -0.881934\n",
      "pattern4 1 1 1 0.917024\n",
      " modified Weights  [-2.83738536  2.95439627] 1.4529781852200208\n",
      " Training with pattern  4  weights  [-2.83471039  2.95439625] 1.4536179641723839   weights  [-2.83606548  2.95571614]  bias  1.4542980585890417\n",
      "pattern1 0 0 1 0.896539\n",
      "pattern2 0 1 1 0.999705\n",
      "pattern3 1 0 -1 -0.881346\n",
      "pattern4 1 1 1 0.917652\n",
      " modified Weights  [-2.83606548  2.95571614] 1.4542980585890417\n",
      "+++++++++++Epoch  420  cost=  0.03156409805942272\n",
      " Training with pattern  1  weights  [-2.83606548  2.95571614] 1.4542980585890417   weights  [-2.83606548  2.95571614]  bias  1.456328129357805\n",
      "pattern1 0 0 1 0.896937\n",
      "pattern2 0 1 1 0.999706\n",
      "pattern3 1 0 -1 -0.880892\n",
      "pattern4 1 1 1 0.917972\n",
      " modified Weights  [-2.83606548  2.95571614] 1.456328129357805\n",
      " Training with pattern  2  weights  [-2.83606548  2.95571614] 1.4542980585890417   weights  [-2.83606548  2.95571616]  bias  1.4563281466716038\n",
      "pattern1 0 0 1 0.896937\n",
      "pattern2 0 1 1 0.999706\n",
      "pattern3 1 0 -1 -0.880892\n",
      "pattern4 1 1 1 0.917972\n",
      " modified Weights  [-2.83606548  2.95571616] 1.4563281466716038\n",
      " Training with pattern  3  weights  [-2.83606548  2.95571614] 1.4542980585890417   weights  [-2.83873383  2.95571616]  bias  1.4536597976495862\n",
      "pattern1 0 0 1 0.896414\n",
      "pattern2 0 1 1 0.999704\n",
      "pattern3 1 0 -1 -0.882082\n",
      "pattern4 1 1 1 0.917128\n",
      " modified Weights  [-2.83873383  2.95571616] 1.4536597976495862\n",
      " Training with pattern  4  weights  [-2.83606548  2.95571614] 1.4542980585890417   weights  [-2.83741719  2.9570328 ]  bias  1.454976441741422\n",
      "pattern1 0 0 1 0.896673\n",
      "pattern2 0 1 1 0.999706\n",
      "pattern3 1 0 -1 -0.881497\n",
      "pattern4 1 1 1 0.917753\n",
      " modified Weights  [-2.83741719  2.9570328 ] 1.454976441741422\n",
      "+++++++++++Epoch  421  cost=  0.0314842519431978\n",
      " *********Epoch  420 Error  0.0314842519431978\n",
      " Training with pattern  1  weights  [-2.83741719  2.9570328 ] 1.454976441741422   weights  [-2.83741719  2.9570328 ]  bias  1.457001437373417\n",
      "pattern1 0 0 1 0.897069\n",
      "pattern2 0 1 1 0.999707\n",
      "pattern3 1 0 -1 -0.881044\n",
      "pattern4 1 1 1 0.918072\n",
      " modified Weights  [-2.83741719  2.9570328 ] 1.457001437373417\n",
      " Training with pattern  2  weights  [-2.83741719  2.9570328 ] 1.454976441741422   weights  [-2.83741719  2.95703282]  bias  1.4570014545499774\n",
      "pattern1 0 0 1 0.897069\n",
      "pattern2 0 1 1 0.999707\n",
      "pattern3 1 0 -1 -0.881044\n",
      "pattern4 1 1 1 0.918072\n",
      " modified Weights  [-2.83741719  2.95703282] 1.4570014545499774\n",
      " Training with pattern  3  weights  [-2.83741719  2.9570328 ] 1.454976441741422   weights  [-2.84007895  2.95703282]  bias  1.4543396917735723\n",
      "pattern1 0 0 1 0.896548\n",
      "pattern2 0 1 1 0.999705\n",
      "pattern3 1 0 -1 -0.88223\n",
      "pattern4 1 1 1 0.917231\n",
      " modified Weights  [-2.84007895  2.95703282] 1.4543396917735723\n",
      " Training with pattern  4  weights  [-2.83741719  2.9570328 ] 1.454976441741422   weights  [-2.83876552  2.95834625]  bias  1.4556531220607407\n",
      "pattern1 0 0 1 0.896805\n",
      "pattern2 0 1 1 0.999707\n",
      "pattern3 1 0 -1 -0.881646\n",
      "pattern4 1 1 1 0.917854\n",
      " modified Weights  [-2.83876552  2.95834625] 1.4556531220607407\n",
      "+++++++++++Epoch  422  cost=  0.03140479900332335\n",
      " Training with pattern  1  weights  [-2.83876552  2.95834625] 1.4556531220607407   weights  [-2.83876552  2.95834625]  bias  1.4576730673907992\n",
      "pattern1 0 0 1 0.8972\n",
      "pattern2 0 1 1 0.999708\n",
      "pattern3 1 0 -1 -0.881196\n",
      "pattern4 1 1 1 0.918172\n",
      " modified Weights  [-2.83876552  2.95834625] 1.4576730673907992\n",
      " Training with pattern  2  weights  [-2.83876552  2.95834625] 1.4556531220607407   weights  [-2.83876552  2.95834626]  bias  1.457673084431542\n",
      "pattern1 0 0 1 0.8972\n",
      "pattern2 0 1 1 0.999708\n",
      "pattern3 1 0 -1 -0.881196\n",
      "pattern4 1 1 1 0.918172\n",
      " modified Weights  [-2.83876552  2.95834626] 1.457673084431542\n",
      " Training with pattern  3  weights  [-2.83876552  2.95834625] 1.4556531220607407   weights  [-2.84142073  2.95834626]  bias  1.4550178760714902\n",
      "pattern1 0 0 1 0.896681\n",
      "pattern2 0 1 1 0.999707\n",
      "pattern3 1 0 -1 -0.882377\n",
      "pattern4 1 1 1 0.917334\n",
      " modified Weights  [-2.84142073  2.95834626] 1.4550178760714902\n",
      " Training with pattern  4  weights  [-2.83876552  2.95834625] 1.4556531220607407   weights  [-2.8401105  2.9596565]  bias  1.4563281079166452\n",
      "pattern1 0 0 1 0.896937\n",
      "pattern2 0 1 1 0.999708\n",
      "pattern3 1 0 -1 -0.881795\n",
      "pattern4 1 1 1 0.917955\n",
      " modified Weights  [-2.8401105  2.9596565] 1.4563281079166452\n",
      "+++++++++++Epoch  423  cost=  0.03132573637830199\n",
      " Training with pattern  1  weights  [-2.8401105  2.9596565] 1.4563281079166452   weights  [-2.8401105  2.9596565]  bias  1.458343027599504\n",
      "pattern1 0 0 1 0.89733\n",
      "pattern2 0 1 1 0.999709\n",
      "pattern3 1 0 -1 -0.881346\n",
      "pattern4 1 1 1 0.918272\n",
      " modified Weights  [-2.8401105  2.9596565] 1.458343027599504\n",
      " Training with pattern  2  weights  [-2.8401105  2.9596565] 1.4563281079166452   weights  [-2.8401105   2.95965651]  bias  1.4583430445058323\n",
      "pattern1 0 0 1 0.89733\n",
      "pattern2 0 1 1 0.999709\n",
      "pattern3 1 0 -1 -0.881346\n",
      "pattern4 1 1 1 0.918272\n",
      " modified Weights  [-2.8401105   2.95965651] 1.4583430445058323\n",
      " Training with pattern  3  weights  [-2.8401105  2.9596565] 1.4563281079166452   weights  [-2.84275918  2.95965651]  bias  1.4556943589608466\n",
      "pattern1 0 0 1 0.896813\n",
      "pattern2 0 1 1 0.999708\n",
      "pattern3 1 0 -1 -0.882523\n",
      "pattern4 1 1 1 0.917437\n",
      " modified Weights  [-2.84275918  2.95965651] 1.4556943589608466\n",
      " Training with pattern  4  weights  [-2.8401105  2.9596565] 1.4563281079166452   weights  [-2.84145213  2.96096356]  bias  1.4570014076178093\n",
      "pattern1 0 0 1 0.897069\n",
      "pattern2 0 1 1 0.999709\n",
      "pattern3 1 0 -1 -0.881944\n",
      "pattern4 1 1 1 0.918056\n",
      " modified Weights  [-2.84145213  2.96096356] 1.4570014076178093\n",
      "+++++++++++Epoch  424  cost=  0.031247061234122804\n",
      " Training with pattern  1  weights  [-2.84145213  2.96096356] 1.4570014076178093   weights  [-2.84145213  2.96096356]  bias  1.4590113261298365\n",
      "pattern1 0 0 1 0.89746\n",
      "pattern2 0 1 1 0.99971\n",
      "pattern3 1 0 -1 -0.881497\n",
      "pattern4 1 1 1 0.918371\n",
      " modified Weights  [-2.84145213  2.96096356] 1.4590113261298365\n",
      " Training with pattern  2  weights  [-2.84145213  2.96096356] 1.4570014076178093   weights  [-2.84145213  2.96096358]  bias  1.4590113429031355\n",
      "pattern1 0 0 1 0.89746\n",
      "pattern2 0 1 1 0.99971\n",
      "pattern3 1 0 -1 -0.881497\n",
      "pattern4 1 1 1 0.918371\n",
      " modified Weights  [-2.84145213  2.96096358] 1.4590113429031355\n",
      " Training with pattern  3  weights  [-2.84145213  2.96096356] 1.4570014076178093   weights  [-2.84409433  2.96096358]  bias  1.456369148797742\n",
      "pattern1 0 0 1 0.896945\n",
      "pattern2 0 1 1 0.999709\n",
      "pattern3 1 0 -1 -0.882669\n",
      "pattern4 1 1 1 0.917539\n",
      " modified Weights  [-2.84409433  2.96096358] 1.456369148797742\n",
      " Training with pattern  4  weights  [-2.84145213  2.96096356] 1.4570014076178093   weights  [-2.84279045  2.96226746]  bias  1.4576730294125193\n",
      "pattern1 0 0 1 0.8972\n",
      "pattern2 0 1 1 0.99971\n",
      "pattern3 1 0 -1 -0.882092\n",
      "pattern4 1 1 1 0.918156\n",
      " modified Weights  [-2.84279045  2.96226746] 1.4576730294125193\n",
      "+++++++++++Epoch  425  cost=  0.031168770763933738\n",
      " Training with pattern  1  weights  [-2.84279045  2.96226746] 1.4576730294125193   weights  [-2.84279045  2.96226746]  bias  1.4596779710534207\n",
      "pattern1 0 0 1 0.89759\n",
      "pattern2 0 1 1 0.999712\n",
      "pattern3 1 0 -1 -0.881646\n",
      "pattern4 1 1 1 0.91847\n",
      " modified Weights  [-2.84279045  2.96226746] 1.4596779710534207\n",
      " Training with pattern  2  weights  [-2.84279045  2.96226746] 1.4576730294125193   weights  [-2.84279045  2.96226748]  bias  1.4596779876950579\n",
      "pattern1 0 0 1 0.89759\n",
      "pattern2 0 1 1 0.999712\n",
      "pattern3 1 0 -1 -0.881646\n",
      "pattern4 1 1 1 0.91847\n",
      " modified Weights  [-2.84279045  2.96226748] 1.4596779876950579\n",
      " Training with pattern  3  weights  [-2.84279045  2.96226746] 1.4576730294125193   weights  [-2.84542618  2.96226748]  bias  1.4570422538774628\n",
      "pattern1 0 0 1 0.897077\n",
      "pattern2 0 1 1 0.99971\n",
      "pattern3 1 0 -1 -0.882815\n",
      "pattern4 1 1 1 0.917641\n",
      " modified Weights  [-2.84542618  2.96226748] 1.4570422538774628\n",
      " Training with pattern  4  weights  [-2.84279045  2.96226746] 1.4576730294125193   weights  [-2.84412545  2.9635682 ]  bias  1.4583429814892555\n",
      "pattern1 0 0 1 0.89733\n",
      "pattern2 0 1 1 0.999712\n",
      "pattern3 1 0 -1 -0.88224\n",
      "pattern4 1 1 1 0.918255\n",
      " modified Weights  [-2.84412545  2.9635682 ] 1.4583429814892555\n",
      "+++++++++++Epoch  426  cost=  0.031090862187718914\n",
      " Training with pattern  1  weights  [-2.84412545  2.9635682 ] 1.4583429814892555   weights  [-2.84412545  2.9635682 ]  bias  1.4603429703837598\n",
      "pattern1 0 0 1 0.897719\n",
      "pattern2 0 1 1 0.999713\n",
      "pattern3 1 0 -1 -0.881795\n",
      "pattern4 1 1 1 0.918568\n",
      " modified Weights  [-2.84412545  2.9635682 ] 1.4603429703837598\n",
      " Training with pattern  2  weights  [-2.84412545  2.9635682 ] 1.4583429814892555   weights  [-2.84412545  2.96356822]  bias  1.4603429868950852\n",
      "pattern1 0 0 1 0.897719\n",
      "pattern2 0 1 1 0.999713\n",
      "pattern3 1 0 -1 -0.881795\n",
      "pattern4 1 1 1 0.918568\n",
      " modified Weights  [-2.84412545  2.96356822] 1.4603429868950852\n",
      " Training with pattern  3  weights  [-2.84412545  2.9635682 ] 1.4583429814892555   weights  [-2.84675476  2.96356822]  bias  1.4577136824350667\n",
      "pattern1 0 0 1 0.897208\n",
      "pattern2 0 1 1 0.999711\n",
      "pattern3 1 0 -1 -0.88296\n",
      "pattern4 1 1 1 0.917743\n",
      " modified Weights  [-2.84675476  2.96356822] 1.4577136824350667\n",
      " Training with pattern  4  weights  [-2.84412545  2.9635682 ] 1.4583429814892555   weights  [-2.84545717  2.96486581]  bias  1.4590112719772643\n",
      "pattern1 0 0 1 0.89746\n",
      "pattern2 0 1 1 0.999713\n",
      "pattern3 1 0 -1 -0.882386\n",
      "pattern4 1 1 1 0.918355\n",
      " modified Weights  [-2.84545717  2.96486581] 1.4590112719772643\n",
      "+++++++++++Epoch  427  cost=  0.031013332751980413\n",
      " Training with pattern  1  weights  [-2.84545717  2.96486581] 1.4590112719772643   weights  [-2.84545717  2.96486581]  bias  1.4610063320767892\n",
      "pattern1 0 0 1 0.897848\n",
      "pattern2 0 1 1 0.999714\n",
      "pattern3 1 0 -1 -0.881944\n",
      "pattern4 1 1 1 0.918667\n",
      " modified Weights  [-2.84545717  2.96486581] 1.4610063320767892\n",
      " Training with pattern  2  weights  [-2.84545717  2.96486581] 1.4590112719772643   weights  [-2.84545717  2.96486583]  bias  1.4610063484591362\n",
      "pattern1 0 0 1 0.897848\n",
      "pattern2 0 1 1 0.999714\n",
      "pattern3 1 0 -1 -0.881944\n",
      "pattern4 1 1 1 0.918667\n",
      " modified Weights  [-2.84545717  2.96486583] 1.4610063484591362\n",
      " Training with pattern  3  weights  [-2.84545717  2.96486581] 1.4590112719772643   weights  [-2.84808007  2.96486583]  bias  1.4583834426459612\n",
      "pattern1 0 0 1 0.897338\n",
      "pattern2 0 1 1 0.999712\n",
      "pattern3 1 0 -1 -0.883104\n",
      "pattern4 1 1 1 0.917844\n",
      " modified Weights  [-2.84808007  2.96486583] 1.4583834426459612\n",
      " Training with pattern  4  weights  [-2.84545717  2.96486581] 1.4590112719772643   weights  [-2.84678561  2.96616029]  bias  1.459677908947126\n",
      "pattern1 0 0 1 0.89759\n",
      "pattern2 0 1 1 0.999714\n",
      "pattern3 1 0 -1 -0.882533\n",
      "pattern4 1 1 1 0.918454\n",
      " modified Weights  [-2.84678561  2.96616029] 1.459677908947126\n",
      "+++++++++++Epoch  428  cost=  0.030936179729424543\n",
      " Training with pattern  1  weights  [-2.84678561  2.96616029] 1.459677908947126   weights  [-2.84678561  2.96616029]  bias  1.4616680640314235\n",
      "pattern1 0 0 1 0.897976\n",
      "pattern2 0 1 1 0.999715\n",
      "pattern3 1 0 -1 -0.882092\n",
      "pattern4 1 1 1 0.918765\n",
      " modified Weights  [-2.84678561  2.96616029] 1.4616680640314235\n",
      " Training with pattern  2  weights  [-2.84678561  2.96616029] 1.459677908947126   weights  [-2.84678561  2.96616031]  bias  1.4616680802861084\n",
      "pattern1 0 0 1 0.897976\n",
      "pattern2 0 1 1 0.999715\n",
      "pattern3 1 0 -1 -0.882092\n",
      "pattern4 1 1 1 0.918765\n",
      " modified Weights  [-2.84678561  2.96616031] 1.4616680802861084\n",
      " Training with pattern  3  weights  [-2.84678561  2.96616029] 1.459677908947126   weights  [-2.84940215  2.96616031]  bias  1.4590515426264732\n",
      "pattern1 0 0 1 0.897468\n",
      "pattern2 0 1 1 0.999713\n",
      "pattern3 1 0 -1 -0.883248\n",
      "pattern4 1 1 1 0.917945\n",
      " modified Weights  [-2.84940215  2.96616031] 1.4590515426264732\n",
      " Training with pattern  4  weights  [-2.84678561  2.96616029] 1.459677908947126   weights  [-2.84811079  2.96745167]  bias  1.4603429004113135\n",
      "pattern1 0 0 1 0.897719\n",
      "pattern2 0 1 1 0.999715\n",
      "pattern3 1 0 -1 -0.882679\n",
      "pattern4 1 1 1 0.918552\n",
      " modified Weights  [-2.84811079  2.96745167] 1.4603429004113135\n",
      "+++++++++++Epoch  429  cost=  0.03085940041865228\n",
      " Training with pattern  1  weights  [-2.84811079  2.96745167] 1.4603429004113135   weights  [-2.84811079  2.96745167]  bias  1.4623281740900973\n",
      "pattern1 0 0 1 0.898104\n",
      "pattern2 0 1 1 0.999716\n",
      "pattern3 1 0 -1 -0.88224\n",
      "pattern4 1 1 1 0.918862\n",
      " modified Weights  [-2.84811079  2.96745167] 1.4623281740900973\n",
      " Training with pattern  2  weights  [-2.84811079  2.96745167] 1.4603429004113135   weights  [-2.84811079  2.96745168]  bias  1.46232819021842\n",
      "pattern1 0 0 1 0.898104\n",
      "pattern2 0 1 1 0.999716\n",
      "pattern3 1 0 -1 -0.88224\n",
      "pattern4 1 1 1 0.918862\n",
      " modified Weights  [-2.84811079  2.96745168] 1.46232819021842\n",
      " Training with pattern  3  weights  [-2.84811079  2.96745167] 1.4603429004113135   weights  [-2.85072099  2.96745168]  bias  1.4597179904344149\n",
      "pattern1 0 0 1 0.897598\n",
      "pattern2 0 1 1 0.999715\n",
      "pattern3 1 0 -1 -0.883391\n",
      "pattern4 1 1 1 0.918045\n",
      " modified Weights  [-2.85072099  2.96745168] 1.4597179904344149\n",
      " Training with pattern  4  weights  [-2.84811079  2.96745167] 1.4603429004113135   weights  [-2.84943272  2.96873995]  bias  1.461006254324746\n",
      "pattern1 0 0 1 0.897848\n",
      "pattern2 0 1 1 0.999716\n",
      "pattern3 1 0 -1 -0.882824\n",
      "pattern4 1 1 1 0.918651\n",
      " modified Weights  [-2.84943272  2.96873995] 1.461006254324746\n",
      "+++++++++++Epoch  430  cost=  0.030782992143854968\n",
      " Training with pattern  1  weights  [-2.84943272  2.96873995] 1.461006254324746   weights  [-2.84943272  2.96873995]  bias  1.462986670039298\n",
      "pattern1 0 0 1 0.898231\n",
      "pattern2 0 1 1 0.999717\n",
      "pattern3 1 0 -1 -0.882387\n",
      "pattern4 1 1 1 0.918959\n",
      " modified Weights  [-2.84943272  2.96873995] 1.462986670039298\n",
      " Training with pattern  2  weights  [-2.84943272  2.96873995] 1.461006254324746   weights  [-2.84943272  2.96873996]  bias  1.462986686042542\n",
      "pattern1 0 0 1 0.898231\n",
      "pattern2 0 1 1 0.999717\n",
      "pattern3 1 0 -1 -0.882387\n",
      "pattern4 1 1 1 0.918959\n",
      " modified Weights  [-2.84943272  2.96873996] 1.462986686042542\n",
      " Training with pattern  3  weights  [-2.84943272  2.96873995] 1.461006254324746   weights  [-2.85203662  2.96873996]  bias  1.4603827940696403\n",
      "pattern1 0 0 1 0.897727\n",
      "pattern2 0 1 1 0.999716\n",
      "pattern3 1 0 -1 -0.883534\n",
      "pattern4 1 1 1 0.918146\n",
      " modified Weights  [-2.85203662  2.96873996] 1.4603827940696403\n",
      " Training with pattern  4  weights  [-2.84943272  2.96873995] 1.461006254324746   weights  [-2.85075143  2.97002515]  bias  1.4616679785853355\n",
      "pattern1 0 0 1 0.897976\n",
      "pattern2 0 1 1 0.999717\n",
      "pattern3 1 0 -1 -0.882969\n",
      "pattern4 1 1 1 0.918749\n",
      " modified Weights  [-2.85075143  2.97002515] 1.4616679785853355\n",
      "+++++++++++Epoch  431  cost=  0.030706952254513045\n",
      " *********Epoch  430 Error  0.030706952254513045\n",
      " Training with pattern  1  weights  [-2.85075143  2.97002515] 1.4616679785853355   weights  [-2.85075143  2.97002515]  bias  1.4636435596100954\n",
      "pattern1 0 0 1 0.898358\n",
      "pattern2 0 1 1 0.999718\n",
      "pattern3 1 0 -1 -0.882533\n",
      "pattern4 1 1 1 0.919056\n",
      " modified Weights  [-2.85075143  2.97002515] 1.4636435596100954\n",
      " Training with pattern  2  weights  [-2.85075143  2.97002515] 1.4616679785853355   weights  [-2.85075143  2.97002516]  bias  1.4636435754895283\n",
      "pattern1 0 0 1 0.898358\n",
      "pattern2 0 1 1 0.999718\n",
      "pattern3 1 0 -1 -0.882533\n",
      "pattern4 1 1 1 0.919056\n",
      " modified Weights  [-2.85075143  2.97002516] 1.4636435754895283\n",
      " Training with pattern  3  weights  [-2.85075143  2.97002515] 1.4616679785853355   weights  [-2.85334904  2.97002516]  bias  1.4610459614745979\n",
      "pattern1 0 0 1 0.897856\n",
      "pattern2 0 1 1 0.999717\n",
      "pattern3 1 0 -1 -0.883677\n",
      "pattern4 1 1 1 0.918245\n",
      " modified Weights  [-2.85334904  2.97002516] 1.4610459614745979\n",
      " Training with pattern  4  weights  [-2.85075143  2.97002515] 1.4616679785853355   weights  [-2.85206693  2.97130728]  bias  1.4623280810345272\n",
      "pattern1 0 0 1 0.898104\n",
      "pattern2 0 1 1 0.999718\n",
      "pattern3 1 0 -1 -0.883113\n",
      "pattern4 1 1 1 0.918846\n",
      " modified Weights  [-2.85206693  2.97130728] 1.4623280810345272\n",
      "+++++++++++Epoch  432  cost=  0.030631278125099814\n",
      " Training with pattern  1  weights  [-2.85206693  2.97130728] 1.4623280810345272   weights  [-2.85206693  2.97130728]  bias  1.4642988504786616\n",
      "pattern1 0 0 1 0.898484\n",
      "pattern2 0 1 1 0.999719\n",
      "pattern3 1 0 -1 -0.882679\n",
      "pattern4 1 1 1 0.919153\n",
      " modified Weights  [-2.85206693  2.97130728] 1.4642988504786616\n",
      " Training with pattern  2  weights  [-2.85206693  2.97130728] 1.4623280810345272   weights  [-2.85206693  2.9713073 ]  bias  1.4642988662355347\n",
      "pattern1 0 0 1 0.898484\n",
      "pattern2 0 1 1 0.999719\n",
      "pattern3 1 0 -1 -0.882679\n",
      "pattern4 1 1 1 0.919153\n",
      " modified Weights  [-2.85206693  2.9713073 ] 1.4642988662355347\n",
      " Training with pattern  3  weights  [-2.85206693  2.97130728] 1.4623280810345272   weights  [-2.85465829  2.9713073 ]  bias  1.4617075005348725\n",
      "pattern1 0 0 1 0.897984\n",
      "pattern2 0 1 1 0.999718\n",
      "pattern3 1 0 -1 -0.883818\n",
      "pattern4 1 1 1 0.918345\n",
      " modified Weights  [-2.85465829  2.9713073 ] 1.4617075005348725\n",
      " Training with pattern  4  weights  [-2.85206693  2.97130728] 1.4623280810345272   weights  [-2.85337922  2.97258637]  bias  1.462986569457832\n",
      "pattern1 0 0 1 0.898231\n",
      "pattern2 0 1 1 0.999719\n",
      "pattern3 1 0 -1 -0.883257\n",
      "pattern4 1 1 1 0.918944\n",
      " modified Weights  [-2.85337922  2.97258637] 1.462986569457832\n",
      "+++++++++++Epoch  433  cost=  0.030555967154789115\n",
      " Training with pattern  1  weights  [-2.85337922  2.97258637] 1.462986569457832   weights  [-2.85337922  2.97258637]  bias  1.4649525502667862\n",
      "pattern1 0 0 1 0.89861\n",
      "pattern2 0 1 1 0.99972\n",
      "pattern3 1 0 -1 -0.882824\n",
      "pattern4 1 1 1 0.919249\n",
      " modified Weights  [-2.85337922  2.97258637] 1.4649525502667862\n",
      " Training with pattern  2  weights  [-2.85337922  2.97258637] 1.462986569457832   weights  [-2.85337922  2.97258638]  bias  1.464952565902336\n",
      "pattern1 0 0 1 0.89861\n",
      "pattern2 0 1 1 0.99972\n",
      "pattern3 1 0 -1 -0.882824\n",
      "pattern4 1 1 1 0.919249\n",
      " modified Weights  [-2.85337922  2.97258638] 1.464952565902336\n",
      " Training with pattern  3  weights  [-2.85337922  2.97258637] 1.462986569457832   weights  [-2.85596437  2.97258638]  bias  1.462367419079726\n",
      "pattern1 0 0 1 0.898111\n",
      "pattern2 0 1 1 0.999719\n",
      "pattern3 1 0 -1 -0.88396\n",
      "pattern4 1 1 1 0.918444\n",
      " modified Weights  [-2.85596437  2.97258638] 1.462367419079726\n",
      " Training with pattern  4  weights  [-2.85337922  2.97258637] 1.462986569457832   weights  [-2.85468834  2.97386242]  bias  1.463643451585356\n",
      "pattern1 0 0 1 0.898358\n",
      "pattern2 0 1 1 0.99972\n",
      "pattern3 1 0 -1 -0.883401\n",
      "pattern4 1 1 1 0.919041\n",
      " modified Weights  [-2.85468834  2.97386242] 1.463643451585356\n",
      "+++++++++++Epoch  434  cost=  0.030481016767167395\n",
      " Training with pattern  1  weights  [-2.85468834  2.97386242] 1.463643451585356   weights  [-2.85468834  2.97386242]  bias  1.4656046665423883\n",
      "pattern1 0 0 1 0.898736\n",
      "pattern2 0 1 1 0.999721\n",
      "pattern3 1 0 -1 -0.882969\n",
      "pattern4 1 1 1 0.919345\n",
      " modified Weights  [-2.85468834  2.97386242] 1.4656046665423883\n",
      " Training with pattern  2  weights  [-2.85468834  2.97386242] 1.463643451585356   weights  [-2.85468834  2.97386243]  bias  1.4656046820578352\n",
      "pattern1 0 0 1 0.898736\n",
      "pattern2 0 1 1 0.999721\n",
      "pattern3 1 0 -1 -0.882969\n",
      "pattern4 1 1 1 0.919345\n",
      " modified Weights  [-2.85468834  2.97386243] 1.4656046820578352\n",
      " Training with pattern  3  weights  [-2.85468834  2.97386242] 1.463643451585356   weights  [-2.85726729  2.97386243]  bias  1.4630257248826282\n",
      "pattern1 0 0 1 0.898239\n",
      "pattern2 0 1 1 0.99972\n",
      "pattern3 1 0 -1 -0.884101\n",
      "pattern4 1 1 1 0.918543\n",
      " modified Weights  [-2.85726729  2.97386243] 1.4630257248826282\n",
      " Training with pattern  4  weights  [-2.85468834  2.97386242] 1.463643451585356   weights  [-2.85599428  2.97513544]  bias  1.464298735092321\n",
      "pattern1 0 0 1 0.898484\n",
      "pattern2 0 1 1 0.999721\n",
      "pattern3 1 0 -1 -0.883543\n",
      "pattern4 1 1 1 0.919137\n",
      " modified Weights  [-2.85599428  2.97513544] 1.464298735092321\n",
      "+++++++++++Epoch  435  cost=  0.0304064244099488\n",
      " Training with pattern  1  weights  [-2.85599428  2.97513544] 1.464298735092321   weights  [-2.85599428  2.97513544]  bias  1.4662552068200172\n",
      "pattern1 0 0 1 0.898861\n",
      "pattern2 0 1 1 0.999723\n",
      "pattern3 1 0 -1 -0.883113\n",
      "pattern4 1 1 1 0.91944\n",
      " modified Weights  [-2.85599428  2.97513544] 1.4662552068200172\n",
      " Training with pattern  2  weights  [-2.85599428  2.97513544] 1.464298735092321   weights  [-2.85599428  2.97513546]  bias  1.466255222216567\n",
      "pattern1 0 0 1 0.898861\n",
      "pattern2 0 1 1 0.999723\n",
      "pattern3 1 0 -1 -0.883113\n",
      "pattern4 1 1 1 0.91944\n",
      " modified Weights  [-2.85599428  2.97513546] 1.466255222216567\n",
      " Training with pattern  3  weights  [-2.85599428  2.97513544] 1.464298735092321   weights  [-2.85856708  2.97513546]  bias  1.4636824256617822\n",
      "pattern1 0 0 1 0.898365\n",
      "pattern2 0 1 1 0.999721\n",
      "pattern3 1 0 -1 -0.884241\n",
      "pattern4 1 1 1 0.918641\n",
      " modified Weights  [-2.85856708  2.97513546] 1.4636824256617822\n",
      " Training with pattern  4  weights  [-2.85599428  2.97513544] 1.464298735092321   weights  [-2.85729708  2.97640546]  bias  1.4649524275995789\n",
      "pattern1 0 0 1 0.89861\n",
      "pattern2 0 1 1 0.999723\n",
      "pattern3 1 0 -1 -0.883686\n",
      "pattern4 1 1 1 0.919234\n",
      " modified Weights  [-2.85729708  2.97640546] 1.4649524275995789\n",
      "+++++++++++Epoch  436  cost=  0.030332187554695716\n",
      " Training with pattern  1  weights  [-2.85729708  2.97640546] 1.4649524275995789   weights  [-2.85729708  2.97640546]  bias  1.4669041785613512\n",
      "pattern1 0 0 1 0.898985\n",
      "pattern2 0 1 1 0.999724\n",
      "pattern3 1 0 -1 -0.883257\n",
      "pattern4 1 1 1 0.919536\n",
      " modified Weights  [-2.85729708  2.97640546] 1.4669041785613512\n",
      " Training with pattern  2  weights  [-2.85729708  2.97640546] 1.4649524275995789   weights  [-2.85729708  2.97640547]  bias  1.4669041938401945\n",
      "pattern1 0 0 1 0.898985\n",
      "pattern2 0 1 1 0.999724\n",
      "pattern3 1 0 -1 -0.883257\n",
      "pattern4 1 1 1 0.919536\n",
      " modified Weights  [-2.85729708  2.97640547] 1.4669041938401945\n",
      " Training with pattern  3  weights  [-2.85729708  2.97640546] 1.4649524275995789   weights  [-2.85986374  2.97640547]  bias  1.4643375290806435\n",
      "pattern1 0 0 1 0.898492\n",
      "pattern2 0 1 1 0.999722\n",
      "pattern3 1 0 -1 -0.884381\n",
      "pattern4 1 1 1 0.918739\n",
      " modified Weights  [-2.85986374  2.97640547] 1.4643375290806435\n",
      " Training with pattern  4  weights  [-2.85729708  2.97640546] 1.4649524275995789   weights  [-2.85859674  2.97767248]  bias  1.4656045366741222\n",
      "pattern1 0 0 1 0.898736\n",
      "pattern2 0 1 1 0.999724\n",
      "pattern3 1 0 -1 -0.883827\n",
      "pattern4 1 1 1 0.91933\n",
      " modified Weights  [-2.85859674  2.97767248] 1.4656045366741222\n",
      "+++++++++++Epoch  437  cost=  0.030258303696541634\n",
      " Training with pattern  1  weights  [-2.85859674  2.97767248] 1.4656045366741222   weights  [-2.85859674  2.97767248]  bias  1.4675515891756898\n",
      "pattern1 0 0 1 0.899109\n",
      "pattern2 0 1 1 0.999725\n",
      "pattern3 1 0 -1 -0.883401\n",
      "pattern4 1 1 1 0.919631\n",
      " modified Weights  [-2.85859674  2.97767248] 1.4675515891756898\n",
      " Training with pattern  2  weights  [-2.85859674  2.97767248] 1.4656045366741222   weights  [-2.85859674  2.9776725 ]  bias  1.4675516043380028\n",
      "pattern1 0 0 1 0.899109\n",
      "pattern2 0 1 1 0.999725\n",
      "pattern3 1 0 -1 -0.883401\n",
      "pattern4 1 1 1 0.919631\n",
      " modified Weights  [-2.85859674  2.9776725 ] 1.4675516043380028\n",
      " Training with pattern  3  weights  [-2.85859674  2.97767248] 1.4656045366741222   weights  [-2.8611573  2.9776725]  bias  1.4649910427484345\n",
      "pattern1 0 0 1 0.898618\n",
      "pattern2 0 1 1 0.999723\n",
      "pattern3 1 0 -1 -0.88452\n",
      "pattern4 1 1 1 0.918837\n",
      " modified Weights  [-2.8611573  2.9776725] 1.4649910427484345\n",
      " Training with pattern  4  weights  [-2.85859674  2.97767248] 1.4656045366741222   weights  [-2.85989327  2.97893652]  bias  1.4662550698295866\n",
      "pattern1 0 0 1 0.898861\n",
      "pattern2 0 1 1 0.999725\n",
      "pattern3 1 0 -1 -0.883969\n",
      "pattern4 1 1 1 0.919425\n",
      " modified Weights  [-2.85989327  2.97893652] 1.4662550698295866\n",
      "+++++++++++Epoch  438  cost=  0.03018477035391921\n",
      " Training with pattern  1  weights  [-2.85989327  2.97893652] 1.4662550698295866   weights  [-2.85989327  2.97893652]  bias  1.4681974460204394\n",
      "pattern1 0 0 1 0.899233\n",
      "pattern2 0 1 1 0.999726\n",
      "pattern3 1 0 -1 -0.883543\n",
      "pattern4 1 1 1 0.919725\n",
      " modified Weights  [-2.85989327  2.97893652] 1.4681974460204394\n",
      " Training with pattern  2  weights  [-2.85989327  2.97893652] 1.4662550698295866   weights  [-2.85989327  2.97893654]  bias  1.4681974610673836\n",
      "pattern1 0 0 1 0.899233\n",
      "pattern2 0 1 1 0.999726\n",
      "pattern3 1 0 -1 -0.883543\n",
      "pattern4 1 1 1 0.919725\n",
      " modified Weights  [-2.85989327  2.97893654] 1.4681974610673836\n",
      " Training with pattern  3  weights  [-2.85989327  2.97893652] 1.4662550698295866   weights  [-2.86244776  2.97893654]  bias  1.4656429742206512\n",
      "pattern1 0 0 1 0.898743\n",
      "pattern2 0 1 1 0.999724\n",
      "pattern3 1 0 -1 -0.884659\n",
      "pattern4 1 1 1 0.918934\n",
      " modified Weights  [-2.86244776  2.97893654] 1.4656429742206512\n",
      " Training with pattern  4  weights  [-2.85989327  2.97893652] 1.4662550698295866   weights  [-2.8611867  2.9801976]  bias  1.4669040345267492\n",
      "pattern1 0 0 1 0.898985\n",
      "pattern2 0 1 1 0.999726\n",
      "pattern3 1 0 -1 -0.88411\n",
      "pattern4 1 1 1 0.919521\n",
      " modified Weights  [-2.8611867  2.9801976] 1.4669040345267492\n",
      "+++++++++++Epoch  439  cost=  0.030111585068290966\n",
      " Training with pattern  1  weights  [-2.8611867  2.9801976] 1.4669040345267492   weights  [-2.8611867  2.9801976]  bias  1.4688417564015943\n",
      "pattern1 0 0 1 0.899356\n",
      "pattern2 0 1 1 0.999727\n",
      "pattern3 1 0 -1 -0.883686\n",
      "pattern4 1 1 1 0.919819\n",
      " modified Weights  [-2.8611867  2.9801976] 1.4688417564015943\n",
      " Training with pattern  2  weights  [-2.8611867  2.9801976] 1.4669040345267492   weights  [-2.8611867   2.98019761]  bias  1.4688417713343167\n",
      "pattern1 0 0 1 0.899356\n",
      "pattern2 0 1 1 0.999727\n",
      "pattern3 1 0 -1 -0.883686\n",
      "pattern4 1 1 1 0.919819\n",
      " modified Weights  [-2.8611867   2.98019761] 1.4688417713343167\n",
      " Training with pattern  3  weights  [-2.8611867  2.9801976] 1.4669040345267492   weights  [-2.86373514  2.98019761]  bias  1.466293330999564\n",
      "pattern1 0 0 1 0.898868\n",
      "pattern2 0 1 1 0.999725\n",
      "pattern3 1 0 -1 -0.884797\n",
      "pattern4 1 1 1 0.919031\n",
      " modified Weights  [-2.86373514  2.98019761] 1.466293330999564\n",
      " Training with pattern  4  weights  [-2.8611867  2.9801976] 1.4669040345267492   weights  [-2.86247703  2.98145572]  bias  1.4675514381740193\n",
      "pattern1 0 0 1 0.899109\n",
      "pattern2 0 1 1 0.999727\n",
      "pattern3 1 0 -1 -0.88425\n",
      "pattern4 1 1 1 0.919616\n",
      " modified Weights  [-2.86247703  2.98145572] 1.4675514381740193\n",
      "+++++++++++Epoch  440  cost=  0.030038745403884543\n",
      " Training with pattern  1  weights  [-2.86247703  2.98145572] 1.4675514381740193   weights  [-2.86247703  2.98145572]  bias  1.4694845275742114\n",
      "pattern1 0 0 1 0.899479\n",
      "pattern2 0 1 1 0.999728\n",
      "pattern3 1 0 -1 -0.883828\n",
      "pattern4 1 1 1 0.919913\n",
      " modified Weights  [-2.86247703  2.98145572] 1.4694845275742114\n",
      " Training with pattern  2  weights  [-2.86247703  2.98145572] 1.4675514381740193   weights  [-2.86247703  2.98145574]  bias  1.4694845423938454\n",
      "pattern1 0 0 1 0.899479\n",
      "pattern2 0 1 1 0.999728\n",
      "pattern3 1 0 -1 -0.883828\n",
      "pattern4 1 1 1 0.919913\n",
      " modified Weights  [-2.86247703  2.98145574] 1.4694845423938454\n",
      " Training with pattern  3  weights  [-2.86247703  2.98145572] 1.4675514381740193   weights  [-2.86501945  2.98145574]  bias  1.466942120534715\n",
      "pattern1 0 0 1 0.898993\n",
      "pattern2 0 1 1 0.999726\n",
      "pattern3 1 0 -1 -0.884935\n",
      "pattern4 1 1 1 0.919128\n",
      " modified Weights  [-2.86501945  2.98145574] 1.466942120534715\n",
      " Training with pattern  4  weights  [-2.86247703  2.98145572] 1.4675514381740193   weights  [-2.86376428  2.9827109 ]  bias  1.468197288127925\n",
      "pattern1 0 0 1 0.899233\n",
      "pattern2 0 1 1 0.999728\n",
      "pattern3 1 0 -1 -0.88439\n",
      "pattern4 1 1 1 0.91971\n",
      " modified Weights  [-2.86376428  2.9827109 ] 1.468197288127925\n",
      "+++++++++++Epoch  441  cost=  0.029966248947430926\n",
      " *********Epoch  440 Error  0.029966248947430926\n",
      "Weights converged in  440  epochs with error  0.00045436831762769826\n",
      "[2.8484798115861825, 0.9892881819429511, 0.6386640411622837, 0.4614522230396772, 0.3572167703222871, 0.289471229525318, 0.24228231795343996, 0.20770610980116636, 0.18137792682933992, 0.16071604091027564, 0.14410247159289785, 0.13047499484230868, 0.11910913209101034, 0.1094947609322838, 0.10126285692651421, 0.09414020428405243, 0.08792041093225963, 0.08244479369880185, 0.07758943772594531, 0.0732562308879512, 0.06936652328408807, 0.06585656005997322, 0.0626741367621696, 0.05977611309011746, 0.05712653945894156, 0.054695227712174055, 0.05245664822336688, 0.05038906991073043, 0.04847388316339275, 0.0466950619940981, 0.0450387332326695, 0.04349282878429525, 0.042046802908316146, 0.040691400806846134, 0.03941846801184398, 0.03822079244420833, 0.037091972812663465, 0.0360263083816144, 0.03501870617853524, 0.03406460251415448, 0.033159896311869025, 0.03230089222993319, 0.0314842519431978, 0.030706952254513045, 0.029966248947430926]\n"
     ]
    }
   ],
   "source": [
    "wts=randomize(2)\n",
    "bia = randomize(1)[0]\n",
    "tabulate(wts,bia)\n",
    "costs=[]\n",
    "epochs = 500\n",
    "for t in range(epochs) :\n",
    "    nwts,nb, cost= trainEpoch(wts,bia)\n",
    "    print(\"+++++++++++Epoch \",t+1,\" cost= \",cost)\n",
    "    wts=np.copy(nwts)\n",
    "    bia = nb\n",
    "    if(t%10 == 0) :\n",
    "        print(\" *********Epoch \",t,\"Error \" ,cost)\n",
    "        costs.append(cost)\n",
    "        if cost < .03 :\n",
    "            print(\"Weights converged in \",t,\" epochs with error \",error)\n",
    "            break\n",
    "print(costs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noWBmZn0cCmZm1ud/AKFasxSNFlbIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd4a986e5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(costs)+1), costs, marker='o')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Sum-squared-error')\n",
    "plt.title('Delta rule - Learning rate 0.1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 1.4]\n",
      " [4.9 1.4]\n",
      " [4.7 1.3]\n",
      " [4.6 1.5]\n",
      " [5.  1.4]\n",
      " [5.4 1.7]\n",
      " [4.6 1.4]\n",
      " [5.  1.5]\n",
      " [4.4 1.4]\n",
      " [4.9 1.5]\n",
      " [5.4 1.5]\n",
      " [4.8 1.6]\n",
      " [4.8 1.4]\n",
      " [4.3 1.1]\n",
      " [5.8 1.2]\n",
      " [5.7 1.5]\n",
      " [5.4 1.3]\n",
      " [5.1 1.4]\n",
      " [5.7 1.7]\n",
      " [5.1 1.5]\n",
      " [5.4 1.7]\n",
      " [5.1 1.5]\n",
      " [4.6 1. ]\n",
      " [5.1 1.7]\n",
      " [4.8 1.9]\n",
      " [5.  1.6]\n",
      " [5.  1.6]\n",
      " [5.2 1.5]\n",
      " [5.2 1.4]\n",
      " [4.7 1.6]\n",
      " [4.8 1.6]\n",
      " [5.4 1.5]\n",
      " [5.2 1.5]\n",
      " [5.5 1.4]\n",
      " [4.9 1.5]\n",
      " [5.  1.2]\n",
      " [5.5 1.3]\n",
      " [4.9 1.5]\n",
      " [4.4 1.3]\n",
      " [5.1 1.5]\n",
      " [5.  1.3]\n",
      " [4.5 1.3]\n",
      " [4.4 1.3]\n",
      " [5.  1.6]\n",
      " [5.1 1.9]\n",
      " [4.8 1.4]\n",
      " [5.1 1.6]\n",
      " [4.6 1.4]\n",
      " [5.3 1.5]\n",
      " [5.  1.4]\n",
      " [7.  4.7]\n",
      " [6.4 4.5]\n",
      " [6.9 4.9]\n",
      " [5.5 4. ]\n",
      " [6.5 4.6]\n",
      " [5.7 4.5]\n",
      " [6.3 4.7]\n",
      " [4.9 3.3]\n",
      " [6.6 4.6]\n",
      " [5.2 3.9]\n",
      " [5.  3.5]\n",
      " [5.9 4.2]\n",
      " [6.  4. ]\n",
      " [6.1 4.7]\n",
      " [5.6 3.6]\n",
      " [6.7 4.4]\n",
      " [5.6 4.5]\n",
      " [5.8 4.1]\n",
      " [6.2 4.5]\n",
      " [5.6 3.9]\n",
      " [5.9 4.8]\n",
      " [6.1 4. ]\n",
      " [6.3 4.9]\n",
      " [6.1 4.7]\n",
      " [6.4 4.3]\n",
      " [6.6 4.4]\n",
      " [6.8 4.8]\n",
      " [6.7 5. ]\n",
      " [6.  4.5]\n",
      " [5.7 3.5]\n",
      " [5.5 3.8]\n",
      " [5.5 3.7]\n",
      " [5.8 3.9]\n",
      " [6.  5.1]\n",
      " [5.4 4.5]\n",
      " [6.  4.5]\n",
      " [6.7 4.7]\n",
      " [6.3 4.4]\n",
      " [5.6 4.1]\n",
      " [5.5 4. ]\n",
      " [5.5 4.4]\n",
      " [6.1 4.6]\n",
      " [5.8 4. ]\n",
      " [5.  3.3]\n",
      " [5.6 4.2]\n",
      " [5.7 4.2]\n",
      " [5.7 4.2]\n",
      " [6.2 4.3]\n",
      " [5.1 3. ]\n",
      " [5.7 4.1]] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)\n",
    "\n",
    "# setosa and versicolor\n",
    "y = df.iloc[0:100, 4].values\n",
    "y = np.where(y == 'Iris-setosa', -1, 1)\n",
    "\n",
    "# sepal length and petal length\n",
    "X = df.iloc[0:100, [0,2]].values\n",
    "print(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.10.0-py2.py3-none-any.whl (1.3MB)\n",
      "\u001b[K    100% || 1.3MB 433kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.17.1 in /home/srm/anaconda3/lib/python3.5/site-packages (from mlxtend)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /home/srm/.local/lib/python3.5/site-packages (from mlxtend)\n",
      "Requirement already satisfied: scipy>=0.17 in /home/srm/.local/lib/python3.5/site-packages (from mlxtend)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /home/srm/anaconda3/lib/python3.5/site-packages (from mlxtend)\n",
      "Requirement already satisfied: matplotlib>=1.5.1 in /home/srm/.local/lib/python3.5/site-packages (from mlxtend)\n",
      "Requirement already satisfied: setuptools in /home/srm/.local/lib/python3.5/site-packages (from mlxtend)\n",
      "Requirement already satisfied: python-dateutil>=2 in /home/srm/.local/lib/python3.5/site-packages (from pandas>=0.17.1->mlxtend)\n",
      "Requirement already satisfied: pytz>=2011k in /home/srm/.local/lib/python3.5/site-packages (from pandas>=0.17.1->mlxtend)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/srm/.local/lib/python3.5/site-packages (from matplotlib>=1.5.1->mlxtend)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/srm/.local/lib/python3.5/site-packages (from matplotlib>=1.5.1->mlxtend)\n",
      "Requirement already satisfied: six>=1.10 in /home/srm/.local/lib/python3.5/site-packages (from matplotlib>=1.5.1->mlxtend)\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class AdalineGD(object):\n",
    "\n",
    "    def __init__(self, eta=0.01, epochs=50):\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def train(self, X, y):\n",
    "\n",
    "        self.w_ = np.zeros(1 + X.shape[1])\n",
    "        self.cost_ = []\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            output = self.net_input(X)\n",
    "            errors = (y - output)\n",
    "            self.w_[1:] += self.eta * X.T.dot(errors)\n",
    "            self.w_[0] += self.eta * errors.sum()\n",
    "            cost = (errors**2).sum() / 2.0\n",
    "            self.cost_.append(cost)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def activation(self, X):\n",
    "        return self.net_input(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.where(self.activation(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niUBEJM4pEYiIxLn/B4g74XPcf6AQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6ba4ce1710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRBKcEoGISIL7f0WNElDH7bbEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6ba4d045f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ada = AdalineGD(epochs=10, eta=0.01).train(X, y)\n",
    "plt.plot(range(1, len(ada.cost_)+1), np.log10(ada.cost_), marker='o')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('log(Sum-squared-error)')\n",
    "plt.title('Adaline - Learning rate 0.01')\n",
    "plt.show()\n",
    "\n",
    "ada = AdalineGD(epochs=10, eta=0.0001).train(X, y)\n",
    "plt.plot(range(1, len(ada.cost_)+1), ada.cost_, marker='o')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Sum-squared-error')\n",
    "plt.title('Adaline - Learning rate 0.0001')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
